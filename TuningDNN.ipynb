{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.feature_selection import SelectFromModel, RFE\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler,scale, MaxAbsScaler # MaxAbs is process sparse data\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "from torch import nn, optim\n",
    "import torch.nn.init as init\n",
    "import torch.utils.data as Data\n",
    "import math\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.multiprocessing as mp\n",
    "# add tuning \n",
    "from skorch import NeuralNetRegressor\n",
    "from skorch.callbacks import EpochScoring\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp.set_start_method('spawn')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### default hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "use_gpu = True\n",
    "y_scale = True\n",
    "lr = 0.001\n",
    "weight_decay = 0.0005\n",
    "\n",
    "# Batch size and learning rate is hyperparameters in deep learning\n",
    "# suggest batch_size is reduced, lr is also reduced which will reduce concussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## using CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## reading file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv('./dataset-0510/train.csv')\n",
    "X_test = pd.read_csv('./dataset-0510/test.csv')\n",
    "\n",
    "columns = X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = X['total_price']\n",
    "X = X.drop(columns=['building_id', 'total_price'], axis=1)\n",
    "X_test = X_test.drop(columns=['building_id'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(233, 256)\n",
    "        self.bn1 = nn.BatchNorm1d(num_features=256)\n",
    "        \n",
    "        self.fc2 = nn.Linear(256, 512)\n",
    "        self.bn2 = nn.BatchNorm1d(num_features=512)\n",
    "        \n",
    "        self.fc3 = nn.Linear(512, 512)\n",
    "        self.bn3 = nn.BatchNorm1d(num_features=512)\n",
    "        \n",
    "        self.fc4 = nn.Linear(512, 256)\n",
    "        self.bn4 = nn.BatchNorm1d(num_features=256)\n",
    "        \n",
    "        self.fc5 = nn.Linear(256, 128)\n",
    "        self.bn5 = nn.BatchNorm1d(num_features=128)\n",
    "        \n",
    "        self.fc6 = nn.Linear(128, 64)\n",
    "        self.bn6 = nn.BatchNorm1d(num_features=64)\n",
    "        \n",
    "        self.fc7 = nn.Linear(64, 32)\n",
    "        self.bn7 = nn.BatchNorm1d(num_features=32)\n",
    "        \n",
    "        self.fc8 = nn.Linear(32, 1)\n",
    "        \n",
    "        \n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        #x = x.unsqueeze(0)\n",
    "        \n",
    "        x = F.relu(self.bn1(self.fc1(x)))\n",
    "        x = F.relu(self.bn2(self.fc2(x)))\n",
    "        x = F.relu(self.bn3(self.fc3(x)))\n",
    "        x = F.relu(self.bn4(self.fc4(x)))\n",
    "        x = F.relu(self.bn5(self.fc5(x)))\n",
    "        x = F.relu(self.bn6(self.fc6(x)))\n",
    "        x = F.relu(self.bn7(self.fc7(x)))\n",
    "        x = torch.tanh(self.fc8(x))\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pipline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/islab/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:66: DeprecationWarning: Class Imputer is deprecated; Imputer was deprecated in version 0.20 and will be removed in 0.22. Import impute.SimpleImputer from sklearn instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# step1. Imputation transformer for completing missing values.\n",
    "step1 = ('Imputer', Imputer())\n",
    "# step2. MinMaxScaler\n",
    "step2 = ('MinMaxScaler', MinMaxScaler())\n",
    "# step3. feature selection\n",
    "#step3 = ('FeatureSelection', SelectFromModel(RandomForestRegressor()))\n",
    "step3 = ('FeatureSelection', VarianceThreshold())\n",
    "\n",
    "pipeline = Pipeline(steps=[step1, step2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X = pipeline.fit_transform(X)\n",
    "\n",
    "X_test = pipeline.transform(X_test)\n",
    "\n",
    "y_scaler = MinMaxScaler(feature_range=[0, 5])\n",
    "y = y_scaler.fit_transform(y.values.reshape(-1, 1))\n",
    "# MaxAbs 0.00012\n",
    "# MinMax 0.0008"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 233)\n",
      "(10000, 233)\n",
      "(60000, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.00041416],\n",
       "       [0.00304174],\n",
       "       [0.00918302],\n",
       "       ...,\n",
       "       [0.01138869],\n",
       "       [0.01754978],\n",
       "       [0.00814078]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(X.shape)\n",
    "\n",
    "print(X_test.shape)\n",
    "\n",
    "print(y.shape)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.from_numpy(X).float().to(device)\n",
    "X_test = torch.from_numpy(X_test).float().to(device)\n",
    "y = torch.from_numpy(y).float().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SqrtMSELoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "    def forward(self, x, y):\n",
    "        return torch.sqrt(torch.mean(torch.pow((x - y), 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    neg_mean_squared_error    train_loss    valid_loss     dur\n",
      "-------  ------------------------  ------------  ------------  ------\n",
      "      1                   \u001b[36m-0.0106\u001b[0m        \u001b[32m0.1348\u001b[0m        \u001b[35m0.0947\u001b[0m  1.6053\n",
      "      2                   \u001b[36m-0.0070\u001b[0m        \u001b[32m0.0806\u001b[0m        \u001b[35m0.0718\u001b[0m  1.4657\n",
      "      3                   \u001b[36m-0.0055\u001b[0m        \u001b[32m0.0633\u001b[0m        \u001b[35m0.0591\u001b[0m  1.4650\n",
      "      4                   \u001b[36m-0.0049\u001b[0m        \u001b[32m0.0536\u001b[0m        \u001b[35m0.0521\u001b[0m  1.4733\n",
      "      5                   \u001b[36m-0.0045\u001b[0m        \u001b[32m0.0481\u001b[0m        \u001b[35m0.0472\u001b[0m  1.4742\n",
      "      6                   \u001b[36m-0.0042\u001b[0m        \u001b[32m0.0439\u001b[0m        \u001b[35m0.0442\u001b[0m  1.4756\n",
      "      7                   \u001b[36m-0.0041\u001b[0m        \u001b[32m0.0411\u001b[0m        \u001b[35m0.0417\u001b[0m  1.4750\n",
      "      8                   \u001b[36m-0.0040\u001b[0m        \u001b[32m0.0393\u001b[0m        \u001b[35m0.0400\u001b[0m  1.4738\n",
      "      9                   \u001b[36m-0.0039\u001b[0m        \u001b[32m0.0377\u001b[0m        \u001b[35m0.0387\u001b[0m  1.4770\n",
      "     10                   \u001b[36m-0.0039\u001b[0m        \u001b[32m0.0369\u001b[0m        \u001b[35m0.0378\u001b[0m  1.4756\n",
      "     11                   \u001b[36m-0.0038\u001b[0m        \u001b[32m0.0357\u001b[0m        \u001b[35m0.0369\u001b[0m  1.4762\n",
      "     12                   \u001b[36m-0.0038\u001b[0m        \u001b[32m0.0351\u001b[0m        \u001b[35m0.0362\u001b[0m  1.4769\n",
      "     13                   \u001b[36m-0.0038\u001b[0m        \u001b[32m0.0345\u001b[0m        \u001b[35m0.0360\u001b[0m  1.4761\n",
      "     14                   \u001b[36m-0.0037\u001b[0m        \u001b[32m0.0338\u001b[0m        \u001b[35m0.0355\u001b[0m  1.4685\n",
      "     15                   \u001b[36m-0.0037\u001b[0m        \u001b[32m0.0337\u001b[0m        \u001b[35m0.0352\u001b[0m  1.4755\n",
      "     16                   \u001b[36m-0.0037\u001b[0m        \u001b[32m0.0334\u001b[0m        \u001b[35m0.0349\u001b[0m  1.4742\n",
      "     17                   \u001b[36m-0.0037\u001b[0m        \u001b[32m0.0330\u001b[0m        \u001b[35m0.0345\u001b[0m  1.4756\n",
      "     18                   -0.0037        \u001b[32m0.0327\u001b[0m        \u001b[35m0.0344\u001b[0m  1.4761\n",
      "     19                   \u001b[36m-0.0037\u001b[0m        \u001b[32m0.0325\u001b[0m        \u001b[35m0.0342\u001b[0m  1.4761\n",
      "     20                   \u001b[36m-0.0037\u001b[0m        \u001b[32m0.0322\u001b[0m        \u001b[35m0.0340\u001b[0m  1.4745\n",
      "     21                   \u001b[36m-0.0037\u001b[0m        \u001b[32m0.0322\u001b[0m        \u001b[35m0.0338\u001b[0m  1.4755\n",
      "     22                   \u001b[36m-0.0037\u001b[0m        0.0322        \u001b[35m0.0337\u001b[0m  1.4762\n",
      "     23                   \u001b[36m-0.0037\u001b[0m        \u001b[32m0.0319\u001b[0m        \u001b[35m0.0336\u001b[0m  1.4761\n",
      "     24                   \u001b[36m-0.0036\u001b[0m        0.0319        \u001b[35m0.0334\u001b[0m  1.4747\n",
      "     25                   \u001b[36m-0.0036\u001b[0m        0.0321        \u001b[35m0.0334\u001b[0m  1.4737\n",
      "     26                   -0.0036        \u001b[32m0.0316\u001b[0m        \u001b[35m0.0332\u001b[0m  1.4758\n",
      "     27                   -0.0036        \u001b[32m0.0316\u001b[0m        \u001b[35m0.0331\u001b[0m  1.4628\n",
      "     28                   \u001b[36m-0.0036\u001b[0m        \u001b[32m0.0313\u001b[0m        \u001b[35m0.0330\u001b[0m  1.4759\n",
      "     29                   \u001b[36m-0.0036\u001b[0m        \u001b[32m0.0310\u001b[0m        \u001b[35m0.0330\u001b[0m  1.4749\n",
      "     30                   \u001b[36m-0.0036\u001b[0m        0.0310        \u001b[35m0.0329\u001b[0m  1.4746\n",
      "     31                   -0.0036        \u001b[32m0.0308\u001b[0m        \u001b[35m0.0328\u001b[0m  1.4752\n",
      "     32                   -0.0036        0.0309        0.0328  1.4756\n",
      "     33                   -0.0036        \u001b[32m0.0305\u001b[0m        \u001b[35m0.0327\u001b[0m  1.4751\n",
      "     34                   \u001b[36m-0.0036\u001b[0m        0.0310        \u001b[35m0.0326\u001b[0m  1.4751\n",
      "     35                   \u001b[36m-0.0036\u001b[0m        0.0306        \u001b[35m0.0325\u001b[0m  1.4755\n",
      "     36                   -0.0036        \u001b[32m0.0304\u001b[0m        \u001b[35m0.0325\u001b[0m  1.4758\n",
      "     37                   -0.0036        \u001b[32m0.0303\u001b[0m        \u001b[35m0.0324\u001b[0m  1.4754\n",
      "     38                   -0.0036        0.0305        0.0325  1.4755\n",
      "     39                   -0.0036        0.0307        \u001b[35m0.0324\u001b[0m  1.4756\n",
      "     40                   \u001b[36m-0.0036\u001b[0m        \u001b[32m0.0302\u001b[0m        \u001b[35m0.0323\u001b[0m  1.4688\n",
      "     41                   \u001b[36m-0.0036\u001b[0m        \u001b[32m0.0301\u001b[0m        \u001b[35m0.0322\u001b[0m  1.4781\n",
      "     42                   \u001b[36m-0.0036\u001b[0m        \u001b[32m0.0297\u001b[0m        \u001b[35m0.0322\u001b[0m  1.4762\n",
      "     43                   \u001b[36m-0.0036\u001b[0m        0.0301        \u001b[35m0.0321\u001b[0m  1.4754\n",
      "     44                   -0.0036        0.0300        \u001b[35m0.0320\u001b[0m  1.4763\n",
      "     45                   -0.0036        0.0301        0.0320  1.4749\n",
      "     46                   -0.0036        \u001b[32m0.0293\u001b[0m        \u001b[35m0.0320\u001b[0m  1.4726\n",
      "     47                   \u001b[36m-0.0036\u001b[0m        0.0299        \u001b[35m0.0319\u001b[0m  1.4712\n",
      "     48                   \u001b[36m-0.0036\u001b[0m        0.0299        \u001b[35m0.0319\u001b[0m  1.4712\n",
      "     49                   \u001b[36m-0.0036\u001b[0m        0.0301        \u001b[35m0.0319\u001b[0m  1.4694\n",
      "     50                   \u001b[36m-0.0036\u001b[0m        0.0296        \u001b[35m0.0318\u001b[0m  1.4706\n",
      "     51                   \u001b[36m-0.0036\u001b[0m        0.0297        0.0319  1.4726\n",
      "     52                   -0.0036        0.0295        \u001b[35m0.0317\u001b[0m  1.4676\n",
      "     53                   -0.0036        0.0293        \u001b[35m0.0317\u001b[0m  1.4655\n",
      "     54                   -0.0036        0.0294        0.0317  1.4634\n",
      "     55                   \u001b[36m-0.0035\u001b[0m        0.0294        \u001b[35m0.0317\u001b[0m  1.4693\n",
      "     56                   \u001b[36m-0.0035\u001b[0m        0.0297        \u001b[35m0.0315\u001b[0m  1.4714\n",
      "     57                   -0.0036        0.0296        0.0317  1.4713\n",
      "     58                   \u001b[36m-0.0035\u001b[0m        \u001b[32m0.0292\u001b[0m        \u001b[35m0.0315\u001b[0m  1.4693\n",
      "     59                   -0.0035        0.0294        0.0315  1.4672\n",
      "     60                   \u001b[36m-0.0035\u001b[0m        0.0296        \u001b[35m0.0314\u001b[0m  1.4681\n",
      "     61                   \u001b[36m-0.0035\u001b[0m        0.0296        \u001b[35m0.0314\u001b[0m  1.4690\n",
      "     62                   -0.0035        \u001b[32m0.0291\u001b[0m        0.0314  1.4711\n",
      "     63                   -0.0035        0.0293        0.0314  1.4735\n",
      "     64                   -0.0035        0.0293        \u001b[35m0.0313\u001b[0m  1.4793\n",
      "     65                   -0.0035        \u001b[32m0.0290\u001b[0m        0.0314  1.4711\n",
      "     66                   \u001b[36m-0.0035\u001b[0m        0.0291        \u001b[35m0.0312\u001b[0m  1.4728\n",
      "     67                   -0.0035        \u001b[32m0.0288\u001b[0m        0.0312  1.4729\n",
      "     68                   -0.0035        0.0289        \u001b[35m0.0312\u001b[0m  1.4733\n",
      "     69                   -0.0035        0.0291        0.0313  1.4720\n",
      "     70                   -0.0035        0.0289        \u001b[35m0.0311\u001b[0m  1.4703\n",
      "     71                   -0.0035        0.0288        \u001b[35m0.0311\u001b[0m  1.4692\n",
      "     72                   \u001b[36m-0.0035\u001b[0m        \u001b[32m0.0286\u001b[0m        \u001b[35m0.0310\u001b[0m  1.4716\n",
      "     73                   -0.0035        0.0287        \u001b[35m0.0310\u001b[0m  1.4713\n",
      "     74                   -0.0035        \u001b[32m0.0282\u001b[0m        0.0311  1.4713\n",
      "     75                   \u001b[36m-0.0035\u001b[0m        0.0288        \u001b[35m0.0310\u001b[0m  1.4727\n",
      "     76                   \u001b[36m-0.0035\u001b[0m        0.0287        0.0310  1.4644\n",
      "     77                   -0.0035        \u001b[32m0.0281\u001b[0m        \u001b[35m0.0310\u001b[0m  1.4665\n",
      "     78                   \u001b[36m-0.0035\u001b[0m        0.0284        \u001b[35m0.0309\u001b[0m  1.4686\n",
      "     79                   \u001b[36m-0.0035\u001b[0m        \u001b[32m0.0280\u001b[0m        \u001b[35m0.0308\u001b[0m  1.4685\n",
      "     80                   -0.0035        0.0286        0.0309  1.4685\n",
      "     81                   -0.0035        0.0285        0.0308  1.4700\n",
      "     82                   -0.0035        0.0281        0.0308  1.4650\n",
      "     83                   -0.0035        0.0282        0.0308  1.4658\n",
      "     84                   \u001b[36m-0.0035\u001b[0m        0.0284        \u001b[35m0.0307\u001b[0m  1.4660\n",
      "     85                   \u001b[36m-0.0035\u001b[0m        0.0283        0.0307  1.4683\n",
      "     86                   -0.0035        0.0281        \u001b[35m0.0307\u001b[0m  1.4658\n",
      "     87                   \u001b[36m-0.0035\u001b[0m        \u001b[32m0.0277\u001b[0m        \u001b[35m0.0307\u001b[0m  1.4660\n",
      "     88                   -0.0035        \u001b[32m0.0275\u001b[0m        0.0307  1.4698\n",
      "     89                   -0.0035        0.0279        \u001b[35m0.0306\u001b[0m  1.4650\n",
      "     90                   \u001b[36m-0.0035\u001b[0m        0.0276        \u001b[35m0.0305\u001b[0m  1.4658\n",
      "     91                   \u001b[36m-0.0035\u001b[0m        0.0281        \u001b[35m0.0305\u001b[0m  1.4647\n",
      "     92                   -0.0035        0.0277        0.0306  1.4678\n",
      "     93                   -0.0035        0.0275        0.0305  1.4665\n",
      "     94                   -0.0035        0.0278        \u001b[35m0.0304\u001b[0m  1.4647\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     95                   \u001b[36m-0.0035\u001b[0m        0.0277        \u001b[35m0.0303\u001b[0m  1.4659\n",
      "     96                   -0.0035        0.0276        0.0304  1.4680\n",
      "     97                   -0.0035        0.0275        0.0304  1.4686\n",
      "     98                   \u001b[36m-0.0034\u001b[0m        0.0276        \u001b[35m0.0303\u001b[0m  1.4693\n",
      "     99                   -0.0035        0.0276        \u001b[35m0.0303\u001b[0m  1.4685\n",
      "    100                   -0.0035        0.0276        0.0303  1.4714\n",
      "    101                   \u001b[36m-0.0034\u001b[0m        \u001b[32m0.0270\u001b[0m        \u001b[35m0.0302\u001b[0m  1.4673\n",
      "    102                   \u001b[36m-0.0034\u001b[0m        \u001b[32m0.0269\u001b[0m        \u001b[35m0.0302\u001b[0m  1.4683\n",
      "    103                   -0.0034        0.0274        \u001b[35m0.0301\u001b[0m  1.4687\n",
      "    104                   -0.0034        0.0269        0.0302  1.4667\n",
      "    105                   -0.0034        \u001b[32m0.0266\u001b[0m        0.0302  1.4690\n",
      "    106                   \u001b[36m-0.0034\u001b[0m        0.0270        \u001b[35m0.0301\u001b[0m  1.4685\n",
      "    107                   -0.0034        0.0271        \u001b[35m0.0300\u001b[0m  1.4682\n",
      "    108                   -0.0034        0.0272        0.0301  1.4685\n",
      "    109                   -0.0034        0.0271        0.0301  1.4683\n",
      "    110                   -0.0034        0.0270        0.0301  1.4703\n",
      "    111                   -0.0034        0.0269        0.0301  1.4698\n",
      "    112                   \u001b[36m-0.0034\u001b[0m        0.0270        \u001b[35m0.0300\u001b[0m  1.4619\n",
      "    113                   -0.0034        0.0267        \u001b[35m0.0299\u001b[0m  1.4688\n",
      "    114                   \u001b[36m-0.0034\u001b[0m        0.0269        \u001b[35m0.0299\u001b[0m  1.4683\n",
      "    115                   -0.0034        0.0268        0.0299  1.4671\n",
      "    116                   \u001b[36m-0.0034\u001b[0m        0.0267        \u001b[35m0.0298\u001b[0m  1.4692\n",
      "    117                   -0.0034        \u001b[32m0.0266\u001b[0m        0.0299  1.4705\n",
      "    118                   \u001b[36m-0.0034\u001b[0m        \u001b[32m0.0265\u001b[0m        0.0298  1.4693\n",
      "    119                   -0.0034        0.0267        0.0298  1.4675\n",
      "    120                   -0.0034        \u001b[32m0.0265\u001b[0m        \u001b[35m0.0297\u001b[0m  1.4678\n",
      "    121                   \u001b[36m-0.0034\u001b[0m        0.0266        \u001b[35m0.0297\u001b[0m  1.4690\n",
      "    122                   \u001b[36m-0.0034\u001b[0m        \u001b[32m0.0262\u001b[0m        0.0298  1.4685\n",
      "    123                   -0.0034        0.0264        0.0298  1.4740\n",
      "    124                   \u001b[36m-0.0034\u001b[0m        0.0267        \u001b[35m0.0297\u001b[0m  1.4696\n",
      "    125                   \u001b[36m-0.0034\u001b[0m        0.0264        0.0297  1.4684\n",
      "    126                   -0.0034        0.0264        0.0297  1.4686\n",
      "    127                   \u001b[36m-0.0034\u001b[0m        0.0264        \u001b[35m0.0296\u001b[0m  1.4691\n",
      "    128                   -0.0034        0.0263        \u001b[35m0.0296\u001b[0m  1.4694\n",
      "    129                   -0.0034        0.0264        0.0296  1.4690\n",
      "    130                   \u001b[36m-0.0034\u001b[0m        \u001b[32m0.0262\u001b[0m        0.0296  1.4687\n",
      "    131                   \u001b[36m-0.0034\u001b[0m        \u001b[32m0.0262\u001b[0m        \u001b[35m0.0296\u001b[0m  1.4677\n",
      "    132                   -0.0034        \u001b[32m0.0260\u001b[0m        \u001b[35m0.0295\u001b[0m  1.4679\n",
      "    133                   -0.0034        0.0260        0.0296  1.4691\n",
      "    134                   -0.0034        0.0261        \u001b[35m0.0295\u001b[0m  1.4676\n",
      "    135                   -0.0034        0.0261        \u001b[35m0.0295\u001b[0m  1.4607\n",
      "    136                   -0.0034        \u001b[32m0.0256\u001b[0m        0.0295  1.4698\n",
      "    137                   \u001b[36m-0.0034\u001b[0m        \u001b[32m0.0256\u001b[0m        0.0295  1.4689\n",
      "    138                   -0.0034        \u001b[32m0.0253\u001b[0m        \u001b[35m0.0295\u001b[0m  1.4695\n",
      "    139                   \u001b[36m-0.0034\u001b[0m        0.0259        \u001b[35m0.0294\u001b[0m  1.4693\n",
      "    140                   -0.0034        0.0257        0.0295  1.4667\n",
      "    141                   -0.0034        0.0256        0.0295  1.4687\n",
      "    142                   \u001b[36m-0.0034\u001b[0m        \u001b[32m0.0253\u001b[0m        0.0295  1.4731\n",
      "    143                   -0.0034        0.0257        0.0294  1.4703\n",
      "    144                   -0.0034        0.0257        0.0294  1.4676\n",
      "    145                   \u001b[36m-0.0034\u001b[0m        0.0256        0.0294  1.4692\n",
      "    146                   -0.0034        0.0255        0.0294  1.4590\n",
      "    147                   -0.0034        0.0257        0.0296  1.4685\n",
      "    148                   -0.0034        \u001b[32m0.0252\u001b[0m        0.0294  1.4743\n",
      "    149                   -0.0034        0.0254        0.0294  1.4706\n",
      "    150                   -0.0034        0.0252        0.0294  1.4701\n",
      "    151                   -0.0034        0.0253        0.0294  1.4673\n",
      "    152                   \u001b[36m-0.0034\u001b[0m        \u001b[32m0.0251\u001b[0m        0.0294  1.4690\n",
      "    153                   -0.0034        \u001b[32m0.0251\u001b[0m        \u001b[35m0.0292\u001b[0m  1.4660\n",
      "    154                   \u001b[36m-0.0034\u001b[0m        0.0252        0.0293  1.4673\n",
      "    155                   -0.0034        0.0251        0.0293  1.4672\n",
      "    156                   -0.0034        0.0254        0.0293  1.4610\n",
      "    157                   \u001b[36m-0.0033\u001b[0m        \u001b[32m0.0249\u001b[0m        \u001b[35m0.0292\u001b[0m  1.4539\n",
      "    158                   -0.0034        \u001b[32m0.0247\u001b[0m        0.0292  1.4631\n",
      "    159                   -0.0034        0.0251        \u001b[35m0.0291\u001b[0m  1.4611\n",
      "    160                   -0.0034        0.0250        0.0292  1.4622\n",
      "    161                   -0.0034        0.0249        0.0292  1.4629\n",
      "    162                   -0.0034        \u001b[32m0.0245\u001b[0m        0.0292  1.4625\n",
      "    163                   -0.0034        0.0246        0.0293  1.4635\n",
      "    164                   \u001b[36m-0.0033\u001b[0m        \u001b[32m0.0243\u001b[0m        \u001b[35m0.0291\u001b[0m  1.4611\n",
      "    165                   \u001b[36m-0.0033\u001b[0m        0.0247        0.0292  1.4621\n",
      "    166                   -0.0033        0.0247        0.0291  1.4613\n",
      "    167                   -0.0034        0.0246        0.0291  1.4625\n",
      "    168                   \u001b[36m-0.0033\u001b[0m        0.0247        \u001b[35m0.0289\u001b[0m  1.4610\n",
      "    169                   -0.0034        0.0245        0.0292  1.4628\n",
      "    170                   \u001b[36m-0.0033\u001b[0m        0.0245        0.0290  1.4651\n",
      "    171                   -0.0033        \u001b[32m0.0243\u001b[0m        0.0290  1.4640\n",
      "    172                   \u001b[36m-0.0033\u001b[0m        0.0245        0.0291  1.4639\n",
      "    173                   -0.0034        \u001b[32m0.0243\u001b[0m        0.0291  1.4624\n",
      "    174                   -0.0033        0.0243        0.0290  1.4619\n",
      "    175                   -0.0033        \u001b[32m0.0238\u001b[0m        \u001b[35m0.0289\u001b[0m  1.4638\n",
      "    176                   -0.0033        0.0244        \u001b[35m0.0288\u001b[0m  1.4646\n",
      "    177                   -0.0033        0.0239        0.0291  1.4624\n",
      "    178                   \u001b[36m-0.0033\u001b[0m        0.0241        \u001b[35m0.0288\u001b[0m  1.4553\n",
      "    179                   -0.0033        0.0243        0.0289  1.4630\n",
      "    180                   -0.0033        0.0243        0.0289  1.4626\n",
      "    181                   -0.0033        0.0242        0.0290  1.4616\n",
      "    182                   -0.0033        0.0242        0.0288  1.4627\n",
      "    183                   -0.0033        0.0241        0.0293  1.4601\n",
      "    184                   -0.0033        0.0241        0.0290  1.4616\n",
      "    185                   -0.0033        \u001b[32m0.0237\u001b[0m        0.0289  1.4613\n",
      "    186                   -0.0033        \u001b[32m0.0236\u001b[0m        0.0289  1.4619\n",
      "    187                   -0.0033        0.0239        0.0289  1.4617\n",
      "    188                   \u001b[36m-0.0033\u001b[0m        0.0237        0.0291  1.4619\n",
      "    189                   -0.0033        0.0236        0.0289  1.4556\n",
      "    190                   -0.0033        0.0237        0.0290  1.4647\n",
      "    191                   -0.0033        0.0239        0.0290  1.4641\n",
      "    192                   \u001b[36m-0.0033\u001b[0m        \u001b[32m0.0235\u001b[0m        0.0289  1.4631\n",
      "    193                   \u001b[36m-0.0033\u001b[0m        \u001b[32m0.0235\u001b[0m        \u001b[35m0.0288\u001b[0m  1.4625\n",
      "    194                   -0.0033        \u001b[32m0.0235\u001b[0m        0.0289  1.4640\n",
      "    195                   -0.0033        \u001b[32m0.0235\u001b[0m        0.0289  1.4629\n",
      "    196                   -0.0033        0.0236        \u001b[35m0.0287\u001b[0m  1.4643\n",
      "    197                   \u001b[36m-0.0033\u001b[0m        \u001b[32m0.0232\u001b[0m        0.0288  1.4637\n",
      "    198                   -0.0033        0.0235        0.0288  1.4644\n",
      "    199                   \u001b[36m-0.0033\u001b[0m        0.0233        0.0291  1.4584\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    200                   -0.0033        0.0237        0.0289  1.4632\n",
      "    201                   \u001b[36m-0.0033\u001b[0m        \u001b[32m0.0232\u001b[0m        0.0288  1.4638\n",
      "    202                   -0.0033        0.0235        0.0287  1.4863\n",
      "    203                   \u001b[36m-0.0033\u001b[0m        0.0232        0.0289  1.4654\n",
      "    204                   \u001b[36m-0.0033\u001b[0m        0.0232        \u001b[35m0.0287\u001b[0m  1.4660\n",
      "    205                   \u001b[36m-0.0033\u001b[0m        \u001b[32m0.0228\u001b[0m        \u001b[35m0.0286\u001b[0m  1.4641\n",
      "    206                   -0.0033        0.0232        0.0286  1.4641\n",
      "    207                   \u001b[36m-0.0033\u001b[0m        0.0230        \u001b[35m0.0285\u001b[0m  1.4662\n",
      "    208                   -0.0033        \u001b[32m0.0228\u001b[0m        0.0288  1.4631\n",
      "    209                   -0.0033        0.0231        0.0288  1.4677\n",
      "    210                   -0.0033        0.0230        0.0288  1.4636\n",
      "    211                   -0.0033        0.0228        0.0285  1.4627\n",
      "    212                   -0.0033        \u001b[32m0.0224\u001b[0m        0.0286  1.4631\n",
      "    213                   -0.0033        0.0229        0.0289  1.4631\n",
      "    214                   \u001b[36m-0.0033\u001b[0m        0.0227        0.0289  1.4641\n",
      "    215                   \u001b[36m-0.0033\u001b[0m        0.0226        \u001b[35m0.0285\u001b[0m  1.4629\n",
      "    216                   -0.0033        0.0227        0.0286  1.4622\n",
      "    217                   \u001b[36m-0.0033\u001b[0m        0.0228        \u001b[35m0.0285\u001b[0m  1.4630\n",
      "    218                   -0.0033        0.0225        \u001b[35m0.0284\u001b[0m  1.4691\n",
      "    219                   -0.0033        0.0224        0.0288  1.4776\n",
      "    220                   \u001b[36m-0.0033\u001b[0m        0.0227        0.0285  1.4716\n",
      "    221                   -0.0033        0.0225        0.0287  1.4712\n",
      "    222                   -0.0033        0.0227        0.0287  1.4724\n",
      "    223                   -0.0033        0.0224        0.0284  1.4720\n",
      "    224                   -0.0033        0.0226        0.0288  1.4713\n",
      "    225                   -0.0033        0.0226        0.0286  1.4724\n",
      "    226                   \u001b[36m-0.0033\u001b[0m        0.0225        0.0284  1.4705\n",
      "    227                   \u001b[36m-0.0032\u001b[0m        \u001b[32m0.0223\u001b[0m        0.0286  1.4751\n",
      "    228                   -0.0033        \u001b[32m0.0223\u001b[0m        0.0284  1.4751\n",
      "    229                   -0.0033        0.0223        0.0288  1.4759\n",
      "    230                   \u001b[36m-0.0032\u001b[0m        \u001b[32m0.0220\u001b[0m        0.0286  1.4723\n",
      "    231                   -0.0033        0.0223        0.0286  1.4758\n",
      "    232                   -0.0033        0.0222        0.0286  1.4720\n",
      "    233                   -0.0032        0.0223        \u001b[35m0.0283\u001b[0m  1.4721\n",
      "    234                   \u001b[36m-0.0032\u001b[0m        \u001b[32m0.0219\u001b[0m        0.0284  1.4709\n",
      "    235                   \u001b[36m-0.0032\u001b[0m        0.0221        \u001b[35m0.0283\u001b[0m  1.4711\n",
      "    236                   -0.0032        0.0220        0.0287  1.4708\n",
      "    237                   -0.0033        0.0220        0.0285  1.4709\n",
      "    238                   -0.0032        0.0220        0.0284  1.4712\n",
      "    239                   \u001b[36m-0.0032\u001b[0m        0.0220        \u001b[35m0.0283\u001b[0m  1.4616\n",
      "    240                   \u001b[36m-0.0032\u001b[0m        0.0220        0.0283  1.4725\n",
      "    241                   -0.0032        0.0219        0.0283  1.4704\n",
      "    242                   \u001b[36m-0.0032\u001b[0m        0.0220        0.0285  1.4708\n",
      "    243                   \u001b[36m-0.0032\u001b[0m        \u001b[32m0.0218\u001b[0m        \u001b[35m0.0281\u001b[0m  1.4707\n",
      "    244                   \u001b[36m-0.0032\u001b[0m        0.0219        0.0282  1.4707\n",
      "    245                   \u001b[36m-0.0032\u001b[0m        \u001b[32m0.0217\u001b[0m        0.0282  1.4717\n",
      "    246                   -0.0032        \u001b[32m0.0215\u001b[0m        0.0283  1.4719\n",
      "    247                   -0.0032        0.0219        0.0281  1.4713\n",
      "    248                   \u001b[36m-0.0032\u001b[0m        0.0216        \u001b[35m0.0281\u001b[0m  1.4727\n",
      "    249                   -0.0032        0.0216        0.0282  1.4709\n",
      "    250                   \u001b[36m-0.0032\u001b[0m        \u001b[32m0.0214\u001b[0m        0.0282  1.4712\n",
      "    251                   \u001b[36m-0.0032\u001b[0m        0.0217        \u001b[35m0.0280\u001b[0m  1.4714\n",
      "    252                   \u001b[36m-0.0032\u001b[0m        0.0216        \u001b[35m0.0280\u001b[0m  1.4732\n",
      "    253                   \u001b[36m-0.0032\u001b[0m        \u001b[32m0.0212\u001b[0m        0.0281  1.4729\n",
      "    254                   -0.0032        0.0215        0.0281  1.4721\n",
      "    255                   \u001b[36m-0.0031\u001b[0m        0.0216        0.0280  1.4714\n",
      "    256                   \u001b[36m-0.0031\u001b[0m        0.0217        0.0283  1.4724\n",
      "    257                   -0.0032        0.0213        0.0281  1.4750\n",
      "    258                   \u001b[36m-0.0031\u001b[0m        0.0214        \u001b[35m0.0279\u001b[0m  1.4638\n",
      "    259                   \u001b[36m-0.0031\u001b[0m        \u001b[32m0.0212\u001b[0m        \u001b[35m0.0279\u001b[0m  1.4717\n",
      "    260                   \u001b[36m-0.0031\u001b[0m        0.0212        \u001b[35m0.0279\u001b[0m  1.4733\n",
      "    261                   -0.0031        0.0214        0.0280  1.4733\n",
      "    262                   -0.0031        \u001b[32m0.0210\u001b[0m        \u001b[35m0.0279\u001b[0m  1.4716\n",
      "    263                   -0.0031        0.0213        0.0280  1.4720\n",
      "    264                   \u001b[36m-0.0031\u001b[0m        0.0211        \u001b[35m0.0279\u001b[0m  1.4892\n",
      "    265                   \u001b[36m-0.0031\u001b[0m        0.0211        \u001b[35m0.0278\u001b[0m  1.4745\n",
      "    266                   -0.0031        0.0212        0.0278  1.4741\n",
      "    267                   -0.0031        \u001b[32m0.0209\u001b[0m        \u001b[35m0.0278\u001b[0m  1.4749\n",
      "    268                   \u001b[36m-0.0031\u001b[0m        0.0209        \u001b[35m0.0278\u001b[0m  1.4744\n",
      "    269                   \u001b[36m-0.0031\u001b[0m        0.0211        \u001b[35m0.0277\u001b[0m  1.4744\n",
      "    270                   -0.0031        0.0210        0.0279  1.4756\n",
      "    271                   \u001b[36m-0.0031\u001b[0m        0.0210        0.0280  1.4748\n",
      "    272                   -0.0031        \u001b[32m0.0206\u001b[0m        0.0278  1.4760\n",
      "    273                   \u001b[36m-0.0031\u001b[0m        0.0209        0.0278  1.4773\n",
      "    274                   -0.0031        0.0208        0.0277  1.4783\n",
      "    275                   \u001b[36m-0.0031\u001b[0m        0.0206        0.0277  1.4753\n",
      "    276                   -0.0031        0.0207        0.0278  1.4764\n",
      "    277                   \u001b[36m-0.0030\u001b[0m        0.0208        0.0278  1.4703\n",
      "    278                   -0.0031        0.0207        0.0278  1.4765\n",
      "    279                   -0.0031        0.0206        0.0277  1.4752\n",
      "    280                   \u001b[36m-0.0030\u001b[0m        \u001b[32m0.0204\u001b[0m        0.0277  1.4745\n",
      "    281                   \u001b[36m-0.0030\u001b[0m        0.0206        \u001b[35m0.0275\u001b[0m  1.4761\n",
      "    282                   -0.0030        0.0205        0.0277  1.4756\n",
      "    283                   -0.0030        0.0205        0.0277  1.4707\n",
      "    284                   \u001b[36m-0.0030\u001b[0m        0.0204        0.0276  1.4725\n",
      "    285                   -0.0030        \u001b[32m0.0202\u001b[0m        \u001b[35m0.0275\u001b[0m  1.4720\n",
      "    286                   \u001b[36m-0.0030\u001b[0m        \u001b[32m0.0202\u001b[0m        0.0277  1.4668\n",
      "    287                   \u001b[36m-0.0030\u001b[0m        \u001b[32m0.0201\u001b[0m        0.0276  1.4718\n",
      "    288                   \u001b[36m-0.0030\u001b[0m        0.0204        \u001b[35m0.0275\u001b[0m  1.4729\n",
      "    289                   \u001b[36m-0.0030\u001b[0m        0.0202        0.0276  1.4718\n",
      "    290                   -0.0030        0.0202        0.0275  1.4715\n",
      "    291                   -0.0030        0.0203        0.0275  1.4701\n",
      "    292                   \u001b[36m-0.0030\u001b[0m        \u001b[32m0.0200\u001b[0m        0.0275  1.4703\n",
      "    293                   -0.0030        0.0202        \u001b[35m0.0274\u001b[0m  1.4707\n",
      "    294                   \u001b[36m-0.0030\u001b[0m        0.0201        0.0274  1.4712\n",
      "    295                   \u001b[36m-0.0029\u001b[0m        0.0200        \u001b[35m0.0273\u001b[0m  1.4663\n",
      "    296                   -0.0029        0.0200        0.0274  1.4701\n",
      "    297                   \u001b[36m-0.0029\u001b[0m        \u001b[32m0.0200\u001b[0m        0.0275  1.4713\n",
      "    298                   -0.0029        0.0200        0.0274  1.4715\n",
      "    299                   -0.0029        0.0200        \u001b[35m0.0273\u001b[0m  1.4711\n",
      "    300                   -0.0029        \u001b[32m0.0197\u001b[0m        0.0275  1.4701\n",
      "    301                   -0.0029        0.0201        0.0274  1.4762\n",
      "    302                   -0.0029        0.0199        \u001b[35m0.0270\u001b[0m  1.4777\n",
      "    303                   -0.0029        0.0198        0.0272  1.4754\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    304                   -0.0029        0.0198        0.0274  1.4720\n",
      "    305                   \u001b[36m-0.0029\u001b[0m        0.0197        0.0272  1.4767\n",
      "    306                   \u001b[36m-0.0029\u001b[0m        0.0198        0.0275  1.4765\n",
      "    307                   -0.0029        0.0198        0.0271  1.4763\n",
      "    308                   \u001b[36m-0.0029\u001b[0m        0.0198        0.0271  1.4748\n",
      "    309                   \u001b[36m-0.0029\u001b[0m        \u001b[32m0.0196\u001b[0m        \u001b[35m0.0269\u001b[0m  1.4758\n",
      "    310                   -0.0029        \u001b[32m0.0194\u001b[0m        0.0273  1.4761\n",
      "    311                   -0.0029        0.0196        0.0272  1.4775\n",
      "    312                   \u001b[36m-0.0028\u001b[0m        0.0196        0.0273  1.4774\n",
      "    313                   \u001b[36m-0.0028\u001b[0m        0.0195        0.0272  1.4717\n",
      "    314                   \u001b[36m-0.0028\u001b[0m        0.0194        0.0271  1.4771\n",
      "    315                   \u001b[36m-0.0028\u001b[0m        0.0195        \u001b[35m0.0268\u001b[0m  1.4776\n",
      "    316                   -0.0028        0.0197        0.0269  1.4760\n",
      "    317                   -0.0028        0.0195        0.0270  1.4710\n",
      "    318                   -0.0028        \u001b[32m0.0193\u001b[0m        0.0270  1.4709\n",
      "    319                   \u001b[36m-0.0028\u001b[0m        0.0195        0.0271  1.4736\n",
      "    320                   -0.0028        0.0194        0.0269  1.4753\n",
      "    321                   \u001b[36m-0.0028\u001b[0m        \u001b[32m0.0193\u001b[0m        0.0270  1.4755\n",
      "    322                   \u001b[36m-0.0028\u001b[0m        0.0194        0.0269  1.4712\n",
      "    323                   -0.0028        \u001b[32m0.0193\u001b[0m        0.0268  1.4747\n",
      "    324                   -0.0028        \u001b[32m0.0191\u001b[0m        \u001b[35m0.0268\u001b[0m  1.4746\n",
      "    325                   \u001b[36m-0.0028\u001b[0m        0.0192        0.0268  1.4740\n",
      "    326                   -0.0028        0.0192        0.0268  1.4751\n",
      "    327                   \u001b[36m-0.0028\u001b[0m        \u001b[32m0.0191\u001b[0m        \u001b[35m0.0266\u001b[0m  1.4757\n",
      "    328                   \u001b[36m-0.0028\u001b[0m        \u001b[32m0.0191\u001b[0m        0.0268  1.4738\n",
      "    329                   -0.0028        0.0193        0.0266  1.4757\n",
      "    330                   -0.0028        \u001b[32m0.0190\u001b[0m        0.0267  1.4755\n",
      "    331                   -0.0028        0.0192        0.0269  1.4740\n",
      "    332                   -0.0028        \u001b[32m0.0190\u001b[0m        0.0268  1.4738\n",
      "    333                   \u001b[36m-0.0028\u001b[0m        0.0192        0.0267  1.4752\n",
      "    334                   \u001b[36m-0.0028\u001b[0m        \u001b[32m0.0189\u001b[0m        0.0268  1.4751\n",
      "    335                   -0.0028        \u001b[32m0.0187\u001b[0m        0.0267  1.4745\n",
      "    336                   -0.0028        0.0189        \u001b[35m0.0265\u001b[0m  1.4760\n",
      "    337                   -0.0028        0.0189        \u001b[35m0.0265\u001b[0m  1.4740\n",
      "    338                   \u001b[36m-0.0027\u001b[0m        0.0189        0.0268  1.4729\n",
      "    339                   \u001b[36m-0.0027\u001b[0m        \u001b[32m0.0186\u001b[0m        0.0268  1.4786\n",
      "    340                   -0.0027        0.0188        0.0265  1.4728\n",
      "    341                   \u001b[36m-0.0027\u001b[0m        0.0188        0.0266  1.4741\n",
      "    342                   -0.0028        0.0188        0.0268  1.4745\n",
      "    343                   -0.0028        0.0187        0.0267  1.4747\n",
      "    344                   -0.0027        0.0188        0.0266  1.4729\n",
      "    345                   \u001b[36m-0.0027\u001b[0m        0.0188        \u001b[35m0.0265\u001b[0m  1.4737\n",
      "    346                   \u001b[36m-0.0027\u001b[0m        0.0187        0.0265  1.4742\n",
      "    347                   \u001b[36m-0.0027\u001b[0m        \u001b[32m0.0184\u001b[0m        0.0266  1.4739\n",
      "    348                   \u001b[36m-0.0027\u001b[0m        0.0187        0.0265  1.4699\n",
      "    349                   -0.0027        0.0186        0.0265  1.4748\n",
      "    350                   -0.0027        \u001b[32m0.0181\u001b[0m        \u001b[35m0.0264\u001b[0m  1.4725\n",
      "    351                   -0.0027        0.0189        0.0266  1.4728\n",
      "    352                   -0.0027        0.0186        \u001b[35m0.0264\u001b[0m  1.4736\n",
      "    353                   -0.0027        0.0185        0.0265  1.4752\n",
      "    354                   -0.0027        0.0184        0.0264  1.4757\n",
      "    355                   -0.0027        0.0184        0.0265  1.4741\n",
      "    356                   -0.0027        0.0184        0.0265  1.4738\n",
      "    357                   -0.0027        0.0184        0.0265  1.4740\n",
      "    358                   -0.0027        0.0185        0.0267  1.4737\n",
      "    359                   \u001b[36m-0.0027\u001b[0m        0.0185        \u001b[35m0.0263\u001b[0m  1.4717\n",
      "    360                   -0.0027        0.0183        0.0264  1.4729\n",
      "    361                   -0.0027        0.0183        0.0263  1.4733\n",
      "    362                   \u001b[36m-0.0027\u001b[0m        0.0186        \u001b[35m0.0263\u001b[0m  1.4726\n",
      "    363                   \u001b[36m-0.0027\u001b[0m        \u001b[32m0.0180\u001b[0m        0.0263  1.4737\n",
      "    364                   -0.0027        0.0182        0.0267  1.4764\n",
      "    365                   -0.0027        0.0183        0.0264  1.4688\n",
      "    366                   -0.0027        0.0182        0.0264  1.4740\n",
      "    367                   -0.0027        0.0183        0.0263  1.4745\n",
      "    368                   -0.0027        0.0183        0.0263  1.4741\n",
      "    369                   -0.0027        0.0182        \u001b[35m0.0262\u001b[0m  1.4767\n",
      "    370                   \u001b[36m-0.0027\u001b[0m        0.0181        \u001b[35m0.0262\u001b[0m  1.4799\n",
      "    371                   \u001b[36m-0.0027\u001b[0m        0.0181        0.0263  1.4806\n",
      "    372                   -0.0027        \u001b[32m0.0180\u001b[0m        \u001b[35m0.0262\u001b[0m  1.4805\n",
      "    373                   -0.0027        0.0182        0.0262  1.4840\n",
      "    374                   \u001b[36m-0.0026\u001b[0m        0.0180        \u001b[35m0.0261\u001b[0m  1.4770\n",
      "    375                   -0.0027        0.0182        0.0262  1.4772\n",
      "    376                   \u001b[36m-0.0026\u001b[0m        0.0180        0.0262  1.4767\n",
      "    377                   -0.0026        0.0180        0.0262  1.4737\n",
      "    378                   \u001b[36m-0.0026\u001b[0m        \u001b[32m0.0180\u001b[0m        0.0261  1.4742\n",
      "    379                   -0.0026        \u001b[32m0.0179\u001b[0m        0.0261  1.4775\n",
      "    380                   \u001b[36m-0.0026\u001b[0m        \u001b[32m0.0178\u001b[0m        0.0263  1.4787\n",
      "    381                   -0.0027        0.0180        0.0263  1.4787\n",
      "    382                   -0.0027        0.0179        \u001b[35m0.0261\u001b[0m  1.4897\n",
      "    383                   \u001b[36m-0.0026\u001b[0m        \u001b[32m0.0176\u001b[0m        \u001b[35m0.0260\u001b[0m  1.4738\n",
      "    384                   -0.0026        0.0178        0.0261  1.4771\n",
      "    385                   -0.0027        0.0178        \u001b[35m0.0260\u001b[0m  1.4761\n",
      "    386                   -0.0027        0.0178        0.0261  1.4755\n",
      "    387                   -0.0026        0.0179        \u001b[35m0.0260\u001b[0m  1.4761\n",
      "    388                   \u001b[36m-0.0026\u001b[0m        0.0178        0.0260  1.4733\n",
      "    389                   \u001b[36m-0.0026\u001b[0m        0.0177        \u001b[35m0.0260\u001b[0m  1.4741\n",
      "    390                   -0.0026        \u001b[32m0.0175\u001b[0m        \u001b[35m0.0259\u001b[0m  1.4708\n",
      "    391                   -0.0026        0.0177        \u001b[35m0.0258\u001b[0m  1.4734\n",
      "    392                   -0.0026        \u001b[32m0.0173\u001b[0m        0.0259  1.4730\n",
      "    393                   -0.0026        0.0177        0.0259  1.4732\n",
      "    394                   -0.0026        0.0175        0.0260  1.4736\n",
      "    395                   -0.0026        0.0176        \u001b[35m0.0258\u001b[0m  1.4741\n",
      "    396                   -0.0026        0.0175        0.0260  1.4726\n",
      "    397                   -0.0026        0.0177        \u001b[35m0.0258\u001b[0m  1.4721\n",
      "    398                   -0.0026        0.0176        0.0260  1.4741\n",
      "    399                   \u001b[36m-0.0026\u001b[0m        0.0176        \u001b[35m0.0257\u001b[0m  1.4765\n",
      "    400                   \u001b[36m-0.0026\u001b[0m        0.0175        \u001b[35m0.0257\u001b[0m  1.4755\n",
      "    401                   -0.0026        0.0175        \u001b[35m0.0256\u001b[0m  1.4744\n",
      "    402                   \u001b[36m-0.0026\u001b[0m        0.0175        0.0258  1.4731\n",
      "    403                   -0.0026        0.0175        0.0259  1.4730\n",
      "    404                   \u001b[36m-0.0026\u001b[0m        \u001b[32m0.0171\u001b[0m        0.0257  1.4737\n",
      "    405                   -0.0026        0.0172        0.0257  1.4709\n",
      "    406                   \u001b[36m-0.0026\u001b[0m        0.0174        0.0258  1.4713\n",
      "    407                   -0.0026        0.0174        \u001b[35m0.0255\u001b[0m  1.4716\n",
      "    408                   -0.0026        0.0173        0.0257  1.4702\n",
      "    409                   -0.0026        0.0173        0.0256  1.4704\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    410                   -0.0026        0.0172        0.0259  1.4711\n",
      "    411                   -0.0026        0.0174        0.0258  1.4711\n",
      "    412                   -0.0026        0.0172        0.0256  1.4742\n",
      "    413                   -0.0026        0.0172        0.0258  1.4744\n",
      "    414                   -0.0026        \u001b[32m0.0170\u001b[0m        0.0257  1.4703\n",
      "    415                   -0.0026        0.0172        0.0259  1.4707\n",
      "    416                   -0.0026        0.0172        0.0258  1.4747\n",
      "    417                   -0.0026        \u001b[32m0.0170\u001b[0m        0.0257  1.4729\n",
      "    418                   -0.0026        0.0171        0.0257  1.4706\n",
      "    419                   \u001b[36m-0.0026\u001b[0m        0.0174        0.0257  1.4726\n",
      "    420                   -0.0026        0.0170        0.0259  1.4735\n",
      "    421                   -0.0026        0.0171        0.0256  1.4719\n",
      "    422                   -0.0026        0.0171        0.0258  1.4704\n",
      "    423                   -0.0026        \u001b[32m0.0170\u001b[0m        \u001b[35m0.0254\u001b[0m  1.4707\n",
      "    424                   \u001b[36m-0.0025\u001b[0m        0.0172        0.0258  1.4739\n",
      "    425                   -0.0026        0.0171        \u001b[35m0.0254\u001b[0m  1.4718\n",
      "    426                   -0.0025        \u001b[32m0.0169\u001b[0m        0.0256  1.4709\n",
      "    427                   -0.0026        0.0170        0.0257  1.4724\n",
      "    428                   -0.0025        \u001b[32m0.0168\u001b[0m        0.0257  1.4691\n",
      "    429                   -0.0025        0.0170        \u001b[35m0.0254\u001b[0m  1.4680\n",
      "    430                   -0.0026        0.0169        0.0257  1.4677\n",
      "    431                   -0.0026        0.0170        0.0256  1.4693\n",
      "    432                   -0.0026        0.0169        \u001b[35m0.0254\u001b[0m  1.4705\n",
      "    433                   -0.0025        0.0168        0.0256  1.4805\n",
      "    434                   -0.0025        0.0170        0.0256  1.4728\n",
      "    435                   -0.0025        0.0169        \u001b[35m0.0254\u001b[0m  1.5268\n",
      "    436                   -0.0025        0.0170        \u001b[35m0.0253\u001b[0m  1.4962\n",
      "    437                   -0.0026        \u001b[32m0.0166\u001b[0m        0.0254  1.4768\n",
      "    438                   -0.0025        0.0170        0.0255  1.4786\n",
      "    439                   -0.0026        0.0168        0.0256  1.4774\n",
      "    440                   -0.0025        0.0167        0.0255  1.4763\n",
      "    441                   -0.0026        0.0169        0.0254  1.4751\n",
      "    442                   -0.0025        0.0167        \u001b[35m0.0253\u001b[0m  1.4776\n",
      "    443                   -0.0026        0.0168        0.0253  1.4779\n",
      "    444                   -0.0025        \u001b[32m0.0165\u001b[0m        \u001b[35m0.0253\u001b[0m  1.4772\n",
      "    445                   -0.0026        0.0166        0.0253  1.4769\n",
      "    446                   -0.0026        0.0167        0.0255  1.4668\n",
      "    447                   -0.0025        0.0166        0.0253  1.4773\n",
      "    448                   -0.0026        0.0167        0.0256  1.4782\n",
      "    449                   -0.0025        0.0167        0.0255  1.4778\n",
      "    450                   \u001b[36m-0.0025\u001b[0m        0.0167        0.0254  1.4790\n",
      "    451                   -0.0025        0.0166        \u001b[35m0.0251\u001b[0m  1.4783\n",
      "    452                   -0.0025        0.0166        0.0252  1.4787\n",
      "    453                   -0.0026        0.0166        0.0254  1.4768\n",
      "    454                   \u001b[36m-0.0025\u001b[0m        0.0167        0.0253  1.5403\n",
      "    455                   -0.0025        \u001b[32m0.0165\u001b[0m        0.0251  1.4759\n",
      "    456                   -0.0025        0.0166        0.0254  1.4791\n",
      "    457                   \u001b[36m-0.0025\u001b[0m        0.0165        0.0253  1.4773\n",
      "    458                   \u001b[36m-0.0025\u001b[0m        \u001b[32m0.0164\u001b[0m        0.0252  1.4766\n",
      "    459                   -0.0025        0.0165        0.0252  1.4771\n",
      "    460                   -0.0025        \u001b[32m0.0164\u001b[0m        0.0253  1.4796\n",
      "    461                   \u001b[36m-0.0025\u001b[0m        0.0164        0.0251  1.4808\n",
      "    462                   -0.0026        0.0165        0.0257  1.4778\n",
      "    463                   -0.0025        0.0166        0.0251  1.4852\n",
      "    464                   -0.0025        0.0165        0.0252  1.4751\n",
      "    465                   \u001b[36m-0.0025\u001b[0m        0.0165        0.0252  1.4742\n",
      "    466                   -0.0025        0.0166        0.0251  1.4726\n",
      "    467                   -0.0025        \u001b[32m0.0163\u001b[0m        0.0252  1.4727\n",
      "    468                   -0.0025        0.0165        \u001b[35m0.0250\u001b[0m  1.4736\n",
      "    469                   -0.0025        0.0165        0.0254  1.4702\n",
      "    470                   -0.0025        \u001b[32m0.0162\u001b[0m        0.0252  1.4737\n",
      "    471                   -0.0025        0.0163        0.0251  1.4741\n",
      "    472                   \u001b[36m-0.0025\u001b[0m        0.0163        \u001b[35m0.0249\u001b[0m  1.4737\n",
      "    473                   -0.0025        0.0164        0.0252  1.4729\n",
      "    474                   -0.0025        \u001b[32m0.0161\u001b[0m        0.0253  1.4719\n",
      "    475                   -0.0025        0.0163        \u001b[35m0.0249\u001b[0m  1.4690\n",
      "    476                   -0.0025        0.0162        0.0250  1.4657\n",
      "    477                   -0.0025        0.0163        0.0250  1.4668\n",
      "    478                   -0.0025        0.0162        0.0253  1.4663\n",
      "    479                   -0.0025        0.0162        0.0251  1.4661\n",
      "    480                   -0.0025        0.0161        0.0252  1.4661\n",
      "    481                   -0.0025        0.0163        0.0250  1.4650\n",
      "    482                   -0.0025        0.0162        0.0251  1.4671\n",
      "    483                   -0.0025        0.0161        0.0251  1.4661\n",
      "    484                   -0.0025        0.0161        0.0249  1.4632\n",
      "    485                   -0.0025        \u001b[32m0.0161\u001b[0m        0.0251  1.4656\n",
      "    486                   -0.0025        0.0161        0.0253  1.4678\n",
      "    487                   -0.0025        \u001b[32m0.0161\u001b[0m        0.0252  1.4660\n",
      "    488                   -0.0025        0.0161        0.0249  1.4652\n",
      "    489                   -0.0025        0.0161        0.0250  1.4659\n",
      "    490                   -0.0025        \u001b[32m0.0160\u001b[0m        0.0250  1.4868\n",
      "    491                   -0.0025        0.0161        0.0250  1.5681\n",
      "    492                   -0.0025        0.0161        0.0249  1.5535\n",
      "    493                   -0.0025        \u001b[32m0.0160\u001b[0m        0.0250  1.4720\n",
      "    494                   -0.0025        0.0162        0.0252  1.4734\n",
      "    495                   -0.0025        0.0160        0.0250  1.5030\n",
      "    496                   -0.0025        0.0160        \u001b[35m0.0249\u001b[0m  1.4717\n",
      "    497                   -0.0025        0.0160        0.0250  1.4724\n",
      "    498                   \u001b[36m-0.0025\u001b[0m        0.0160        \u001b[35m0.0249\u001b[0m  1.4717\n",
      "    499                   -0.0025        0.0161        0.0250  1.4676\n",
      "    500                   -0.0025        0.0160        0.0250  1.4715\n",
      "    501                   -0.0025        0.0160        \u001b[35m0.0248\u001b[0m  1.4711\n",
      "    502                   -0.0025        \u001b[32m0.0160\u001b[0m        0.0250  1.4706\n",
      "    503                   \u001b[36m-0.0025\u001b[0m        0.0160        0.0250  1.4714\n",
      "    504                   \u001b[36m-0.0025\u001b[0m        \u001b[32m0.0159\u001b[0m        0.0248  1.4717\n",
      "    505                   \u001b[36m-0.0025\u001b[0m        0.0160        0.0250  1.4709\n",
      "    506                   -0.0025        0.0159        0.0255  1.4719\n",
      "    507                   -0.0025        \u001b[32m0.0157\u001b[0m        0.0250  1.4718\n",
      "    508                   -0.0025        0.0160        0.0249  1.4710\n",
      "    509                   -0.0025        0.0157        0.0254  1.4710\n",
      "    510                   -0.0025        0.0159        0.0251  1.4712\n",
      "    511                   -0.0025        0.0158        0.0249  1.4706\n",
      "    512                   -0.0025        0.0158        0.0248  1.4715\n",
      "    513                   -0.0025        \u001b[32m0.0156\u001b[0m        0.0249  1.4707\n",
      "    514                   -0.0025        0.0160        0.0251  1.4634\n"
     ]
    }
   ],
   "source": [
    "auc = EpochScoring(scoring='neg_mean_squared_error', lower_is_better=False)\n",
    "\n",
    "net = NeuralNetRegressor(\n",
    "    DNN,\n",
    "    max_epochs=2000,\n",
    "    lr=0.001,\n",
    "    # Shuffle training data on each epoch\n",
    "    iterator_train__shuffle=True,\n",
    "    callbacks=[auc],\n",
    "    device='cuda',\n",
    "    criterion= SqrtMSELoss,\n",
    ")\n",
    "\n",
    "#net.fit(X, y)\n",
    "#y_proba = net.predict_proba(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Tensor' object has no attribute 'astype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-baab9583c467>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m params = {\n\u001b[1;32m      5\u001b[0m     \u001b[0;34m'lr'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0.0015\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.003\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.005\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Tensor' object has no attribute 'astype'"
     ]
    }
   ],
   "source": [
    "X = X.astype(np.float32)\n",
    "y = y.astype(np.float32)\n",
    "\n",
    "params = {\n",
    "    'lr': [0.0015, 0.003, 0.005],\n",
    "    #'max_epochs': [2000, 5000],\n",
    "}\n",
    "gs = GridSearchCV(net, params, refit=False, cv=3, scoring='neg_mean_squared_error')\n",
    "\n",
    "gs.fit(X, y)\n",
    "print(gs.best_score_, gs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 1)\n"
     ]
    }
   ],
   "source": [
    "y_proba = net.predict_proba(X_test)\n",
    "pred = y_scaler.inverse_transform(y_proba)       \n",
    "print(pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>building_id</th>\n",
       "      <th>total_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>X5gsdTWGS3W7JJQB</td>\n",
       "      <td>1.910691e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BTshNOJyKHnT2YIT</td>\n",
       "      <td>2.268285e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dhdymr0lV8N5kZOT</td>\n",
       "      <td>1.123758e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>VEwyGGMcD56w5BOc</td>\n",
       "      <td>1.969187e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>wmUeMoJZfsqaSX9b</td>\n",
       "      <td>-1.727904e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>EtBjGAHmHCe9t7TZ</td>\n",
       "      <td>2.860874e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>hPNH34vmaZtvBtqc</td>\n",
       "      <td>1.397353e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>wXjeI38bYDMJJwZC</td>\n",
       "      <td>1.533666e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>fxZSGX6aPAFKU8W4</td>\n",
       "      <td>4.654310e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ewr0Fx6ign87OwaV</td>\n",
       "      <td>-1.102196e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>gHKurnEP4AowzsLg</td>\n",
       "      <td>4.150280e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>PmLfTgY2FElLrTl0</td>\n",
       "      <td>3.439630e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>eM2NppIOwzW0o8iy</td>\n",
       "      <td>7.748000e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>dxxwNun97NH4WTrZ</td>\n",
       "      <td>4.670196e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>jykBfhh3vdeFUi3H</td>\n",
       "      <td>5.825636e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>NlXbvdFfmJZf3L18</td>\n",
       "      <td>1.555474e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>D7jaFWHCzSqLBwdt</td>\n",
       "      <td>-6.824197e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>L10dBBdqGmemweSl</td>\n",
       "      <td>3.968190e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>OgB0AdiPKlElakKN</td>\n",
       "      <td>-1.591637e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>StiWNN1GQrpPBOYt</td>\n",
       "      <td>4.461342e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>a016eMAVQKnfwMnt</td>\n",
       "      <td>2.246584e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>gsCFcQHnOH3AKMcZ</td>\n",
       "      <td>7.125153e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>IbNsDXfsPwSuFpow</td>\n",
       "      <td>4.606690e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>EgAVWOVxD1Jy5YkE</td>\n",
       "      <td>5.354776e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>BrKghvR76XdbQPnx</td>\n",
       "      <td>9.322833e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>a7fxkXTnUGWHUmKG</td>\n",
       "      <td>1.099648e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>WgzXa170DfpzpURE</td>\n",
       "      <td>7.470104e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>JPWqZbLq0VNC0yKI</td>\n",
       "      <td>2.767996e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>JQgTtbVstqFZwEK1</td>\n",
       "      <td>1.327230e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>bCSDbEthlS3nSIor</td>\n",
       "      <td>2.895804e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9970</th>\n",
       "      <td>QL412tWF5RDIX7IO</td>\n",
       "      <td>-3.030862e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9971</th>\n",
       "      <td>d3c2ceGtckONZzsr</td>\n",
       "      <td>1.741138e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9972</th>\n",
       "      <td>P1j8YRbxDAovumaI</td>\n",
       "      <td>9.952168e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9973</th>\n",
       "      <td>IxcBhEoFLcrI9TPr</td>\n",
       "      <td>4.408756e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9974</th>\n",
       "      <td>rKiV0KDbAl2myBQI</td>\n",
       "      <td>1.293370e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9975</th>\n",
       "      <td>GSdIXmKr0g5jQQcF</td>\n",
       "      <td>-3.571346e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9976</th>\n",
       "      <td>Am6Wcg3TO64qvzd8</td>\n",
       "      <td>2.777762e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9977</th>\n",
       "      <td>RZqACAhkL4Tgw4Jr</td>\n",
       "      <td>9.986374e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9978</th>\n",
       "      <td>u7NKZfWoMUlZy9rJ</td>\n",
       "      <td>7.645667e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9979</th>\n",
       "      <td>C1BqV4MWH15rjAgz</td>\n",
       "      <td>2.681173e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9980</th>\n",
       "      <td>wz8A2UbwsgR0lXGJ</td>\n",
       "      <td>2.993034e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9981</th>\n",
       "      <td>MGJ8ABBTmC2yIaSm</td>\n",
       "      <td>7.546485e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9982</th>\n",
       "      <td>MjHL2HP1PGIp8aBt</td>\n",
       "      <td>5.434886e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9983</th>\n",
       "      <td>FMz7nnURFn85LaGt</td>\n",
       "      <td>8.211306e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9984</th>\n",
       "      <td>kydULx0r0G7OklRD</td>\n",
       "      <td>5.216309e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9985</th>\n",
       "      <td>nVNYRuk2fRbtlV00</td>\n",
       "      <td>4.154064e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9986</th>\n",
       "      <td>F8SGEOGPxrPfiRv2</td>\n",
       "      <td>-3.005466e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9987</th>\n",
       "      <td>w7VMfiMvRb765ejK</td>\n",
       "      <td>4.450637e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9988</th>\n",
       "      <td>lgZWdUKliWt2y5sM</td>\n",
       "      <td>1.176073e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9989</th>\n",
       "      <td>TER8YrP9mw7UwWwr</td>\n",
       "      <td>6.867172e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9990</th>\n",
       "      <td>TXHk3oUpVsm5Cmag</td>\n",
       "      <td>7.944416e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9991</th>\n",
       "      <td>JtgDm9aQcGE9zELB</td>\n",
       "      <td>4.985268e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9992</th>\n",
       "      <td>wTQmcqbN0OCuSF1t</td>\n",
       "      <td>3.434268e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9993</th>\n",
       "      <td>WgsI1cBtzSfiWA1j</td>\n",
       "      <td>4.672384e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9994</th>\n",
       "      <td>qNgt1ajb5uVMKbqm</td>\n",
       "      <td>1.301363e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>UEeCDaAJzPwdKKKA</td>\n",
       "      <td>-5.132256e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>i0fgbPaQsDWs7Q87</td>\n",
       "      <td>1.768069e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>YunNwAhcqkf6YclI</td>\n",
       "      <td>7.889846e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>A2NotxtRY9MYoWMl</td>\n",
       "      <td>1.241324e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>kKvgBXiA50gRmQhP</td>\n",
       "      <td>-1.161348e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           building_id   total_price\n",
       "0     X5gsdTWGS3W7JJQB  1.910691e+07\n",
       "1     BTshNOJyKHnT2YIT  2.268285e+06\n",
       "2     dhdymr0lV8N5kZOT  1.123758e+07\n",
       "3     VEwyGGMcD56w5BOc  1.969187e+06\n",
       "4     wmUeMoJZfsqaSX9b -1.727904e+06\n",
       "5     EtBjGAHmHCe9t7TZ  2.860874e+06\n",
       "6     hPNH34vmaZtvBtqc  1.397353e+07\n",
       "7     wXjeI38bYDMJJwZC  1.533666e+07\n",
       "8     fxZSGX6aPAFKU8W4  4.654310e+06\n",
       "9     ewr0Fx6ign87OwaV -1.102196e+06\n",
       "10    gHKurnEP4AowzsLg  4.150280e+06\n",
       "11    PmLfTgY2FElLrTl0  3.439630e+06\n",
       "12    eM2NppIOwzW0o8iy  7.748000e+06\n",
       "13    dxxwNun97NH4WTrZ  4.670196e+06\n",
       "14    jykBfhh3vdeFUi3H  5.825636e+06\n",
       "15    NlXbvdFfmJZf3L18  1.555474e+07\n",
       "16    D7jaFWHCzSqLBwdt -6.824197e+05\n",
       "17    L10dBBdqGmemweSl  3.968190e+06\n",
       "18    OgB0AdiPKlElakKN -1.591637e+06\n",
       "19    StiWNN1GQrpPBOYt  4.461342e+06\n",
       "20    a016eMAVQKnfwMnt  2.246584e+07\n",
       "21    gsCFcQHnOH3AKMcZ  7.125153e+06\n",
       "22    IbNsDXfsPwSuFpow  4.606690e+06\n",
       "23    EgAVWOVxD1Jy5YkE  5.354776e+06\n",
       "24    BrKghvR76XdbQPnx  9.322833e+06\n",
       "25    a7fxkXTnUGWHUmKG  1.099648e+07\n",
       "26    WgzXa170DfpzpURE  7.470104e+06\n",
       "27    JPWqZbLq0VNC0yKI  2.767996e+07\n",
       "28    JQgTtbVstqFZwEK1  1.327230e+06\n",
       "29    bCSDbEthlS3nSIor  2.895804e+06\n",
       "...                ...           ...\n",
       "9970  QL412tWF5RDIX7IO -3.030862e+06\n",
       "9971  d3c2ceGtckONZzsr  1.741138e+06\n",
       "9972  P1j8YRbxDAovumaI  9.952168e+06\n",
       "9973  IxcBhEoFLcrI9TPr  4.408756e+06\n",
       "9974  rKiV0KDbAl2myBQI  1.293370e+06\n",
       "9975  GSdIXmKr0g5jQQcF -3.571346e+06\n",
       "9976  Am6Wcg3TO64qvzd8  2.777762e+07\n",
       "9977  RZqACAhkL4Tgw4Jr  9.986374e+07\n",
       "9978  u7NKZfWoMUlZy9rJ  7.645667e+06\n",
       "9979  C1BqV4MWH15rjAgz  2.681173e+06\n",
       "9980  wz8A2UbwsgR0lXGJ  2.993034e+06\n",
       "9981  MGJ8ABBTmC2yIaSm  7.546485e+05\n",
       "9982  MjHL2HP1PGIp8aBt  5.434886e+06\n",
       "9983  FMz7nnURFn85LaGt  8.211306e+06\n",
       "9984  kydULx0r0G7OklRD  5.216309e+06\n",
       "9985  nVNYRuk2fRbtlV00  4.154064e+07\n",
       "9986  F8SGEOGPxrPfiRv2 -3.005466e+06\n",
       "9987  w7VMfiMvRb765ejK  4.450637e+07\n",
       "9988  lgZWdUKliWt2y5sM  1.176073e+07\n",
       "9989  TER8YrP9mw7UwWwr  6.867172e+06\n",
       "9990  TXHk3oUpVsm5Cmag  7.944416e+06\n",
       "9991  JtgDm9aQcGE9zELB  4.985268e+06\n",
       "9992  wTQmcqbN0OCuSF1t  3.434268e+07\n",
       "9993  WgsI1cBtzSfiWA1j  4.672384e+07\n",
       "9994  qNgt1ajb5uVMKbqm  1.301363e+07\n",
       "9995  UEeCDaAJzPwdKKKA -5.132256e+05\n",
       "9996  i0fgbPaQsDWs7Q87  1.768069e+07\n",
       "9997  YunNwAhcqkf6YclI  7.889846e+05\n",
       "9998  A2NotxtRY9MYoWMl  1.241324e+07\n",
       "9999  kKvgBXiA50gRmQhP -1.161348e+06\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.read_csv('./dataset-0510/submit_test.csv')\n",
    "submission['total_price'] = pred\n",
    "submission.to_csv('submission/TuningDNN_result.csv', index=False)\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
