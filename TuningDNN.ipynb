{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.feature_selection import SelectFromModel, RFE\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler,scale, MaxAbsScaler # MaxAbs is process sparse data\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "from torch import nn, optim\n",
    "import torch.nn.init as init\n",
    "import torch.utils.data as Data\n",
    "import math\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.multiprocessing as mp\n",
    "# add tuning \n",
    "from skorch import NeuralNetRegressor\n",
    "from skorch.callbacks import EpochScoring\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp.set_start_method('spawn')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### default hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "use_gpu = True\n",
    "y_scale = True\n",
    "lr = 0.001\n",
    "weight_decay = 0.0005\n",
    "\n",
    "# Batch size and learning rate is hyperparameters in deep learning\n",
    "# suggest batch_size is reduced, lr is also reduced which will reduce concussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## using CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## reading file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv('./dataset-0510/train.csv')\n",
    "X_test = pd.read_csv('./dataset-0510/test.csv')\n",
    "\n",
    "columns = X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = X['total_price']\n",
    "X = X.drop(columns=['building_id', 'total_price'], axis=1)\n",
    "X_test = X_test.drop(columns=['building_id'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(233, 256)\n",
    "        self.bn1 = nn.BatchNorm1d(num_features=256)\n",
    "        \n",
    "        self.fc2 = nn.Linear(256, 512)\n",
    "        self.bn2 = nn.BatchNorm1d(num_features=512)\n",
    "        \n",
    "        self.fc3 = nn.Linear(512, 512)\n",
    "        self.bn3 = nn.BatchNorm1d(num_features=512)\n",
    "        \n",
    "        self.fc4 = nn.Linear(512, 256)\n",
    "        self.bn4 = nn.BatchNorm1d(num_features=256)\n",
    "        \n",
    "        self.fc5 = nn.Linear(256, 128)\n",
    "        self.bn5 = nn.BatchNorm1d(num_features=128)\n",
    "        \n",
    "        self.fc6 = nn.Linear(128, 64)\n",
    "        self.bn6 = nn.BatchNorm1d(num_features=64)\n",
    "        \n",
    "        self.fc7 = nn.Linear(64, 32)\n",
    "        self.bn7 = nn.BatchNorm1d(num_features=32)\n",
    "        \n",
    "        self.fc8 = nn.Linear(32, 1)\n",
    "        \n",
    "        \n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        #x = x.unsqueeze(0)\n",
    "        \n",
    "        x = F.relu(self.bn1(self.fc1(x)))\n",
    "        x = F.relu(self.bn2(self.fc2(x)))\n",
    "        x = F.relu(self.bn3(self.fc3(x)))\n",
    "        x = F.relu(self.bn4(self.fc4(x)))\n",
    "        x = F.relu(self.bn5(self.fc5(x)))\n",
    "        x = F.relu(self.bn6(self.fc6(x)))\n",
    "        x = F.relu(self.bn7(self.fc7(x)))\n",
    "        x = self.fc8(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pipline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/islab/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:66: DeprecationWarning: Class Imputer is deprecated; Imputer was deprecated in version 0.20 and will be removed in 0.22. Import impute.SimpleImputer from sklearn instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# step1. Imputation transformer for completing missing values.\n",
    "step1 = ('Imputer', Imputer())\n",
    "# step2. MinMaxScaler\n",
    "step2 = ('MinMaxScaler', MinMaxScaler())\n",
    "# step3. feature selection\n",
    "#step3 = ('FeatureSelection', SelectFromModel(RandomForestRegressor()))\n",
    "step3 = ('FeatureSelection', VarianceThreshold())\n",
    "\n",
    "pipeline = Pipeline(steps=[step1, step2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X = pipeline.fit_transform(X)\n",
    "\n",
    "X_test = pipeline.transform(X_test)\n",
    "\n",
    "y_scaler = MaxAbsScaler()\n",
    "y = y_scaler.fit_transform(y.values.reshape(-1, 1))\n",
    "# MaxAbs 0.00012\n",
    "# MinMax 0.0008"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 233)\n",
      "(10000, 233)\n",
      "(60000, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.00012727],\n",
       "       [0.00065277],\n",
       "       [0.00188097],\n",
       "       ...,\n",
       "       [0.00232208],\n",
       "       [0.00355425],\n",
       "       [0.00167253]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(X.shape)\n",
    "\n",
    "print(X_test.shape)\n",
    "\n",
    "print(y.shape)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.from_numpy(X).float().to(device)\n",
    "X_test = torch.from_numpy(X_test).float().to(device)\n",
    "y = torch.from_numpy(y).float().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SqrtMSELoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "    def forward(self, x, y):\n",
    "        return torch.sqrt(torch.mean(torch.pow((x - y), 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc = EpochScoring(scoring='neg_mean_squared_error', lower_is_better=False)\n",
    "\n",
    "net = NeuralNetRegressor(\n",
    "    DNN,\n",
    "    max_epochs=10,\n",
    "    lr=0.001,\n",
    "    # Shuffle training data on each epoch\n",
    "    iterator_train__shuffle=True,\n",
    "    callbacks=[auc],\n",
    "    device='cuda',\n",
    "    criterion= SqrtMSELoss,\n",
    ")\n",
    "\n",
    "#net.fit(X, y)\n",
    "#y_proba = net.predict_proba(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    neg_mean_squared_error    train_loss    valid_loss     dur\n",
      "-------  ------------------------  ------------  ------------  ------\n",
      "      1                   \u001b[36m-0.0075\u001b[0m        \u001b[32m0.1224\u001b[0m        \u001b[35m0.0864\u001b[0m  1.1858\n",
      "      2                   \u001b[36m-0.0036\u001b[0m        \u001b[32m0.0734\u001b[0m        \u001b[35m0.0598\u001b[0m  1.0619\n",
      "      3                   \u001b[36m-0.0022\u001b[0m        \u001b[32m0.0535\u001b[0m        \u001b[35m0.0467\u001b[0m  1.0448\n",
      "      4                   \u001b[36m-0.0014\u001b[0m        \u001b[32m0.0421\u001b[0m        \u001b[35m0.0370\u001b[0m  1.0511\n",
      "      5                   \u001b[36m-0.0010\u001b[0m        \u001b[32m0.0349\u001b[0m        \u001b[35m0.0311\u001b[0m  1.0447\n",
      "      6                   \u001b[36m-0.0007\u001b[0m        \u001b[32m0.0295\u001b[0m        \u001b[35m0.0267\u001b[0m  1.0447\n",
      "      7                   \u001b[36m-0.0005\u001b[0m        \u001b[32m0.0255\u001b[0m        \u001b[35m0.0229\u001b[0m  1.0507\n",
      "      8                   \u001b[36m-0.0004\u001b[0m        \u001b[32m0.0225\u001b[0m        \u001b[35m0.0203\u001b[0m  1.0507\n",
      "      9                   \u001b[36m-0.0003\u001b[0m        \u001b[32m0.0201\u001b[0m        \u001b[35m0.0182\u001b[0m  1.0457\n",
      "     10                   \u001b[36m-0.0003\u001b[0m        \u001b[32m0.0181\u001b[0m        \u001b[35m0.0165\u001b[0m  1.0379\n",
      "  epoch    neg_mean_squared_error    train_loss    valid_loss     dur\n",
      "-------  ------------------------  ------------  ------------  ------\n",
      "      1                   \u001b[36m-0.0081\u001b[0m        \u001b[32m0.1396\u001b[0m        \u001b[35m0.0898\u001b[0m  1.0477\n",
      "      2                   \u001b[36m-0.0040\u001b[0m        \u001b[32m0.0763\u001b[0m        \u001b[35m0.0630\u001b[0m  1.0515\n",
      "      3                   \u001b[36m-0.0023\u001b[0m        \u001b[32m0.0552\u001b[0m        \u001b[35m0.0478\u001b[0m  1.0442\n",
      "      4                   \u001b[36m-0.0016\u001b[0m        \u001b[32m0.0427\u001b[0m        \u001b[35m0.0392\u001b[0m  1.0510\n",
      "      5                   \u001b[36m-0.0011\u001b[0m        \u001b[32m0.0347\u001b[0m        \u001b[35m0.0322\u001b[0m  1.0479\n",
      "      6                   \u001b[36m-0.0008\u001b[0m        \u001b[32m0.0285\u001b[0m        \u001b[35m0.0269\u001b[0m  1.0487\n",
      "      7                   \u001b[36m-0.0006\u001b[0m        \u001b[32m0.0242\u001b[0m        \u001b[35m0.0232\u001b[0m  1.0459\n",
      "      8                   \u001b[36m-0.0005\u001b[0m        \u001b[32m0.0209\u001b[0m        \u001b[35m0.0204\u001b[0m  1.0521\n",
      "      9                   \u001b[36m-0.0004\u001b[0m        \u001b[32m0.0184\u001b[0m        \u001b[35m0.0185\u001b[0m  1.0459\n",
      "     10                   \u001b[36m-0.0004\u001b[0m        \u001b[32m0.0165\u001b[0m        \u001b[35m0.0164\u001b[0m  1.0500\n",
      "  epoch    neg_mean_squared_error    train_loss    valid_loss     dur\n",
      "-------  ------------------------  ------------  ------------  ------\n",
      "      1                   \u001b[36m-0.0097\u001b[0m        \u001b[32m0.1602\u001b[0m        \u001b[35m0.0979\u001b[0m  1.0515\n",
      "      2                   \u001b[36m-0.0049\u001b[0m        \u001b[32m0.0819\u001b[0m        \u001b[35m0.0693\u001b[0m  1.0494\n",
      "      3                   \u001b[36m-0.0029\u001b[0m        \u001b[32m0.0601\u001b[0m        \u001b[35m0.0533\u001b[0m  1.0434\n",
      "      4                   \u001b[36m-0.0020\u001b[0m        \u001b[32m0.0483\u001b[0m        \u001b[35m0.0443\u001b[0m  1.0473\n",
      "      5                   \u001b[36m-0.0015\u001b[0m        \u001b[32m0.0399\u001b[0m        \u001b[35m0.0377\u001b[0m  1.0457\n",
      "      6                   \u001b[36m-0.0011\u001b[0m        \u001b[32m0.0337\u001b[0m        \u001b[35m0.0318\u001b[0m  1.0491\n",
      "      7                   \u001b[36m-0.0008\u001b[0m        \u001b[32m0.0291\u001b[0m        \u001b[35m0.0275\u001b[0m  1.0472\n",
      "      8                   \u001b[36m-0.0007\u001b[0m        \u001b[32m0.0256\u001b[0m        \u001b[35m0.0243\u001b[0m  1.0472\n",
      "      9                   \u001b[36m-0.0006\u001b[0m        \u001b[32m0.0227\u001b[0m        \u001b[35m0.0218\u001b[0m  1.0399\n",
      "     10                   \u001b[36m-0.0005\u001b[0m        \u001b[32m0.0204\u001b[0m        \u001b[35m0.0199\u001b[0m  1.0474\n",
      "  epoch    neg_mean_squared_error    train_loss    valid_loss     dur\n",
      "-------  ------------------------  ------------  ------------  ------\n",
      "      1                   \u001b[36m-0.0054\u001b[0m        \u001b[32m0.1266\u001b[0m        \u001b[35m0.0732\u001b[0m  1.0406\n",
      "      2                   \u001b[36m-0.0025\u001b[0m        \u001b[32m0.0607\u001b[0m        \u001b[35m0.0495\u001b[0m  1.0467\n",
      "      3                   \u001b[36m-0.0014\u001b[0m        \u001b[32m0.0430\u001b[0m        \u001b[35m0.0366\u001b[0m  1.0457\n",
      "      4                   \u001b[36m-0.0009\u001b[0m        \u001b[32m0.0338\u001b[0m        \u001b[35m0.0296\u001b[0m  1.0509\n",
      "      5                   \u001b[36m-0.0006\u001b[0m        \u001b[32m0.0276\u001b[0m        \u001b[35m0.0245\u001b[0m  1.0498\n",
      "      6                   \u001b[36m-0.0005\u001b[0m        \u001b[32m0.0234\u001b[0m        \u001b[35m0.0210\u001b[0m  1.0527\n",
      "      7                   \u001b[36m-0.0004\u001b[0m        \u001b[32m0.0204\u001b[0m        \u001b[35m0.0185\u001b[0m  1.0561\n",
      "      8                   \u001b[36m-0.0003\u001b[0m        \u001b[32m0.0183\u001b[0m        \u001b[35m0.0166\u001b[0m  1.0548\n",
      "      9                   \u001b[36m-0.0002\u001b[0m        \u001b[32m0.0164\u001b[0m        \u001b[35m0.0150\u001b[0m  1.0585\n",
      "     10                   \u001b[36m-0.0002\u001b[0m        \u001b[32m0.0149\u001b[0m        \u001b[35m0.0138\u001b[0m  1.0576\n",
      "  epoch    neg_mean_squared_error    train_loss    valid_loss     dur\n",
      "-------  ------------------------  ------------  ------------  ------\n",
      "      1                   \u001b[36m-0.0082\u001b[0m        \u001b[32m0.1431\u001b[0m        \u001b[35m0.0903\u001b[0m  1.0500\n",
      "      2                   \u001b[36m-0.0034\u001b[0m        \u001b[32m0.0721\u001b[0m        \u001b[35m0.0580\u001b[0m  1.0511\n",
      "      3                   \u001b[36m-0.0019\u001b[0m        \u001b[32m0.0488\u001b[0m        \u001b[35m0.0426\u001b[0m  1.0525\n",
      "      4                   \u001b[36m-0.0012\u001b[0m        \u001b[32m0.0363\u001b[0m        \u001b[35m0.0334\u001b[0m  1.0533\n",
      "      5                   \u001b[36m-0.0008\u001b[0m        \u001b[32m0.0292\u001b[0m        \u001b[35m0.0262\u001b[0m  1.0473\n",
      "      6                   \u001b[36m-0.0006\u001b[0m        \u001b[32m0.0240\u001b[0m        \u001b[35m0.0229\u001b[0m  1.0567\n",
      "      7                   \u001b[36m-0.0005\u001b[0m        \u001b[32m0.0207\u001b[0m        \u001b[35m0.0201\u001b[0m  1.0524\n",
      "      8                   \u001b[36m-0.0004\u001b[0m        \u001b[32m0.0182\u001b[0m        \u001b[35m0.0179\u001b[0m  1.0429\n",
      "      9                   \u001b[36m-0.0003\u001b[0m        \u001b[32m0.0162\u001b[0m        \u001b[35m0.0154\u001b[0m  1.0554\n",
      "     10                   \u001b[36m-0.0003\u001b[0m        \u001b[32m0.0147\u001b[0m        \u001b[35m0.0139\u001b[0m  1.0573\n",
      "  epoch    neg_mean_squared_error    train_loss    valid_loss     dur\n",
      "-------  ------------------------  ------------  ------------  ------\n",
      "      1                   \u001b[36m-0.0067\u001b[0m        \u001b[32m0.1348\u001b[0m        \u001b[35m0.0814\u001b[0m  1.0534\n",
      "      2                   \u001b[36m-0.0025\u001b[0m        \u001b[32m0.0622\u001b[0m        \u001b[35m0.0497\u001b[0m  1.0534\n",
      "      3                   \u001b[36m-0.0014\u001b[0m        \u001b[32m0.0412\u001b[0m        \u001b[35m0.0361\u001b[0m  1.0585\n",
      "      4                   \u001b[36m-0.0008\u001b[0m        \u001b[32m0.0304\u001b[0m        \u001b[35m0.0274\u001b[0m  1.0546\n",
      "      5                   \u001b[36m-0.0006\u001b[0m        \u001b[32m0.0241\u001b[0m        \u001b[35m0.0227\u001b[0m  1.0518\n",
      "      6                   \u001b[36m-0.0004\u001b[0m        \u001b[32m0.0200\u001b[0m        \u001b[35m0.0189\u001b[0m  1.0539\n",
      "      7                   \u001b[36m-0.0004\u001b[0m        \u001b[32m0.0170\u001b[0m        \u001b[35m0.0164\u001b[0m  1.0510\n",
      "      8                   \u001b[36m-0.0003\u001b[0m        \u001b[32m0.0150\u001b[0m        \u001b[35m0.0147\u001b[0m  1.0510\n",
      "      9                   \u001b[36m-0.0003\u001b[0m        \u001b[32m0.0134\u001b[0m        \u001b[35m0.0133\u001b[0m  1.0535\n",
      "     10                   \u001b[36m-0.0003\u001b[0m        \u001b[32m0.0120\u001b[0m        \u001b[35m0.0122\u001b[0m  1.0539\n",
      "  epoch    neg_mean_squared_error    train_loss    valid_loss     dur\n",
      "-------  ------------------------  ------------  ------------  ------\n",
      "      1                   \u001b[36m-0.0022\u001b[0m        \u001b[32m0.0838\u001b[0m        \u001b[35m0.0466\u001b[0m  1.0559\n",
      "      2                   \u001b[36m-0.0008\u001b[0m        \u001b[32m0.0364\u001b[0m        \u001b[35m0.0275\u001b[0m  1.0526\n",
      "      3                   \u001b[36m-0.0004\u001b[0m        \u001b[32m0.0238\u001b[0m        \u001b[35m0.0191\u001b[0m  1.0562\n",
      "      4                   \u001b[36m-0.0002\u001b[0m        \u001b[32m0.0178\u001b[0m        \u001b[35m0.0148\u001b[0m  1.0523\n",
      "      5                   \u001b[36m-0.0002\u001b[0m        \u001b[32m0.0145\u001b[0m        \u001b[35m0.0126\u001b[0m  1.0532\n",
      "      6                   \u001b[36m-0.0001\u001b[0m        \u001b[32m0.0124\u001b[0m        \u001b[35m0.0107\u001b[0m  1.0545\n",
      "      7                   \u001b[36m-0.0001\u001b[0m        \u001b[32m0.0111\u001b[0m        \u001b[35m0.0097\u001b[0m  1.0365\n",
      "      8                   \u001b[36m-0.0001\u001b[0m        \u001b[32m0.0101\u001b[0m        \u001b[35m0.0088\u001b[0m  1.0496\n",
      "      9                   \u001b[36m-0.0001\u001b[0m        \u001b[32m0.0094\u001b[0m        \u001b[35m0.0083\u001b[0m  1.0554\n",
      "     10                   \u001b[36m-0.0001\u001b[0m        \u001b[32m0.0089\u001b[0m        \u001b[35m0.0078\u001b[0m  1.0492\n",
      "  epoch    neg_mean_squared_error    train_loss    valid_loss     dur\n",
      "-------  ------------------------  ------------  ------------  ------\n",
      "      1                   \u001b[36m-0.0018\u001b[0m        \u001b[32m0.0867\u001b[0m        \u001b[35m0.0413\u001b[0m  1.0510\n",
      "      2                   \u001b[36m-0.0007\u001b[0m        \u001b[32m0.0305\u001b[0m        \u001b[35m0.0245\u001b[0m  1.0553\n",
      "      3                   \u001b[36m-0.0004\u001b[0m        \u001b[32m0.0206\u001b[0m        \u001b[35m0.0185\u001b[0m  1.0594\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      4                   \u001b[36m-0.0003\u001b[0m        \u001b[32m0.0161\u001b[0m        \u001b[35m0.0152\u001b[0m  1.0535\n",
      "      5                   \u001b[36m-0.0003\u001b[0m        \u001b[32m0.0136\u001b[0m        \u001b[35m0.0129\u001b[0m  1.0524\n",
      "      6                   \u001b[36m-0.0002\u001b[0m        \u001b[32m0.0119\u001b[0m        \u001b[35m0.0117\u001b[0m  1.0513\n",
      "      7                   \u001b[36m-0.0002\u001b[0m        \u001b[32m0.0108\u001b[0m        \u001b[35m0.0108\u001b[0m  1.0604\n",
      "      8                   \u001b[36m-0.0002\u001b[0m        \u001b[32m0.0099\u001b[0m        \u001b[35m0.0100\u001b[0m  1.0528\n"
     ]
    }
   ],
   "source": [
    "X = X.astype(np.float32)\n",
    "y = y.astype(np.float32)\n",
    "\n",
    "params = {\n",
    "    'lr': [0.001, 0.0015, 0.003, 0.005],\n",
    "    #'max_epochs': [2000, 5000],\n",
    "}\n",
    "gs = GridSearchCV(net, params, refit=False, cv=3, scoring='neg_mean_squared_error')\n",
    "\n",
    "gs.fit(X, y)\n",
    "print(gs.best_score_, gs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_proba = net.predict_proba(X_test)\n",
    "pred = y_scaler.inverse_transform(y_proba)       \n",
    "print(pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>building_id</th>\n",
       "      <th>total_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>X5gsdTWGS3W7JJQB</td>\n",
       "      <td>2.085470e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BTshNOJyKHnT2YIT</td>\n",
       "      <td>8.500902e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dhdymr0lV8N5kZOT</td>\n",
       "      <td>7.683752e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>VEwyGGMcD56w5BOc</td>\n",
       "      <td>9.981914e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>wmUeMoJZfsqaSX9b</td>\n",
       "      <td>5.877293e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>EtBjGAHmHCe9t7TZ</td>\n",
       "      <td>1.415726e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>hPNH34vmaZtvBtqc</td>\n",
       "      <td>1.381302e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>wXjeI38bYDMJJwZC</td>\n",
       "      <td>-6.184460e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>fxZSGX6aPAFKU8W4</td>\n",
       "      <td>-7.499238e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ewr0Fx6ign87OwaV</td>\n",
       "      <td>-6.231330e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>gHKurnEP4AowzsLg</td>\n",
       "      <td>1.143969e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>PmLfTgY2FElLrTl0</td>\n",
       "      <td>1.502866e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>eM2NppIOwzW0o8iy</td>\n",
       "      <td>7.482906e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>dxxwNun97NH4WTrZ</td>\n",
       "      <td>-2.226149e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>jykBfhh3vdeFUi3H</td>\n",
       "      <td>-4.635274e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>NlXbvdFfmJZf3L18</td>\n",
       "      <td>1.378339e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>D7jaFWHCzSqLBwdt</td>\n",
       "      <td>-7.218017e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>L10dBBdqGmemweSl</td>\n",
       "      <td>2.624886e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>OgB0AdiPKlElakKN</td>\n",
       "      <td>-7.399115e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>StiWNN1GQrpPBOYt</td>\n",
       "      <td>-3.269799e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>a016eMAVQKnfwMnt</td>\n",
       "      <td>-5.613142e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>gsCFcQHnOH3AKMcZ</td>\n",
       "      <td>2.172695e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>IbNsDXfsPwSuFpow</td>\n",
       "      <td>1.702904e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>EgAVWOVxD1Jy5YkE</td>\n",
       "      <td>-1.321436e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>BrKghvR76XdbQPnx</td>\n",
       "      <td>1.129163e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>a7fxkXTnUGWHUmKG</td>\n",
       "      <td>4.521217e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>WgzXa170DfpzpURE</td>\n",
       "      <td>6.405656e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>JPWqZbLq0VNC0yKI</td>\n",
       "      <td>5.033824e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>JQgTtbVstqFZwEK1</td>\n",
       "      <td>-4.046679e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>bCSDbEthlS3nSIor</td>\n",
       "      <td>2.956426e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9970</th>\n",
       "      <td>QL412tWF5RDIX7IO</td>\n",
       "      <td>-9.270505e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9971</th>\n",
       "      <td>d3c2ceGtckONZzsr</td>\n",
       "      <td>2.815418e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9972</th>\n",
       "      <td>P1j8YRbxDAovumaI</td>\n",
       "      <td>-5.217618e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9973</th>\n",
       "      <td>IxcBhEoFLcrI9TPr</td>\n",
       "      <td>1.157924e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9974</th>\n",
       "      <td>rKiV0KDbAl2myBQI</td>\n",
       "      <td>6.882317e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9975</th>\n",
       "      <td>GSdIXmKr0g5jQQcF</td>\n",
       "      <td>-1.263082e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9976</th>\n",
       "      <td>Am6Wcg3TO64qvzd8</td>\n",
       "      <td>-2.258302e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9977</th>\n",
       "      <td>RZqACAhkL4Tgw4Jr</td>\n",
       "      <td>-6.411594e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9978</th>\n",
       "      <td>u7NKZfWoMUlZy9rJ</td>\n",
       "      <td>-6.861040e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9979</th>\n",
       "      <td>C1BqV4MWH15rjAgz</td>\n",
       "      <td>-8.482967e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9980</th>\n",
       "      <td>wz8A2UbwsgR0lXGJ</td>\n",
       "      <td>8.332906e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9981</th>\n",
       "      <td>MGJ8ABBTmC2yIaSm</td>\n",
       "      <td>-2.792938e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9982</th>\n",
       "      <td>MjHL2HP1PGIp8aBt</td>\n",
       "      <td>1.977112e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9983</th>\n",
       "      <td>FMz7nnURFn85LaGt</td>\n",
       "      <td>-1.177211e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9984</th>\n",
       "      <td>kydULx0r0G7OklRD</td>\n",
       "      <td>-5.352129e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9985</th>\n",
       "      <td>nVNYRuk2fRbtlV00</td>\n",
       "      <td>-6.138347e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9986</th>\n",
       "      <td>F8SGEOGPxrPfiRv2</td>\n",
       "      <td>4.972916e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9987</th>\n",
       "      <td>w7VMfiMvRb765ejK</td>\n",
       "      <td>5.450106e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9988</th>\n",
       "      <td>lgZWdUKliWt2y5sM</td>\n",
       "      <td>1.196780e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9989</th>\n",
       "      <td>TER8YrP9mw7UwWwr</td>\n",
       "      <td>6.183394e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9990</th>\n",
       "      <td>TXHk3oUpVsm5Cmag</td>\n",
       "      <td>4.539065e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9991</th>\n",
       "      <td>JtgDm9aQcGE9zELB</td>\n",
       "      <td>3.854207e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9992</th>\n",
       "      <td>wTQmcqbN0OCuSF1t</td>\n",
       "      <td>2.417260e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9993</th>\n",
       "      <td>WgsI1cBtzSfiWA1j</td>\n",
       "      <td>-2.978591e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9994</th>\n",
       "      <td>qNgt1ajb5uVMKbqm</td>\n",
       "      <td>3.480702e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>UEeCDaAJzPwdKKKA</td>\n",
       "      <td>1.296964e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>i0fgbPaQsDWs7Q87</td>\n",
       "      <td>-1.868753e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>YunNwAhcqkf6YclI</td>\n",
       "      <td>5.782412e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>A2NotxtRY9MYoWMl</td>\n",
       "      <td>-1.322042e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>kKvgBXiA50gRmQhP</td>\n",
       "      <td>-5.017334e+07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           building_id   total_price\n",
       "0     X5gsdTWGS3W7JJQB  2.085470e+07\n",
       "1     BTshNOJyKHnT2YIT  8.500902e+07\n",
       "2     dhdymr0lV8N5kZOT  7.683752e+07\n",
       "3     VEwyGGMcD56w5BOc  9.981914e+07\n",
       "4     wmUeMoJZfsqaSX9b  5.877293e+06\n",
       "5     EtBjGAHmHCe9t7TZ  1.415726e+07\n",
       "6     hPNH34vmaZtvBtqc  1.381302e+07\n",
       "7     wXjeI38bYDMJJwZC -6.184460e+07\n",
       "8     fxZSGX6aPAFKU8W4 -7.499238e+07\n",
       "9     ewr0Fx6ign87OwaV -6.231330e+07\n",
       "10    gHKurnEP4AowzsLg  1.143969e+07\n",
       "11    PmLfTgY2FElLrTl0  1.502866e+08\n",
       "12    eM2NppIOwzW0o8iy  7.482906e+07\n",
       "13    dxxwNun97NH4WTrZ -2.226149e+07\n",
       "14    jykBfhh3vdeFUi3H -4.635274e+07\n",
       "15    NlXbvdFfmJZf3L18  1.378339e+08\n",
       "16    D7jaFWHCzSqLBwdt -7.218017e+07\n",
       "17    L10dBBdqGmemweSl  2.624886e+06\n",
       "18    OgB0AdiPKlElakKN -7.399115e+07\n",
       "19    StiWNN1GQrpPBOYt -3.269799e+05\n",
       "20    a016eMAVQKnfwMnt -5.613142e+07\n",
       "21    gsCFcQHnOH3AKMcZ  2.172695e+07\n",
       "22    IbNsDXfsPwSuFpow  1.702904e+08\n",
       "23    EgAVWOVxD1Jy5YkE -1.321436e+07\n",
       "24    BrKghvR76XdbQPnx  1.129163e+07\n",
       "25    a7fxkXTnUGWHUmKG  4.521217e+07\n",
       "26    WgzXa170DfpzpURE  6.405656e+07\n",
       "27    JPWqZbLq0VNC0yKI  5.033824e+07\n",
       "28    JQgTtbVstqFZwEK1 -4.046679e+07\n",
       "29    bCSDbEthlS3nSIor  2.956426e+07\n",
       "...                ...           ...\n",
       "9970  QL412tWF5RDIX7IO -9.270505e+07\n",
       "9971  d3c2ceGtckONZzsr  2.815418e+07\n",
       "9972  P1j8YRbxDAovumaI -5.217618e+07\n",
       "9973  IxcBhEoFLcrI9TPr  1.157924e+07\n",
       "9974  rKiV0KDbAl2myBQI  6.882317e+07\n",
       "9975  GSdIXmKr0g5jQQcF -1.263082e+08\n",
       "9976  Am6Wcg3TO64qvzd8 -2.258302e+07\n",
       "9977  RZqACAhkL4Tgw4Jr -6.411594e+06\n",
       "9978  u7NKZfWoMUlZy9rJ -6.861040e+07\n",
       "9979  C1BqV4MWH15rjAgz -8.482967e+07\n",
       "9980  wz8A2UbwsgR0lXGJ  8.332906e+07\n",
       "9981  MGJ8ABBTmC2yIaSm -2.792938e+07\n",
       "9982  MjHL2HP1PGIp8aBt  1.977112e+07\n",
       "9983  FMz7nnURFn85LaGt -1.177211e+07\n",
       "9984  kydULx0r0G7OklRD -5.352129e+07\n",
       "9985  nVNYRuk2fRbtlV00 -6.138347e+07\n",
       "9986  F8SGEOGPxrPfiRv2  4.972916e+07\n",
       "9987  w7VMfiMvRb765ejK  5.450106e+07\n",
       "9988  lgZWdUKliWt2y5sM  1.196780e+08\n",
       "9989  TER8YrP9mw7UwWwr  6.183394e+07\n",
       "9990  TXHk3oUpVsm5Cmag  4.539065e+05\n",
       "9991  JtgDm9aQcGE9zELB  3.854207e+07\n",
       "9992  wTQmcqbN0OCuSF1t  2.417260e+07\n",
       "9993  WgsI1cBtzSfiWA1j -2.978591e+07\n",
       "9994  qNgt1ajb5uVMKbqm  3.480702e+07\n",
       "9995  UEeCDaAJzPwdKKKA  1.296964e+08\n",
       "9996  i0fgbPaQsDWs7Q87 -1.868753e+08\n",
       "9997  YunNwAhcqkf6YclI  5.782412e+07\n",
       "9998  A2NotxtRY9MYoWMl -1.322042e+08\n",
       "9999  kKvgBXiA50gRmQhP -5.017334e+07\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.read_csv('./dataset-0510/submit_test.csv')\n",
    "submission['total_price'] = pred\n",
    "submission.to_csv('submission/TuningDNN_result.csv', index=False)\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
