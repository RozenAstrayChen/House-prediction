{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.feature_selection import SelectFromModel, RFE\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler,scale, MaxAbsScaler # MaxAbs is process sparse data\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "from torch import nn, optim\n",
    "import torch.nn.init as init\n",
    "import torch.utils.data as Data\n",
    "import math\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.multiprocessing as mp\n",
    "# add tuning \n",
    "from skorch import NeuralNetRegressor\n",
    "from skorch.callbacks import EpochScoring\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp.set_start_method('spawn')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### default hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "use_gpu = True\n",
    "y_scale = True\n",
    "lr = 0.001\n",
    "weight_decay = 0.0005\n",
    "\n",
    "# Batch size and learning rate is hyperparameters in deep learning\n",
    "# suggest batch_size is reduced, lr is also reduced which will reduce concussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## using CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## reading file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv('./dataset-0510/train.csv')\n",
    "X_test = pd.read_csv('./dataset-0510/test.csv')\n",
    "\n",
    "columns = X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = X['total_price']\n",
    "X = X.drop(columns=['building_id', 'total_price'], axis=1)\n",
    "X_test = X_test.drop(columns=['building_id'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(233, 256)\n",
    "        self.bn1 = nn.BatchNorm1d(num_features=256)\n",
    "        \n",
    "        self.fc2 = nn.Linear(256, 512)\n",
    "        self.bn2 = nn.BatchNorm1d(num_features=512)\n",
    "        \n",
    "        self.fc3 = nn.Linear(512, 512)\n",
    "        self.bn3 = nn.BatchNorm1d(num_features=512)\n",
    "        \n",
    "        self.fc4 = nn.Linear(512, 256)\n",
    "        self.bn4 = nn.BatchNorm1d(num_features=256)\n",
    "        \n",
    "        self.fc5 = nn.Linear(256, 128)\n",
    "        self.bn5 = nn.BatchNorm1d(num_features=128)\n",
    "        \n",
    "        self.fc6 = nn.Linear(128, 64)\n",
    "        self.bn6 = nn.BatchNorm1d(num_features=64)\n",
    "        \n",
    "        self.fc7 = nn.Linear(64, 32)\n",
    "        self.bn7 = nn.BatchNorm1d(num_features=32)\n",
    "        \n",
    "        self.fc8 = nn.Linear(32, 1)\n",
    "        \n",
    "        \n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        #x = x.unsqueeze(0)\n",
    "        \n",
    "        x = F.relu(self.bn1(self.fc1(x)))\n",
    "        x = F.relu(self.bn2(self.fc2(x)))\n",
    "        x = F.relu(self.bn3(self.fc3(x)))\n",
    "        x = F.relu(self.bn4(self.fc4(x)))\n",
    "        x = F.relu(self.bn5(self.fc5(x)))\n",
    "        x = F.relu(self.bn6(self.fc6(x)))\n",
    "        x = F.relu(self.bn7(self.fc7(x)))\n",
    "        x = self.fc8(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pipline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/islab/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:66: DeprecationWarning: Class Imputer is deprecated; Imputer was deprecated in version 0.20 and will be removed in 0.22. Import impute.SimpleImputer from sklearn instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# step1. Imputation transformer for completing missing values.\n",
    "step1 = ('Imputer', Imputer())\n",
    "# step2. MinMaxScaler\n",
    "step2 = ('MinMaxScaler', MinMaxScaler())\n",
    "# step3. feature selection\n",
    "#step3 = ('FeatureSelection', SelectFromModel(RandomForestRegressor()))\n",
    "step3 = ('FeatureSelection', VarianceThreshold())\n",
    "\n",
    "pipeline = Pipeline(steps=[step1, step2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X = pipeline.fit_transform(X)\n",
    "\n",
    "X_test = pipeline.transform(X_test)\n",
    "\n",
    "y_scaler = MaxAbsScaler()\n",
    "y = y_scaler.fit_transform(y.values.reshape(-1, 1))\n",
    "# MaxAbs 0.00012\n",
    "# MinMax 0.0008"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 233)\n",
      "(10000, 233)\n",
      "(60000, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.00012727],\n",
       "       [0.00065277],\n",
       "       [0.00188097],\n",
       "       ...,\n",
       "       [0.00232208],\n",
       "       [0.00355425],\n",
       "       [0.00167253]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(X.shape)\n",
    "\n",
    "print(X_test.shape)\n",
    "\n",
    "print(y.shape)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.from_numpy(X).float().to(device)\n",
    "X_test = torch.from_numpy(X_test).float().to(device)\n",
    "y = torch.from_numpy(y).float().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SqrtMSELoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "    def forward(self, x, y):\n",
    "        return torch.sqrt(torch.mean(torch.pow((x - y), 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc = EpochScoring(scoring='neg_mean_squared_error', lower_is_better=False)\n",
    "\n",
    "net = NeuralNetRegressor(\n",
    "    DNN,\n",
    "    max_epochs=10,\n",
    "    lr=0.001,\n",
    "    # Shuffle training data on each epoch\n",
    "    iterator_train__shuffle=True,\n",
    "    callbacks=[auc],\n",
    "    device='cuda',\n",
    "    criterion= SqrtMSELoss,\n",
    ")\n",
    "\n",
    "#net.fit(X, y)\n",
    "#y_proba = net.predict_proba(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch         r2    train_loss    valid_loss     dur\n",
      "-------  ---------  ------------  ------------  ------\n",
      "      1  \u001b[36m-136.6220\u001b[0m        \u001b[32m0.1543\u001b[0m        \u001b[35m0.1006\u001b[0m  1.1904\n",
      "      2  \u001b[36m-50.0385\u001b[0m        \u001b[32m0.0778\u001b[0m        \u001b[35m0.0613\u001b[0m  1.0534\n",
      "      3  \u001b[36m-25.8976\u001b[0m        \u001b[32m0.0529\u001b[0m        \u001b[35m0.0444\u001b[0m  1.0560\n",
      "      4  \u001b[36m-15.3997\u001b[0m        \u001b[32m0.0402\u001b[0m        \u001b[35m0.0347\u001b[0m  1.0533\n",
      "      5  \u001b[36m-10.2142\u001b[0m        \u001b[32m0.0323\u001b[0m        \u001b[35m0.0286\u001b[0m  1.0623\n",
      "      6  \u001b[36m-6.7863\u001b[0m        \u001b[32m0.0269\u001b[0m        \u001b[35m0.0238\u001b[0m  1.0489\n",
      "      7  \u001b[36m-4.7905\u001b[0m        \u001b[32m0.0230\u001b[0m        \u001b[35m0.0205\u001b[0m  1.0567\n",
      "      8  \u001b[36m-3.5500\u001b[0m        \u001b[32m0.0205\u001b[0m        \u001b[35m0.0181\u001b[0m  1.0537\n",
      "      9  \u001b[36m-2.8050\u001b[0m        \u001b[32m0.0182\u001b[0m        \u001b[35m0.0164\u001b[0m  1.0528\n",
      "     10  \u001b[36m-2.2201\u001b[0m        \u001b[32m0.0166\u001b[0m        \u001b[35m0.0150\u001b[0m  1.0520\n",
      "  epoch        r2    train_loss    valid_loss     dur\n",
      "-------  --------  ------------  ------------  ------\n",
      "      1  \u001b[36m-43.1039\u001b[0m        \u001b[32m0.1486\u001b[0m        \u001b[35m0.0889\u001b[0m  1.0583\n",
      "      2  \u001b[36m-20.7429\u001b[0m        \u001b[32m0.0733\u001b[0m        \u001b[35m0.0622\u001b[0m  1.0525\n",
      "      3  \u001b[36m-11.9094\u001b[0m        \u001b[32m0.0536\u001b[0m        \u001b[35m0.0477\u001b[0m  1.0537\n",
      "      4  \u001b[36m-7.9216\u001b[0m        \u001b[32m0.0427\u001b[0m        \u001b[35m0.0394\u001b[0m  1.0570\n",
      "      5  \u001b[36m-5.6232\u001b[0m        \u001b[32m0.0354\u001b[0m        \u001b[35m0.0336\u001b[0m  1.0670\n",
      "      6  \u001b[36m-3.9306\u001b[0m        \u001b[32m0.0297\u001b[0m        \u001b[35m0.0286\u001b[0m  1.0557\n",
      "      7  \u001b[36m-2.8771\u001b[0m        \u001b[32m0.0259\u001b[0m        \u001b[35m0.0249\u001b[0m  1.0507\n",
      "      8  \u001b[36m-2.1924\u001b[0m        \u001b[32m0.0227\u001b[0m        \u001b[35m0.0222\u001b[0m  1.0579\n",
      "      9  \u001b[36m-1.6882\u001b[0m        \u001b[32m0.0201\u001b[0m        \u001b[35m0.0199\u001b[0m  1.0560\n",
      "     10  \u001b[36m-1.3274\u001b[0m        \u001b[32m0.0181\u001b[0m        \u001b[35m0.0180\u001b[0m  1.0563\n",
      "  epoch        r2    train_loss    valid_loss     dur\n",
      "-------  --------  ------------  ------------  ------\n",
      "      1  \u001b[36m-68.4905\u001b[0m        \u001b[32m0.2015\u001b[0m        \u001b[35m0.1115\u001b[0m  1.0542\n",
      "      2  \u001b[36m-28.7511\u001b[0m        \u001b[32m0.0901\u001b[0m        \u001b[35m0.0728\u001b[0m  1.0591\n",
      "      3  \u001b[36m-15.3694\u001b[0m        \u001b[32m0.0625\u001b[0m        \u001b[35m0.0538\u001b[0m  1.0390\n",
      "      4  \u001b[36m-9.6623\u001b[0m        \u001b[32m0.0481\u001b[0m        \u001b[35m0.0432\u001b[0m  1.0556\n",
      "      5  \u001b[36m-6.2364\u001b[0m        \u001b[32m0.0386\u001b[0m        \u001b[35m0.0353\u001b[0m  1.0561\n",
      "      6  \u001b[36m-4.4673\u001b[0m        \u001b[32m0.0323\u001b[0m        \u001b[35m0.0304\u001b[0m  1.0545\n",
      "      7  \u001b[36m-3.1884\u001b[0m        \u001b[32m0.0274\u001b[0m        \u001b[35m0.0261\u001b[0m  1.0562\n",
      "      8  \u001b[36m-2.3290\u001b[0m        \u001b[32m0.0241\u001b[0m        \u001b[35m0.0229\u001b[0m  1.0657\n",
      "      9  \u001b[36m-1.7776\u001b[0m        \u001b[32m0.0214\u001b[0m        \u001b[35m0.0205\u001b[0m  1.0569\n",
      "     10  \u001b[36m-1.3960\u001b[0m        \u001b[32m0.0191\u001b[0m        \u001b[35m0.0186\u001b[0m  1.0531\n",
      "  epoch         r2    train_loss    valid_loss     dur\n",
      "-------  ---------  ------------  ------------  ------\n",
      "      1  \u001b[36m-101.7431\u001b[0m        \u001b[32m0.1765\u001b[0m        \u001b[35m0.0868\u001b[0m  1.0540\n",
      "      2  \u001b[36m-35.8370\u001b[0m        \u001b[32m0.0677\u001b[0m        \u001b[35m0.0520\u001b[0m  1.0556\n",
      "      3  \u001b[36m-17.6178\u001b[0m        \u001b[32m0.0446\u001b[0m        \u001b[35m0.0369\u001b[0m  1.0570\n",
      "      4  \u001b[36m-9.3509\u001b[0m        \u001b[32m0.0328\u001b[0m        \u001b[35m0.0274\u001b[0m  1.0567\n",
      "      5  \u001b[36m-6.0928\u001b[0m        \u001b[32m0.0255\u001b[0m        \u001b[35m0.0226\u001b[0m  1.0603\n",
      "      6  \u001b[36m-3.5605\u001b[0m        \u001b[32m0.0207\u001b[0m        \u001b[35m0.0180\u001b[0m  1.0553\n",
      "      7  \u001b[36m-2.4169\u001b[0m        \u001b[32m0.0175\u001b[0m        \u001b[35m0.0154\u001b[0m  1.0556\n",
      "      8  \u001b[36m-1.6814\u001b[0m        \u001b[32m0.0152\u001b[0m        \u001b[35m0.0135\u001b[0m  1.0536\n",
      "      9  \u001b[36m-1.1976\u001b[0m        \u001b[32m0.0134\u001b[0m        \u001b[35m0.0120\u001b[0m  1.0571\n",
      "     10  \u001b[36m-0.8361\u001b[0m        \u001b[32m0.0120\u001b[0m        \u001b[35m0.0108\u001b[0m  1.0556\n",
      "  epoch        r2    train_loss    valid_loss     dur\n",
      "-------  --------  ------------  ------------  ------\n",
      "      1  \u001b[36m-23.2893\u001b[0m        \u001b[32m0.1106\u001b[0m        \u001b[35m0.0657\u001b[0m  1.0520\n",
      "      2  \u001b[36m-7.9813\u001b[0m        \u001b[32m0.0492\u001b[0m        \u001b[35m0.0394\u001b[0m  1.0828\n",
      "      3  \u001b[36m-4.2075\u001b[0m        \u001b[32m0.0327\u001b[0m        \u001b[35m0.0293\u001b[0m  1.0528\n",
      "      4  \u001b[36m-2.4463\u001b[0m        \u001b[32m0.0249\u001b[0m        \u001b[35m0.0230\u001b[0m  1.0559\n",
      "      5  \u001b[36m-1.5571\u001b[0m        \u001b[32m0.0202\u001b[0m        \u001b[35m0.0191\u001b[0m  1.0519\n",
      "      6  \u001b[36m-1.1317\u001b[0m        \u001b[32m0.0173\u001b[0m        \u001b[35m0.0169\u001b[0m  1.0541\n",
      "      7  \u001b[36m-0.8275\u001b[0m        \u001b[32m0.0152\u001b[0m        \u001b[35m0.0150\u001b[0m  1.0573\n",
      "      8  \u001b[36m-0.6275\u001b[0m        \u001b[32m0.0136\u001b[0m        \u001b[35m0.0137\u001b[0m  1.0589\n",
      "      9  \u001b[36m-0.5112\u001b[0m        \u001b[32m0.0125\u001b[0m        \u001b[35m0.0127\u001b[0m  1.0585\n",
      "     10  \u001b[36m-0.4112\u001b[0m        \u001b[32m0.0116\u001b[0m        \u001b[35m0.0119\u001b[0m  1.0570\n",
      "  epoch        r2    train_loss    valid_loss     dur\n",
      "-------  --------  ------------  ------------  ------\n",
      "      1  \u001b[36m-33.1871\u001b[0m        \u001b[32m0.1456\u001b[0m        \u001b[35m0.0782\u001b[0m  1.0586\n",
      "      2  \u001b[36m-13.8785\u001b[0m        \u001b[32m0.0631\u001b[0m        \u001b[35m0.0513\u001b[0m  1.0592\n",
      "      3  \u001b[36m-7.2195\u001b[0m        \u001b[32m0.0437\u001b[0m        \u001b[35m0.0377\u001b[0m  1.0566\n",
      "      4  \u001b[36m-4.3972\u001b[0m        \u001b[32m0.0334\u001b[0m        \u001b[35m0.0301\u001b[0m  1.0538\n",
      "      5  \u001b[36m-2.8586\u001b[0m        \u001b[32m0.0269\u001b[0m        \u001b[35m0.0248\u001b[0m  1.0573\n",
      "      6  \u001b[36m-1.8897\u001b[0m        \u001b[32m0.0225\u001b[0m        \u001b[35m0.0208\u001b[0m  1.0557\n",
      "      7  \u001b[36m-1.4765\u001b[0m        \u001b[32m0.0195\u001b[0m        \u001b[35m0.0188\u001b[0m  1.0609\n",
      "      8  \u001b[36m-1.1084\u001b[0m        \u001b[32m0.0172\u001b[0m        \u001b[35m0.0168\u001b[0m  1.0560\n",
      "      9  \u001b[36m-0.8307\u001b[0m        \u001b[32m0.0155\u001b[0m        \u001b[35m0.0150\u001b[0m  1.0550\n",
      "     10  \u001b[36m-0.7021\u001b[0m        \u001b[32m0.0141\u001b[0m        \u001b[35m0.0142\u001b[0m  1.0539\n",
      "  epoch         r2    train_loss    valid_loss     dur\n",
      "-------  ---------  ------------  ------------  ------\n",
      "      1  \u001b[36m-260.3186\u001b[0m        \u001b[32m0.1645\u001b[0m        \u001b[35m0.1385\u001b[0m  1.0655\n",
      "      2  \u001b[36m-176.6542\u001b[0m        \u001b[32m0.1276\u001b[0m        \u001b[35m0.1142\u001b[0m  1.0538\n",
      "      3  \u001b[36m-119.6367\u001b[0m        \u001b[32m0.1056\u001b[0m        \u001b[35m0.0941\u001b[0m  1.0620\n",
      "      4  \u001b[36m-90.4950\u001b[0m        \u001b[32m0.0904\u001b[0m        \u001b[35m0.0819\u001b[0m  1.0504\n",
      "      5  \u001b[36m-71.8954\u001b[0m        \u001b[32m0.0790\u001b[0m        \u001b[35m0.0732\u001b[0m  1.0548\n",
      "      6  \u001b[36m-58.1384\u001b[0m        \u001b[32m0.0711\u001b[0m        \u001b[35m0.0659\u001b[0m  1.0571\n",
      "      7  \u001b[36m-49.8913\u001b[0m        \u001b[32m0.0644\u001b[0m        \u001b[35m0.0611\u001b[0m  1.0525\n",
      "      8  \u001b[36m-43.3500\u001b[0m        \u001b[32m0.0587\u001b[0m        \u001b[35m0.0571\u001b[0m  1.0521\n",
      "      9  \u001b[36m-34.8690\u001b[0m        \u001b[32m0.0544\u001b[0m        \u001b[35m0.0513\u001b[0m  1.0523\n",
      "     10  \u001b[36m-30.9520\u001b[0m        \u001b[32m0.0507\u001b[0m        \u001b[35m0.0484\u001b[0m  1.0505\n",
      "  epoch         r2    train_loss    valid_loss     dur\n",
      "-------  ---------  ------------  ------------  ------\n",
      "      1  \u001b[36m-105.7997\u001b[0m        \u001b[32m0.1770\u001b[0m        \u001b[35m0.1384\u001b[0m  1.0529\n",
      "      2  \u001b[36m-61.5012\u001b[0m        \u001b[32m0.1220\u001b[0m        \u001b[35m0.1059\u001b[0m  1.0673\n",
      "      3  \u001b[36m-41.0347\u001b[0m        \u001b[32m0.0962\u001b[0m        \u001b[35m0.0868\u001b[0m  1.0582\n",
      "      4  \u001b[36m-30.1500\u001b[0m        \u001b[32m0.0805\u001b[0m        \u001b[35m0.0746\u001b[0m  1.0598\n",
      "      5  \u001b[36m-21.6276\u001b[0m        \u001b[32m0.0685\u001b[0m        \u001b[35m0.0635\u001b[0m  1.0580\n",
      "      6  \u001b[36m-16.3396\u001b[0m        \u001b[32m0.0602\u001b[0m        \u001b[35m0.0555\u001b[0m  1.0551\n",
      "      7  \u001b[36m-12.7360\u001b[0m        \u001b[32m0.0535\u001b[0m        \u001b[35m0.0492\u001b[0m  1.0586\n",
      "      8  \u001b[36m-10.9263\u001b[0m        \u001b[32m0.0481\u001b[0m        \u001b[35m0.0458\u001b[0m  1.0682\n",
      "      9  \u001b[36m-8.9557\u001b[0m        \u001b[32m0.0437\u001b[0m        \u001b[35m0.0417\u001b[0m  1.0574\n",
      "     10  \u001b[36m-7.4380\u001b[0m        \u001b[32m0.0404\u001b[0m        \u001b[35m0.0382\u001b[0m  1.0717\n",
      "  epoch         r2    train_loss    valid_loss     dur\n",
      "-------  ---------  ------------  ------------  ------\n",
      "      1  \u001b[36m-141.3276\u001b[0m        \u001b[32m0.1950\u001b[0m        \u001b[35m0.1597\u001b[0m  1.0552\n",
      "      2  \u001b[36m-91.5499\u001b[0m        \u001b[32m0.1439\u001b[0m        \u001b[35m0.1288\u001b[0m  1.0636\n",
      "      3  \u001b[36m-62.7587\u001b[0m        \u001b[32m0.1171\u001b[0m        \u001b[35m0.1069\u001b[0m  1.0504\n",
      "      4  \u001b[36m-47.4062\u001b[0m        \u001b[32m0.0993\u001b[0m        \u001b[35m0.0931\u001b[0m  1.0546\n",
      "      5  \u001b[36m-36.3103\u001b[0m        \u001b[32m0.0866\u001b[0m        \u001b[35m0.0817\u001b[0m  1.0566\n",
      "      6  \u001b[36m-30.2134\u001b[0m        \u001b[32m0.0771\u001b[0m        \u001b[35m0.0747\u001b[0m  1.0509\n",
      "      7  \u001b[36m-23.4993\u001b[0m        \u001b[32m0.0695\u001b[0m        \u001b[35m0.0661\u001b[0m  1.0494\n",
      "      8  \u001b[36m-20.7751\u001b[0m        \u001b[32m0.0631\u001b[0m        \u001b[35m0.0622\u001b[0m  1.0559\n",
      "      9  \u001b[36m-16.5509\u001b[0m        \u001b[32m0.0584\u001b[0m        \u001b[35m0.0558\u001b[0m  1.0527\n",
      "     10  \u001b[36m-14.7844\u001b[0m        \u001b[32m0.0539\u001b[0m        \u001b[35m0.0528\u001b[0m  1.0527\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.00020160180671761432 {'lr': 0.0015}\n"
     ]
    }
   ],
   "source": [
    "X = X.astype(np.float32)\n",
    "y = y.astype(np.float32)\n",
    "\n",
    "params = {\n",
    "    'lr': [0.001, 0.0015, 0.003, 0.005],\n",
    "    #'max_epochs': [2000, 5000],\n",
    "}\n",
    "gs = GridSearchCV(net, params, refit=False, cv=3, scoring='neg_mean_squared_error')\n",
    "\n",
    "gs.fit(X, y)\n",
    "print(gs.best_score_, gs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_proba = net.predict_proba(X_test)\n",
    "pred = y_scaler.inverse_transform(y_proba)       \n",
    "print(pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>building_id</th>\n",
       "      <th>total_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>X5gsdTWGS3W7JJQB</td>\n",
       "      <td>2.085470e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BTshNOJyKHnT2YIT</td>\n",
       "      <td>8.500902e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dhdymr0lV8N5kZOT</td>\n",
       "      <td>7.683752e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>VEwyGGMcD56w5BOc</td>\n",
       "      <td>9.981914e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>wmUeMoJZfsqaSX9b</td>\n",
       "      <td>5.877293e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>EtBjGAHmHCe9t7TZ</td>\n",
       "      <td>1.415726e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>hPNH34vmaZtvBtqc</td>\n",
       "      <td>1.381302e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>wXjeI38bYDMJJwZC</td>\n",
       "      <td>-6.184460e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>fxZSGX6aPAFKU8W4</td>\n",
       "      <td>-7.499238e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ewr0Fx6ign87OwaV</td>\n",
       "      <td>-6.231330e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>gHKurnEP4AowzsLg</td>\n",
       "      <td>1.143969e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>PmLfTgY2FElLrTl0</td>\n",
       "      <td>1.502866e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>eM2NppIOwzW0o8iy</td>\n",
       "      <td>7.482906e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>dxxwNun97NH4WTrZ</td>\n",
       "      <td>-2.226149e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>jykBfhh3vdeFUi3H</td>\n",
       "      <td>-4.635274e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>NlXbvdFfmJZf3L18</td>\n",
       "      <td>1.378339e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>D7jaFWHCzSqLBwdt</td>\n",
       "      <td>-7.218017e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>L10dBBdqGmemweSl</td>\n",
       "      <td>2.624886e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>OgB0AdiPKlElakKN</td>\n",
       "      <td>-7.399115e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>StiWNN1GQrpPBOYt</td>\n",
       "      <td>-3.269799e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>a016eMAVQKnfwMnt</td>\n",
       "      <td>-5.613142e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>gsCFcQHnOH3AKMcZ</td>\n",
       "      <td>2.172695e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>IbNsDXfsPwSuFpow</td>\n",
       "      <td>1.702904e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>EgAVWOVxD1Jy5YkE</td>\n",
       "      <td>-1.321436e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>BrKghvR76XdbQPnx</td>\n",
       "      <td>1.129163e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>a7fxkXTnUGWHUmKG</td>\n",
       "      <td>4.521217e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>WgzXa170DfpzpURE</td>\n",
       "      <td>6.405656e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>JPWqZbLq0VNC0yKI</td>\n",
       "      <td>5.033824e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>JQgTtbVstqFZwEK1</td>\n",
       "      <td>-4.046679e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>bCSDbEthlS3nSIor</td>\n",
       "      <td>2.956426e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9970</th>\n",
       "      <td>QL412tWF5RDIX7IO</td>\n",
       "      <td>-9.270505e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9971</th>\n",
       "      <td>d3c2ceGtckONZzsr</td>\n",
       "      <td>2.815418e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9972</th>\n",
       "      <td>P1j8YRbxDAovumaI</td>\n",
       "      <td>-5.217618e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9973</th>\n",
       "      <td>IxcBhEoFLcrI9TPr</td>\n",
       "      <td>1.157924e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9974</th>\n",
       "      <td>rKiV0KDbAl2myBQI</td>\n",
       "      <td>6.882317e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9975</th>\n",
       "      <td>GSdIXmKr0g5jQQcF</td>\n",
       "      <td>-1.263082e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9976</th>\n",
       "      <td>Am6Wcg3TO64qvzd8</td>\n",
       "      <td>-2.258302e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9977</th>\n",
       "      <td>RZqACAhkL4Tgw4Jr</td>\n",
       "      <td>-6.411594e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9978</th>\n",
       "      <td>u7NKZfWoMUlZy9rJ</td>\n",
       "      <td>-6.861040e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9979</th>\n",
       "      <td>C1BqV4MWH15rjAgz</td>\n",
       "      <td>-8.482967e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9980</th>\n",
       "      <td>wz8A2UbwsgR0lXGJ</td>\n",
       "      <td>8.332906e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9981</th>\n",
       "      <td>MGJ8ABBTmC2yIaSm</td>\n",
       "      <td>-2.792938e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9982</th>\n",
       "      <td>MjHL2HP1PGIp8aBt</td>\n",
       "      <td>1.977112e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9983</th>\n",
       "      <td>FMz7nnURFn85LaGt</td>\n",
       "      <td>-1.177211e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9984</th>\n",
       "      <td>kydULx0r0G7OklRD</td>\n",
       "      <td>-5.352129e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9985</th>\n",
       "      <td>nVNYRuk2fRbtlV00</td>\n",
       "      <td>-6.138347e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9986</th>\n",
       "      <td>F8SGEOGPxrPfiRv2</td>\n",
       "      <td>4.972916e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9987</th>\n",
       "      <td>w7VMfiMvRb765ejK</td>\n",
       "      <td>5.450106e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9988</th>\n",
       "      <td>lgZWdUKliWt2y5sM</td>\n",
       "      <td>1.196780e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9989</th>\n",
       "      <td>TER8YrP9mw7UwWwr</td>\n",
       "      <td>6.183394e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9990</th>\n",
       "      <td>TXHk3oUpVsm5Cmag</td>\n",
       "      <td>4.539065e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9991</th>\n",
       "      <td>JtgDm9aQcGE9zELB</td>\n",
       "      <td>3.854207e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9992</th>\n",
       "      <td>wTQmcqbN0OCuSF1t</td>\n",
       "      <td>2.417260e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9993</th>\n",
       "      <td>WgsI1cBtzSfiWA1j</td>\n",
       "      <td>-2.978591e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9994</th>\n",
       "      <td>qNgt1ajb5uVMKbqm</td>\n",
       "      <td>3.480702e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>UEeCDaAJzPwdKKKA</td>\n",
       "      <td>1.296964e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>i0fgbPaQsDWs7Q87</td>\n",
       "      <td>-1.868753e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>YunNwAhcqkf6YclI</td>\n",
       "      <td>5.782412e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>A2NotxtRY9MYoWMl</td>\n",
       "      <td>-1.322042e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>kKvgBXiA50gRmQhP</td>\n",
       "      <td>-5.017334e+07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           building_id   total_price\n",
       "0     X5gsdTWGS3W7JJQB  2.085470e+07\n",
       "1     BTshNOJyKHnT2YIT  8.500902e+07\n",
       "2     dhdymr0lV8N5kZOT  7.683752e+07\n",
       "3     VEwyGGMcD56w5BOc  9.981914e+07\n",
       "4     wmUeMoJZfsqaSX9b  5.877293e+06\n",
       "5     EtBjGAHmHCe9t7TZ  1.415726e+07\n",
       "6     hPNH34vmaZtvBtqc  1.381302e+07\n",
       "7     wXjeI38bYDMJJwZC -6.184460e+07\n",
       "8     fxZSGX6aPAFKU8W4 -7.499238e+07\n",
       "9     ewr0Fx6ign87OwaV -6.231330e+07\n",
       "10    gHKurnEP4AowzsLg  1.143969e+07\n",
       "11    PmLfTgY2FElLrTl0  1.502866e+08\n",
       "12    eM2NppIOwzW0o8iy  7.482906e+07\n",
       "13    dxxwNun97NH4WTrZ -2.226149e+07\n",
       "14    jykBfhh3vdeFUi3H -4.635274e+07\n",
       "15    NlXbvdFfmJZf3L18  1.378339e+08\n",
       "16    D7jaFWHCzSqLBwdt -7.218017e+07\n",
       "17    L10dBBdqGmemweSl  2.624886e+06\n",
       "18    OgB0AdiPKlElakKN -7.399115e+07\n",
       "19    StiWNN1GQrpPBOYt -3.269799e+05\n",
       "20    a016eMAVQKnfwMnt -5.613142e+07\n",
       "21    gsCFcQHnOH3AKMcZ  2.172695e+07\n",
       "22    IbNsDXfsPwSuFpow  1.702904e+08\n",
       "23    EgAVWOVxD1Jy5YkE -1.321436e+07\n",
       "24    BrKghvR76XdbQPnx  1.129163e+07\n",
       "25    a7fxkXTnUGWHUmKG  4.521217e+07\n",
       "26    WgzXa170DfpzpURE  6.405656e+07\n",
       "27    JPWqZbLq0VNC0yKI  5.033824e+07\n",
       "28    JQgTtbVstqFZwEK1 -4.046679e+07\n",
       "29    bCSDbEthlS3nSIor  2.956426e+07\n",
       "...                ...           ...\n",
       "9970  QL412tWF5RDIX7IO -9.270505e+07\n",
       "9971  d3c2ceGtckONZzsr  2.815418e+07\n",
       "9972  P1j8YRbxDAovumaI -5.217618e+07\n",
       "9973  IxcBhEoFLcrI9TPr  1.157924e+07\n",
       "9974  rKiV0KDbAl2myBQI  6.882317e+07\n",
       "9975  GSdIXmKr0g5jQQcF -1.263082e+08\n",
       "9976  Am6Wcg3TO64qvzd8 -2.258302e+07\n",
       "9977  RZqACAhkL4Tgw4Jr -6.411594e+06\n",
       "9978  u7NKZfWoMUlZy9rJ -6.861040e+07\n",
       "9979  C1BqV4MWH15rjAgz -8.482967e+07\n",
       "9980  wz8A2UbwsgR0lXGJ  8.332906e+07\n",
       "9981  MGJ8ABBTmC2yIaSm -2.792938e+07\n",
       "9982  MjHL2HP1PGIp8aBt  1.977112e+07\n",
       "9983  FMz7nnURFn85LaGt -1.177211e+07\n",
       "9984  kydULx0r0G7OklRD -5.352129e+07\n",
       "9985  nVNYRuk2fRbtlV00 -6.138347e+07\n",
       "9986  F8SGEOGPxrPfiRv2  4.972916e+07\n",
       "9987  w7VMfiMvRb765ejK  5.450106e+07\n",
       "9988  lgZWdUKliWt2y5sM  1.196780e+08\n",
       "9989  TER8YrP9mw7UwWwr  6.183394e+07\n",
       "9990  TXHk3oUpVsm5Cmag  4.539065e+05\n",
       "9991  JtgDm9aQcGE9zELB  3.854207e+07\n",
       "9992  wTQmcqbN0OCuSF1t  2.417260e+07\n",
       "9993  WgsI1cBtzSfiWA1j -2.978591e+07\n",
       "9994  qNgt1ajb5uVMKbqm  3.480702e+07\n",
       "9995  UEeCDaAJzPwdKKKA  1.296964e+08\n",
       "9996  i0fgbPaQsDWs7Q87 -1.868753e+08\n",
       "9997  YunNwAhcqkf6YclI  5.782412e+07\n",
       "9998  A2NotxtRY9MYoWMl -1.322042e+08\n",
       "9999  kKvgBXiA50gRmQhP -5.017334e+07\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.read_csv('./dataset-0510/submit_test.csv')\n",
    "submission['total_price'] = pred\n",
    "submission.to_csv('submission/TuningDNN_result.csv', index=False)\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
