{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.feature_selection import SelectFromModel, RFE\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "from torch import nn, optim\n",
    "import torch.nn.init as init\n",
    "import torch.utils.data as Data\n",
    "import math\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.multiprocessing as mp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp.set_start_method('spawn')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 512\n",
    "#epochs = 2000\n",
    "use_gpu = True\n",
    "lr = 0.001\n",
    "weight_decay = 10\n",
    "\n",
    "# Batch size and learning rate is hyperparameters in deep learning\n",
    "# suggest batch_size is reduced, lr is also reduced which will reduce concussion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv('./dataset-0510/train.csv')\n",
    "X_test = pd.read_csv('./dataset-0510/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = X['total_price']\n",
    "X = X.drop(columns=['building_id', 'total_price'], axis=1)\n",
    "\n",
    "X_test = X_test.drop(columns=['building_id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_eval, y_train, y_eval = train_test_split(X, y, test_size=0.3, random_state=42) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### scale y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_scaler = StandardScaler()\n",
    "y_train = y_scaler.fit_transform(y_train.values.reshape(-1, 1))\n",
    "y_eval = y_scaler.fit_transform(y_eval.values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imputer, Scaler, Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/islab/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:58: DeprecationWarning: Class Imputer is deprecated; Imputer was deprecated in version 0.20 and will be removed in 0.22. Import impute.SimpleImputer from sklearn instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# step1. Imputation transformer for completing missing values.\n",
    "step1 = ('Imputer', Imputer())\n",
    "# step2. MinMaxScaler\n",
    "step2 = ('MinMaxScaler', StandardScaler())\n",
    "# step3. feature selection\n",
    "#step3 = ('FeatureSelection', SelectFromModel(RandomForestRegressor()))\n",
    "step3 = ('FeatureSelection', VarianceThreshold())\n",
    "\n",
    "pipeline = Pipeline(steps=[step1, step2])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42000, 233)\n",
      "(10000, 233)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "X_train = pipeline.fit_transform(X_train)\n",
    "X_eval = pipeline.fit_transform(X_eval)\n",
    "\n",
    "print(X_test.shape)\n",
    "X_test = pipeline.fit_transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.from_numpy(X_train).float().to(device)\n",
    "X_eval = torch.from_numpy(X_eval).float().to(device)\n",
    "\n",
    "y_train = torch.from_numpy(y_train).float().to(device)\n",
    "y_eval = torch.from_numpy(y_eval).float().to(device)\n",
    "\n",
    "X_test = torch.from_numpy(X_test).float().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([42000, 233])\n",
      "torch.Size([10000, 233])\n",
      "torch.Size([42000, 1])\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Data.TensorDataset(X_train, y_train)\n",
    "loader = Data.DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=8,\n",
    "    pin_memory=True,\n",
    ")\n",
    "\n",
    "eval_dataset = Data.TensorDataset(X_eval, y_eval)\n",
    "loader = Data.DataLoader(\n",
    "    dataset=eval_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=8,\n",
    "    pin_memory=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## building model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(233, 256)\n",
    "        self.fc2 = nn.Linear(256, 256)\n",
    "        self.fc3 = nn.Linear(256, 128)\n",
    "        self.fc4 = nn.Linear(128, 64)\n",
    "        self.fc5 = nn.Linear(64, 1)\n",
    "        \n",
    "        self.dropout = nn.Dropout(p=0.3)\n",
    "    def forward(self, x):\n",
    "        '''\n",
    "        # fc1\n",
    "        x = self.dropout(self.fc1(x))\n",
    "        x = F.relu(x)\n",
    "        # fc2\n",
    "        x = self.dropout(self.fc2(x))\n",
    "        x = F.relu(x)\n",
    "        # fc3\n",
    "        x = self.fc3(x)\n",
    "        '''\n",
    "        \n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = F.relu(self.fc4(x))\n",
    "        x = self.fc5(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DNN().to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optim = optim.Adam(model.parameters(), lr= lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "def train_func(model, loader, epochs=10):\n",
    "    model.train()\n",
    "    for e in range(epochs):\n",
    "        train_loss = []\n",
    "        for step, (batch_x, batch_y) in enumerate(loader):\n",
    "            optim.zero_grad()\n",
    "            pred = model(batch_x)\n",
    "            loss = criterion(batch_y, pred)\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "\n",
    "            train_loss.append(loss.item())\n",
    "\n",
    "        print('training loss', np.array(train_loss).mean())\n",
    "    return model\n",
    "'''\n",
    "def train_func(model, loader, accumlation_steps=512):\n",
    "    model.train()\n",
    "    optim.zero_grad()\n",
    "    train_loss = []\n",
    "    for step, (batch_x, batch_y) in enumerate(loader):\n",
    "        pred = model(batch_x)\n",
    "        loss = criterion(pred, batch_y)\n",
    "        \n",
    "        train_loss.append(loss.item())\n",
    "        \n",
    "        loss = loss / accumlation_steps\n",
    "        loss.backward()\n",
    "        \n",
    "        if step % accumlation_steps == 0 or step == len(loader)-1:\n",
    "            optim.step()\n",
    "            optim.zero_grad()\n",
    "            \n",
    "\n",
    "        \n",
    "\n",
    "    print('training loss', np.array(train_loss).mean())\n",
    "    return model, np.array(train_loss).mean()\n",
    "\n",
    "def eval_func(model, loader):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for step, (batch_x, batch_y) in enumerate(loader):\n",
    "            pred = model(batch_x)\n",
    "            loss = criterion(pred, batch_y)\n",
    "        print('testing loss', loss.item())\n",
    "    return loss\n",
    "\n",
    "def test_func(model, X, y_scaler=None):\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        pred = model(X)\n",
    "        pred = pred.cpu().numpy()\n",
    "        \n",
    "        if y_scaler != None:\n",
    "            pred = y_scaler.inverse_transform(pred)\n",
    "    return pred\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs 0\n",
      "training loss 0.7698279699510758\n",
      "testing loss 0.01868021860718727\n",
      "epochs 1\n",
      "training loss 0.6884910366466356\n",
      "testing loss 0.007518833037465811\n",
      "epochs 2\n",
      "training loss 0.6003569964527457\n",
      "testing loss 0.006978231947869062\n",
      "epochs 3\n",
      "training loss 0.5137999311762166\n",
      "testing loss 0.035754673182964325\n",
      "epochs 4\n",
      "training loss 0.3508571008244699\n",
      "testing loss 0.00019288693147245795\n",
      "epochs 5\n",
      "training loss 0.3042194698923113\n",
      "testing loss 0.01173837948590517\n",
      "epochs 6\n",
      "training loss 0.30560825211690124\n",
      "testing loss 0.01259123906493187\n",
      "epochs 7\n",
      "training loss 0.24708083824759827\n",
      "testing loss 0.1663922816514969\n",
      "epochs 8\n",
      "training loss 0.15582394923587162\n",
      "testing loss 0.29259467124938965\n",
      "epochs 9\n",
      "training loss 0.1721114019399397\n",
      "testing loss 0.14111556112766266\n",
      "epochs 10\n",
      "training loss 0.24349504344814418\n",
      "testing loss 0.29374170303344727\n",
      "epochs 11\n",
      "training loss 0.15609322675252268\n",
      "testing loss 0.18755172193050385\n",
      "epochs 12\n",
      "training loss 0.137689195810089\n",
      "testing loss 0.41718921065330505\n",
      "epochs 13\n",
      "training loss 0.1679592185271094\n",
      "testing loss 0.17427976429462433\n",
      "epochs 14\n",
      "training loss 0.15378628165847902\n",
      "testing loss 0.38898998498916626\n",
      "epochs 15\n",
      "training loss 0.13471801797925612\n",
      "testing loss 0.4056127667427063\n",
      "epochs 16\n",
      "training loss 0.14327103182915268\n",
      "testing loss 0.3808608055114746\n",
      "epochs 17\n",
      "training loss 0.1309463691064628\n",
      "testing loss 0.5331485867500305\n",
      "epochs 18\n",
      "training loss 0.1418142057940499\n",
      "testing loss 0.3981233537197113\n",
      "epochs 19\n",
      "training loss 0.12613950052591594\n",
      "testing loss 0.5130400061607361\n",
      "epochs 20\n",
      "training loss 0.15288497297411638\n",
      "testing loss 0.6233417987823486\n",
      "epochs 21\n",
      "training loss 0.13491530324019943\n",
      "testing loss 0.45987778902053833\n",
      "epochs 22\n",
      "training loss 0.1500908382218318\n",
      "testing loss 0.637117862701416\n",
      "epochs 23\n",
      "training loss 0.12189240237959718\n",
      "testing loss 0.5033882260322571\n",
      "epochs 24\n",
      "training loss 0.13549358680832965\n",
      "testing loss 0.4659770429134369\n",
      "epochs 25\n",
      "training loss 0.10097789377648313\n",
      "testing loss 0.14343693852424622\n",
      "epochs 26\n",
      "training loss 0.12355409567755307\n",
      "testing loss 0.6684084534645081\n",
      "epochs 27\n",
      "training loss 0.09571348284882698\n",
      "testing loss 0.06127385050058365\n",
      "epochs 28\n",
      "training loss 0.09580554781010896\n",
      "testing loss 0.40469372272491455\n",
      "epochs 29\n",
      "training loss 0.07924499330266932\n",
      "testing loss 0.07937721163034439\n",
      "epochs 30\n",
      "training loss 0.0856419183710868\n",
      "testing loss 0.31693580746650696\n",
      "epochs 31\n",
      "training loss 0.06911236404845442\n",
      "testing loss 0.04453849419951439\n",
      "epochs 32\n",
      "training loss 0.0702070414898852\n",
      "testing loss 0.17175769805908203\n",
      "epochs 33\n",
      "training loss 0.05612852531615986\n",
      "testing loss 0.03481154143810272\n",
      "epochs 34\n",
      "training loss 0.05917859969155934\n",
      "testing loss 0.1114153116941452\n",
      "epochs 35\n",
      "training loss 0.04769008561076567\n",
      "testing loss 0.017739713191986084\n",
      "epochs 36\n",
      "training loss 0.048350162470263136\n",
      "testing loss 0.04774746671319008\n",
      "epochs 37\n",
      "training loss 0.04055040995428083\n",
      "testing loss 0.007962089963257313\n",
      "epochs 38\n",
      "training loss 0.04001528214275568\n",
      "testing loss 0.01741201989352703\n",
      "epochs 39\n",
      "training loss 0.0342101349162631\n",
      "testing loss 0.0030528635252267122\n",
      "epochs 40\n",
      "training loss 0.03514707016182432\n",
      "testing loss 0.006062447093427181\n",
      "epochs 41\n",
      "training loss 0.027944658644545182\n",
      "testing loss 0.0006329405005089939\n",
      "epochs 42\n",
      "training loss 0.030661095241722364\n",
      "testing loss 0.0030572484247386456\n",
      "epochs 43\n",
      "training loss 0.028192269670241465\n",
      "testing loss 0.00016132403106894344\n",
      "epochs 44\n",
      "training loss 0.03246800358801833\n",
      "testing loss 0.0010060310596600175\n",
      "epochs 45\n",
      "training loss 0.028162926310419646\n",
      "testing loss 0.00044050280121155083\n",
      "epochs 46\n",
      "training loss 0.03612124317974326\n",
      "testing loss 4.609786174114561e-06\n",
      "epochs 47\n",
      "training loss 0.029931254130079445\n",
      "testing loss 0.0002870566677302122\n",
      "epochs 48\n",
      "training loss 0.0394324805354835\n",
      "testing loss 0.002686395775526762\n",
      "epochs 49\n",
      "training loss 0.03912276223170866\n",
      "testing loss 0.0003383104922249913\n",
      "epochs 50\n",
      "training loss 0.05318841096717362\n",
      "testing loss 0.005723980721086264\n",
      "epochs 51\n",
      "training loss 0.25527759662797084\n",
      "testing loss 0.004261687397956848\n",
      "epochs 52\n",
      "training loss 0.281539493062116\n",
      "testing loss 0.00045975824468769133\n",
      "epochs 53\n",
      "training loss 0.14214718643096513\n",
      "testing loss 0.008826391771435738\n",
      "epochs 54\n",
      "training loss 0.0543319917493859\n",
      "testing loss 0.015299194492399693\n",
      "epochs 55\n",
      "training loss 0.043805136034027845\n",
      "testing loss 0.0029909044969826937\n",
      "epochs 56\n",
      "training loss 0.044990417488300884\n",
      "testing loss 0.0014962480636313558\n",
      "epochs 57\n",
      "training loss 0.041160727844474436\n",
      "testing loss 0.0017304294742643833\n",
      "epochs 58\n",
      "training loss 0.03982717728098795\n",
      "testing loss 0.0001808497036108747\n",
      "epochs 59\n",
      "training loss 0.03115757962496151\n",
      "testing loss 9.138655514107086e-06\n",
      "epochs 60\n",
      "training loss 0.03600616959542683\n",
      "testing loss 0.000658532022498548\n",
      "epochs 61\n",
      "training loss 0.03465834379802243\n",
      "testing loss 5.732547379011521e-06\n",
      "epochs 62\n",
      "training loss 0.03840352112570941\n",
      "testing loss 0.00015372068446595222\n",
      "epochs 63\n",
      "training loss 0.033380380399218104\n",
      "testing loss 0.0008647393551655114\n",
      "epochs 64\n",
      "training loss 0.03622739018962321\n",
      "testing loss 0.0001580761163495481\n",
      "epochs 65\n",
      "training loss 0.028861715632677004\n",
      "testing loss 0.002236527856439352\n",
      "epochs 66\n",
      "training loss 0.0312992279511124\n",
      "testing loss 0.0008970217313617468\n",
      "epochs 67\n",
      "training loss 0.023467739687655965\n",
      "testing loss 0.0023326941300183535\n",
      "epochs 68\n",
      "training loss 0.02351696557581025\n",
      "testing loss 0.0025315340608358383\n",
      "epochs 69\n",
      "training loss 0.018094590961606167\n",
      "testing loss 0.0014421141240745783\n",
      "epochs 70\n",
      "training loss 0.018219705505870664\n",
      "testing loss 0.004407483618706465\n",
      "epochs 71\n",
      "training loss 0.015546046518485398\n",
      "testing loss 0.0031129764392971992\n",
      "epochs 72\n",
      "training loss 0.014506414364364421\n",
      "testing loss 0.005690766964107752\n",
      "epochs 73\n",
      "training loss 0.014074671950686641\n",
      "testing loss 0.0048960112035274506\n",
      "epochs 74\n",
      "training loss 0.013611647130194878\n",
      "testing loss 0.005426534451544285\n",
      "epochs 75\n",
      "training loss 0.015930053941705963\n",
      "testing loss 0.006617785897105932\n",
      "epochs 76\n",
      "training loss 0.018510523759567327\n",
      "testing loss 0.004023856017738581\n",
      "epochs 77\n",
      "training loss 0.023288965068494615\n",
      "testing loss 0.007995019666850567\n",
      "epochs 78\n",
      "training loss 0.04011090744640726\n",
      "testing loss 0.0018525338964536786\n",
      "epochs 79\n",
      "training loss 0.04741825198885784\n",
      "testing loss 0.0059714531525969505\n",
      "epochs 80\n",
      "training loss 0.07455486209953559\n",
      "testing loss 0.0010789691004902124\n",
      "epochs 81\n",
      "training loss 0.09070565992667781\n",
      "testing loss 0.0020254957489669323\n",
      "epochs 82\n",
      "training loss 0.262231394686626\n",
      "testing loss 0.03356565907597542\n",
      "epochs 83\n",
      "training loss 0.23872332679995006\n",
      "testing loss 0.00013784717884846032\n",
      "epochs 84\n",
      "training loss 0.10725634869517171\n",
      "testing loss 0.0033356763888150454\n",
      "epochs 85\n",
      "training loss 0.08719737577165021\n",
      "testing loss 0.0018217632314190269\n",
      "epochs 86\n",
      "training loss 0.06964916540047977\n",
      "testing loss 0.0018941067392006516\n",
      "epochs 87\n",
      "training loss 0.06337138625273264\n",
      "testing loss 1.9237717424402945e-05\n",
      "epochs 88\n",
      "training loss 0.06707490214844611\n",
      "testing loss 4.1827577661024407e-05\n",
      "epochs 89\n",
      "training loss 0.05846078637186522\n",
      "testing loss 1.2365255770419026e-06\n",
      "epochs 90\n",
      "training loss 0.04982208076688163\n",
      "testing loss 4.497888767218683e-06\n",
      "epochs 91\n",
      "training loss 0.04302336523337411\n",
      "testing loss 0.00021833741629961878\n",
      "epochs 92\n",
      "training loss 0.03684656170846191\n",
      "testing loss 0.0002030320029007271\n",
      "epochs 93\n",
      "training loss 0.031606283021924864\n",
      "testing loss 0.0006314620259217918\n",
      "epochs 94\n",
      "training loss 0.02762406722467508\n",
      "testing loss 0.0004890468553639948\n",
      "epochs 95\n",
      "training loss 0.023804828970043265\n",
      "testing loss 0.0006531901308335364\n",
      "epochs 96\n",
      "training loss 0.02117559602573947\n",
      "testing loss 0.0008721210178919137\n",
      "epochs 97\n",
      "training loss 0.018014471865158862\n",
      "testing loss 0.0010678994003683329\n",
      "epochs 98\n",
      "training loss 0.015808975749940092\n",
      "testing loss 0.0016934999730437994\n",
      "epochs 99\n",
      "training loss 0.013524642533933104\n",
      "testing loss 0.0016578048234805465\n",
      "epochs 100\n",
      "training loss 0.011599417269146591\n",
      "testing loss 0.001729734125547111\n",
      "epochs 101\n",
      "training loss 0.01041804465729718\n",
      "testing loss 0.002452350687235594\n",
      "epochs 102\n",
      "training loss 0.009875135174582342\n",
      "testing loss 0.0025342856533825397\n",
      "epochs 103\n",
      "training loss 0.010792093628565399\n",
      "testing loss 0.0032126798760145903\n",
      "epochs 104\n",
      "training loss 0.013203229823226274\n",
      "testing loss 0.004083438776433468\n",
      "epochs 105\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss 0.014870961306629927\n",
      "testing loss 0.0036541568115353584\n",
      "epochs 106\n",
      "training loss 0.013620663651134715\n",
      "testing loss 0.005953841842710972\n",
      "epochs 107\n",
      "training loss 0.013511319903512523\n",
      "testing loss 0.0028853281401097775\n",
      "epochs 108\n",
      "training loss 0.020613024374546346\n",
      "testing loss 0.005518397316336632\n",
      "epochs 109\n",
      "training loss 0.02224284021651668\n",
      "testing loss 0.0017609111964702606\n",
      "epochs 110\n",
      "training loss 0.045107087342450315\n",
      "testing loss 0.005903028417378664\n",
      "epochs 111\n",
      "training loss 0.045099903977175504\n",
      "testing loss 0.0002476542431395501\n",
      "epochs 112\n",
      "training loss 0.04660995894744102\n",
      "testing loss 0.004177351947873831\n",
      "epochs 113\n",
      "training loss 0.04129568455038421\n",
      "testing loss 0.0013873518910259008\n",
      "epochs 114\n",
      "training loss 0.030804728769736126\n",
      "testing loss 0.0031745382584631443\n",
      "epochs 115\n",
      "training loss 0.032102230221759946\n",
      "testing loss 0.00046399314305745065\n",
      "epochs 116\n",
      "training loss 0.02479200740700732\n",
      "testing loss 0.0007119146175682545\n",
      "epochs 117\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-775319b95b65>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'epochs'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0meval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-16-5fe43e85748d>\u001b[0m in \u001b[0;36mtrain_func\u001b[0;34m(model, loader, accumlation_steps)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0maccumlation_steps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0maccumlation_steps\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \"\"\"\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_losses = []\n",
    "eval_losses = []\n",
    "for t in range(1000):\n",
    "    print('epochs', t)\n",
    "    model, train_loss = train_func(model, train_dataset)\n",
    "    eval_loss = eval_func(model, eval_dataset)\n",
    "    \n",
    "    train_losses.append(train_loss)\n",
    "    eval_losses.append(eval_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plot data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f0fcff6bcf8>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(train_losses, label='Training loss')\n",
    "plt.plot(eval_losses, label='Validation loss')\n",
    "plt.legend(frameon=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## vaildation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing loss 4.56169800600037e-06\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(4.5617e-06, device='cuda:0')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_func(model, eval_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = test_func(model, X_test, y_scaler)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "submission = pd.read_csv('./dataset-0510/submit_test.csv')\n",
    "submission['total_price'] = pred\n",
    "submission.to_csv('submission/DNN2_result.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Batch size use 128 or 32 , learning rate use 0.003 which find loss will stock in 0.6\n",
    "\n",
    "Result 1 DNN 233->256->128->1, lr=0.001, batch_size=128, predict score : 13\n",
    "change: \n",
    "- replacing Standard to MinMax \n",
    "- adding DropOut 0.3 layer\n",
    "- batch size change to 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
