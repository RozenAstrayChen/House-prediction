{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.feature_selection import SelectFromModel, RFE\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler,scale\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "from torch import nn, optim\n",
    "import torch.nn.init as init\n",
    "import torch.utils.data as Data\n",
    "import math\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.multiprocessing as mp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp.set_start_method('spawn')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "use_gpu = True\n",
    "y_scale = True\n",
    "lr = 0.001\n",
    "weight_decay = 0.01\n",
    "\n",
    "# Batch size and learning rate is hyperparameters in deep learning\n",
    "# suggest batch_size is reduced, lr is also reduced which will reduce concussion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv('./dataset-0510/train.csv')\n",
    "X_test = pd.read_csv('./dataset-0510/test.csv')\n",
    "\n",
    "\n",
    "columns = X.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['building_id', 'building_material', 'city', 'txn_dt', 'total_floor',\n",
       "       'building_type', 'building_use', 'building_complete_dt', 'parking_way',\n",
       "       'parking_area',\n",
       "       ...\n",
       "       'XIV_500', 'XIV_index_500', 'XIV_1000', 'XIV_index_1000', 'XIV_5000',\n",
       "       'XIV_index_5000', 'XIV_10000', 'XIV_index_10000', 'XIV_MIN',\n",
       "       'total_price'],\n",
       "      dtype='object', length=235)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imputer, Scaler, Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/islab/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:58: DeprecationWarning: Class Imputer is deprecated; Imputer was deprecated in version 0.20 and will be removed in 0.22. Import impute.SimpleImputer from sklearn instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# step1. Imputation transformer for completing missing values.\n",
    "step1 = ('Imputer', Imputer())\n",
    "# step2. MinMaxScaler\n",
    "step2 = ('MinMaxScaler', MinMaxScaler())\n",
    "# step3. feature selection\n",
    "#step3 = ('FeatureSelection', SelectFromModel(RandomForestRegressor()))\n",
    "step3 = ('FeatureSelection', VarianceThreshold())\n",
    "\n",
    "pipeline = Pipeline(steps=[step1, step2, step3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = X['total_price']\n",
    "X = X.drop(columns=['building_id', 'total_price'], axis=1)\n",
    "X_test = X_test.drop(columns=['building_id'], axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### X sacle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 211)\n",
      "(10000, 211)\n"
     ]
    }
   ],
   "source": [
    "X = pipeline.fit_transform(X)\n",
    "print(X.shape)\n",
    "\n",
    "X_test = pipeline.transform(X_test)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X = pd.DataFrame(X, columns=columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### y scale "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_scaler = MinMaxScaler()\n",
    "if y_scale:\n",
    "    y = y_scaler.fit_transform(y.values.reshape(-1, 1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_eval, y_train, y_eval = train_test_split(X, y, test_size=0.3, random_state=42) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.from_numpy(X_train).float().to(device)\n",
    "X_eval = torch.from_numpy(X_eval).float().to(device)\n",
    "\n",
    "y_train = torch.from_numpy(y_train).float().to(device)\n",
    "y_eval = torch.from_numpy(y_eval).float().to(device)\n",
    "\n",
    "X_test = torch.from_numpy(X_test).float().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([42000, 211])\n",
      "torch.Size([10000, 211])\n",
      "torch.Size([42000, 1])\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Data.TensorDataset(X_train, y_train)\n",
    "train_loader = Data.DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=0,\n",
    ")\n",
    "\n",
    "eval_dataset = Data.TensorDataset(X_eval, y_eval)\n",
    "eval_loader = Data.DataLoader(\n",
    "    dataset=eval_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## building model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(211, 256)\n",
    "        self.fc2 = nn.Linear(256, 512)\n",
    "        self.fc3 = nn.Linear(512, 512)\n",
    "        self.fc4 = nn.Linear(512, 256)\n",
    "        self.fc5 = nn.Linear(256, 128)\n",
    "        self.fc6 = nn.Linear(128, 64)\n",
    "        self.fc7 = nn.Linear(64, 32)\n",
    "        self.fc8 = nn.Linear(32, 1)\n",
    "        \n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        #x = x.unsqueeze(0)\n",
    "        \n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = F.relu(self.fc4(x))\n",
    "        x = F.relu(self.fc5(x))\n",
    "        x = F.relu(self.fc6(x))\n",
    "        x = F.relu(self.fc7(x))\n",
    "        x = self.fc8(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DNN().to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optim = optim.Adam(model.parameters(), lr= lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_func(model, loader):\n",
    "    model.train()\n",
    "    train_loss = []\n",
    "    for step, (batch_x, batch_y) in enumerate(loader):\n",
    "        optim.zero_grad()\n",
    "        pred = model(batch_x)\n",
    "        loss = torch.sqrt(criterion(pred, batch_y))\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "\n",
    "        train_loss.append(loss.item())\n",
    "        \n",
    "    print('training loss', np.array(train_loss).mean())\n",
    "    return np.array(train_loss).mean()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def eval_func(model, loader):\n",
    "    model.eval()\n",
    "    eval_loss = []\n",
    "    with torch.no_grad():\n",
    "        for step, (batch_x, batch_y) in enumerate(loader):\n",
    "            pred = model(batch_x)\n",
    "            loss = torch.sqrt(criterion(pred, batch_y))\n",
    "            \n",
    "            eval_loss.append(loss.item())\n",
    "        print('testing loss', np.array(eval_loss).mean())\n",
    "    return np.array(eval_loss).mean()\n",
    "\n",
    "def test_func(model, X):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        pred = model(X)\n",
    "        \n",
    "        pred = pred.cpu().numpy()\n",
    "        if y_scale:\n",
    "            pred = y_scaler.inverse_transform(pred)            \n",
    "    return pred\n",
    "\n",
    "\n",
    "def accuracy(model, pct_close=0.5):\n",
    "    #pred, y_eval\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        pred = model(X_eval)\n",
    "        \n",
    "    n_correct = torch.sum((torch.abs(pred - y_eval) < torch.abs(pct_close * y_eval)))\n",
    "    result = (n_correct.item()/len(y_eval))  # scalar\n",
    "    return result \n",
    "\n",
    "def plot(label, pred):\n",
    "    plt.plot(label, label='actual')\n",
    "    plt.plot(pred, label='pred')\n",
    "    plt.legend(frameon=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs 0\n",
      "training loss 0.006422948999483263\n",
      "epochs 1\n",
      "training loss 0.006056437275222415\n",
      "epochs 2\n",
      "training loss 0.005955726137217757\n",
      "epochs 3\n",
      "training loss 0.005924502837381079\n",
      "epochs 4\n",
      "training loss 0.006277736624041827\n",
      "epochs 5\n",
      "training loss 0.006030793773083973\n",
      "epochs 6\n",
      "training loss 0.006059891003251959\n",
      "epochs 7\n",
      "training loss 0.006257857825878815\n",
      "epochs 8\n",
      "training loss 0.005982358165023039\n",
      "epochs 9\n",
      "training loss 0.005898672602589506\n",
      "testing loss 0.006586242181493352\n",
      "epochs 10\n",
      "training loss 0.005731636897510761\n",
      "epochs 11\n",
      "training loss 0.005884248715553625\n",
      "epochs 12\n",
      "training loss 0.005533632614627186\n",
      "epochs 13\n",
      "training loss 0.005711548329376273\n",
      "epochs 14\n",
      "training loss 0.006669217080874284\n",
      "epochs 15\n",
      "training loss 0.005856510948483184\n",
      "epochs 16\n",
      "training loss 0.006216286153654288\n",
      "epochs 17\n",
      "training loss 0.005692190414940015\n",
      "epochs 18\n",
      "training loss 0.005463047924743099\n",
      "epochs 19\n",
      "training loss 0.005867086382056261\n",
      "testing loss 0.006552166852056451\n",
      "epochs 20\n",
      "training loss 0.0061041566742850205\n",
      "epochs 21\n",
      "training loss 0.005927411036843315\n",
      "epochs 22\n",
      "training loss 0.005305031452138305\n",
      "epochs 23\n",
      "training loss 0.005294083510058448\n",
      "epochs 24\n",
      "training loss 0.005574440624278978\n",
      "epochs 25\n",
      "training loss 0.00563112881755043\n",
      "epochs 26\n",
      "training loss 0.005346175644470316\n",
      "epochs 27\n",
      "training loss 0.0050234522618845924\n",
      "epochs 28\n",
      "training loss 0.0054578859027118445\n",
      "epochs 29\n",
      "training loss 0.005071076891090619\n",
      "testing loss 0.006380758932725599\n",
      "epochs 30\n",
      "training loss 0.0052678849081732445\n",
      "epochs 31\n",
      "training loss 0.005109274582257976\n",
      "epochs 32\n",
      "training loss 0.005219891331920055\n",
      "epochs 33\n",
      "training loss 0.005062798337832569\n",
      "epochs 34\n",
      "training loss 0.005132810208425606\n",
      "epochs 35\n",
      "training loss 0.0048495696321141125\n",
      "epochs 36\n",
      "training loss 0.0047265001481376296\n",
      "epochs 37\n",
      "training loss 0.004745074794811726\n",
      "epochs 38\n",
      "training loss 0.0044932509298325944\n",
      "epochs 39\n",
      "training loss 0.0049360593901890525\n",
      "testing loss 0.005273975654842055\n",
      "epochs 40\n",
      "training loss 0.004936771888404768\n",
      "epochs 41\n",
      "training loss 0.004975734241405859\n",
      "epochs 42\n",
      "training loss 0.004750278224605263\n",
      "epochs 43\n",
      "training loss 0.005272156121577264\n",
      "epochs 44\n",
      "training loss 0.004884943176389284\n",
      "epochs 45\n",
      "training loss 0.005025877273715127\n",
      "epochs 46\n",
      "training loss 0.004804707860141018\n",
      "epochs 47\n",
      "training loss 0.004803213069716462\n",
      "epochs 48\n",
      "training loss 0.004740427014641577\n",
      "epochs 49\n",
      "training loss 0.004766510216389021\n",
      "testing loss 0.0051330921681043\n",
      "epochs 50\n",
      "training loss 0.00469390030010493\n",
      "epochs 51\n",
      "training loss 0.004542247778990824\n",
      "epochs 52\n",
      "training loss 0.004595010488656404\n",
      "epochs 53\n",
      "training loss 0.004386546290875908\n",
      "epochs 54\n",
      "training loss 0.004687134542369417\n",
      "epochs 55\n",
      "training loss 0.004444952542174574\n",
      "epochs 56\n",
      "training loss 0.0044743292972071825\n",
      "epochs 57\n",
      "training loss 0.004267293717825395\n",
      "epochs 58\n",
      "training loss 0.004749810755165084\n",
      "epochs 59\n",
      "training loss 0.0046824209751578265\n",
      "testing loss 0.005678415653487363\n",
      "epochs 60\n",
      "training loss 0.004486640236598063\n",
      "epochs 61\n",
      "training loss 0.005471811351001172\n",
      "epochs 62\n",
      "training loss 0.004657752407462786\n",
      "epochs 63\n",
      "training loss 0.004258927812029843\n",
      "epochs 64\n",
      "training loss 0.00484850026113703\n",
      "epochs 65\n",
      "training loss 0.005130110457497097\n",
      "epochs 66\n",
      "training loss 0.005620721297332943\n",
      "epochs 67\n",
      "training loss 0.005167312405601506\n",
      "epochs 68\n",
      "training loss 0.004508460530060086\n",
      "epochs 69\n",
      "training loss 0.0043520496430662445\n",
      "testing loss 0.0049323195885496995\n",
      "epochs 70\n",
      "training loss 0.004190107269671188\n",
      "epochs 71\n",
      "training loss 0.0040533593371029275\n",
      "epochs 72\n",
      "training loss 0.004955589609209301\n",
      "epochs 73\n",
      "training loss 0.004311433161034229\n",
      "epochs 74\n",
      "training loss 0.00459898902155674\n",
      "epochs 75\n",
      "training loss 0.00409566479527015\n",
      "epochs 76\n",
      "training loss 0.00398399912338919\n",
      "epochs 77\n",
      "training loss 0.003987237193981203\n",
      "epochs 78\n",
      "training loss 0.005001080147766347\n",
      "epochs 79\n",
      "training loss 0.0054579733667108245\n",
      "testing loss 0.006435458071146768\n",
      "epochs 80\n",
      "training loss 0.005225342350210825\n",
      "epochs 81\n",
      "training loss 0.004543331448529425\n",
      "epochs 82\n",
      "training loss 0.004625528399750454\n",
      "epochs 83\n",
      "training loss 0.00434486059214365\n",
      "epochs 84\n",
      "training loss 0.004618638985589328\n",
      "epochs 85\n",
      "training loss 0.005533333809403731\n",
      "epochs 86\n",
      "training loss 0.004834781321244014\n",
      "epochs 87\n",
      "training loss 0.004614974764150236\n",
      "epochs 88\n",
      "training loss 0.004384499575410571\n",
      "epochs 89\n",
      "training loss 0.005428593740925918\n",
      "testing loss 0.006436191269705164\n",
      "epochs 90\n",
      "training loss 0.004821341109354513\n",
      "epochs 91\n",
      "training loss 0.005064966429186289\n",
      "epochs 92\n",
      "training loss 0.004174725649705706\n",
      "epochs 93\n",
      "training loss 0.005222739562983865\n",
      "epochs 94\n",
      "training loss 0.003971729357160719\n",
      "epochs 95\n",
      "training loss 0.004711644960380524\n",
      "epochs 96\n",
      "training loss 0.00443594157978847\n",
      "epochs 97\n",
      "training loss 0.0038750483827823972\n",
      "epochs 98\n",
      "training loss 0.0037758709341966998\n",
      "epochs 99\n",
      "training loss 0.003988822403726222\n",
      "testing loss 0.005146009241501596\n",
      "epochs 100\n",
      "training loss 0.0040580165005603235\n",
      "epochs 101\n",
      "training loss 0.0041905353613633746\n",
      "epochs 102\n",
      "training loss 0.0037052311041423525\n",
      "epochs 103\n",
      "training loss 0.0035329919119470254\n",
      "epochs 104\n",
      "training loss 0.0036757968650638242\n",
      "epochs 105\n",
      "training loss 0.0035358750017920344\n",
      "epochs 106\n",
      "training loss 0.00446301314549515\n",
      "epochs 107\n",
      "training loss 0.0037199270527238045\n",
      "epochs 108\n",
      "training loss 0.003759902381086241\n",
      "epochs 109\n",
      "training loss 0.003897515035695807\n",
      "testing loss 0.00482270365055809\n",
      "epochs 110\n",
      "training loss 0.00353685100343486\n",
      "epochs 111\n",
      "training loss 0.0034361732138199082\n",
      "epochs 112\n",
      "training loss 0.003477776275896736\n",
      "epochs 113\n",
      "training loss 0.006693883704185758\n",
      "epochs 114\n",
      "training loss 0.0048162007802038664\n",
      "epochs 115\n",
      "training loss 0.003929893640478603\n",
      "epochs 116\n",
      "training loss 0.0038084578710979016\n",
      "epochs 117\n",
      "training loss 0.003799255912568658\n",
      "epochs 118\n",
      "training loss 0.0034638692806743788\n",
      "epochs 119\n",
      "training loss 0.00359413193398662\n",
      "testing loss 0.004722172547138382\n",
      "epochs 120\n",
      "training loss 0.0031979466486993986\n",
      "epochs 121\n",
      "training loss 0.0032367356442478358\n",
      "epochs 122\n",
      "training loss 0.0033013687103188465\n",
      "epochs 123\n",
      "training loss 0.0039578815890294935\n",
      "epochs 124\n",
      "training loss 0.005251042381718777\n",
      "epochs 125\n",
      "training loss 0.003609006091425801\n",
      "epochs 126\n",
      "training loss 0.003359420304639565\n",
      "epochs 127\n",
      "training loss 0.003150981884449013\n",
      "epochs 128\n",
      "training loss 0.004752332412235801\n",
      "epochs 129\n",
      "training loss 0.005721819428882723\n",
      "testing loss 0.006398812309568022\n",
      "epochs 130\n",
      "training loss 0.005523652472748424\n",
      "epochs 131\n",
      "training loss 0.004962349006917475\n",
      "epochs 132\n",
      "training loss 0.0045586792510823775\n",
      "epochs 133\n",
      "training loss 0.004104799394266493\n",
      "epochs 134\n",
      "training loss 0.003770966490441905\n",
      "epochs 135\n",
      "training loss 0.003694909131140264\n",
      "epochs 136\n",
      "training loss 0.00357413136203544\n",
      "epochs 137\n",
      "training loss 0.0031362410523648456\n",
      "epochs 138\n",
      "training loss 0.0032112767598252052\n",
      "epochs 139\n",
      "training loss 0.0031240804079852116\n",
      "testing loss 0.004607999547061028\n",
      "epochs 140\n",
      "training loss 0.0030726402099909528\n",
      "epochs 141\n",
      "training loss 0.0033296441569454446\n",
      "epochs 142\n",
      "training loss 0.003248814177079449\n",
      "epochs 143\n",
      "training loss 0.003423147230114686\n",
      "epochs 144\n",
      "training loss 0.003295361352758907\n",
      "epochs 145\n",
      "training loss 0.0031597140729200876\n",
      "epochs 146\n",
      "training loss 0.002983896747885391\n",
      "epochs 147\n",
      "training loss 0.002989579851620216\n",
      "epochs 148\n",
      "training loss 0.0030814391563683294\n",
      "epochs 149\n",
      "training loss 0.00275888635655214\n",
      "testing loss 0.005103623023065111\n",
      "epochs 150\n",
      "training loss 0.002912155030179191\n",
      "epochs 151\n",
      "training loss 0.0030195351879715375\n",
      "epochs 152\n",
      "training loss 0.0032034614689557565\n",
      "epochs 153\n",
      "training loss 0.002835641314323686\n",
      "epochs 154\n",
      "training loss 0.0028813323200649176\n",
      "epochs 155\n",
      "training loss 0.0030331361336820395\n",
      "epochs 156\n",
      "training loss 0.0031700420337035617\n",
      "epochs 157\n",
      "training loss 0.0035795692154871567\n",
      "epochs 158\n",
      "training loss 0.0032101402173843516\n",
      "epochs 159\n",
      "training loss 0.0042757723598293735\n",
      "testing loss 0.006977417866256854\n",
      "epochs 160\n",
      "training loss 0.00504222579228219\n",
      "epochs 161\n",
      "training loss 0.0037621412890479194\n",
      "epochs 162\n",
      "training loss 0.003208934239573256\n",
      "epochs 163\n",
      "training loss 0.0032078093459184274\n",
      "epochs 164\n",
      "training loss 0.002858917174739112\n",
      "epochs 165\n",
      "training loss 0.0027915406476785526\n",
      "epochs 166\n",
      "training loss 0.003276902721914545\n",
      "epochs 167\n",
      "training loss 0.0030398260179969362\n",
      "epochs 168\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss 0.0027233960954783807\n",
      "epochs 169\n",
      "training loss 0.0027581296222833605\n",
      "testing loss 0.0042424650577141355\n",
      "epochs 170\n",
      "training loss 0.0026018049188968823\n",
      "epochs 171\n",
      "training loss 0.002980002699247179\n",
      "epochs 172\n",
      "training loss 0.002668383235457186\n",
      "epochs 173\n",
      "training loss 0.002765183173202114\n",
      "epochs 174\n",
      "training loss 0.004876679575953938\n",
      "epochs 175\n",
      "training loss 0.004794421551273542\n",
      "epochs 176\n",
      "training loss 0.0030135858254110876\n",
      "epochs 177\n",
      "training loss 0.002789724679057993\n",
      "epochs 178\n",
      "training loss 0.0028353250857250127\n",
      "epochs 179\n",
      "training loss 0.002764203759776513\n",
      "testing loss 0.004066234575881762\n",
      "epochs 180\n",
      "training loss 0.0027109768601151405\n",
      "epochs 181\n",
      "training loss 0.0026370697894691287\n",
      "epochs 182\n",
      "training loss 0.0026171024670077086\n",
      "epochs 183\n",
      "training loss 0.002647003864318891\n",
      "epochs 184\n",
      "training loss 0.0027316019128679685\n",
      "epochs 185\n",
      "training loss 0.005141002611514736\n",
      "epochs 186\n",
      "training loss 0.005166740900140516\n",
      "epochs 187\n",
      "training loss 0.005038837179694449\n",
      "epochs 188\n",
      "training loss 0.0036229819029648886\n",
      "epochs 189\n",
      "training loss 0.005234696504611828\n",
      "testing loss 0.006512412563600438\n",
      "epochs 190\n",
      "training loss 0.004733054241233457\n",
      "epochs 191\n",
      "training loss 0.0038744311582999116\n",
      "epochs 192\n",
      "training loss 0.0036459016669569905\n",
      "epochs 193\n",
      "training loss 0.0031003932632069956\n",
      "epochs 194\n",
      "training loss 0.002757568785985847\n",
      "epochs 195\n",
      "training loss 0.0029126824269716635\n",
      "epochs 196\n",
      "training loss 0.003197743831978018\n",
      "epochs 197\n",
      "training loss 0.0028252432269318807\n",
      "epochs 198\n",
      "training loss 0.0028352231729569023\n",
      "epochs 199\n",
      "training loss 0.0026878968997940556\n",
      "testing loss 0.004483345072841972\n",
      "epochs 200\n",
      "training loss 0.0026754408377352933\n",
      "epochs 201\n",
      "training loss 0.003149403107712062\n",
      "epochs 202\n",
      "training loss 0.005179188061027157\n",
      "epochs 203\n",
      "training loss 0.0028773289043626162\n",
      "epochs 204\n",
      "training loss 0.0027719062475606484\n",
      "epochs 205\n",
      "training loss 0.0026161003819635664\n",
      "epochs 206\n",
      "training loss 0.0025315641002350213\n",
      "epochs 207\n",
      "training loss 0.0033576747672887106\n",
      "epochs 208\n",
      "training loss 0.002633891763352424\n",
      "epochs 209\n",
      "training loss 0.0026040090047004193\n",
      "testing loss 0.0038798704862277556\n",
      "epochs 210\n",
      "training loss 0.0025296106498963046\n",
      "epochs 211\n",
      "training loss 0.0025836961551945893\n",
      "epochs 212\n",
      "training loss 0.002540378003150485\n",
      "epochs 213\n",
      "training loss 0.0026748935144612607\n",
      "epochs 214\n",
      "training loss 0.004123795959082259\n",
      "epochs 215\n",
      "training loss 0.002654562125373122\n",
      "epochs 216\n",
      "training loss 0.0026208676470692712\n",
      "epochs 217\n",
      "training loss 0.0025920838002245704\n",
      "epochs 218\n",
      "training loss 0.002461965801972771\n",
      "epochs 219\n",
      "training loss 0.0023993454412854416\n",
      "testing loss 0.004069083764924542\n",
      "epochs 220\n",
      "training loss 0.0025705381453682676\n",
      "epochs 221\n",
      "training loss 0.002384724169063713\n",
      "epochs 222\n",
      "training loss 0.002478928495931657\n",
      "epochs 223\n",
      "training loss 0.0027270965132364113\n",
      "epochs 224\n",
      "training loss 0.0033642377695181948\n",
      "epochs 225\n",
      "training loss 0.002707130969381724\n",
      "epochs 226\n",
      "training loss 0.002457520920970112\n",
      "epochs 227\n",
      "training loss 0.002391436217935886\n",
      "epochs 228\n",
      "training loss 0.00259055852703184\n",
      "epochs 229\n",
      "training loss 0.0023965430799815068\n",
      "testing loss 0.0037362331645034836\n",
      "epochs 230\n",
      "training loss 0.002363993612713942\n",
      "epochs 231\n",
      "training loss 0.002323065042611789\n",
      "epochs 232\n",
      "training loss 0.002508321241440257\n",
      "epochs 233\n",
      "training loss 0.006938428750706095\n",
      "epochs 234\n",
      "training loss 0.004351389941852823\n",
      "epochs 235\n",
      "training loss 0.002516584152406744\n",
      "epochs 236\n",
      "training loss 0.002482709921415227\n",
      "epochs 237\n",
      "training loss 0.002735359198979943\n",
      "epochs 238\n",
      "training loss 0.0024514497315446\n",
      "epochs 239\n",
      "training loss 0.002448357021051111\n",
      "testing loss 0.0037587767323241273\n",
      "epochs 240\n",
      "training loss 0.002405951371399465\n",
      "epochs 241\n",
      "training loss 0.0023340552013458\n",
      "epochs 242\n",
      "training loss 0.0023446204151397736\n",
      "epochs 243\n",
      "training loss 0.002398665300867659\n",
      "epochs 244\n",
      "training loss 0.006056672278834128\n",
      "epochs 245\n",
      "training loss 0.006329840253670572\n",
      "epochs 246\n",
      "training loss 0.006121667129933087\n",
      "epochs 247\n",
      "training loss 0.005976762092887427\n",
      "epochs 248\n",
      "training loss 0.003687519102079913\n",
      "epochs 249\n",
      "training loss 0.0028455630259724236\n",
      "testing loss 0.004006498922587287\n",
      "epochs 250\n",
      "training loss 0.0024757629510236048\n",
      "epochs 251\n",
      "training loss 0.0025432910554331802\n",
      "epochs 252\n",
      "training loss 0.0024847331415086215\n",
      "epochs 253\n",
      "training loss 0.0024209610583886257\n",
      "epochs 254\n",
      "training loss 0.0023752777326970977\n",
      "epochs 255\n",
      "training loss 0.0024066349359846313\n",
      "epochs 256\n",
      "training loss 0.002425663001583408\n",
      "epochs 257\n",
      "training loss 0.00231375112173524\n",
      "epochs 258\n",
      "training loss 0.0025365120240509803\n",
      "epochs 259\n",
      "training loss 0.0023129682791190034\n",
      "testing loss 0.003918597332684072\n",
      "epochs 260\n",
      "training loss 0.0025023610248318152\n",
      "epochs 261\n",
      "training loss 0.0022652720130900755\n",
      "epochs 262\n",
      "training loss 0.0035817222425566933\n",
      "epochs 263\n",
      "training loss 0.0031221716110608724\n",
      "epochs 264\n",
      "training loss 0.0024865344472832433\n",
      "epochs 265\n",
      "training loss 0.002512515499539628\n",
      "epochs 266\n",
      "training loss 0.0027349170505799533\n",
      "epochs 267\n",
      "training loss 0.002229920558356836\n",
      "epochs 268\n",
      "training loss 0.0022981409622160973\n",
      "epochs 269\n",
      "training loss 0.0022103068239047083\n",
      "testing loss 0.003841433409066435\n",
      "epochs 270\n",
      "training loss 0.0022829766141103528\n",
      "epochs 271\n",
      "training loss 0.002219170083908936\n",
      "epochs 272\n",
      "training loss 0.0023095109678683153\n",
      "epochs 273\n",
      "training loss 0.002434866923957746\n",
      "epochs 274\n",
      "training loss 0.0026660734928414045\n",
      "epochs 275\n",
      "training loss 0.002243803398284529\n",
      "epochs 276\n",
      "training loss 0.0023223016404696826\n",
      "epochs 277\n",
      "training loss 0.0026612351885586297\n",
      "epochs 278\n",
      "training loss 0.0022705183905835256\n",
      "epochs 279\n",
      "training loss 0.002232659432618089\n",
      "testing loss 0.0036843746763502135\n",
      "epochs 280\n",
      "training loss 0.0022705385021265247\n",
      "epochs 281\n",
      "training loss 0.0020211104772090457\n",
      "epochs 282\n",
      "training loss 0.0021461387112521563\n",
      "epochs 283\n",
      "training loss 0.002302754832266074\n",
      "epochs 284\n",
      "training loss 0.0022029461564515977\n",
      "epochs 285\n",
      "training loss 0.0021348924050178368\n",
      "epochs 286\n",
      "training loss 0.002163508175914728\n",
      "epochs 287\n",
      "training loss 0.002052116483955228\n",
      "epochs 288\n",
      "training loss 0.0022303482045569543\n",
      "epochs 289\n",
      "training loss 0.002231213346967264\n",
      "testing loss 0.0038560738263598887\n",
      "epochs 290\n",
      "training loss 0.0021984037933630535\n",
      "epochs 291\n",
      "training loss 0.0031750745757123436\n",
      "epochs 292\n",
      "training loss 0.0032852320517144395\n",
      "epochs 293\n",
      "training loss 0.002075207734085608\n",
      "epochs 294\n",
      "training loss 0.0020097998854786293\n",
      "epochs 295\n",
      "training loss 0.001929364361769115\n",
      "epochs 296\n",
      "training loss 0.0019441491355949667\n",
      "epochs 297\n",
      "training loss 0.0023403070370969577\n",
      "epochs 298\n",
      "training loss 0.00220173829211075\n",
      "epochs 299\n",
      "training loss 0.002005990806225359\n",
      "testing loss 0.003525436342304163\n",
      "epochs 300\n",
      "training loss 0.002079731851283993\n",
      "epochs 301\n",
      "training loss 0.0022410050871014865\n",
      "epochs 302\n",
      "training loss 0.001985820307888906\n",
      "epochs 303\n",
      "training loss 0.0019958230617631648\n",
      "epochs 304\n",
      "training loss 0.001895410488366707\n",
      "epochs 305\n",
      "training loss 0.0020175626696763973\n",
      "epochs 306\n",
      "training loss 0.002283071841843607\n",
      "epochs 307\n",
      "training loss 0.0020360328015760947\n",
      "epochs 308\n",
      "training loss 0.00204823419202606\n",
      "epochs 309\n",
      "training loss 0.002198267948182475\n",
      "testing loss 0.004243468740254852\n",
      "epochs 310\n",
      "training loss 0.0022930544608210333\n",
      "epochs 311\n",
      "training loss 0.0020400050675105814\n",
      "epochs 312\n",
      "training loss 0.0019151635268437012\n",
      "epochs 313\n",
      "training loss 0.001966630110069883\n",
      "epochs 314\n",
      "training loss 0.0020026778942044813\n",
      "epochs 315\n",
      "training loss 0.00202927957104921\n",
      "epochs 316\n",
      "training loss 0.001913121934360216\n",
      "epochs 317\n",
      "training loss 0.0020414939966536833\n",
      "epochs 318\n",
      "training loss 0.0019045188137695283\n",
      "epochs 319\n",
      "training loss 0.0018269047344536564\n",
      "testing loss 0.0033815971093503296\n",
      "epochs 320\n",
      "training loss 0.0017923640680292728\n",
      "epochs 321\n",
      "training loss 0.0018558622251893182\n",
      "epochs 322\n",
      "training loss 0.002630311253022029\n",
      "epochs 323\n",
      "training loss 0.0019097451846353075\n",
      "epochs 324\n",
      "training loss 0.0019617440149974994\n",
      "epochs 325\n",
      "training loss 0.0018916857562602518\n",
      "epochs 326\n",
      "training loss 0.0019056071597363766\n",
      "epochs 327\n",
      "training loss 0.002081266004241165\n",
      "epochs 328\n",
      "training loss 0.0017992245841213703\n",
      "epochs 329\n",
      "training loss 0.0018365197402062771\n",
      "testing loss 0.003452912752817101\n",
      "epochs 330\n",
      "training loss 0.0019602930140724026\n",
      "epochs 331\n",
      "training loss 0.0020562996726913385\n",
      "epochs 332\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss 0.0020020364456042918\n",
      "epochs 333\n",
      "training loss 0.001796187228051872\n",
      "epochs 334\n",
      "training loss 0.0019078500815497366\n",
      "epochs 335\n",
      "training loss 0.0019062020406155284\n",
      "epochs 336\n",
      "training loss 0.0018578090030547108\n",
      "epochs 337\n",
      "training loss 0.002007585023473212\n",
      "epochs 338\n",
      "training loss 0.0020858582918104746\n",
      "epochs 339\n",
      "training loss 0.0020240078519925043\n",
      "testing loss 0.0033767699315179643\n",
      "epochs 340\n",
      "training loss 0.0018445150093401932\n",
      "epochs 341\n",
      "training loss 0.001914908492012023\n",
      "epochs 342\n",
      "training loss 0.0023207621424923166\n",
      "epochs 343\n",
      "training loss 0.001969863182941514\n",
      "epochs 344\n",
      "training loss 0.001984429577546687\n",
      "epochs 345\n",
      "training loss 0.002049470943997481\n",
      "epochs 346\n",
      "training loss 0.0019165005688456462\n",
      "epochs 347\n",
      "training loss 0.0018994603219362808\n",
      "epochs 348\n",
      "training loss 0.0016763520085233006\n",
      "epochs 349\n",
      "training loss 0.0016841168887276304\n",
      "testing loss 0.0038239846405645848\n",
      "epochs 350\n",
      "training loss 0.0018654193574885376\n",
      "epochs 351\n",
      "training loss 0.001717621518056953\n",
      "epochs 352\n",
      "training loss 0.0017107231482314258\n",
      "epochs 353\n",
      "training loss 0.00167511799691194\n",
      "epochs 354\n",
      "training loss 0.0018188870957087284\n",
      "epochs 355\n",
      "training loss 0.0017556266441281691\n",
      "epochs 356\n",
      "training loss 0.0016375258524256749\n",
      "epochs 357\n",
      "training loss 0.0016719924852515269\n",
      "epochs 358\n",
      "training loss 0.0016861100469526232\n",
      "epochs 359\n",
      "training loss 0.0017380702253048928\n",
      "testing loss 0.003109249113794707\n",
      "epochs 360\n",
      "training loss 0.0016755882012275667\n",
      "epochs 361\n",
      "training loss 0.003302605046875107\n",
      "epochs 362\n",
      "training loss 0.002800973049452738\n",
      "epochs 363\n",
      "training loss 0.0018415577339198112\n",
      "epochs 364\n",
      "training loss 0.0017156600433764102\n",
      "epochs 365\n",
      "training loss 0.0019415552679401197\n",
      "epochs 366\n",
      "training loss 0.0016086839233584544\n",
      "epochs 367\n",
      "training loss 0.0017159792911657628\n",
      "epochs 368\n",
      "training loss 0.0017867806048407063\n",
      "epochs 369\n",
      "training loss 0.001572337380177299\n",
      "testing loss 0.0030649517297890064\n",
      "epochs 370\n",
      "training loss 0.0017482364680448201\n",
      "epochs 371\n",
      "training loss 0.0019270193539800457\n",
      "epochs 372\n",
      "training loss 0.001672967917025429\n",
      "epochs 373\n",
      "training loss 0.0017438131472305323\n",
      "epochs 374\n",
      "training loss 0.00170229044764113\n",
      "epochs 375\n",
      "training loss 0.0016526707149419288\n",
      "epochs 376\n",
      "training loss 0.0020641105495093214\n",
      "epochs 377\n",
      "training loss 0.0018503398292678151\n",
      "epochs 378\n",
      "training loss 0.0018116554705706342\n",
      "epochs 379\n",
      "training loss 0.0026244713684563784\n",
      "testing loss 0.004960127373833658\n",
      "epochs 380\n",
      "training loss 0.0025717069642224822\n",
      "epochs 381\n",
      "training loss 0.0017902630591470647\n",
      "epochs 382\n",
      "training loss 0.001628912254632946\n",
      "epochs 383\n",
      "training loss 0.0022273735172613483\n",
      "epochs 384\n",
      "training loss 0.0022118391306705683\n",
      "epochs 385\n",
      "training loss 0.0017478533181514715\n",
      "epochs 386\n",
      "training loss 0.001530936954537333\n",
      "epochs 387\n",
      "training loss 0.0016851542424835197\n",
      "epochs 388\n",
      "training loss 0.002123722556934587\n",
      "epochs 389\n",
      "training loss 0.00179486866123227\n",
      "testing loss 0.0031526341690873423\n",
      "epochs 390\n",
      "training loss 0.0016321467674807234\n",
      "epochs 391\n",
      "training loss 0.0015397902725315384\n",
      "epochs 392\n",
      "training loss 0.0014722730377391773\n",
      "epochs 393\n",
      "training loss 0.0016076862153888746\n",
      "epochs 394\n",
      "training loss 0.0016052611556122119\n",
      "epochs 395\n",
      "training loss 0.0016418061554247915\n",
      "epochs 396\n",
      "training loss 0.0015741448078409267\n",
      "epochs 397\n",
      "training loss 0.0015936197308217682\n",
      "epochs 398\n",
      "training loss 0.0016254686869363836\n",
      "epochs 399\n",
      "training loss 0.0016353066338687615\n",
      "testing loss 0.003183026502077329\n",
      "epochs 400\n",
      "training loss 0.0016512793103462273\n",
      "epochs 401\n",
      "training loss 0.0015257798805111016\n",
      "epochs 402\n",
      "training loss 0.001585787527530672\n",
      "epochs 403\n",
      "training loss 0.0015876443832291793\n",
      "epochs 404\n",
      "training loss 0.0015303289939190819\n",
      "epochs 405\n",
      "training loss 0.0016399542230505519\n",
      "epochs 406\n",
      "training loss 0.0017589846288708908\n",
      "epochs 407\n",
      "training loss 0.002523521695103451\n",
      "epochs 408\n",
      "training loss 0.00205735525712201\n",
      "epochs 409\n",
      "training loss 0.0015921405614580178\n",
      "testing loss 0.002992334763654871\n",
      "epochs 410\n",
      "training loss 0.0017764726894310362\n",
      "epochs 411\n",
      "training loss 0.0016301707115157374\n",
      "epochs 412\n",
      "training loss 0.0016068225685085275\n",
      "epochs 413\n",
      "training loss 0.0015383814178452485\n",
      "epochs 414\n",
      "training loss 0.0015952237057258972\n",
      "epochs 415\n",
      "training loss 0.0015536420723836653\n",
      "epochs 416\n",
      "training loss 0.001621331575844652\n",
      "epochs 417\n",
      "training loss 0.0015556517704305066\n",
      "epochs 418\n",
      "training loss 0.001501635680864013\n",
      "epochs 419\n",
      "training loss 0.0015552738871804713\n",
      "testing loss 0.0031304652344415636\n",
      "epochs 420\n",
      "training loss 0.0015331392201572362\n",
      "epochs 421\n",
      "training loss 0.0015444272327998308\n",
      "epochs 422\n",
      "training loss 0.0016493445239666748\n",
      "epochs 423\n",
      "training loss 0.0017477744795016854\n",
      "epochs 424\n",
      "training loss 0.0016568222809950949\n",
      "epochs 425\n",
      "training loss 0.0014988388464570973\n",
      "epochs 426\n",
      "training loss 0.0018601307122101923\n",
      "epochs 427\n",
      "training loss 0.00159014990828552\n",
      "epochs 428\n",
      "training loss 0.0016704055957997212\n",
      "epochs 429\n",
      "training loss 0.0057614791457538455\n",
      "testing loss 0.006186627218968743\n",
      "epochs 430\n",
      "training loss 0.0037997895880038978\n",
      "epochs 431\n",
      "training loss 0.002718934216069505\n",
      "epochs 432\n",
      "training loss 0.001985480701572072\n",
      "epochs 433\n",
      "training loss 0.0017522312852902208\n",
      "epochs 434\n",
      "training loss 0.0015916991494114774\n",
      "epochs 435\n",
      "training loss 0.0015543488593486147\n",
      "epochs 436\n",
      "training loss 0.0015193357638021122\n",
      "epochs 437\n",
      "training loss 0.0014345259672826252\n",
      "epochs 438\n",
      "training loss 0.0014683012533890463\n",
      "epochs 439\n",
      "training loss 0.0014835675560167247\n",
      "testing loss 0.0033322615302927424\n",
      "epochs 440\n",
      "training loss 0.0014371816449272122\n",
      "epochs 441\n",
      "training loss 0.0013928587009173488\n",
      "epochs 442\n",
      "training loss 0.0014250155155813055\n",
      "epochs 443\n",
      "training loss 0.0014991092005189747\n",
      "epochs 444\n",
      "training loss 0.0015428101893027503\n",
      "epochs 445\n",
      "training loss 0.0014851736561197074\n",
      "epochs 446\n",
      "training loss 0.001471072207856074\n",
      "epochs 447\n",
      "training loss 0.0014268405973277194\n",
      "epochs 448\n",
      "training loss 0.0015114467181647508\n",
      "epochs 449\n",
      "training loss 0.0014154569939059123\n",
      "testing loss 0.00310363014375606\n",
      "epochs 450\n",
      "training loss 0.0014452595220550352\n",
      "epochs 451\n",
      "training loss 0.001442402960572641\n",
      "epochs 452\n",
      "training loss 0.0014983864862395389\n",
      "epochs 453\n",
      "training loss 0.0015079458196375713\n",
      "epochs 454\n",
      "training loss 0.0014566655214493783\n",
      "epochs 455\n",
      "training loss 0.001570263068088384\n",
      "epochs 456\n",
      "training loss 0.0014262724558802996\n",
      "epochs 457\n",
      "training loss 0.0014340497980086773\n",
      "epochs 458\n",
      "training loss 0.0013617234340639597\n",
      "epochs 459\n",
      "training loss 0.0014109449771779242\n",
      "testing loss 0.0031346860085779155\n",
      "epochs 460\n",
      "training loss 0.0014213293020848446\n",
      "epochs 461\n",
      "training loss 0.0013737293948577916\n",
      "epochs 462\n",
      "training loss 0.0013667374847904075\n",
      "epochs 463\n",
      "training loss 0.0015183086857329885\n",
      "epochs 464\n",
      "training loss 0.0013464857841131354\n",
      "epochs 465\n",
      "training loss 0.0013813419622442711\n",
      "epochs 466\n",
      "training loss 0.001438770042293589\n",
      "epochs 467\n",
      "training loss 0.0015333829671257716\n",
      "epochs 468\n",
      "training loss 0.0016586484133101727\n",
      "epochs 469\n",
      "training loss 0.0014870526277216713\n",
      "testing loss 0.0028747405955098994\n",
      "epochs 470\n",
      "training loss 0.0013892769800799142\n",
      "epochs 471\n",
      "training loss 0.0013498836069574473\n",
      "epochs 472\n",
      "training loss 0.0013723157437894732\n",
      "epochs 473\n",
      "training loss 0.0013880274604615333\n",
      "epochs 474\n",
      "training loss 0.0015255768988975027\n",
      "epochs 475\n",
      "training loss 0.0015572300212638945\n",
      "epochs 476\n",
      "training loss 0.001563732150133903\n",
      "epochs 477\n",
      "training loss 0.0017210457742562388\n",
      "epochs 478\n",
      "training loss 0.0015632054728871964\n",
      "epochs 479\n",
      "training loss 0.0014105510018981066\n",
      "testing loss 0.0028271630954605047\n",
      "epochs 480\n",
      "training loss 0.001370073473052685\n",
      "epochs 481\n",
      "training loss 0.0012752354453957574\n",
      "epochs 482\n",
      "training loss 0.0014369582985938275\n",
      "epochs 483\n",
      "training loss 0.0012570951549027761\n",
      "epochs 484\n",
      "training loss 0.0013597666246655162\n",
      "epochs 485\n",
      "training loss 0.001301732289181643\n",
      "epochs 486\n",
      "training loss 0.0013743348191081798\n",
      "epochs 487\n",
      "training loss 0.0013282527251163424\n",
      "epochs 488\n",
      "training loss 0.001297965092198091\n",
      "epochs 489\n",
      "training loss 0.0013094418857311745\n",
      "testing loss 0.0026910744775879257\n",
      "epochs 490\n",
      "training loss 0.0013504427371866504\n",
      "epochs 491\n",
      "training loss 0.0013126298738501989\n",
      "epochs 492\n",
      "training loss 0.0013079922451668825\n",
      "epochs 493\n",
      "training loss 0.001292344852913975\n",
      "epochs 494\n",
      "training loss 0.0013617772002503456\n",
      "epochs 495\n",
      "training loss 0.0014107573436329703\n",
      "epochs 496\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss 0.0013351092434567499\n",
      "epochs 497\n",
      "training loss 0.0012991619977525415\n",
      "epochs 498\n",
      "training loss 0.0013447703218999062\n",
      "epochs 499\n",
      "training loss 0.0012971121381888998\n",
      "testing loss 0.002892412863678385\n",
      "epochs 500\n",
      "training loss 0.0013041076298851214\n",
      "epochs 501\n",
      "training loss 0.0014777582994730163\n",
      "epochs 502\n",
      "training loss 0.0013453922438644733\n",
      "epochs 503\n",
      "training loss 0.0013960146208613613\n",
      "epochs 504\n",
      "training loss 0.0013014569607532177\n",
      "epochs 505\n",
      "training loss 0.0012522327522945373\n",
      "epochs 506\n",
      "training loss 0.0013231396302510064\n",
      "epochs 507\n",
      "training loss 0.001951981367370663\n",
      "epochs 508\n",
      "training loss 0.001512841234128005\n",
      "epochs 509\n",
      "training loss 0.001467362535079958\n",
      "testing loss 0.00282765128889207\n",
      "epochs 510\n",
      "training loss 0.0012773909548716479\n",
      "epochs 511\n",
      "training loss 0.0013154740809777179\n",
      "epochs 512\n",
      "training loss 0.0013003581661573897\n",
      "epochs 513\n",
      "training loss 0.0012811567309867352\n",
      "epochs 514\n",
      "training loss 0.0013454427670526084\n",
      "epochs 515\n",
      "training loss 0.0012711646866143927\n",
      "epochs 516\n",
      "training loss 0.0013450616730043047\n",
      "epochs 517\n",
      "training loss 0.0012153883924280325\n",
      "epochs 518\n",
      "training loss 0.0013149160651863754\n",
      "epochs 519\n",
      "training loss 0.0012895078792825546\n",
      "testing loss 0.0030742551700430032\n",
      "epochs 520\n",
      "training loss 0.0012804543299424975\n",
      "epochs 521\n",
      "training loss 0.001303635931277993\n",
      "epochs 522\n",
      "training loss 0.0012128106736837062\n",
      "epochs 523\n",
      "training loss 0.001306107635029498\n",
      "epochs 524\n",
      "training loss 0.0012768251029845316\n",
      "epochs 525\n",
      "training loss 0.0012449859775953832\n",
      "epochs 526\n",
      "training loss 0.0012569592669068362\n",
      "epochs 527\n",
      "training loss 0.0016525775913536934\n",
      "epochs 528\n",
      "training loss 0.0013006182870824784\n",
      "epochs 529\n",
      "training loss 0.001186009212489039\n",
      "testing loss 0.0027974436422050367\n",
      "epochs 530\n",
      "training loss 0.0012798511396985965\n",
      "epochs 531\n",
      "training loss 0.0012302716279623176\n",
      "epochs 532\n",
      "training loss 0.001281557857670388\n",
      "epochs 533\n",
      "training loss 0.001648442830153002\n",
      "epochs 534\n",
      "training loss 0.0014161451675116698\n",
      "epochs 535\n",
      "training loss 0.0012593661943778938\n",
      "epochs 536\n",
      "training loss 0.0012704926062768783\n",
      "epochs 537\n",
      "training loss 0.0013156601682158136\n",
      "epochs 538\n",
      "training loss 0.002797867776189101\n",
      "epochs 539\n",
      "training loss 0.002690380518600673\n",
      "testing loss 0.0030701286609429892\n",
      "epochs 540\n",
      "training loss 0.0032614556154997674\n",
      "epochs 541\n",
      "training loss 0.002768310399600064\n",
      "epochs 542\n",
      "training loss 0.001428267090881419\n",
      "epochs 543\n",
      "training loss 0.0013044631971318081\n",
      "epochs 544\n",
      "training loss 0.0012556876563311393\n",
      "epochs 545\n",
      "training loss 0.0012881572876340714\n",
      "epochs 546\n",
      "training loss 0.0012327574882061874\n",
      "epochs 547\n",
      "training loss 0.001182925871659727\n",
      "epochs 548\n",
      "training loss 0.0012699208216314236\n",
      "epochs 549\n",
      "training loss 0.0013128274571897864\n",
      "testing loss 0.002792052795007455\n",
      "epochs 550\n",
      "training loss 0.0012107376254441098\n",
      "epochs 551\n",
      "training loss 0.0012992023181461795\n",
      "epochs 552\n",
      "training loss 0.0011787208960969057\n",
      "epochs 553\n",
      "training loss 0.0012529370745454312\n",
      "epochs 554\n",
      "training loss 0.00121553711618628\n",
      "epochs 555\n",
      "training loss 0.0012568501314349292\n",
      "epochs 556\n",
      "training loss 0.0012845804657939945\n",
      "epochs 557\n",
      "training loss 0.0012147568534609599\n",
      "epochs 558\n",
      "training loss 0.0012476558630399996\n",
      "epochs 559\n",
      "training loss 0.0012316941357950898\n",
      "testing loss 0.0029637101263217365\n",
      "epochs 560\n",
      "training loss 0.0012164061501944907\n",
      "epochs 561\n",
      "training loss 0.001247278603974243\n",
      "epochs 562\n",
      "training loss 0.0012927049554043695\n",
      "epochs 563\n",
      "training loss 0.0012707549027354092\n",
      "epochs 564\n",
      "training loss 0.0011754098962596122\n",
      "epochs 565\n",
      "training loss 0.0012038668768344543\n",
      "epochs 566\n",
      "training loss 0.0011476882137881881\n",
      "epochs 567\n",
      "training loss 0.0012125564802092667\n",
      "epochs 568\n",
      "training loss 0.0011887821667165266\n",
      "epochs 569\n",
      "training loss 0.0012380984168794107\n",
      "testing loss 0.002769789413684411\n",
      "epochs 570\n",
      "training loss 0.0011896704342874407\n",
      "epochs 571\n",
      "training loss 0.0011704206142198056\n",
      "epochs 572\n",
      "training loss 0.0011326627265152416\n",
      "epochs 573\n",
      "training loss 0.001316553160957256\n",
      "epochs 574\n",
      "training loss 0.0012072300783282084\n",
      "epochs 575\n",
      "training loss 0.0012001477914018767\n",
      "epochs 576\n",
      "training loss 0.0011804833414463332\n",
      "epochs 577\n",
      "training loss 0.0011654950844302299\n",
      "epochs 578\n",
      "training loss 0.0011903440926894885\n",
      "epochs 579\n",
      "training loss 0.0012152072908795555\n",
      "testing loss 0.0030605009668638783\n",
      "epochs 580\n",
      "training loss 0.0012402403297357115\n",
      "epochs 581\n",
      "training loss 0.0012456287559487016\n",
      "epochs 582\n",
      "training loss 0.0012530137964886668\n",
      "epochs 583\n",
      "training loss 0.0011698551784555418\n",
      "epochs 584\n",
      "training loss 0.0011723425915524206\n",
      "epochs 585\n",
      "training loss 0.0011889068809646467\n",
      "epochs 586\n",
      "training loss 0.0011072521747973122\n",
      "epochs 587\n",
      "training loss 0.0011865715243242184\n",
      "epochs 588\n",
      "training loss 0.0011728053343182255\n",
      "epochs 589\n",
      "training loss 0.0011234834121814773\n",
      "testing loss 0.0027851567942985987\n",
      "epochs 590\n",
      "training loss 0.00293786472026655\n",
      "epochs 591\n",
      "training loss 0.001698741048332417\n",
      "epochs 592\n",
      "training loss 0.0014180942188373746\n",
      "epochs 593\n",
      "training loss 0.0011625036984359376\n",
      "epochs 594\n",
      "training loss 0.0011317526246137962\n",
      "epochs 595\n",
      "training loss 0.0010981203954225254\n",
      "epochs 596\n",
      "training loss 0.0011267529004026985\n",
      "epochs 597\n",
      "training loss 0.001095359448957792\n",
      "epochs 598\n",
      "training loss 0.0012161791056400238\n",
      "epochs 599\n",
      "training loss 0.0012047684682097207\n",
      "testing loss 0.002805525294161593\n",
      "epochs 600\n",
      "training loss 0.0011251251930498312\n",
      "epochs 601\n",
      "training loss 0.001152331633514535\n",
      "epochs 602\n",
      "training loss 0.0011117773907758737\n",
      "epochs 603\n",
      "training loss 0.0010767585598286185\n",
      "epochs 604\n",
      "training loss 0.0011831598436335346\n",
      "epochs 605\n",
      "training loss 0.001158510352482051\n",
      "epochs 606\n",
      "training loss 0.0012343312432496925\n",
      "epochs 607\n",
      "training loss 0.0011199976080153873\n",
      "epochs 608\n",
      "training loss 0.0011562317277879475\n",
      "epochs 609\n",
      "training loss 0.0012329651657095615\n",
      "testing loss 0.0030552657541541503\n",
      "epochs 610\n",
      "training loss 0.0011826369900463042\n",
      "epochs 611\n",
      "training loss 0.0011542444368597901\n",
      "epochs 612\n",
      "training loss 0.0010745625371130405\n",
      "epochs 613\n",
      "training loss 0.0011641105030462326\n",
      "epochs 614\n",
      "training loss 0.0011069456837741562\n",
      "epochs 615\n",
      "training loss 0.0011712260214161796\n",
      "epochs 616\n",
      "training loss 0.0010600958908002223\n",
      "epochs 617\n",
      "training loss 0.0011472782411323832\n",
      "epochs 618\n",
      "training loss 0.0011511435068784265\n",
      "epochs 619\n",
      "training loss 0.001142134431375921\n",
      "testing loss 0.0027718473851667544\n",
      "epochs 620\n",
      "training loss 0.0011058508761377162\n",
      "epochs 621\n",
      "training loss 0.001120373594474138\n",
      "epochs 622\n",
      "training loss 0.0011795122396854802\n",
      "epochs 623\n",
      "training loss 0.0012935998355601786\n",
      "epochs 624\n",
      "training loss 0.001184640390165773\n",
      "epochs 625\n",
      "training loss 0.0010938789070255512\n",
      "epochs 626\n",
      "training loss 0.0011075743529620073\n",
      "epochs 627\n",
      "training loss 0.0011148019249715183\n",
      "epochs 628\n",
      "training loss 0.0011272825220016633\n",
      "epochs 629\n",
      "training loss 0.0011459461911892841\n",
      "testing loss 0.0029442687423946005\n",
      "epochs 630\n",
      "training loss 0.0010458083317677368\n",
      "epochs 631\n",
      "training loss 0.001090164998359412\n",
      "epochs 632\n",
      "training loss 0.0011202200700877105\n",
      "epochs 633\n",
      "training loss 0.0011263535132257998\n",
      "epochs 634\n",
      "training loss 0.0011969589195525597\n",
      "epochs 635\n",
      "training loss 0.0010644103309116963\n",
      "epochs 636\n",
      "training loss 0.0011555632635792518\n",
      "epochs 637\n",
      "training loss 0.0011282077824872406\n",
      "epochs 638\n",
      "training loss 0.0011468566766597535\n",
      "epochs 639\n",
      "training loss 0.0011209150771667054\n",
      "testing loss 0.0027423684191328623\n",
      "epochs 640\n",
      "training loss 0.0010300109277572766\n",
      "epochs 641\n",
      "training loss 0.0011218835445443638\n",
      "epochs 642\n",
      "training loss 0.0010734866663394637\n",
      "epochs 643\n",
      "training loss 0.0010269794855153579\n",
      "epochs 644\n",
      "training loss 0.0012358287972112196\n",
      "epochs 645\n",
      "training loss 0.0012470474243758524\n",
      "epochs 646\n",
      "training loss 0.0011812628166874626\n",
      "epochs 647\n",
      "training loss 0.0011728165048814313\n",
      "epochs 648\n",
      "training loss 0.0010957256627218135\n",
      "epochs 649\n",
      "training loss 0.0010967208040697008\n",
      "testing loss 0.0027862362685804882\n",
      "epochs 650\n",
      "training loss 0.001058447048581831\n",
      "epochs 651\n",
      "training loss 0.0010456436385873331\n",
      "epochs 652\n",
      "training loss 0.0010445235644914437\n",
      "epochs 653\n",
      "training loss 0.0010781230503696055\n",
      "epochs 654\n",
      "training loss 0.0010503659537557434\n",
      "epochs 655\n",
      "training loss 0.0012192986661421084\n",
      "epochs 656\n",
      "training loss 0.0010098690254823233\n",
      "epochs 657\n",
      "training loss 0.0010128495597286223\n",
      "epochs 658\n",
      "training loss 0.0011381624980566394\n",
      "epochs 659\n",
      "training loss 0.0009944860716944838\n",
      "testing loss 0.0029330840429244893\n",
      "epochs 660\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss 0.0010751800503338317\n",
      "epochs 661\n",
      "training loss 0.0012028558194951513\n",
      "epochs 662\n",
      "training loss 0.0018358253351961882\n",
      "epochs 663\n",
      "training loss 0.001378572732245544\n",
      "epochs 664\n",
      "training loss 0.0010836949951643843\n",
      "epochs 665\n",
      "training loss 0.0010345911847407672\n",
      "epochs 666\n",
      "training loss 0.0010516446232045561\n",
      "epochs 667\n",
      "training loss 0.001039309507288254\n",
      "epochs 668\n",
      "training loss 0.0012883972491584946\n",
      "epochs 669\n",
      "training loss 0.0010879093446375344\n",
      "testing loss 0.002758517685092008\n",
      "epochs 670\n",
      "training loss 0.0009870680916338232\n",
      "epochs 671\n",
      "training loss 0.002810838858923934\n",
      "epochs 672\n",
      "training loss 0.0031954053404392806\n",
      "epochs 673\n",
      "training loss 0.0019855968435478926\n",
      "epochs 674\n",
      "training loss 0.0019842086628427597\n",
      "epochs 675\n",
      "training loss 0.0018107463744763386\n",
      "epochs 676\n",
      "training loss 0.00121372898224611\n",
      "epochs 677\n",
      "training loss 0.0010909268310177493\n",
      "epochs 678\n",
      "training loss 0.0010461961209355063\n",
      "epochs 679\n",
      "training loss 0.0010410719425530714\n",
      "testing loss 0.002677970714883628\n",
      "epochs 680\n",
      "training loss 0.0010210623760144354\n",
      "epochs 681\n",
      "training loss 0.0010494315199904981\n",
      "epochs 682\n",
      "training loss 0.0010766270044995727\n",
      "epochs 683\n",
      "training loss 0.0010842987207772272\n",
      "epochs 684\n",
      "training loss 0.0010894146126179778\n",
      "epochs 685\n",
      "training loss 0.0009940800582211588\n",
      "epochs 686\n",
      "training loss 0.001039196257118566\n",
      "epochs 687\n",
      "training loss 0.0010060294447070423\n",
      "epochs 688\n",
      "training loss 0.0010721726046866626\n",
      "epochs 689\n",
      "training loss 0.0012490621169584614\n",
      "testing loss 0.0026744564942328642\n",
      "epochs 690\n",
      "training loss 0.0010308649650658834\n",
      "epochs 691\n",
      "training loss 0.0010692731533581703\n",
      "epochs 692\n",
      "training loss 0.0010543078547527612\n",
      "epochs 693\n",
      "training loss 0.0010821352451671718\n",
      "epochs 694\n",
      "training loss 0.002504525881148818\n",
      "epochs 695\n",
      "training loss 0.002590729127139827\n",
      "epochs 696\n",
      "training loss 0.0031854805904921813\n",
      "epochs 697\n",
      "training loss 0.00268724823503622\n",
      "epochs 698\n",
      "training loss 0.001593538577134769\n",
      "epochs 699\n",
      "training loss 0.0013006207349888505\n",
      "testing loss 0.0027513194165410516\n",
      "epochs 700\n",
      "training loss 0.0011826366650387872\n",
      "epochs 701\n",
      "training loss 0.001100269800170939\n",
      "epochs 702\n",
      "training loss 0.0010692038347570956\n",
      "epochs 703\n",
      "training loss 0.0010475230664736663\n",
      "epochs 704\n",
      "training loss 0.0010425758464573274\n",
      "epochs 705\n",
      "training loss 0.00110932646866316\n",
      "epochs 706\n",
      "training loss 0.0010616575156502698\n",
      "epochs 707\n",
      "training loss 0.001022816278991547\n",
      "epochs 708\n",
      "training loss 0.0010302393181648637\n",
      "epochs 709\n",
      "training loss 0.0013632975107534453\n",
      "testing loss 0.0028677060527244834\n",
      "epochs 710\n",
      "training loss 0.0010470001783864545\n",
      "epochs 711\n",
      "training loss 0.0010272934986844569\n",
      "epochs 712\n",
      "training loss 0.001006832195404849\n",
      "epochs 713\n",
      "training loss 0.0009950611867381423\n",
      "epochs 714\n",
      "training loss 0.0011134406956518493\n",
      "epochs 715\n",
      "training loss 0.0011105307342136408\n",
      "epochs 716\n",
      "training loss 0.0010147817062403678\n",
      "epochs 717\n",
      "training loss 0.0010045055506289525\n",
      "epochs 718\n",
      "training loss 0.0010723311467857686\n",
      "epochs 719\n",
      "training loss 0.001028465027291056\n",
      "testing loss 0.00274511545331792\n",
      "epochs 720\n",
      "training loss 0.0010482775575359632\n",
      "epochs 721\n",
      "training loss 0.0010547467341468213\n",
      "epochs 722\n",
      "training loss 0.001069350484270308\n",
      "epochs 723\n",
      "training loss 0.0010547237988245762\n",
      "epochs 724\n",
      "training loss 0.001088310762182569\n",
      "epochs 725\n",
      "training loss 0.0012134473466903176\n",
      "epochs 726\n",
      "training loss 0.001086281598007765\n",
      "epochs 727\n",
      "training loss 0.001065041943832575\n",
      "epochs 728\n",
      "training loss 0.0010385390130115111\n",
      "epochs 729\n",
      "training loss 0.0009945704782874207\n",
      "testing loss 0.0030381272362003512\n",
      "epochs 730\n",
      "training loss 0.001005602146868274\n",
      "epochs 731\n",
      "training loss 0.0010569458896376328\n",
      "epochs 732\n",
      "training loss 0.0009894290706142783\n",
      "epochs 733\n",
      "training loss 0.0011124510940278974\n",
      "epochs 734\n",
      "training loss 0.0009879931810348774\n",
      "epochs 735\n",
      "training loss 0.0010523935857775274\n",
      "epochs 736\n",
      "training loss 0.000978563248574745\n",
      "epochs 737\n",
      "training loss 0.0010842156117374367\n",
      "epochs 738\n",
      "training loss 0.001041758240598302\n",
      "epochs 739\n",
      "training loss 0.0010188080327610816\n",
      "testing loss 0.0027753326770228646\n",
      "epochs 740\n",
      "training loss 0.0009793107510023499\n",
      "epochs 741\n",
      "training loss 0.001028594811621057\n",
      "epochs 742\n",
      "training loss 0.000979124616525818\n",
      "epochs 743\n",
      "training loss 0.000998439006139397\n",
      "epochs 744\n",
      "training loss 0.0010154298970215362\n",
      "epochs 745\n",
      "training loss 0.0010361679403980385\n",
      "epochs 746\n",
      "training loss 0.0011441488669778994\n",
      "epochs 747\n",
      "training loss 0.0010291212126025278\n",
      "epochs 748\n",
      "training loss 0.0009523836046062399\n",
      "epochs 749\n",
      "training loss 0.0010019198051543403\n",
      "testing loss 0.0032171724324530746\n",
      "epochs 750\n",
      "training loss 0.00104534988097654\n",
      "epochs 751\n",
      "training loss 0.0010697794216543459\n",
      "epochs 752\n",
      "training loss 0.0009681763958807265\n",
      "epochs 753\n",
      "training loss 0.0009750943830149039\n",
      "epochs 754\n",
      "training loss 0.0009685719660327608\n",
      "epochs 755\n",
      "training loss 0.0010451817241749276\n",
      "epochs 756\n",
      "training loss 0.0009514352049831426\n",
      "epochs 757\n",
      "training loss 0.0009805963054089878\n",
      "epochs 758\n",
      "training loss 0.001313123245699484\n",
      "epochs 759\n",
      "training loss 0.0009470246121850668\n",
      "testing loss 0.0028361036146640883\n",
      "epochs 760\n",
      "training loss 0.0009772766223686852\n",
      "epochs 761\n",
      "training loss 0.000973123939400737\n",
      "epochs 762\n",
      "training loss 0.0011686768331833886\n",
      "epochs 763\n",
      "training loss 0.0009719682537163622\n",
      "epochs 764\n",
      "training loss 0.001004490235114136\n",
      "epochs 765\n",
      "training loss 0.0009181150827927679\n",
      "epochs 766\n",
      "training loss 0.0009767250322431076\n",
      "epochs 767\n",
      "training loss 0.000937837872039923\n",
      "epochs 768\n",
      "training loss 0.0009677255891354069\n",
      "epochs 769\n",
      "training loss 0.0009779292861166718\n",
      "testing loss 0.002709805828780068\n",
      "epochs 770\n",
      "training loss 0.0009636142754489924\n",
      "epochs 771\n",
      "training loss 0.0009998464840110448\n",
      "epochs 772\n",
      "training loss 0.0009504896574469685\n",
      "epochs 773\n",
      "training loss 0.0011174361668045895\n",
      "epochs 774\n",
      "training loss 0.0009718740024210427\n",
      "epochs 775\n",
      "training loss 0.0010223379110072465\n",
      "epochs 776\n",
      "training loss 0.0010154973743851424\n",
      "epochs 777\n",
      "training loss 0.0009615983950939471\n",
      "epochs 778\n",
      "training loss 0.0009705261270710944\n",
      "epochs 779\n",
      "training loss 0.0009311756828947043\n",
      "testing loss 0.0027406798602999946\n",
      "epochs 780\n",
      "training loss 0.0009173702934790844\n",
      "epochs 781\n",
      "training loss 0.0010772854630059724\n",
      "epochs 782\n",
      "training loss 0.0009719397731855693\n",
      "epochs 783\n",
      "training loss 0.000957458343542263\n",
      "epochs 784\n",
      "training loss 0.0010090635492859866\n",
      "epochs 785\n",
      "training loss 0.0011412500232913867\n",
      "epochs 786\n",
      "training loss 0.0009522261083873391\n",
      "epochs 787\n",
      "training loss 0.0009450286630000409\n",
      "epochs 788\n",
      "training loss 0.0009554822935926583\n",
      "epochs 789\n",
      "training loss 0.0009474583199434548\n",
      "testing loss 0.002936774923413305\n",
      "epochs 790\n",
      "training loss 0.0009456784988110913\n",
      "epochs 791\n",
      "training loss 0.000979222245192393\n",
      "epochs 792\n",
      "training loss 0.00117750769717432\n",
      "epochs 793\n",
      "training loss 0.002103945734347344\n",
      "epochs 794\n",
      "training loss 0.0011853932087751257\n",
      "epochs 795\n",
      "training loss 0.0009568299675157922\n",
      "epochs 796\n",
      "training loss 0.0009347913252638432\n",
      "epochs 797\n",
      "training loss 0.0009236291927033554\n",
      "epochs 798\n",
      "training loss 0.0011478087059462777\n",
      "epochs 799\n",
      "training loss 0.001003032699450256\n",
      "testing loss 0.0027157884939071715\n",
      "epochs 800\n",
      "training loss 0.0009895583050676528\n",
      "epochs 801\n",
      "training loss 0.0009822798852163357\n",
      "epochs 802\n",
      "training loss 0.000889581556136134\n",
      "epochs 803\n",
      "training loss 0.0009746093484841989\n",
      "epochs 804\n",
      "training loss 0.0009081232496664653\n",
      "epochs 805\n",
      "training loss 0.0009384484015798654\n",
      "epochs 806\n",
      "training loss 0.0009056148340424528\n",
      "epochs 807\n",
      "training loss 0.0009378226525058239\n",
      "epochs 808\n",
      "training loss 0.0008999373595545912\n",
      "epochs 809\n",
      "training loss 0.0009406993374735185\n",
      "testing loss 0.002717434054204256\n",
      "epochs 810\n",
      "training loss 0.0009351359055049174\n",
      "epochs 811\n",
      "training loss 0.0010218225935428745\n",
      "epochs 812\n",
      "training loss 0.0008779331743802117\n",
      "epochs 813\n",
      "training loss 0.0009832093141842802\n",
      "epochs 814\n",
      "training loss 0.0009305269033138535\n",
      "epochs 815\n",
      "training loss 0.0009983663017632252\n",
      "epochs 816\n",
      "training loss 0.0010065026662671955\n",
      "epochs 817\n",
      "training loss 0.0008808374815368543\n",
      "epochs 818\n",
      "training loss 0.0009351402480794983\n",
      "epochs 819\n",
      "training loss 0.001018340528378614\n",
      "testing loss 0.0026482473641918007\n",
      "epochs 820\n",
      "training loss 0.0009444681929330989\n",
      "epochs 821\n",
      "training loss 0.0009763636096418866\n",
      "epochs 822\n",
      "training loss 0.000994322403605835\n",
      "epochs 823\n",
      "training loss 0.0008948067409987066\n",
      "epochs 824\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss 0.0008869761276259837\n",
      "epochs 825\n",
      "training loss 0.0009543409542390075\n",
      "epochs 826\n",
      "training loss 0.000979508055422857\n",
      "epochs 827\n",
      "training loss 0.000901377989166051\n",
      "epochs 828\n",
      "training loss 0.0009363567682002928\n",
      "epochs 829\n",
      "training loss 0.0009454109263323292\n",
      "testing loss 0.002725618794405212\n",
      "epochs 830\n",
      "training loss 0.0008944745513817187\n",
      "epochs 831\n",
      "training loss 0.0009800448658448676\n",
      "epochs 832\n",
      "training loss 0.001001008883657183\n",
      "epochs 833\n",
      "training loss 0.0009236761351472678\n",
      "epochs 834\n",
      "training loss 0.0010111248523165333\n",
      "epochs 835\n",
      "training loss 0.0009634698352615114\n",
      "epochs 836\n",
      "training loss 0.0016898249164874748\n",
      "epochs 837\n",
      "training loss 0.0009200754602854409\n",
      "epochs 838\n",
      "training loss 0.0008829865826854318\n",
      "epochs 839\n",
      "training loss 0.0009479247013957588\n",
      "testing loss 0.002791658214356169\n",
      "epochs 840\n",
      "training loss 0.0017693227657334918\n",
      "epochs 841\n",
      "training loss 0.0009794234028185143\n",
      "epochs 842\n",
      "training loss 0.0008946456068894602\n",
      "epochs 843\n",
      "training loss 0.0010264947937729295\n",
      "epochs 844\n",
      "training loss 0.0009999015079429061\n",
      "epochs 845\n",
      "training loss 0.0014658937466721473\n",
      "epochs 846\n",
      "training loss 0.001039727702262701\n",
      "epochs 847\n",
      "training loss 0.001028617313570459\n",
      "epochs 848\n",
      "training loss 0.0009134888265417792\n",
      "epochs 849\n",
      "training loss 0.000944191380828551\n",
      "testing loss 0.002717843853475539\n",
      "epochs 850\n",
      "training loss 0.0008676635144076007\n",
      "epochs 851\n",
      "training loss 0.000941635518353206\n",
      "epochs 852\n",
      "training loss 0.0009352748841684209\n",
      "epochs 853\n",
      "training loss 0.0008646705537103117\n",
      "epochs 854\n",
      "training loss 0.0009097969233791562\n",
      "epochs 855\n",
      "training loss 0.0009999759451027586\n",
      "epochs 856\n",
      "training loss 0.0009234944548837183\n",
      "epochs 857\n",
      "training loss 0.0010061821751515905\n",
      "epochs 858\n",
      "training loss 0.0009216721838242502\n",
      "epochs 859\n",
      "training loss 0.0008854320890087589\n",
      "testing loss 0.002775486081868331\n",
      "epochs 860\n",
      "training loss 0.0008523482486101768\n",
      "epochs 861\n",
      "training loss 0.0009158886076513067\n",
      "epochs 862\n",
      "training loss 0.0009947162860895486\n",
      "epochs 863\n",
      "training loss 0.0008968432463272432\n",
      "epochs 864\n",
      "training loss 0.0009420900282734512\n",
      "epochs 865\n",
      "training loss 0.0009221414048019457\n",
      "epochs 866\n",
      "training loss 0.0008860023980280866\n",
      "epochs 867\n",
      "training loss 0.0009081743549312094\n",
      "epochs 868\n",
      "training loss 0.0009059606155021099\n",
      "epochs 869\n",
      "training loss 0.000901703311871358\n",
      "testing loss 0.0030092857732662123\n",
      "epochs 870\n",
      "training loss 0.0009111348764459945\n",
      "epochs 871\n",
      "training loss 0.000913123729338694\n",
      "epochs 872\n",
      "training loss 0.000871047882170708\n",
      "epochs 873\n",
      "training loss 0.0009292103228085649\n",
      "epochs 874\n",
      "training loss 0.0008872785168667366\n",
      "epochs 875\n",
      "training loss 0.0009006534693875891\n",
      "epochs 876\n",
      "training loss 0.0008989315576239922\n",
      "epochs 877\n",
      "training loss 0.0009030802274479511\n",
      "epochs 878\n",
      "training loss 0.0012617512704453525\n",
      "epochs 879\n",
      "training loss 0.000922880854845432\n",
      "testing loss 0.0029567620181973945\n",
      "epochs 880\n",
      "training loss 0.0009394148247893956\n",
      "epochs 881\n",
      "training loss 0.0008372234941869238\n",
      "epochs 882\n",
      "training loss 0.0008863767243300403\n",
      "epochs 883\n",
      "training loss 0.0010341726536126552\n",
      "epochs 884\n",
      "training loss 0.0010664487644353468\n",
      "epochs 885\n",
      "training loss 0.0009249076776214986\n",
      "epochs 886\n",
      "training loss 0.0009419673966742078\n",
      "epochs 887\n",
      "training loss 0.0009324494413153968\n",
      "epochs 888\n",
      "training loss 0.0008611572109513822\n",
      "epochs 889\n",
      "training loss 0.0008946101788585683\n",
      "testing loss 0.0027834930620651613\n",
      "epochs 890\n",
      "training loss 0.0008613831306295328\n",
      "epochs 891\n",
      "training loss 0.0009702784264931528\n",
      "epochs 892\n",
      "training loss 0.0008929943463992961\n",
      "epochs 893\n",
      "training loss 0.0009087126017024451\n",
      "epochs 894\n",
      "training loss 0.0008626714336231498\n",
      "epochs 895\n",
      "training loss 0.0009197554008619107\n",
      "epochs 896\n",
      "training loss 0.0008634570515417355\n",
      "epochs 897\n",
      "training loss 0.0009127657342663935\n",
      "epochs 898\n",
      "training loss 0.0008385996751792978\n",
      "epochs 899\n",
      "training loss 0.000921397455076271\n",
      "testing loss 0.0028331501203826925\n",
      "epochs 900\n",
      "training loss 0.0008915358500436266\n",
      "epochs 901\n",
      "training loss 0.0009292266476689908\n",
      "epochs 902\n",
      "training loss 0.0008549180619933821\n",
      "epochs 903\n",
      "training loss 0.0008997627708064477\n",
      "epochs 904\n",
      "training loss 0.0008311832431947252\n",
      "epochs 905\n",
      "training loss 0.0009607765245949142\n",
      "epochs 906\n",
      "training loss 0.0009174971325722124\n",
      "epochs 907\n",
      "training loss 0.0009971728077261654\n",
      "epochs 908\n",
      "training loss 0.0009866478630181652\n",
      "epochs 909\n",
      "training loss 0.0009012637488468972\n",
      "testing loss 0.0027828562809880954\n",
      "epochs 910\n",
      "training loss 0.000855630910251216\n",
      "epochs 911\n",
      "training loss 0.0008958588050158926\n",
      "epochs 912\n",
      "training loss 0.0008399559588824034\n",
      "epochs 913\n",
      "training loss 0.0008819216600828734\n",
      "epochs 914\n",
      "training loss 0.0016929086730857932\n",
      "epochs 915\n",
      "training loss 0.001649667113654225\n",
      "epochs 916\n",
      "training loss 0.0010710108539055592\n",
      "epochs 917\n",
      "training loss 0.0008588409959621682\n",
      "epochs 918\n",
      "training loss 0.0008890530226135055\n",
      "epochs 919\n",
      "training loss 0.0009652835726178899\n",
      "testing loss 0.0026936085353083646\n",
      "epochs 920\n",
      "training loss 0.0008033613005927608\n",
      "epochs 921\n",
      "training loss 0.0008429090702434929\n",
      "epochs 922\n",
      "training loss 0.0008457561997848203\n",
      "epochs 923\n",
      "training loss 0.0008656253791760971\n",
      "epochs 924\n",
      "training loss 0.0008150172422676826\n",
      "epochs 925\n",
      "training loss 0.0008303680109344197\n",
      "epochs 926\n",
      "training loss 0.0009785211555012941\n",
      "epochs 927\n",
      "training loss 0.0008853592030211468\n",
      "epochs 928\n",
      "training loss 0.0008817821419811992\n",
      "epochs 929\n",
      "training loss 0.0008709308416030644\n",
      "testing loss 0.0028165540532440157\n",
      "epochs 930\n",
      "training loss 0.0008673786149766455\n",
      "epochs 931\n",
      "training loss 0.00089019099936897\n",
      "epochs 932\n",
      "training loss 0.0008481355235553814\n",
      "epochs 933\n",
      "training loss 0.0008472034282696442\n",
      "epochs 934\n",
      "training loss 0.0008867050197837439\n",
      "epochs 935\n",
      "training loss 0.0008366521479566171\n",
      "epochs 936\n",
      "training loss 0.0009177223168699903\n",
      "epochs 937\n",
      "training loss 0.0009978794987103973\n",
      "epochs 938\n",
      "training loss 0.0008342101832775337\n",
      "epochs 939\n",
      "training loss 0.0008966739422685572\n",
      "testing loss 0.0030411147679274917\n",
      "epochs 940\n",
      "training loss 0.0009305519740964855\n",
      "epochs 941\n",
      "training loss 0.0009175996753630599\n",
      "epochs 942\n",
      "training loss 0.0010926913438891385\n",
      "epochs 943\n",
      "training loss 0.0009037082415784633\n",
      "epochs 944\n",
      "training loss 0.0009122492376988114\n",
      "epochs 945\n",
      "training loss 0.0008784091777888645\n",
      "epochs 946\n",
      "training loss 0.0008643958112508014\n",
      "epochs 947\n",
      "training loss 0.0008669434021344539\n",
      "epochs 948\n",
      "training loss 0.0008433231968739803\n",
      "epochs 949\n",
      "training loss 0.0008539594858488504\n",
      "testing loss 0.0027674961680751163\n",
      "epochs 950\n",
      "training loss 0.0008574249746566666\n",
      "epochs 951\n",
      "training loss 0.0008553803829747991\n",
      "epochs 952\n",
      "training loss 0.0008556794882596309\n",
      "epochs 953\n",
      "training loss 0.0009656147624431094\n",
      "epochs 954\n",
      "training loss 0.0008846405605356688\n",
      "epochs 955\n",
      "training loss 0.0008445414539361457\n",
      "epochs 956\n",
      "training loss 0.0009536818193560494\n",
      "epochs 957\n",
      "training loss 0.0008370724081530272\n",
      "epochs 958\n",
      "training loss 0.0008794276003434258\n",
      "epochs 959\n",
      "training loss 0.0008267214453473438\n",
      "testing loss 0.002833552140881248\n",
      "epochs 960\n",
      "training loss 0.000842500579140735\n",
      "epochs 961\n",
      "training loss 0.0008192389473137884\n",
      "epochs 962\n",
      "training loss 0.0008592877145481542\n",
      "epochs 963\n",
      "training loss 0.0008085922874675888\n",
      "epochs 964\n",
      "training loss 0.0007744386902229016\n",
      "epochs 965\n",
      "training loss 0.000879709765252779\n",
      "epochs 966\n",
      "training loss 0.0008536467425444512\n",
      "epochs 967\n",
      "training loss 0.0009281585388604585\n",
      "epochs 968\n",
      "training loss 0.0008483811297190679\n",
      "epochs 969\n",
      "training loss 0.0008969123396169009\n",
      "testing loss 0.0029302729369662965\n",
      "epochs 970\n",
      "training loss 0.0008189923718775478\n",
      "epochs 971\n",
      "training loss 0.000816000087379894\n",
      "epochs 972\n",
      "training loss 0.0008519859891632532\n",
      "epochs 973\n",
      "training loss 0.0008396478208832125\n",
      "epochs 974\n",
      "training loss 0.0008616671829532526\n",
      "epochs 975\n",
      "training loss 0.0008549082874409617\n",
      "epochs 976\n",
      "training loss 0.000889550589660528\n",
      "epochs 977\n",
      "training loss 0.0012585927621181206\n",
      "epochs 978\n",
      "training loss 0.0009761981004042308\n",
      "epochs 979\n",
      "training loss 0.0008802555013507446\n",
      "testing loss 0.0027501753982196145\n",
      "epochs 980\n",
      "training loss 0.0008171401512957713\n",
      "epochs 981\n",
      "training loss 0.0008640018980709502\n",
      "epochs 982\n",
      "training loss 0.0008884308851567468\n",
      "epochs 983\n",
      "training loss 0.0008082267195609112\n",
      "epochs 984\n",
      "training loss 0.0008223401333027064\n",
      "epochs 985\n",
      "training loss 0.000835558952530846\n",
      "epochs 986\n",
      "training loss 0.0008385706291141945\n",
      "epochs 987\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss 0.000794802245943691\n",
      "epochs 988\n",
      "training loss 0.00154733580928494\n",
      "epochs 989\n",
      "training loss 0.0009357797024038403\n",
      "testing loss 0.00287671233296183\n",
      "epochs 990\n",
      "training loss 0.0008418446420522061\n",
      "epochs 991\n",
      "training loss 0.0008143752087601163\n",
      "epochs 992\n",
      "training loss 0.001051147389303508\n",
      "epochs 993\n",
      "training loss 0.0008121635358799023\n",
      "epochs 994\n",
      "training loss 0.0009051123797634508\n",
      "epochs 995\n",
      "training loss 0.0008453434046766916\n",
      "epochs 996\n",
      "training loss 0.0008467804075439537\n",
      "epochs 997\n",
      "training loss 0.0007869362691169644\n",
      "epochs 998\n",
      "training loss 0.0007861161492708334\n",
      "epochs 999\n",
      "training loss 0.0008316069746200324\n",
      "testing loss 0.002733445537676176\n",
      "epochs 1000\n",
      "training loss 0.0008180473707680022\n",
      "epochs 1001\n",
      "training loss 0.0009089020938233198\n",
      "epochs 1002\n",
      "training loss 0.0007738178389962185\n",
      "epochs 1003\n",
      "training loss 0.0008182158044540808\n",
      "epochs 1004\n",
      "training loss 0.0011540430739145487\n",
      "epochs 1005\n",
      "training loss 0.0014429391123988527\n",
      "epochs 1006\n",
      "training loss 0.0015928491643604492\n",
      "epochs 1007\n",
      "training loss 0.001157601796002849\n",
      "epochs 1008\n",
      "training loss 0.0008458406959007859\n",
      "epochs 1009\n",
      "training loss 0.0008122208859066629\n",
      "testing loss 0.002787341393038287\n",
      "epochs 1010\n",
      "training loss 0.0008114530639630943\n",
      "epochs 1011\n",
      "training loss 0.0008177234197465709\n",
      "epochs 1012\n",
      "training loss 0.0007823732442549489\n",
      "epochs 1013\n",
      "training loss 0.0008380627575419606\n",
      "epochs 1014\n",
      "training loss 0.0008470715259946317\n",
      "epochs 1015\n",
      "training loss 0.0008182666894497129\n",
      "epochs 1016\n",
      "training loss 0.0008108674093520433\n",
      "epochs 1017\n",
      "training loss 0.000813999252112888\n",
      "epochs 1018\n",
      "training loss 0.0008422815161127326\n",
      "epochs 1019\n",
      "training loss 0.0007743519079081692\n",
      "testing loss 0.0027310151626613547\n",
      "epochs 1020\n",
      "training loss 0.0008495095732450588\n",
      "epochs 1021\n",
      "training loss 0.0008625570515002263\n",
      "epochs 1022\n",
      "training loss 0.000860072509067184\n",
      "epochs 1023\n",
      "training loss 0.0008169763020379893\n",
      "epochs 1024\n",
      "training loss 0.0008639897428428907\n",
      "epochs 1025\n",
      "training loss 0.0009724309796744838\n",
      "epochs 1026\n",
      "training loss 0.000835132580883886\n",
      "epochs 1027\n",
      "training loss 0.0018445963166848019\n",
      "epochs 1028\n",
      "training loss 0.0008532558617360414\n",
      "epochs 1029\n",
      "training loss 0.000810004998809491\n",
      "testing loss 0.0028392545646056533\n",
      "epochs 1030\n",
      "training loss 0.0008227427669278541\n",
      "epochs 1031\n",
      "training loss 0.0008493736023607022\n",
      "epochs 1032\n",
      "training loss 0.0008020433802497333\n",
      "epochs 1033\n",
      "training loss 0.0008080929478292147\n",
      "epochs 1034\n",
      "training loss 0.0008149728931608329\n",
      "epochs 1035\n",
      "training loss 0.0008346096194620983\n",
      "epochs 1036\n",
      "training loss 0.000780929411452909\n",
      "epochs 1037\n",
      "training loss 0.0008132974166029606\n",
      "epochs 1038\n",
      "training loss 0.0007983141133418777\n",
      "epochs 1039\n",
      "training loss 0.0009288622915078136\n",
      "testing loss 0.0028607481793361776\n",
      "epochs 1040\n",
      "training loss 0.000843274695384755\n",
      "epochs 1041\n",
      "training loss 0.0007934368605262636\n",
      "epochs 1042\n",
      "training loss 0.0008304791869475339\n",
      "epochs 1043\n",
      "training loss 0.000781185268976451\n",
      "epochs 1044\n",
      "training loss 0.0008406825261905302\n",
      "epochs 1045\n",
      "training loss 0.0008439677005802142\n",
      "epochs 1046\n",
      "training loss 0.0008378675961895283\n",
      "epochs 1047\n",
      "training loss 0.0008088718009206798\n",
      "epochs 1048\n",
      "training loss 0.0008632491197115756\n",
      "epochs 1049\n",
      "training loss 0.0008145576510309471\n",
      "testing loss 0.003044870060766182\n",
      "epochs 1050\n",
      "training loss 0.0007846495851387459\n",
      "epochs 1051\n",
      "training loss 0.0008315951552802533\n",
      "epochs 1052\n",
      "training loss 0.0008370386862789074\n",
      "epochs 1053\n",
      "training loss 0.0008356237127997638\n",
      "epochs 1054\n",
      "training loss 0.0008336286002835174\n",
      "epochs 1055\n",
      "training loss 0.0009156776016958816\n",
      "epochs 1056\n",
      "training loss 0.0008034498930065171\n",
      "epochs 1057\n",
      "training loss 0.000806737841194705\n",
      "epochs 1058\n",
      "training loss 0.0008064451472448768\n",
      "epochs 1059\n",
      "training loss 0.0011668785207686906\n",
      "testing loss 0.0028277368529151517\n",
      "epochs 1060\n",
      "training loss 0.0009545214017032219\n",
      "epochs 1061\n",
      "training loss 0.0007952559639566711\n",
      "epochs 1062\n",
      "training loss 0.0010631305801096205\n",
      "epochs 1063\n",
      "training loss 0.0008540049882281549\n",
      "epochs 1064\n",
      "training loss 0.0008087461571192148\n",
      "epochs 1065\n",
      "training loss 0.0008069716908262708\n",
      "epochs 1066\n",
      "training loss 0.000773434688572101\n",
      "epochs 1067\n",
      "training loss 0.0008533627623168462\n",
      "epochs 1068\n",
      "training loss 0.0008249312580321098\n",
      "epochs 1069\n",
      "training loss 0.0007701695935254334\n",
      "testing loss 0.0027355846894429403\n",
      "epochs 1070\n",
      "training loss 0.0007996046058458522\n",
      "epochs 1071\n",
      "training loss 0.0008086064436945691\n",
      "epochs 1072\n",
      "training loss 0.0008733036417809901\n",
      "epochs 1073\n",
      "training loss 0.0008198966623013585\n",
      "epochs 1074\n",
      "training loss 0.0007633177149902157\n",
      "epochs 1075\n",
      "training loss 0.0008083976775840898\n",
      "epochs 1076\n",
      "training loss 0.0007965943488040457\n",
      "epochs 1077\n",
      "training loss 0.0008473016235320673\n",
      "epochs 1078\n",
      "training loss 0.0010459963930239985\n",
      "epochs 1079\n",
      "training loss 0.0009847023453751697\n",
      "testing loss 0.0029662481120272363\n",
      "epochs 1080\n",
      "training loss 0.0008265952965192282\n",
      "epochs 1081\n",
      "training loss 0.0008391823359881174\n",
      "epochs 1082\n",
      "training loss 0.000785950081664248\n",
      "epochs 1083\n",
      "training loss 0.0007806189754011115\n",
      "epochs 1084\n",
      "training loss 0.0007983326063934419\n",
      "epochs 1085\n",
      "training loss 0.0011290252418540373\n",
      "epochs 1086\n",
      "training loss 0.001613449135096036\n",
      "epochs 1087\n",
      "training loss 0.0009049332180870046\n",
      "epochs 1088\n",
      "training loss 0.0007934289378266906\n",
      "epochs 1089\n",
      "training loss 0.0008048011352892648\n",
      "testing loss 0.002949868007695157\n",
      "epochs 1090\n",
      "training loss 0.0008441893127145342\n",
      "epochs 1091\n",
      "training loss 0.0007814531559358128\n",
      "epochs 1092\n",
      "training loss 0.0007746611475183043\n",
      "epochs 1093\n",
      "training loss 0.0008198964774168428\n",
      "epochs 1094\n",
      "training loss 0.0007428246040546865\n",
      "epochs 1095\n",
      "training loss 0.0007958109468458034\n",
      "epochs 1096\n",
      "training loss 0.0007978277224311351\n",
      "epochs 1097\n",
      "training loss 0.0007372394221478162\n",
      "epochs 1098\n",
      "training loss 0.0008318083382729656\n",
      "epochs 1099\n",
      "training loss 0.0008614242266535215\n",
      "testing loss 0.003166781927472152\n",
      "epochs 1100\n",
      "training loss 0.0008029706105073251\n",
      "epochs 1101\n",
      "training loss 0.0007977137859772019\n",
      "epochs 1102\n",
      "training loss 0.0007818190287692489\n",
      "epochs 1103\n",
      "training loss 0.0007752055494400664\n",
      "epochs 1104\n",
      "training loss 0.0008108497268731188\n",
      "epochs 1105\n",
      "training loss 0.0007896403136123878\n",
      "epochs 1106\n",
      "training loss 0.000821509077139397\n",
      "epochs 1107\n",
      "training loss 0.0007894576352378382\n",
      "epochs 1108\n",
      "training loss 0.0007816776612916491\n",
      "epochs 1109\n",
      "training loss 0.0008410048767666709\n",
      "testing loss 0.0027644472091016194\n",
      "epochs 1110\n",
      "training loss 0.0008799986286431347\n",
      "epochs 1111\n",
      "training loss 0.0008034899786233585\n",
      "epochs 1112\n",
      "training loss 0.0008277382007566504\n",
      "epochs 1113\n",
      "training loss 0.0008014495848815345\n",
      "epochs 1114\n",
      "training loss 0.0007948484893649035\n",
      "epochs 1115\n",
      "training loss 0.0008204876473364576\n",
      "epochs 1116\n",
      "training loss 0.0008022686358474727\n",
      "epochs 1117\n",
      "training loss 0.0007686412617766602\n",
      "epochs 1118\n",
      "training loss 0.0007705453573266117\n",
      "epochs 1119\n",
      "training loss 0.0009001528368845276\n",
      "testing loss 0.0028651603637923693\n",
      "epochs 1120\n",
      "training loss 0.0008783611095840208\n",
      "epochs 1121\n",
      "training loss 0.0009387574973516166\n",
      "epochs 1122\n",
      "training loss 0.0010144427609077929\n",
      "epochs 1123\n",
      "training loss 0.0009104671692907369\n",
      "epochs 1124\n",
      "training loss 0.00086379019574667\n",
      "epochs 1125\n",
      "training loss 0.0010931779840843623\n",
      "epochs 1126\n",
      "training loss 0.0024576783560621225\n",
      "epochs 1127\n",
      "training loss 0.003719249118181755\n",
      "epochs 1128\n",
      "training loss 0.0020526215597905084\n",
      "epochs 1129\n",
      "training loss 0.001791658931932664\n",
      "testing loss 0.0029991288353187024\n",
      "epochs 1130\n",
      "training loss 0.0012366722465639985\n",
      "epochs 1131\n",
      "training loss 0.0010749134981699038\n",
      "epochs 1132\n",
      "training loss 0.0009928514732799483\n",
      "epochs 1133\n",
      "training loss 0.0008827895393147838\n",
      "epochs 1134\n",
      "training loss 0.001321049352632241\n",
      "epochs 1135\n",
      "training loss 0.0009285551682503832\n",
      "epochs 1136\n",
      "training loss 0.0008595644243912188\n",
      "epochs 1137\n",
      "training loss 0.0008375673877014453\n",
      "epochs 1138\n",
      "training loss 0.0007631638610847351\n",
      "epochs 1139\n",
      "training loss 0.0007727562902264557\n",
      "testing loss 0.002722714554951097\n",
      "epochs 1140\n",
      "training loss 0.0008079479522804947\n",
      "epochs 1141\n",
      "training loss 0.0007689702980068872\n",
      "epochs 1142\n",
      "training loss 0.000786205905660885\n",
      "epochs 1143\n",
      "training loss 0.0007978488024505348\n",
      "epochs 1144\n",
      "training loss 0.0007788897216876283\n",
      "epochs 1145\n",
      "training loss 0.0008242052459967603\n",
      "epochs 1146\n",
      "training loss 0.0008120146064486887\n",
      "epochs 1147\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss 0.0008034291429484779\n",
      "epochs 1148\n",
      "training loss 0.0007911463361693473\n",
      "epochs 1149\n",
      "training loss 0.0007978769201122927\n",
      "testing loss 0.002926002571554128\n",
      "epochs 1150\n",
      "training loss 0.0008508239290323165\n",
      "epochs 1151\n",
      "training loss 0.0008182178359722158\n",
      "epochs 1152\n",
      "training loss 0.0008176115961068828\n",
      "epochs 1153\n",
      "training loss 0.0008344069484367933\n",
      "epochs 1154\n",
      "training loss 0.0007810243745093831\n",
      "epochs 1155\n",
      "training loss 0.000777401452555709\n",
      "epochs 1156\n",
      "training loss 0.0008034620115230579\n",
      "epochs 1157\n",
      "training loss 0.0010240014190792664\n",
      "epochs 1158\n",
      "training loss 0.0009514290868979808\n",
      "epochs 1159\n",
      "training loss 0.0018202618532672547\n",
      "testing loss 0.002946083727441332\n",
      "epochs 1160\n",
      "training loss 0.0016664515603630943\n",
      "epochs 1161\n",
      "training loss 0.0009626124236778013\n",
      "epochs 1162\n",
      "training loss 0.0008198676254362502\n",
      "epochs 1163\n",
      "training loss 0.0009910998673823672\n",
      "epochs 1164\n",
      "training loss 0.0008184867303310341\n",
      "epochs 1165\n",
      "training loss 0.0007981352456229652\n",
      "epochs 1166\n",
      "training loss 0.000834513630871562\n",
      "epochs 1167\n",
      "training loss 0.0008414613849435308\n",
      "epochs 1168\n",
      "training loss 0.0007747915420556684\n",
      "epochs 1169\n",
      "training loss 0.0006963112558723685\n",
      "testing loss 0.0028073183667073225\n",
      "epochs 1170\n",
      "training loss 0.00076120338911519\n",
      "epochs 1171\n",
      "training loss 0.0007269424086438045\n",
      "epochs 1172\n",
      "training loss 0.0007794966121872259\n",
      "epochs 1173\n",
      "training loss 0.000757834994755006\n",
      "epochs 1174\n",
      "training loss 0.0007970181041139554\n",
      "epochs 1175\n",
      "training loss 0.0007238832602629829\n",
      "epochs 1176\n",
      "training loss 0.0008119328015966561\n",
      "epochs 1177\n",
      "training loss 0.0008494511532765674\n",
      "epochs 1178\n",
      "training loss 0.0007733418030337371\n",
      "epochs 1179\n",
      "training loss 0.0008440705493593583\n",
      "testing loss 0.00274999432491984\n",
      "epochs 1180\n",
      "training loss 0.0007634593076907709\n",
      "epochs 1181\n",
      "training loss 0.0007494808561069534\n",
      "epochs 1182\n",
      "training loss 0.000880084098277806\n",
      "epochs 1183\n",
      "training loss 0.0007796228079883931\n",
      "epochs 1184\n",
      "training loss 0.0007828763928681918\n",
      "epochs 1185\n",
      "training loss 0.0007769161167251665\n",
      "epochs 1186\n",
      "training loss 0.0008500467258361154\n",
      "epochs 1187\n",
      "training loss 0.004972184103266775\n",
      "epochs 1188\n",
      "training loss 0.0022648071366331134\n",
      "epochs 1189\n",
      "training loss 0.0019347527231398324\n",
      "testing loss 0.002934544549921382\n",
      "epochs 1190\n",
      "training loss 0.0018502847143975411\n",
      "epochs 1191\n",
      "training loss 0.0017554971004134232\n",
      "epochs 1192\n",
      "training loss 0.0014674997399136492\n",
      "epochs 1193\n",
      "training loss 0.001802372202839091\n",
      "epochs 1194\n",
      "training loss 0.001606041274852994\n",
      "epochs 1195\n",
      "training loss 0.0015297525882222733\n",
      "epochs 1196\n",
      "training loss 0.0010668415338081225\n",
      "epochs 1197\n",
      "training loss 0.0008980109847128096\n",
      "epochs 1198\n",
      "training loss 0.0010035380469507744\n",
      "epochs 1199\n",
      "training loss 0.0008705184999485372\n",
      "testing loss 0.0027608617521815847\n",
      "epochs 1200\n",
      "training loss 0.0007782279914329933\n",
      "epochs 1201\n",
      "training loss 0.0008273299037384034\n",
      "epochs 1202\n",
      "training loss 0.0008314029278416232\n",
      "epochs 1203\n",
      "training loss 0.0007695865603821991\n",
      "epochs 1204\n",
      "training loss 0.0007668534127640111\n",
      "epochs 1205\n",
      "training loss 0.0007487708379091316\n",
      "epochs 1206\n",
      "training loss 0.0007880919114552087\n",
      "epochs 1207\n",
      "training loss 0.0008131674903807284\n",
      "epochs 1208\n",
      "training loss 0.0008298917537297499\n",
      "epochs 1209\n",
      "training loss 0.0007799684571981215\n",
      "testing loss 0.002763149764055241\n",
      "epochs 1210\n",
      "training loss 0.0007542427658424699\n",
      "epochs 1211\n",
      "training loss 0.0007934304959873887\n",
      "epochs 1212\n",
      "training loss 0.0007527754193569581\n",
      "epochs 1213\n",
      "training loss 0.0008704617618983696\n",
      "epochs 1214\n",
      "training loss 0.0008448477554747885\n",
      "epochs 1215\n",
      "training loss 0.0007579009765886495\n",
      "epochs 1216\n",
      "training loss 0.0009893548550504601\n",
      "epochs 1217\n",
      "training loss 0.0008801890933096386\n",
      "epochs 1218\n",
      "training loss 0.0007946980958960181\n",
      "epochs 1219\n",
      "training loss 0.0007844024411605043\n",
      "testing loss 0.002676091574674063\n",
      "epochs 1220\n",
      "training loss 0.0007622393789718148\n",
      "epochs 1221\n",
      "training loss 0.0007525004603437185\n",
      "epochs 1222\n",
      "training loss 0.0008724954378745861\n",
      "epochs 1223\n",
      "training loss 0.0008112969719818977\n",
      "epochs 1224\n",
      "training loss 0.0007424412064691637\n",
      "epochs 1225\n",
      "training loss 0.000793574865759523\n",
      "epochs 1226\n",
      "training loss 0.0008049296442699537\n",
      "epochs 1227\n",
      "training loss 0.0007759949681066022\n",
      "epochs 1228\n",
      "training loss 0.0007920205133286302\n",
      "epochs 1229\n",
      "training loss 0.0009196503477993402\n",
      "testing loss 0.0028746146242239956\n",
      "epochs 1230\n",
      "training loss 0.0008496742718216134\n",
      "epochs 1231\n",
      "training loss 0.0008081406115881226\n",
      "epochs 1232\n",
      "training loss 0.0008719783620611626\n",
      "epochs 1233\n",
      "training loss 0.0009524564118631252\n",
      "epochs 1234\n",
      "training loss 0.0009746029091069028\n",
      "epochs 1235\n",
      "training loss 0.0009946448679434526\n",
      "epochs 1236\n",
      "training loss 0.0009111830472661675\n",
      "epochs 1237\n",
      "training loss 0.0008500975904856047\n",
      "epochs 1238\n",
      "training loss 0.0008871666544809156\n",
      "epochs 1239\n",
      "training loss 0.0009621365377460082\n",
      "testing loss 0.002660954206379408\n",
      "epochs 1240\n",
      "training loss 0.0011699619472287255\n",
      "epochs 1241\n",
      "training loss 0.0012571389244983998\n",
      "epochs 1242\n",
      "training loss 0.0024010159026075575\n",
      "epochs 1243\n",
      "training loss 0.0015075607012991303\n",
      "epochs 1244\n",
      "training loss 0.0011170953305191884\n",
      "epochs 1245\n",
      "training loss 0.0008675408250430038\n",
      "epochs 1246\n",
      "training loss 0.0012314119592088198\n",
      "epochs 1247\n",
      "training loss 0.0008278175028561866\n",
      "epochs 1248\n",
      "training loss 0.0007245600223364337\n",
      "epochs 1249\n",
      "training loss 0.0007457226417685567\n",
      "testing loss 0.002710427974965027\n",
      "epochs 1250\n",
      "training loss 0.0007485678193186293\n",
      "epochs 1251\n",
      "training loss 0.0006915742982926249\n",
      "epochs 1252\n",
      "training loss 0.0007764136736807739\n",
      "epochs 1253\n",
      "training loss 0.0007212129716993533\n",
      "epochs 1254\n",
      "training loss 0.0007694636488023376\n",
      "epochs 1255\n",
      "training loss 0.0007649377659125973\n",
      "epochs 1256\n",
      "training loss 0.0007595404602890115\n",
      "epochs 1257\n",
      "training loss 0.0008569262608833396\n",
      "epochs 1258\n",
      "training loss 0.0008407777294199518\n",
      "epochs 1259\n",
      "training loss 0.0007102599841299096\n",
      "testing loss 0.002699604592325681\n",
      "epochs 1260\n",
      "training loss 0.0007610549005760463\n",
      "epochs 1261\n",
      "training loss 0.0007466852886455083\n",
      "epochs 1262\n",
      "training loss 0.000765472641858728\n",
      "epochs 1263\n",
      "training loss 0.0007507319467129486\n",
      "epochs 1264\n",
      "training loss 0.0007488979118675175\n",
      "epochs 1265\n",
      "training loss 0.0007957920879175134\n",
      "epochs 1266\n",
      "training loss 0.000720188328798147\n",
      "epochs 1267\n",
      "training loss 0.0007559656808478333\n",
      "epochs 1268\n",
      "training loss 0.0010772343151912512\n",
      "epochs 1269\n",
      "training loss 0.000871201675391606\n",
      "testing loss 0.002770463987220581\n",
      "epochs 1270\n",
      "training loss 0.0007629108192019822\n",
      "epochs 1271\n",
      "training loss 0.0007422352275148736\n",
      "epochs 1272\n",
      "training loss 0.0007827624449142648\n",
      "epochs 1273\n",
      "training loss 0.0007838325165948154\n",
      "epochs 1274\n",
      "training loss 0.0008211812905161882\n",
      "epochs 1275\n",
      "training loss 0.0007174531638156623\n",
      "epochs 1276\n",
      "training loss 0.0007780981147491959\n",
      "epochs 1277\n",
      "training loss 0.0019055257532264369\n",
      "epochs 1278\n",
      "training loss 0.0009516059212410669\n",
      "epochs 1279\n",
      "training loss 0.0008985628583574651\n",
      "testing loss 0.002836653563534141\n",
      "epochs 1280\n",
      "training loss 0.0007369354836809758\n",
      "epochs 1281\n",
      "training loss 0.0006938197647892279\n",
      "epochs 1282\n",
      "training loss 0.0007525730827160882\n",
      "epochs 1283\n",
      "training loss 0.0007075351795802986\n",
      "epochs 1284\n",
      "training loss 0.00075130997612042\n",
      "epochs 1285\n",
      "training loss 0.000735162187291247\n",
      "epochs 1286\n",
      "training loss 0.0007591192322354311\n",
      "epochs 1287\n",
      "training loss 0.0007999199255027081\n",
      "epochs 1288\n",
      "training loss 0.001083087583184299\n",
      "epochs 1289\n",
      "training loss 0.001944881418753857\n",
      "testing loss 0.007735808384901983\n",
      "epochs 1290\n",
      "training loss 0.0031687992122123375\n",
      "epochs 1291\n",
      "training loss 0.0018087065071688462\n",
      "epochs 1292\n",
      "training loss 0.0013880401918392822\n",
      "epochs 1293\n",
      "training loss 0.0012546085085900992\n",
      "epochs 1294\n",
      "training loss 0.0009798170372562081\n",
      "epochs 1295\n",
      "training loss 0.0008312557150056376\n",
      "epochs 1296\n",
      "training loss 0.000747861875391687\n",
      "epochs 1297\n",
      "training loss 0.0007736031457889361\n",
      "epochs 1298\n",
      "training loss 0.000728772188933838\n",
      "epochs 1299\n",
      "training loss 0.0007919799400235903\n",
      "testing loss 0.0028506448101879803\n",
      "epochs 1300\n",
      "training loss 0.0008557131823568427\n",
      "epochs 1301\n",
      "training loss 0.0010596328161269041\n",
      "epochs 1302\n",
      "training loss 0.0007619270586902644\n",
      "epochs 1303\n",
      "training loss 0.0007410850163583154\n",
      "epochs 1304\n",
      "training loss 0.0007168798281748901\n",
      "epochs 1305\n",
      "training loss 0.0007249354438801044\n",
      "epochs 1306\n",
      "training loss 0.000697148694620697\n",
      "epochs 1307\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss 0.0006950906443191653\n",
      "epochs 1308\n",
      "training loss 0.0007746165562038929\n",
      "epochs 1309\n",
      "training loss 0.0007327322232095372\n",
      "testing loss 0.00276921101282714\n",
      "epochs 1310\n",
      "training loss 0.0013044314182258712\n",
      "epochs 1311\n",
      "training loss 0.0011338531467808824\n",
      "epochs 1312\n",
      "training loss 0.0007291051699273221\n",
      "epochs 1313\n",
      "training loss 0.0007571576631664777\n",
      "epochs 1314\n",
      "training loss 0.000647805995445155\n",
      "epochs 1315\n",
      "training loss 0.000672515596356526\n",
      "epochs 1316\n",
      "training loss 0.0007691435406365259\n",
      "epochs 1317\n",
      "training loss 0.0007090762654414236\n",
      "epochs 1318\n",
      "training loss 0.0008821242520236056\n",
      "epochs 1319\n",
      "training loss 0.0008100949487532843\n",
      "testing loss 0.0026514048313272865\n",
      "epochs 1320\n",
      "training loss 0.000739757067578389\n",
      "epochs 1321\n",
      "training loss 0.0007092184195185992\n",
      "epochs 1322\n",
      "training loss 0.0007045755258727378\n",
      "epochs 1323\n",
      "training loss 0.000715260824636559\n",
      "epochs 1324\n",
      "training loss 0.0007606679582501277\n",
      "epochs 1325\n",
      "training loss 0.0007343267089380149\n",
      "epochs 1326\n",
      "training loss 0.0007435474630571211\n",
      "epochs 1327\n",
      "training loss 0.0007292031479283239\n",
      "epochs 1328\n",
      "training loss 0.0007589707851847266\n",
      "epochs 1329\n",
      "training loss 0.0007490173364723367\n",
      "testing loss 0.0026893882243563785\n",
      "epochs 1330\n",
      "training loss 0.0007829878635465318\n",
      "epochs 1331\n",
      "training loss 0.0007585010851880586\n",
      "epochs 1332\n",
      "training loss 0.0006786289528977567\n",
      "epochs 1333\n",
      "training loss 0.0007736056679144989\n",
      "epochs 1334\n",
      "training loss 0.0007743079241472764\n",
      "epochs 1335\n",
      "training loss 0.0007610096430581482\n",
      "epochs 1336\n",
      "training loss 0.0007650949602124301\n",
      "epochs 1337\n",
      "training loss 0.0007994030795122375\n",
      "epochs 1338\n",
      "training loss 0.0007267358479667511\n",
      "epochs 1339\n",
      "training loss 0.0007330955211943621\n",
      "testing loss 0.002790577840538867\n",
      "epochs 1340\n",
      "training loss 0.0007563357051790304\n",
      "epochs 1341\n",
      "training loss 0.0006743954674349277\n",
      "epochs 1342\n",
      "training loss 0.0007070543614780887\n",
      "epochs 1343\n",
      "training loss 0.000788060688883587\n",
      "epochs 1344\n",
      "training loss 0.0007256895016580198\n",
      "epochs 1345\n",
      "training loss 0.0011963436216728812\n",
      "epochs 1346\n",
      "training loss 0.0024361726827919483\n",
      "epochs 1347\n",
      "training loss 0.0018055250606001398\n",
      "epochs 1348\n",
      "training loss 0.0015225838680502513\n",
      "epochs 1349\n",
      "training loss 0.0013136938640686449\n",
      "testing loss 0.002784232940055853\n",
      "epochs 1350\n",
      "training loss 0.0010589875187441752\n",
      "epochs 1351\n",
      "training loss 0.0009069942287523243\n",
      "epochs 1352\n",
      "training loss 0.0008947194673688544\n",
      "epochs 1353\n",
      "training loss 0.0007767790553760135\n",
      "epochs 1354\n",
      "training loss 0.0007347153520245546\n",
      "epochs 1355\n",
      "training loss 0.0006926188851907668\n",
      "epochs 1356\n",
      "training loss 0.000660616570378096\n",
      "epochs 1357\n",
      "training loss 0.0006968545905062447\n",
      "epochs 1358\n",
      "training loss 0.0007359011015234838\n",
      "epochs 1359\n",
      "training loss 0.0007067072269999306\n",
      "testing loss 0.002605907630145629\n",
      "epochs 1360\n",
      "training loss 0.0007179749976188273\n",
      "epochs 1361\n",
      "training loss 0.0006806803447913412\n",
      "epochs 1362\n",
      "training loss 0.0006812481959081484\n",
      "epochs 1363\n",
      "training loss 0.000693981747155709\n",
      "epochs 1364\n",
      "training loss 0.0007055957878070761\n",
      "epochs 1365\n",
      "training loss 0.0006754071843431057\n",
      "epochs 1366\n",
      "training loss 0.000828652116940654\n",
      "epochs 1367\n",
      "training loss 0.0009046452644346197\n",
      "epochs 1368\n",
      "training loss 0.0008407521109722306\n",
      "epochs 1369\n",
      "training loss 0.000737443156657163\n",
      "testing loss 0.0026785648223144787\n",
      "epochs 1370\n",
      "training loss 0.0009217475065720865\n",
      "epochs 1371\n",
      "training loss 0.000762860445248382\n",
      "epochs 1372\n",
      "training loss 0.0008322502401307803\n",
      "epochs 1373\n",
      "training loss 0.0009144221969114441\n",
      "epochs 1374\n",
      "training loss 0.0007498723924150096\n",
      "epochs 1375\n",
      "training loss 0.0008054467253026051\n",
      "epochs 1376\n",
      "training loss 0.0009672201900618394\n",
      "epochs 1377\n",
      "training loss 0.0007551640459148094\n",
      "epochs 1378\n",
      "training loss 0.0007488225016312668\n",
      "epochs 1379\n",
      "training loss 0.0007415553641584801\n",
      "testing loss 0.002894445319564234\n",
      "epochs 1380\n",
      "training loss 0.0007952005255827256\n",
      "epochs 1381\n",
      "training loss 0.000695164830071461\n",
      "epochs 1382\n",
      "training loss 0.0007758623379704437\n",
      "epochs 1383\n",
      "training loss 0.0007733801684284294\n",
      "epochs 1384\n",
      "training loss 0.0007969436609387217\n",
      "epochs 1385\n",
      "training loss 0.0007358865810120846\n",
      "epochs 1386\n",
      "training loss 0.0007449113049099964\n",
      "epochs 1387\n",
      "training loss 0.0007148172586411804\n",
      "epochs 1388\n",
      "training loss 0.000740520055986103\n",
      "epochs 1389\n",
      "training loss 0.0007927951696300511\n",
      "testing loss 0.002677886637839231\n",
      "epochs 1390\n",
      "training loss 0.0008143283966199798\n",
      "epochs 1391\n",
      "training loss 0.0006858718164490202\n",
      "epochs 1392\n",
      "training loss 0.0007774908876536261\n",
      "epochs 1393\n",
      "training loss 0.0007392372402587571\n",
      "epochs 1394\n",
      "training loss 0.0007666560155474001\n",
      "epochs 1395\n",
      "training loss 0.0007759529787100183\n",
      "epochs 1396\n",
      "training loss 0.0007253731140940475\n",
      "epochs 1397\n",
      "training loss 0.0007106538858097669\n",
      "epochs 1398\n",
      "training loss 0.0006818011036676307\n",
      "epochs 1399\n",
      "training loss 0.0006985269495927216\n",
      "testing loss 0.002646949947630022\n",
      "epochs 1400\n",
      "training loss 0.0007204881712325812\n",
      "epochs 1401\n",
      "training loss 0.0007809182004628018\n",
      "epochs 1402\n",
      "training loss 0.0006969629155824351\n",
      "epochs 1403\n",
      "training loss 0.0007490006077852055\n",
      "epochs 1404\n",
      "training loss 0.000758542295061986\n",
      "epochs 1405\n",
      "training loss 0.0007070698621428053\n",
      "epochs 1406\n",
      "training loss 0.0007263025914504274\n",
      "epochs 1407\n",
      "training loss 0.0029437433652959107\n",
      "epochs 1408\n",
      "training loss 0.0015774679111563077\n",
      "epochs 1409\n",
      "training loss 0.0011531055125048367\n",
      "testing loss 0.003118447620910427\n",
      "epochs 1410\n",
      "training loss 0.0010675505984795357\n",
      "epochs 1411\n",
      "training loss 0.0008157475092122756\n",
      "epochs 1412\n",
      "training loss 0.0007865019617665921\n",
      "epochs 1413\n",
      "training loss 0.0006930424365969403\n",
      "epochs 1414\n",
      "training loss 0.0007169068574064657\n",
      "epochs 1415\n",
      "training loss 0.0007332948133445665\n",
      "epochs 1416\n",
      "training loss 0.0006710266618172732\n",
      "epochs 1417\n",
      "training loss 0.000697827726173693\n",
      "epochs 1418\n",
      "training loss 0.0007240065319695733\n",
      "epochs 1419\n",
      "training loss 0.0007946305960631932\n",
      "testing loss 0.00280044117987037\n",
      "epochs 1420\n",
      "training loss 0.0007809015968602184\n",
      "epochs 1421\n",
      "training loss 0.0008295104379969504\n",
      "epochs 1422\n",
      "training loss 0.0006798842100399663\n",
      "epochs 1423\n",
      "training loss 0.0007443225477775417\n",
      "epochs 1424\n",
      "training loss 0.0007087025687198996\n",
      "epochs 1425\n",
      "training loss 0.0007719353050500222\n",
      "epochs 1426\n",
      "training loss 0.0007749191461637684\n",
      "epochs 1427\n",
      "training loss 0.0007649931050327501\n",
      "epochs 1428\n",
      "training loss 0.0007253262121654979\n",
      "epochs 1429\n",
      "training loss 0.0007281356161540957\n",
      "testing loss 0.00285033658122089\n",
      "epochs 1430\n",
      "training loss 0.0007520214071367106\n",
      "epochs 1431\n",
      "training loss 0.0008433450803006391\n",
      "epochs 1432\n",
      "training loss 0.0007129854914176032\n",
      "epochs 1433\n",
      "training loss 0.0007200185498781786\n",
      "epochs 1434\n",
      "training loss 0.0007657156868853343\n",
      "epochs 1435\n",
      "training loss 0.0007396790908973687\n",
      "epochs 1436\n",
      "training loss 0.0007610952273389115\n",
      "epochs 1437\n",
      "training loss 0.0007307611784995406\n",
      "epochs 1438\n",
      "training loss 0.0007411881686488342\n",
      "epochs 1439\n",
      "training loss 0.0006651988058028272\n",
      "testing loss 0.00285596450450599\n",
      "epochs 1440\n",
      "training loss 0.0007709167529878385\n",
      "epochs 1441\n",
      "training loss 0.0007171029284084074\n",
      "epochs 1442\n",
      "training loss 0.0006901054242540909\n",
      "epochs 1443\n",
      "training loss 0.0007386036279312644\n",
      "epochs 1444\n",
      "training loss 0.0008215740667004988\n",
      "epochs 1445\n",
      "training loss 0.000919063082393004\n",
      "epochs 1446\n",
      "training loss 0.003796396910610657\n",
      "epochs 1447\n",
      "training loss 0.0019396377478281778\n",
      "epochs 1448\n",
      "training loss 0.001721739132589969\n",
      "epochs 1449\n",
      "training loss 0.001729577324723989\n",
      "testing loss 0.0028127651964644537\n",
      "epochs 1450\n",
      "training loss 0.0016047861409376413\n",
      "epochs 1451\n",
      "training loss 0.0015318772647994086\n",
      "epochs 1452\n",
      "training loss 0.0013919186128705378\n",
      "epochs 1453\n",
      "training loss 0.0012867224505694872\n",
      "epochs 1454\n",
      "training loss 0.0012458618747998923\n",
      "epochs 1455\n",
      "training loss 0.0011738223070774149\n",
      "epochs 1456\n",
      "training loss 0.0011626428538454997\n",
      "epochs 1457\n",
      "training loss 0.0012468060708214106\n",
      "epochs 1458\n",
      "training loss 0.0014156170320657499\n",
      "epochs 1459\n",
      "training loss 0.0010645939523741988\n",
      "testing loss 0.00317538222743872\n",
      "epochs 1460\n",
      "training loss 0.001904552440282161\n",
      "epochs 1461\n",
      "training loss 0.0013021449055975604\n",
      "epochs 1462\n",
      "training loss 0.0009054398477483699\n",
      "epochs 1463\n",
      "training loss 0.0007728836778692879\n",
      "epochs 1464\n",
      "training loss 0.0008104060051855164\n",
      "epochs 1465\n",
      "training loss 0.0007621985427592245\n",
      "epochs 1466\n",
      "training loss 0.0007792831485062034\n",
      "epochs 1467\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss 0.000775423813041577\n",
      "epochs 1468\n",
      "training loss 0.0008255649867749243\n",
      "epochs 1469\n",
      "training loss 0.0008619040747754853\n",
      "testing loss 0.0027158659167013112\n",
      "epochs 1470\n",
      "training loss 0.000791953069491929\n",
      "epochs 1471\n",
      "training loss 0.0007573924400513895\n",
      "epochs 1472\n",
      "training loss 0.0007682090697174546\n",
      "epochs 1473\n",
      "training loss 0.0007630222957187805\n",
      "epochs 1474\n",
      "training loss 0.0007760879054833996\n",
      "epochs 1475\n",
      "training loss 0.000777765151624933\n",
      "epochs 1476\n",
      "training loss 0.0007784343772216794\n",
      "epochs 1477\n",
      "training loss 0.0008193059190315135\n",
      "epochs 1478\n",
      "training loss 0.000792662651663063\n",
      "epochs 1479\n",
      "training loss 0.0007634058212196189\n",
      "testing loss 0.002777142879546534\n",
      "epochs 1480\n",
      "training loss 0.000709946746856546\n",
      "epochs 1481\n",
      "training loss 0.0007943966724778211\n",
      "epochs 1482\n",
      "training loss 0.0007687312626742721\n",
      "epochs 1483\n",
      "training loss 0.0007421980788195251\n",
      "epochs 1484\n",
      "training loss 0.000817605942179163\n",
      "epochs 1485\n",
      "training loss 0.0007466953093862574\n",
      "epochs 1486\n",
      "training loss 0.0007822547868880695\n",
      "epochs 1487\n",
      "training loss 0.000932907700764389\n",
      "epochs 1488\n",
      "training loss 0.0008771053856305246\n",
      "epochs 1489\n",
      "training loss 0.000931086083346876\n",
      "testing loss 0.002864215810740274\n",
      "epochs 1490\n",
      "training loss 0.0009274978714706348\n",
      "epochs 1491\n",
      "training loss 0.0008495888080254005\n",
      "epochs 1492\n",
      "training loss 0.0008845554160854375\n",
      "epochs 1493\n",
      "training loss 0.0008734956257735976\n",
      "epochs 1494\n",
      "training loss 0.0008425726661441627\n",
      "epochs 1495\n",
      "training loss 0.0009281889649248175\n",
      "epochs 1496\n",
      "training loss 0.0009021324038860815\n",
      "epochs 1497\n",
      "training loss 0.00089127949023574\n",
      "epochs 1498\n",
      "training loss 0.0008842318627868685\n",
      "epochs 1499\n",
      "training loss 0.0010531165942798814\n",
      "testing loss 0.00315414651227679\n",
      "epochs 1500\n",
      "training loss 0.0012710832011968033\n",
      "epochs 1501\n",
      "training loss 0.001099863624105394\n",
      "epochs 1502\n",
      "training loss 0.0009196146607532033\n",
      "epochs 1503\n",
      "training loss 0.0008944432784755089\n",
      "epochs 1504\n",
      "training loss 0.0008929799470801394\n",
      "epochs 1505\n",
      "training loss 0.0008842561372391608\n",
      "epochs 1506\n",
      "training loss 0.0009078414041915552\n",
      "epochs 1507\n",
      "training loss 0.0008435584668432416\n",
      "epochs 1508\n",
      "training loss 0.0008711495072620505\n",
      "epochs 1509\n",
      "training loss 0.0008566984845754212\n",
      "testing loss 0.002693274632634608\n",
      "epochs 1510\n",
      "training loss 0.0008974956821984297\n",
      "epochs 1511\n",
      "training loss 0.0008292856412489636\n",
      "epochs 1512\n",
      "training loss 0.0008758135431157397\n",
      "epochs 1513\n",
      "training loss 0.0008563191384377134\n",
      "epochs 1514\n",
      "training loss 0.0009310081470927569\n",
      "epochs 1515\n",
      "training loss 0.0008836484764169018\n",
      "epochs 1516\n",
      "training loss 0.0008606059206217969\n",
      "epochs 1517\n",
      "training loss 0.000849486570957465\n",
      "epochs 1518\n",
      "training loss 0.0008668593094913476\n",
      "epochs 1519\n",
      "training loss 0.0013151023700397383\n",
      "testing loss 0.0028953043610214237\n",
      "epochs 1520\n",
      "training loss 0.0008886117587399621\n",
      "epochs 1521\n",
      "training loss 0.0007120220939449026\n",
      "epochs 1522\n",
      "training loss 0.000764471216029615\n",
      "epochs 1523\n",
      "training loss 0.0009606346175906823\n",
      "epochs 1524\n",
      "training loss 0.0008892713606111298\n",
      "epochs 1525\n",
      "training loss 0.0008305755309763401\n",
      "epochs 1526\n",
      "training loss 0.0010219232850116437\n",
      "epochs 1527\n",
      "training loss 0.0008336050266231549\n",
      "epochs 1528\n",
      "training loss 0.0007352973931606315\n",
      "epochs 1529\n",
      "training loss 0.0007296384830242957\n",
      "testing loss 0.0028537629594933903\n",
      "epochs 1530\n",
      "training loss 0.000716238089774857\n",
      "epochs 1531\n",
      "training loss 0.0007395315854307717\n",
      "epochs 1532\n",
      "training loss 0.0007037636102106433\n",
      "epochs 1533\n",
      "training loss 0.000713902613003724\n",
      "epochs 1534\n",
      "training loss 0.0006476111068194986\n",
      "epochs 1535\n",
      "training loss 0.0007062950014953408\n",
      "epochs 1536\n",
      "training loss 0.0007279253913136341\n",
      "epochs 1537\n",
      "training loss 0.000696291732775206\n",
      "epochs 1538\n",
      "training loss 0.0007983622590389873\n",
      "epochs 1539\n",
      "training loss 0.0007672654285264062\n",
      "testing loss 0.00266694480838941\n",
      "epochs 1540\n",
      "training loss 0.0007500414368392203\n",
      "epochs 1541\n",
      "training loss 0.0006588433309575673\n",
      "epochs 1542\n",
      "training loss 0.000686602850531661\n",
      "epochs 1543\n",
      "training loss 0.0007068699282044857\n",
      "epochs 1544\n",
      "training loss 0.0012156953289432558\n",
      "epochs 1545\n",
      "training loss 0.0013874674423443476\n",
      "epochs 1546\n",
      "training loss 0.0016492771604530072\n",
      "epochs 1547\n",
      "training loss 0.0009562847858944506\n",
      "epochs 1548\n",
      "training loss 0.0009069477386120141\n",
      "epochs 1549\n",
      "training loss 0.0007905954261357107\n",
      "testing loss 0.0026763828866784825\n",
      "epochs 1550\n",
      "training loss 0.0007603974189498889\n",
      "epochs 1551\n",
      "training loss 0.000718783300071332\n",
      "epochs 1552\n",
      "training loss 0.0007541560993238288\n",
      "epochs 1553\n",
      "training loss 0.0007040793443980448\n",
      "epochs 1554\n",
      "training loss 0.0007302573509443563\n",
      "epochs 1555\n",
      "training loss 0.0008507510331370174\n",
      "epochs 1556\n",
      "training loss 0.0008301388921349176\n",
      "epochs 1557\n",
      "training loss 0.00085782800441237\n",
      "epochs 1558\n",
      "training loss 0.0006824678056349689\n",
      "epochs 1559\n",
      "training loss 0.0007146228854806307\n",
      "testing loss 0.003020076086110574\n",
      "epochs 1560\n",
      "training loss 0.0007815865935484587\n",
      "epochs 1561\n",
      "training loss 0.0006932768753820345\n",
      "epochs 1562\n",
      "training loss 0.0007626359302502432\n",
      "epochs 1563\n",
      "training loss 0.0007452833396170322\n",
      "epochs 1564\n",
      "training loss 0.0007819638536757532\n",
      "epochs 1565\n",
      "training loss 0.0007173855685328889\n",
      "epochs 1566\n",
      "training loss 0.000701801223138285\n",
      "epochs 1567\n",
      "training loss 0.0007136856009553847\n",
      "epochs 1568\n",
      "training loss 0.0007169520169974936\n",
      "epochs 1569\n",
      "training loss 0.0006628272014473336\n",
      "testing loss 0.0028657110128056337\n",
      "epochs 1570\n",
      "training loss 0.000862997187755147\n",
      "epochs 1571\n",
      "training loss 0.0011468530914039948\n",
      "epochs 1572\n",
      "training loss 0.0006712224967154961\n",
      "epochs 1573\n",
      "training loss 0.0006644066257223963\n",
      "epochs 1574\n",
      "training loss 0.0006642322092972367\n",
      "epochs 1575\n",
      "training loss 0.0007520006087786973\n",
      "epochs 1576\n",
      "training loss 0.0007376490796153295\n",
      "epochs 1577\n",
      "training loss 0.0007399191698986516\n",
      "epochs 1578\n",
      "training loss 0.0006813541462356197\n",
      "epochs 1579\n",
      "training loss 0.0006734143422794809\n",
      "testing loss 0.002684186546277281\n",
      "epochs 1580\n",
      "training loss 0.0007179648111012444\n",
      "epochs 1581\n",
      "training loss 0.0007427048362192831\n",
      "epochs 1582\n",
      "training loss 0.0007250029066475646\n",
      "epochs 1583\n",
      "training loss 0.0008868748975151974\n",
      "epochs 1584\n",
      "training loss 0.0007776330423500321\n",
      "epochs 1585\n",
      "training loss 0.0006542503393232528\n",
      "epochs 1586\n",
      "training loss 0.0006590445984528601\n",
      "epochs 1587\n",
      "training loss 0.0006274769019327016\n",
      "epochs 1588\n",
      "training loss 0.0007142557349094221\n",
      "epochs 1589\n",
      "training loss 0.0006952761576191089\n",
      "testing loss 0.002786043738279201\n",
      "epochs 1590\n",
      "training loss 0.0007126649522674086\n",
      "epochs 1591\n",
      "training loss 0.0007948283148373231\n",
      "epochs 1592\n",
      "training loss 0.0006851971301244499\n",
      "epochs 1593\n",
      "training loss 0.0007634348880731724\n",
      "epochs 1594\n",
      "training loss 0.0007636690277699665\n",
      "epochs 1595\n",
      "training loss 0.000696851733288555\n",
      "epochs 1596\n",
      "training loss 0.0006962906947680735\n",
      "epochs 1597\n",
      "training loss 0.0006945333518774325\n",
      "epochs 1598\n",
      "training loss 0.0007302033160119615\n",
      "epochs 1599\n",
      "training loss 0.0006865685300386332\n",
      "testing loss 0.0026878832665219216\n",
      "epochs 1600\n",
      "training loss 0.0007060088519265983\n",
      "epochs 1601\n",
      "training loss 0.0009103206506120692\n",
      "epochs 1602\n",
      "training loss 0.0007256173577738535\n",
      "epochs 1603\n",
      "training loss 0.000724824312540043\n",
      "epochs 1604\n",
      "training loss 0.0006371085377378916\n",
      "epochs 1605\n",
      "training loss 0.0007051517342119605\n",
      "epochs 1606\n",
      "training loss 0.0006868895864231642\n",
      "epochs 1607\n",
      "training loss 0.0007450195202939382\n",
      "epochs 1608\n",
      "training loss 0.0007634300986796018\n",
      "epochs 1609\n",
      "training loss 0.0007155239826215482\n",
      "testing loss 0.0028024825039616925\n",
      "epochs 1610\n",
      "training loss 0.0006859627932537981\n",
      "epochs 1611\n",
      "training loss 0.0006856164923482674\n",
      "epochs 1612\n",
      "training loss 0.0006820554668112095\n",
      "epochs 1613\n",
      "training loss 0.0006918158446931164\n",
      "epochs 1614\n",
      "training loss 0.0006694364576249477\n",
      "epochs 1615\n",
      "training loss 0.0006752480923673732\n",
      "epochs 1616\n",
      "training loss 0.0011780452697805347\n",
      "epochs 1617\n",
      "training loss 0.0010827771389940442\n",
      "epochs 1618\n",
      "training loss 0.000752689670714745\n",
      "epochs 1619\n",
      "training loss 0.000715381132263979\n",
      "testing loss 0.002724599879621429\n",
      "epochs 1620\n",
      "training loss 0.0007046812427503349\n",
      "epochs 1621\n",
      "training loss 0.0006666807893919829\n",
      "epochs 1622\n",
      "training loss 0.0007233591384033597\n",
      "epochs 1623\n",
      "training loss 0.0006480029380581651\n",
      "epochs 1624\n",
      "training loss 0.00069066532922903\n",
      "epochs 1625\n",
      "training loss 0.0006682189127662443\n",
      "epochs 1626\n",
      "training loss 0.0006553806158597935\n",
      "epochs 1627\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss 0.0006686362996449733\n",
      "epochs 1628\n",
      "training loss 0.0006859241779553944\n",
      "epochs 1629\n",
      "training loss 0.0006875066313288234\n",
      "testing loss 0.002773967174010629\n",
      "epochs 1630\n",
      "training loss 0.0006744776516098325\n",
      "epochs 1631\n",
      "training loss 0.0007370000110307884\n",
      "epochs 1632\n",
      "training loss 0.0006995522420666546\n",
      "epochs 1633\n",
      "training loss 0.0007268004581165191\n",
      "epochs 1634\n",
      "training loss 0.0007356929119165398\n",
      "epochs 1635\n",
      "training loss 0.000672085785061421\n",
      "epochs 1636\n",
      "training loss 0.000621855358195443\n",
      "epochs 1637\n",
      "training loss 0.0006722151492878025\n",
      "epochs 1638\n",
      "training loss 0.0008363247886024087\n",
      "epochs 1639\n",
      "training loss 0.0008066142282921447\n",
      "testing loss 0.0027772133347598164\n",
      "epochs 1640\n",
      "training loss 0.0007105520438108491\n",
      "epochs 1641\n",
      "training loss 0.0006474690794191778\n",
      "epochs 1642\n",
      "training loss 0.0006378064823576099\n",
      "epochs 1643\n",
      "training loss 0.0006505879623062433\n",
      "epochs 1644\n",
      "training loss 0.0006965844650288597\n",
      "epochs 1645\n",
      "training loss 0.0007593954086557064\n",
      "epochs 1646\n",
      "training loss 0.0016288950617883728\n",
      "epochs 1647\n",
      "training loss 0.002027120815213532\n",
      "epochs 1648\n",
      "training loss 0.001327535965002926\n",
      "epochs 1649\n",
      "training loss 0.001342559629438394\n",
      "testing loss 0.002903639911492322\n",
      "epochs 1650\n",
      "training loss 0.0009134673056303096\n",
      "epochs 1651\n",
      "training loss 0.0007411470748363827\n",
      "epochs 1652\n",
      "training loss 0.0007563508519977841\n",
      "epochs 1653\n",
      "training loss 0.0006533550338445962\n",
      "epochs 1654\n",
      "training loss 0.0007044212197521163\n",
      "epochs 1655\n",
      "training loss 0.0006518569659218078\n",
      "epochs 1656\n",
      "training loss 0.0006897649021839049\n",
      "epochs 1657\n",
      "training loss 0.0006633375491451551\n",
      "epochs 1658\n",
      "training loss 0.0007006437618548679\n",
      "epochs 1659\n",
      "training loss 0.0007736389562388525\n",
      "testing loss 0.0027348670521453815\n",
      "epochs 1660\n",
      "training loss 0.0007282317893637633\n",
      "epochs 1661\n",
      "training loss 0.0007766732174830969\n",
      "epochs 1662\n",
      "training loss 0.0006654654325397917\n",
      "epochs 1663\n",
      "training loss 0.0006881453299266498\n",
      "epochs 1664\n",
      "training loss 0.0006494035081489232\n",
      "epochs 1665\n",
      "training loss 0.0006418473637127813\n",
      "epochs 1666\n",
      "training loss 0.0006926150932005043\n",
      "epochs 1667\n",
      "training loss 0.0006897160417179501\n",
      "epochs 1668\n",
      "training loss 0.0006873697204526661\n",
      "epochs 1669\n",
      "training loss 0.0006506636097962121\n",
      "testing loss 0.0028765291113452655\n",
      "epochs 1670\n",
      "training loss 0.0006724867537528514\n",
      "epochs 1671\n",
      "training loss 0.0006715755382981604\n",
      "epochs 1672\n",
      "training loss 0.0006973155551960856\n",
      "epochs 1673\n",
      "training loss 0.0006675752498864799\n",
      "epochs 1674\n",
      "training loss 0.0007827718934860918\n",
      "epochs 1675\n",
      "training loss 0.0021493763188367263\n",
      "epochs 1676\n",
      "training loss 0.001295196596429737\n",
      "epochs 1677\n",
      "training loss 0.0009568894551260154\n",
      "epochs 1678\n",
      "training loss 0.0008094295784852278\n",
      "epochs 1679\n",
      "training loss 0.0009070549049311371\n",
      "testing loss 0.0029214587717330256\n",
      "epochs 1680\n",
      "training loss 0.0010198225188677661\n",
      "epochs 1681\n",
      "training loss 0.0009444891753794745\n",
      "epochs 1682\n",
      "training loss 0.0008597073153526123\n",
      "epochs 1683\n",
      "training loss 0.0007757836911051696\n",
      "epochs 1684\n",
      "training loss 0.0007353440021047238\n",
      "epochs 1685\n",
      "training loss 0.000600843093397611\n",
      "epochs 1686\n",
      "training loss 0.0006548210033385429\n",
      "epochs 1687\n",
      "training loss 0.0006378719875607413\n",
      "epochs 1688\n",
      "training loss 0.0006531501992281504\n",
      "epochs 1689\n",
      "training loss 0.0006918668486694537\n",
      "testing loss 0.0027733193078831315\n",
      "epochs 1690\n",
      "training loss 0.0006414859741961578\n",
      "epochs 1691\n",
      "training loss 0.000659868449250825\n",
      "epochs 1692\n",
      "training loss 0.0006851359352959167\n",
      "epochs 1693\n",
      "training loss 0.0007127097881778417\n",
      "epochs 1694\n",
      "training loss 0.0007216243915851468\n",
      "epochs 1695\n",
      "training loss 0.000655660325343548\n",
      "epochs 1696\n",
      "training loss 0.0006970640137086773\n",
      "epochs 1697\n",
      "training loss 0.0007171554016416446\n",
      "epochs 1698\n",
      "training loss 0.0007025067652731364\n",
      "epochs 1699\n",
      "training loss 0.0006355471739377034\n",
      "testing loss 0.002742841281657312\n",
      "epochs 1700\n",
      "training loss 0.0007959129307369523\n",
      "epochs 1701\n",
      "training loss 0.000762762201155216\n",
      "epochs 1702\n",
      "training loss 0.0006711865845348652\n",
      "epochs 1703\n",
      "training loss 0.0006753907812827219\n",
      "epochs 1704\n",
      "training loss 0.0006615566546210629\n",
      "epochs 1705\n",
      "training loss 0.0006501138059735173\n",
      "epochs 1706\n",
      "training loss 0.0007391328067804678\n",
      "epochs 1707\n",
      "training loss 0.0007232811322646629\n",
      "epochs 1708\n",
      "training loss 0.0012001535168949425\n",
      "epochs 1709\n",
      "training loss 0.001493004660403758\n",
      "testing loss 0.0028963693341649806\n",
      "epochs 1710\n",
      "training loss 0.0012269760556320878\n",
      "epochs 1711\n",
      "training loss 0.0010121316422735224\n",
      "epochs 1712\n",
      "training loss 0.001354497319103663\n",
      "epochs 1713\n",
      "training loss 0.0012737565121357258\n",
      "epochs 1714\n",
      "training loss 0.0008526171106805509\n",
      "epochs 1715\n",
      "training loss 0.0008964977237943696\n",
      "epochs 1716\n",
      "training loss 0.0006851695701239296\n",
      "epochs 1717\n",
      "training loss 0.0006944395152895817\n",
      "epochs 1718\n",
      "training loss 0.0006469349235495818\n",
      "epochs 1719\n",
      "training loss 0.0006673843989971074\n",
      "testing loss 0.00277736171351825\n",
      "epochs 1720\n",
      "training loss 0.0006766461027364352\n",
      "epochs 1721\n",
      "training loss 0.0008258734977277601\n",
      "epochs 1722\n",
      "training loss 0.0018247469654943693\n",
      "epochs 1723\n",
      "training loss 0.0012237536705008462\n",
      "epochs 1724\n",
      "training loss 0.0009388634678483077\n",
      "epochs 1725\n",
      "training loss 0.0008040423150985335\n",
      "epochs 1726\n",
      "training loss 0.000793934433677129\n",
      "epochs 1727\n",
      "training loss 0.0007689960886891309\n",
      "epochs 1728\n",
      "training loss 0.000805528358981653\n",
      "epochs 1729\n",
      "training loss 0.0007486623989830025\n",
      "testing loss 0.002777107223432432\n",
      "epochs 1730\n",
      "training loss 0.0007045156799050156\n",
      "epochs 1731\n",
      "training loss 0.0007418903535816501\n",
      "epochs 1732\n",
      "training loss 0.0007411947278914503\n",
      "epochs 1733\n",
      "training loss 0.0007040849387027198\n",
      "epochs 1734\n",
      "training loss 0.0007143755130948198\n",
      "epochs 1735\n",
      "training loss 0.0007118766652002625\n",
      "epochs 1736\n",
      "training loss 0.0006690757558079533\n",
      "epochs 1737\n",
      "training loss 0.0006880955033727545\n",
      "epochs 1738\n",
      "training loss 0.0006695203759104557\n",
      "epochs 1739\n",
      "training loss 0.0007470569067873842\n",
      "testing loss 0.0027454292049948524\n",
      "epochs 1740\n",
      "training loss 0.0006932062206586036\n",
      "epochs 1741\n",
      "training loss 0.0008307822331917787\n",
      "epochs 1742\n",
      "training loss 0.0008782614208262493\n",
      "epochs 1743\n",
      "training loss 0.0008200963772090271\n",
      "epochs 1744\n",
      "training loss 0.0008288932920682688\n",
      "epochs 1745\n",
      "training loss 0.0006896746013576086\n",
      "epochs 1746\n",
      "training loss 0.0006817843755997299\n",
      "epochs 1747\n",
      "training loss 0.0007786141685670169\n",
      "epochs 1748\n",
      "training loss 0.002007070103997087\n",
      "epochs 1749\n",
      "training loss 0.004214171162030821\n",
      "testing loss 0.004561286071209726\n",
      "epochs 1750\n",
      "training loss 0.00300282494930726\n",
      "epochs 1751\n",
      "training loss 0.0019843803370501677\n",
      "epochs 1752\n",
      "training loss 0.0015269128903307836\n",
      "epochs 1753\n",
      "training loss 0.001977933609842586\n",
      "epochs 1754\n",
      "training loss 0.0014832884217980445\n",
      "epochs 1755\n",
      "training loss 0.0013236129077188218\n",
      "epochs 1756\n",
      "training loss 0.001278512476197526\n",
      "epochs 1757\n",
      "training loss 0.0015418930708127815\n",
      "epochs 1758\n",
      "training loss 0.0018963587849321676\n",
      "epochs 1759\n",
      "training loss 0.0012249347435715284\n",
      "testing loss 0.002677368027395866\n",
      "epochs 1760\n",
      "training loss 0.0010231847635620362\n",
      "epochs 1761\n",
      "training loss 0.0009297524638315465\n",
      "epochs 1762\n",
      "training loss 0.0008106316048099933\n",
      "epochs 1763\n",
      "training loss 0.0007840737482493228\n",
      "epochs 1764\n",
      "training loss 0.0008253861624906038\n",
      "epochs 1765\n",
      "training loss 0.0007498077187498912\n",
      "epochs 1766\n",
      "training loss 0.0007879196230596707\n",
      "epochs 1767\n",
      "training loss 0.000797997385555012\n",
      "epochs 1768\n",
      "training loss 0.0006999088689050776\n",
      "epochs 1769\n",
      "training loss 0.0006901744022784262\n",
      "testing loss 0.0027470562098455345\n",
      "epochs 1770\n",
      "training loss 0.0007351098264925646\n",
      "epochs 1771\n",
      "training loss 0.0006819270143574132\n",
      "epochs 1772\n",
      "training loss 0.0007212700616493311\n",
      "epochs 1773\n",
      "training loss 0.001635808547294209\n",
      "epochs 1774\n",
      "training loss 0.0014544218542594971\n",
      "epochs 1775\n",
      "training loss 0.0015218044418167877\n",
      "epochs 1776\n",
      "training loss 0.0010011562961507532\n",
      "epochs 1777\n",
      "training loss 0.0008572205718207572\n",
      "epochs 1778\n",
      "training loss 0.0008116883269438978\n",
      "epochs 1779\n",
      "training loss 0.0008042294217668485\n",
      "testing loss 0.00284432508307344\n",
      "epochs 1780\n",
      "training loss 0.0008285845725232379\n",
      "epochs 1781\n",
      "training loss 0.0007231973908136749\n",
      "epochs 1782\n",
      "training loss 0.0007680852802457588\n",
      "epochs 1783\n",
      "training loss 0.0007998453000083418\n",
      "epochs 1784\n",
      "training loss 0.000760675372296129\n",
      "epochs 1785\n",
      "training loss 0.0007148312560797847\n",
      "epochs 1786\n",
      "training loss 0.0007639828271276423\n",
      "epochs 1787\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss 0.0007317757074215865\n",
      "epochs 1788\n",
      "training loss 0.0007380391709049343\n",
      "epochs 1789\n",
      "training loss 0.0007221823333342217\n",
      "testing loss 0.0028642900469745937\n",
      "epochs 1790\n",
      "training loss 0.0008873144084358401\n",
      "epochs 1791\n",
      "training loss 0.0008576978856094725\n",
      "epochs 1792\n",
      "training loss 0.0007130909590991808\n",
      "epochs 1793\n",
      "training loss 0.0007830251051264455\n",
      "epochs 1794\n",
      "training loss 0.0008284597008136642\n",
      "epochs 1795\n",
      "training loss 0.0007845605539559956\n",
      "epochs 1796\n",
      "training loss 0.0007358885217687302\n",
      "epochs 1797\n",
      "training loss 0.0007808572088303129\n",
      "epochs 1798\n",
      "training loss 0.0017149721950435542\n",
      "epochs 1799\n",
      "training loss 0.0011954933375199425\n",
      "testing loss 0.002848380694829641\n",
      "epochs 1800\n",
      "training loss 0.0009132883349422218\n",
      "epochs 1801\n",
      "training loss 0.0007536682618023278\n",
      "epochs 1802\n",
      "training loss 0.0007775765021882193\n",
      "epochs 1803\n",
      "training loss 0.0006816724245754951\n",
      "epochs 1804\n",
      "training loss 0.0007044576867632172\n",
      "epochs 1805\n",
      "training loss 0.0006624258160138202\n",
      "epochs 1806\n",
      "training loss 0.000683271786655189\n",
      "epochs 1807\n",
      "training loss 0.000751572131659796\n",
      "epochs 1808\n",
      "training loss 0.0006676290726882199\n",
      "epochs 1809\n",
      "training loss 0.0006860153958177347\n",
      "testing loss 0.002817659202471032\n",
      "epochs 1810\n",
      "training loss 0.0006494640139509049\n",
      "epochs 1811\n",
      "training loss 0.0007479688920339677\n",
      "epochs 1812\n",
      "training loss 0.0007104992038162714\n",
      "epochs 1813\n",
      "training loss 0.0007019285042734822\n",
      "epochs 1814\n",
      "training loss 0.0006818071596528259\n",
      "epochs 1815\n",
      "training loss 0.0007038797588210757\n",
      "epochs 1816\n",
      "training loss 0.000775583607401546\n",
      "epochs 1817\n",
      "training loss 0.0007457751479979298\n",
      "epochs 1818\n",
      "training loss 0.0007248147231375227\n",
      "epochs 1819\n",
      "training loss 0.0007638792934796368\n",
      "testing loss 0.0028570825056542792\n",
      "epochs 1820\n",
      "training loss 0.0007012616440485371\n",
      "epochs 1821\n",
      "training loss 0.0006867115004384455\n",
      "epochs 1822\n",
      "training loss 0.0007148438016884029\n",
      "epochs 1823\n",
      "training loss 0.000755285499560842\n",
      "epochs 1824\n",
      "training loss 0.0008114833390236886\n",
      "epochs 1825\n",
      "training loss 0.0008382920316798403\n",
      "epochs 1826\n",
      "training loss 0.0008424396912735748\n",
      "epochs 1827\n",
      "training loss 0.0008328590967754711\n",
      "epochs 1828\n",
      "training loss 0.0007272218009931146\n",
      "epochs 1829\n",
      "training loss 0.0006995999979139744\n",
      "testing loss 0.0028063961641585575\n",
      "epochs 1830\n",
      "training loss 0.0007604976883688857\n",
      "epochs 1831\n",
      "training loss 0.0007240534108981354\n",
      "epochs 1832\n",
      "training loss 0.0006860025608515802\n",
      "epochs 1833\n",
      "training loss 0.0008133847657789258\n",
      "epochs 1834\n",
      "training loss 0.0008374806177713214\n",
      "epochs 1835\n",
      "training loss 0.0007072785965840709\n",
      "epochs 1836\n",
      "training loss 0.0007382054794806206\n",
      "epochs 1837\n",
      "training loss 0.003313590041846518\n",
      "epochs 1838\n",
      "training loss 0.0021125779414300364\n",
      "epochs 1839\n",
      "training loss 0.0014090942067453655\n",
      "testing loss 0.0029209610921040125\n",
      "epochs 1840\n",
      "training loss 0.0012806108485734638\n",
      "epochs 1841\n",
      "training loss 0.0013106635720914904\n",
      "epochs 1842\n",
      "training loss 0.0008516884112545207\n",
      "epochs 1843\n",
      "training loss 0.0010493053345393254\n",
      "epochs 1844\n",
      "training loss 0.000993115253945371\n",
      "epochs 1845\n",
      "training loss 0.0007270424286898588\n",
      "epochs 1846\n",
      "training loss 0.0008351927335475965\n",
      "epochs 1847\n",
      "training loss 0.0009385739094160191\n",
      "epochs 1848\n",
      "training loss 0.000781138074063444\n",
      "epochs 1849\n",
      "training loss 0.0007243119025394875\n",
      "testing loss 0.0027415457520970797\n",
      "epochs 1850\n",
      "training loss 0.0007405407136903459\n",
      "epochs 1851\n",
      "training loss 0.0006812350655690764\n",
      "epochs 1852\n",
      "training loss 0.0007117176034783599\n",
      "epochs 1853\n",
      "training loss 0.0007200080509146104\n",
      "epochs 1854\n",
      "training loss 0.0007585400357555122\n",
      "epochs 1855\n",
      "training loss 0.0007336418155727959\n",
      "epochs 1856\n",
      "training loss 0.0007996386147775096\n",
      "epochs 1857\n",
      "training loss 0.0007236788001040274\n",
      "epochs 1858\n",
      "training loss 0.0008132186305877614\n",
      "epochs 1859\n",
      "training loss 0.0007228173842224771\n",
      "testing loss 0.0029028489507061054\n",
      "epochs 1860\n",
      "training loss 0.0007384036976198657\n",
      "epochs 1861\n",
      "training loss 0.0006811778093999575\n",
      "epochs 1862\n",
      "training loss 0.0007529381833691716\n",
      "epochs 1863\n",
      "training loss 0.0017997176264516023\n",
      "epochs 1864\n",
      "training loss 0.0014572437285759845\n",
      "epochs 1865\n",
      "training loss 0.001389499061413981\n",
      "epochs 1866\n",
      "training loss 0.0008858485133380071\n",
      "epochs 1867\n",
      "training loss 0.0007252556845612292\n",
      "epochs 1868\n",
      "training loss 0.0009204117857425058\n",
      "epochs 1869\n",
      "training loss 0.0006568937098514005\n",
      "testing loss 0.0027972232547905694\n",
      "epochs 1870\n",
      "training loss 0.0007752581325424751\n",
      "epochs 1871\n",
      "training loss 0.000693498803058492\n",
      "epochs 1872\n",
      "training loss 0.0006931989316086888\n",
      "epochs 1873\n",
      "training loss 0.0006815812161785344\n",
      "epochs 1874\n",
      "training loss 0.0006788702238291661\n",
      "epochs 1875\n",
      "training loss 0.0007011013022004018\n",
      "epochs 1876\n",
      "training loss 0.0006351687089649049\n",
      "epochs 1877\n",
      "training loss 0.0006826846238641821\n",
      "epochs 1878\n",
      "training loss 0.0007185513030003054\n",
      "epochs 1879\n",
      "training loss 0.0007277390845141184\n",
      "testing loss 0.00281126176523943\n",
      "epochs 1880\n",
      "training loss 0.0006759062084393423\n",
      "epochs 1881\n",
      "training loss 0.0007172983193184082\n",
      "epochs 1882\n",
      "training loss 0.0006659088100237336\n",
      "epochs 1883\n",
      "training loss 0.0006842517272228132\n",
      "epochs 1884\n",
      "training loss 0.0006825095846701277\n",
      "epochs 1885\n",
      "training loss 0.0007070648990993283\n",
      "epochs 1886\n",
      "training loss 0.0006445738001115122\n",
      "epochs 1887\n",
      "training loss 0.0006779714857792839\n",
      "epochs 1888\n",
      "training loss 0.0007190336324670848\n",
      "epochs 1889\n",
      "training loss 0.0006756360673927348\n",
      "testing loss 0.0027607026087212647\n",
      "epochs 1890\n",
      "training loss 0.0006561324303427649\n",
      "epochs 1891\n",
      "training loss 0.0006885647946773351\n",
      "epochs 1892\n",
      "training loss 0.0006273309273806635\n",
      "epochs 1893\n",
      "training loss 0.0006418657746720822\n",
      "epochs 1894\n",
      "training loss 0.0006861643671796949\n",
      "epochs 1895\n",
      "training loss 0.0006670351912469906\n",
      "epochs 1896\n",
      "training loss 0.0007055332831292495\n",
      "epochs 1897\n",
      "training loss 0.0007891755304822987\n",
      "epochs 1898\n",
      "training loss 0.0008229206934165051\n",
      "epochs 1899\n",
      "training loss 0.0007816781401336985\n",
      "testing loss 0.0027460941845874783\n",
      "epochs 1900\n",
      "training loss 0.000788269615905518\n",
      "epochs 1901\n",
      "training loss 0.0007561028829392182\n",
      "epochs 1902\n",
      "training loss 0.0007497356041464785\n",
      "epochs 1903\n",
      "training loss 0.0006987449948712731\n",
      "epochs 1904\n",
      "training loss 0.0007765081137529147\n",
      "epochs 1905\n",
      "training loss 0.0006902652848717165\n",
      "epochs 1906\n",
      "training loss 0.0007967829803715384\n",
      "epochs 1907\n",
      "training loss 0.0007600422628722111\n",
      "epochs 1908\n",
      "training loss 0.0007869432369632063\n",
      "epochs 1909\n",
      "training loss 0.0007530975118909302\n",
      "testing loss 0.0027443337194780087\n",
      "epochs 1910\n",
      "training loss 0.001047683686356267\n",
      "epochs 1911\n",
      "training loss 0.002149572995888341\n",
      "epochs 1912\n",
      "training loss 0.0017456645814781177\n",
      "epochs 1913\n",
      "training loss 0.001336909073870629\n",
      "epochs 1914\n",
      "training loss 0.0011856085787128126\n",
      "epochs 1915\n",
      "training loss 0.001293555955122307\n",
      "epochs 1916\n",
      "training loss 0.0013304081875307196\n",
      "epochs 1917\n",
      "training loss 0.0013884500215413178\n",
      "epochs 1918\n",
      "training loss 0.0017219139907033519\n",
      "epochs 1919\n",
      "training loss 0.002813830796210237\n",
      "testing loss 0.0037230464038670273\n",
      "epochs 1920\n",
      "training loss 0.0018356103038890883\n",
      "epochs 1921\n",
      "training loss 0.0013264579092305277\n",
      "epochs 1922\n",
      "training loss 0.0014425329596871414\n",
      "epochs 1923\n",
      "training loss 0.0011799184052241078\n",
      "epochs 1924\n",
      "training loss 0.0011375305595090132\n",
      "epochs 1925\n",
      "training loss 0.0009670323357170046\n",
      "epochs 1926\n",
      "training loss 0.0009158442930444384\n",
      "epochs 1927\n",
      "training loss 0.0014172097846567007\n",
      "epochs 1928\n",
      "training loss 0.001055082685146396\n",
      "epochs 1929\n",
      "training loss 0.0015128229949609192\n",
      "testing loss 0.0026366125461183064\n",
      "epochs 1930\n",
      "training loss 0.0009887614973897176\n",
      "epochs 1931\n",
      "training loss 0.0009860990982641406\n",
      "epochs 1932\n",
      "training loss 0.0008650598172657475\n",
      "epochs 1933\n",
      "training loss 0.0008353453529729737\n",
      "epochs 1934\n",
      "training loss 0.0008481471812760168\n",
      "epochs 1935\n",
      "training loss 0.0008238381002024722\n",
      "epochs 1936\n",
      "training loss 0.0007537134540356458\n",
      "epochs 1937\n",
      "training loss 0.0007571151798009295\n",
      "epochs 1938\n",
      "training loss 0.0007285166388139762\n",
      "epochs 1939\n",
      "training loss 0.0007075485121423384\n",
      "testing loss 0.0025737646158870493\n",
      "epochs 1940\n",
      "training loss 0.0007953650808516652\n",
      "epochs 1941\n",
      "training loss 0.000737676722946574\n",
      "epochs 1942\n",
      "training loss 0.0006729659816713036\n",
      "epochs 1943\n",
      "training loss 0.0007683502034797958\n",
      "epochs 1944\n",
      "training loss 0.0006933227397457591\n",
      "epochs 1945\n",
      "training loss 0.0006910664667049847\n",
      "epochs 1946\n",
      "training loss 0.0007117310038019017\n",
      "epochs 1947\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss 0.0009028676244087721\n",
      "epochs 1948\n",
      "training loss 0.0007872708271134441\n",
      "epochs 1949\n",
      "training loss 0.0007393911247719136\n",
      "testing loss 0.0026609098348033397\n",
      "epochs 1950\n",
      "training loss 0.0007345142402214856\n",
      "epochs 1951\n",
      "training loss 0.0006738898687037756\n",
      "epochs 1952\n",
      "training loss 0.0006851796109454372\n",
      "epochs 1953\n",
      "training loss 0.0006717134852352974\n",
      "epochs 1954\n",
      "training loss 0.0007167860819062212\n",
      "epochs 1955\n",
      "training loss 0.0007339458233934451\n",
      "epochs 1956\n",
      "training loss 0.0006948776274571326\n",
      "epochs 1957\n",
      "training loss 0.000695705800218151\n",
      "epochs 1958\n",
      "training loss 0.0007964908036560465\n",
      "epochs 1959\n",
      "training loss 0.0006709406307175201\n",
      "testing loss 0.002589173056845758\n",
      "epochs 1960\n",
      "training loss 0.0007484129046714131\n",
      "epochs 1961\n",
      "training loss 0.0006705802618695769\n",
      "epochs 1962\n",
      "training loss 0.0006524307621815624\n",
      "epochs 1963\n",
      "training loss 0.0007392911884104295\n",
      "epochs 1964\n",
      "training loss 0.000637792413088275\n",
      "epochs 1965\n",
      "training loss 0.0007147126871629655\n",
      "epochs 1966\n",
      "training loss 0.0006217062003566603\n",
      "epochs 1967\n",
      "training loss 0.0009751207991198871\n",
      "epochs 1968\n",
      "training loss 0.0007240923040540816\n",
      "epochs 1969\n",
      "training loss 0.001196438253175688\n",
      "testing loss 0.0029668987568481067\n",
      "epochs 1970\n",
      "training loss 0.0009982631463765544\n",
      "epochs 1971\n",
      "training loss 0.0007407881038569163\n",
      "epochs 1972\n",
      "training loss 0.0007176336300337127\n",
      "epochs 1973\n",
      "training loss 0.0006443174069536437\n",
      "epochs 1974\n",
      "training loss 0.0006618588577388392\n",
      "epochs 1975\n",
      "training loss 0.0007060868355960764\n",
      "epochs 1976\n",
      "training loss 0.0006442250658072939\n",
      "epochs 1977\n",
      "training loss 0.0007215111668039068\n",
      "epochs 1978\n",
      "training loss 0.0006472002467180186\n",
      "epochs 1979\n",
      "training loss 0.00063426473753323\n",
      "testing loss 0.0026660836000385172\n",
      "epochs 1980\n",
      "training loss 0.0006506329403742922\n",
      "epochs 1981\n",
      "training loss 0.000773722550136074\n",
      "epochs 1982\n",
      "training loss 0.0006651425590677792\n",
      "epochs 1983\n",
      "training loss 0.0007232403233866731\n",
      "epochs 1984\n",
      "training loss 0.0006203689903663443\n",
      "epochs 1985\n",
      "training loss 0.0006469459147128845\n",
      "epochs 1986\n",
      "training loss 0.0006428963060124203\n",
      "epochs 1987\n",
      "training loss 0.0007107422091236684\n",
      "epochs 1988\n",
      "training loss 0.0006680086681104087\n",
      "epochs 1989\n",
      "training loss 0.0006912322639732546\n",
      "testing loss 0.0028553694277730977\n",
      "epochs 1990\n",
      "training loss 0.0006420348318347476\n",
      "epochs 1991\n",
      "training loss 0.0007095529210766477\n",
      "epochs 1992\n",
      "training loss 0.0006778922229566495\n",
      "epochs 1993\n",
      "training loss 0.0007096660288233355\n",
      "epochs 1994\n",
      "training loss 0.0006247565242614722\n",
      "epochs 1995\n",
      "training loss 0.000680737421029788\n",
      "epochs 1996\n",
      "training loss 0.0006599338322001761\n",
      "epochs 1997\n",
      "training loss 0.000733870527007133\n",
      "epochs 1998\n",
      "training loss 0.0007209807739976657\n",
      "epochs 1999\n",
      "training loss 0.0006523173640158005\n",
      "testing loss 0.002694689586976583\n",
      "epochs 2000\n",
      "training loss 0.000695463493225762\n",
      "epochs 2001\n",
      "training loss 0.0006131579566748366\n",
      "epochs 2002\n",
      "training loss 0.0006451043063253844\n",
      "epochs 2003\n",
      "training loss 0.0007755084889112918\n",
      "epochs 2004\n",
      "training loss 0.0006855663383099332\n",
      "epochs 2005\n",
      "training loss 0.0006299253847198079\n",
      "epochs 2006\n",
      "training loss 0.0008752298235113373\n",
      "epochs 2007\n",
      "training loss 0.0006355934767165762\n",
      "epochs 2008\n",
      "training loss 0.0007547400560934878\n",
      "epochs 2009\n",
      "training loss 0.0006363980014211184\n",
      "testing loss 0.002890788707700525\n",
      "epochs 2010\n",
      "training loss 0.0006413474052862794\n",
      "epochs 2011\n",
      "training loss 0.000631592223986185\n",
      "epochs 2012\n",
      "training loss 0.0006567126653605851\n",
      "epochs 2013\n",
      "training loss 0.0006186162783462825\n",
      "epochs 2014\n",
      "training loss 0.0006576506494393\n",
      "epochs 2015\n",
      "training loss 0.0006573145472590379\n",
      "epochs 2016\n",
      "training loss 0.0006484103871730232\n",
      "epochs 2017\n",
      "training loss 0.0006530740210576985\n",
      "epochs 2018\n",
      "training loss 0.0006674081547996793\n",
      "epochs 2019\n",
      "training loss 0.0006283445662031896\n",
      "testing loss 0.002788561023524071\n",
      "epochs 2020\n",
      "training loss 0.0006405230180578346\n",
      "epochs 2021\n",
      "training loss 0.0007125303436015481\n",
      "epochs 2022\n",
      "training loss 0.0007008230336658702\n",
      "epochs 2023\n",
      "training loss 0.0006679311868137365\n",
      "epochs 2024\n",
      "training loss 0.000683390352475856\n",
      "epochs 2025\n",
      "training loss 0.0006294864799372999\n",
      "epochs 2026\n",
      "training loss 0.0007002833893800035\n",
      "epochs 2027\n",
      "training loss 0.0006768243187595454\n",
      "epochs 2028\n",
      "training loss 0.0006641028360477833\n",
      "epochs 2029\n",
      "training loss 0.0006874325228034092\n",
      "testing loss 0.002766760405077077\n",
      "epochs 2030\n",
      "training loss 0.0006493966076218758\n",
      "epochs 2031\n",
      "training loss 0.0007412830684553424\n",
      "epochs 2032\n",
      "training loss 0.0006565094615317213\n",
      "epochs 2033\n",
      "training loss 0.0006130203110375371\n",
      "epochs 2034\n",
      "training loss 0.0006423670824901639\n",
      "epochs 2035\n",
      "training loss 0.0006171737124012518\n",
      "epochs 2036\n",
      "training loss 0.0006813252854088779\n",
      "epochs 2037\n",
      "training loss 0.0006917480324143062\n",
      "epochs 2038\n",
      "training loss 0.0006836484175558997\n",
      "epochs 2039\n",
      "training loss 0.0006649248448121262\n",
      "testing loss 0.0027798870945818298\n",
      "epochs 2040\n",
      "training loss 0.0007447824928602402\n",
      "epochs 2041\n",
      "training loss 0.0008776589954203974\n",
      "epochs 2042\n",
      "training loss 0.0008451932029923181\n",
      "epochs 2043\n",
      "training loss 0.0008149221071536089\n",
      "epochs 2044\n",
      "training loss 0.0006889727079496354\n",
      "epochs 2045\n",
      "training loss 0.00064002628343344\n",
      "epochs 2046\n",
      "training loss 0.0006085098945779165\n",
      "epochs 2047\n",
      "training loss 0.0005908263352732132\n",
      "epochs 2048\n",
      "training loss 0.0006090424102830126\n",
      "epochs 2049\n",
      "training loss 0.0006464345919040505\n",
      "testing loss 0.0028741155145854975\n",
      "epochs 2050\n",
      "training loss 0.0006566987536411654\n",
      "epochs 2051\n",
      "training loss 0.0006703380124656183\n",
      "epochs 2052\n",
      "training loss 0.0006556912260922662\n",
      "epochs 2053\n",
      "training loss 0.0006278749965102975\n",
      "epochs 2054\n",
      "training loss 0.0006532679432415684\n",
      "epochs 2055\n",
      "training loss 0.0006411568075736934\n",
      "epochs 2056\n",
      "training loss 0.000625721894336955\n",
      "epochs 2057\n",
      "training loss 0.0006820141637873323\n",
      "epochs 2058\n",
      "training loss 0.0006505701507620037\n",
      "epochs 2059\n",
      "training loss 0.0006993259153771851\n",
      "testing loss 0.002858098373411501\n",
      "epochs 2060\n",
      "training loss 0.0008024946760986351\n",
      "epochs 2061\n",
      "training loss 0.0007087615908457583\n",
      "epochs 2062\n",
      "training loss 0.0006918319694536503\n",
      "epochs 2063\n",
      "training loss 0.0006778050362844428\n",
      "epochs 2064\n",
      "training loss 0.0006696829576919982\n",
      "epochs 2065\n",
      "training loss 0.0007000800218973819\n",
      "epochs 2066\n",
      "training loss 0.0006253919327995347\n",
      "epochs 2067\n",
      "training loss 0.0006457998939771431\n",
      "epochs 2068\n",
      "training loss 0.0006494766585479312\n",
      "epochs 2069\n",
      "training loss 0.0006676676808212429\n",
      "testing loss 0.0028469882404319412\n",
      "epochs 2070\n",
      "training loss 0.0007621851957779615\n",
      "epochs 2071\n",
      "training loss 0.001299170251651936\n",
      "epochs 2072\n",
      "training loss 0.002268561110216105\n",
      "epochs 2073\n",
      "training loss 0.0019789084804167907\n",
      "epochs 2074\n",
      "training loss 0.004318735250526626\n",
      "epochs 2075\n",
      "training loss 0.002980284980394931\n",
      "epochs 2076\n",
      "training loss 0.0022844228269688015\n",
      "epochs 2077\n",
      "training loss 0.001978870858098621\n",
      "epochs 2078\n",
      "training loss 0.0017525921395263639\n",
      "epochs 2079\n",
      "training loss 0.001586431612106363\n",
      "testing loss 0.002854685484041982\n",
      "epochs 2080\n",
      "training loss 0.0014455051359148713\n",
      "epochs 2081\n",
      "training loss 0.0014329942487856786\n",
      "epochs 2082\n",
      "training loss 0.0013106400868926186\n",
      "epochs 2083\n",
      "training loss 0.0014545320971808072\n",
      "epochs 2084\n",
      "training loss 0.0018193417791019571\n",
      "epochs 2085\n",
      "training loss 0.001037079651856308\n",
      "epochs 2086\n",
      "training loss 0.0007149471614211175\n",
      "epochs 2087\n",
      "training loss 0.0008250025492359666\n",
      "epochs 2088\n",
      "training loss 0.0008399920409975579\n",
      "epochs 2089\n",
      "training loss 0.0007152166704103736\n",
      "testing loss 0.0028256825518180083\n",
      "epochs 2090\n",
      "training loss 0.0007320204076511462\n",
      "epochs 2091\n",
      "training loss 0.0007975882275410755\n",
      "epochs 2092\n",
      "training loss 0.0007846685944515702\n",
      "epochs 2093\n",
      "training loss 0.0008095077190853904\n",
      "epochs 2094\n",
      "training loss 0.0007200063592655227\n",
      "epochs 2095\n",
      "training loss 0.0007061365519269542\n",
      "epochs 2096\n",
      "training loss 0.0007917051602333308\n",
      "epochs 2097\n",
      "training loss 0.0008215795458283128\n",
      "epochs 2098\n",
      "training loss 0.0007142367383350524\n",
      "epochs 2099\n",
      "training loss 0.0006086654200517264\n",
      "testing loss 0.0027619325498066155\n",
      "epochs 2100\n",
      "training loss 0.0006290628245888748\n",
      "epochs 2101\n",
      "training loss 0.0006738062335834994\n",
      "epochs 2102\n",
      "training loss 0.0006612703237062643\n",
      "epochs 2103\n",
      "training loss 0.0006850286916614507\n",
      "epochs 2104\n",
      "training loss 0.0007031822466895856\n",
      "epochs 2105\n",
      "training loss 0.0008865326980382238\n",
      "epochs 2106\n",
      "training loss 0.0007817008749137443\n",
      "epochs 2107\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss 0.0007178892066920216\n",
      "epochs 2108\n",
      "training loss 0.0006615048452028523\n",
      "epochs 2109\n",
      "training loss 0.0006604244011471269\n",
      "testing loss 0.0028501458830160506\n",
      "epochs 2110\n",
      "training loss 0.0006302479661804395\n",
      "epochs 2111\n",
      "training loss 0.0006324545773826143\n",
      "epochs 2112\n",
      "training loss 0.0006187266784636616\n",
      "epochs 2113\n",
      "training loss 0.0007783337704990184\n",
      "epochs 2114\n",
      "training loss 0.0006510283394418034\n",
      "epochs 2115\n",
      "training loss 0.0006542867181382473\n",
      "epochs 2116\n",
      "training loss 0.0006309800942663363\n",
      "epochs 2117\n",
      "training loss 0.0006197490439237885\n",
      "epochs 2118\n",
      "training loss 0.0006569625565988835\n",
      "epochs 2119\n",
      "training loss 0.0007231005960735733\n",
      "testing loss 0.0026884591417446575\n",
      "epochs 2120\n",
      "training loss 0.0007212931758407107\n",
      "epochs 2121\n",
      "training loss 0.0006724565750268206\n",
      "epochs 2122\n",
      "training loss 0.0005976901862750504\n",
      "epochs 2123\n",
      "training loss 0.0006517523038147957\n",
      "epochs 2124\n",
      "training loss 0.0006456531099140033\n",
      "epochs 2125\n",
      "training loss 0.0006322022857417645\n",
      "epochs 2126\n",
      "training loss 0.000707082933478063\n",
      "epochs 2127\n",
      "training loss 0.000672181505171333\n",
      "epochs 2128\n",
      "training loss 0.0007129319083465031\n",
      "epochs 2129\n",
      "training loss 0.0006207259897161049\n",
      "testing loss 0.0028149982615446687\n",
      "epochs 2130\n",
      "training loss 0.000601442036959187\n",
      "epochs 2131\n",
      "training loss 0.0006784541368920435\n",
      "epochs 2132\n",
      "training loss 0.0006881425701935229\n",
      "epochs 2133\n",
      "training loss 0.0006158742913020928\n",
      "epochs 2134\n",
      "training loss 0.0006597812363940169\n",
      "epochs 2135\n",
      "training loss 0.0006720622626202617\n",
      "epochs 2136\n",
      "training loss 0.0007512687989772442\n",
      "epochs 2137\n",
      "training loss 0.0006144132241670405\n",
      "epochs 2138\n",
      "training loss 0.0006527801701200328\n",
      "epochs 2139\n",
      "training loss 0.000659777898741971\n",
      "testing loss 0.002783510093379052\n",
      "epochs 2140\n",
      "training loss 0.0006434696681916396\n",
      "epochs 2141\n",
      "training loss 0.0006744566230750204\n",
      "epochs 2142\n",
      "training loss 0.001447943011638468\n",
      "epochs 2143\n",
      "training loss 0.001229988299961284\n",
      "epochs 2144\n",
      "training loss 0.0010256791127474815\n",
      "epochs 2145\n",
      "training loss 0.0007416082317530429\n",
      "epochs 2146\n",
      "training loss 0.0007540287297271407\n",
      "epochs 2147\n",
      "training loss 0.0006370295451651115\n",
      "epochs 2148\n",
      "training loss 0.0006450025095302883\n",
      "epochs 2149\n",
      "training loss 0.001049577285419572\n",
      "testing loss 0.0027754618307403852\n",
      "epochs 2150\n",
      "training loss 0.0012366284904145213\n",
      "epochs 2151\n",
      "training loss 0.0009611235123154591\n",
      "epochs 2152\n",
      "training loss 0.0010366223875106252\n",
      "epochs 2153\n",
      "training loss 0.0009239114426242012\n",
      "epochs 2154\n",
      "training loss 0.0010099376524914635\n",
      "epochs 2155\n",
      "training loss 0.0006744444417508211\n",
      "epochs 2156\n",
      "training loss 0.0006696139543676766\n",
      "epochs 2157\n",
      "training loss 0.0006585665498145412\n",
      "epochs 2158\n",
      "training loss 0.0006480911152336837\n",
      "epochs 2159\n",
      "training loss 0.0007597900987043693\n",
      "testing loss 0.002718057237393784\n",
      "epochs 2160\n",
      "training loss 0.0006406534696528604\n",
      "epochs 2161\n",
      "training loss 0.0006515649271177802\n",
      "epochs 2162\n",
      "training loss 0.0006819837163152926\n",
      "epochs 2163\n",
      "training loss 0.0006773514509636988\n",
      "epochs 2164\n",
      "training loss 0.0006110260015747037\n",
      "epochs 2165\n",
      "training loss 0.0006187082281389973\n",
      "epochs 2166\n",
      "training loss 0.0006122542976891469\n",
      "epochs 2167\n",
      "training loss 0.0006633775427620462\n",
      "epochs 2168\n",
      "training loss 0.0007346866895284752\n",
      "epochs 2169\n",
      "training loss 0.0006763719321804625\n",
      "testing loss 0.0028203386171053806\n",
      "epochs 2170\n",
      "training loss 0.0007368651321150736\n",
      "epochs 2171\n",
      "training loss 0.0006896758388011719\n",
      "epochs 2172\n",
      "training loss 0.0007052755202336582\n",
      "epochs 2173\n",
      "training loss 0.0006729427230223096\n",
      "epochs 2174\n",
      "training loss 0.0007582158888803404\n",
      "epochs 2175\n",
      "training loss 0.0007612534556651097\n",
      "epochs 2176\n",
      "training loss 0.0008570787438126365\n",
      "epochs 2177\n",
      "training loss 0.000683144521796906\n",
      "epochs 2178\n",
      "training loss 0.0014711227231711365\n",
      "epochs 2179\n",
      "training loss 0.0011993857398898112\n",
      "testing loss 0.0027496976231337123\n",
      "epochs 2180\n",
      "training loss 0.0010845863294297981\n",
      "epochs 2181\n",
      "training loss 0.002748759090475806\n",
      "epochs 2182\n",
      "training loss 0.0013158108574114627\n",
      "epochs 2183\n",
      "training loss 0.0011053553138934585\n",
      "epochs 2184\n",
      "training loss 0.0008473229466436436\n",
      "epochs 2185\n",
      "training loss 0.0008174529486501414\n",
      "epochs 2186\n",
      "training loss 0.0007603482681533214\n",
      "epochs 2187\n",
      "training loss 0.0008747078607313188\n",
      "epochs 2188\n",
      "training loss 0.0007969211086547314\n",
      "epochs 2189\n",
      "training loss 0.0007005300342585144\n",
      "testing loss 0.0027650872010949023\n",
      "epochs 2190\n",
      "training loss 0.0006812926782380031\n",
      "epochs 2191\n",
      "training loss 0.0006489243082727637\n",
      "epochs 2192\n",
      "training loss 0.0006437428217943147\n",
      "epochs 2193\n",
      "training loss 0.0006498863675000322\n",
      "epochs 2194\n",
      "training loss 0.0006565893273078766\n",
      "epochs 2195\n",
      "training loss 0.0006514511896137397\n",
      "epochs 2196\n",
      "training loss 0.0006963335845257102\n",
      "epochs 2197\n",
      "training loss 0.0013971569704452366\n",
      "epochs 2198\n",
      "training loss 0.000931155091271195\n",
      "epochs 2199\n",
      "training loss 0.0008156659301139674\n",
      "testing loss 0.002803309656702748\n",
      "epochs 2200\n",
      "training loss 0.0006851441943260776\n",
      "epochs 2201\n",
      "training loss 0.0006891376481145213\n",
      "epochs 2202\n",
      "training loss 0.0012119450139505988\n",
      "epochs 2203\n",
      "training loss 0.0007989232734094818\n",
      "epochs 2204\n",
      "training loss 0.0010006946324382124\n",
      "epochs 2205\n",
      "training loss 0.001037679403336679\n",
      "epochs 2206\n",
      "training loss 0.0008890820856632149\n",
      "epochs 2207\n",
      "training loss 0.0006752591555383294\n",
      "epochs 2208\n",
      "training loss 0.0006717398483518477\n",
      "epochs 2209\n",
      "training loss 0.0006585783883504637\n",
      "testing loss 0.0027352549418054044\n",
      "epochs 2210\n",
      "training loss 0.0006344147574292399\n",
      "epochs 2211\n",
      "training loss 0.0006372313672254899\n",
      "epochs 2212\n",
      "training loss 0.0006494785224315413\n",
      "epochs 2213\n",
      "training loss 0.0006362994673511857\n",
      "epochs 2214\n",
      "training loss 0.0006699403557724016\n",
      "epochs 2215\n",
      "training loss 0.0006228428105590157\n",
      "epochs 2216\n",
      "training loss 0.0007126582064595085\n",
      "epochs 2217\n",
      "training loss 0.0005969268853328896\n",
      "epochs 2218\n",
      "training loss 0.0006241821776827837\n",
      "epochs 2219\n",
      "training loss 0.0007087184629497885\n",
      "testing loss 0.0025679683160030197\n",
      "epochs 2220\n",
      "training loss 0.0006311020936313054\n",
      "epochs 2221\n",
      "training loss 0.0006982102406481535\n",
      "epochs 2222\n",
      "training loss 0.0006374848406233947\n",
      "epochs 2223\n",
      "training loss 0.0007063821799406289\n",
      "epochs 2224\n",
      "training loss 0.0007256637466257569\n",
      "epochs 2225\n",
      "training loss 0.0006298898104620718\n",
      "epochs 2226\n",
      "training loss 0.0006456679406598505\n",
      "epochs 2227\n",
      "training loss 0.0005998667733818802\n",
      "epochs 2228\n",
      "training loss 0.0006659010691125241\n",
      "epochs 2229\n",
      "training loss 0.0006842320388795859\n",
      "testing loss 0.0028866060765077037\n",
      "epochs 2230\n",
      "training loss 0.0007357277472554438\n",
      "epochs 2231\n",
      "training loss 0.0006678050111817893\n",
      "epochs 2232\n",
      "training loss 0.0006081580972061195\n",
      "epochs 2233\n",
      "training loss 0.0005932029525644647\n",
      "epochs 2234\n",
      "training loss 0.0008344843411835131\n",
      "epochs 2235\n",
      "training loss 0.0007047436936435751\n",
      "epochs 2236\n",
      "training loss 0.0005877046551453488\n",
      "epochs 2237\n",
      "training loss 0.0006903502918527911\n",
      "epochs 2238\n",
      "training loss 0.0006380671310439525\n",
      "epochs 2239\n",
      "training loss 0.0006951510698865748\n",
      "testing loss 0.0027914948886134895\n",
      "epochs 2240\n",
      "training loss 0.0006136890071922613\n",
      "epochs 2241\n",
      "training loss 0.0006217987295721395\n",
      "epochs 2242\n",
      "training loss 0.0006159269381852362\n",
      "epochs 2243\n",
      "training loss 0.0007051479299255508\n",
      "epochs 2244\n",
      "training loss 0.000686541113876497\n",
      "epochs 2245\n",
      "training loss 0.0007019924022197882\n",
      "epochs 2246\n",
      "training loss 0.0006124742219782234\n",
      "epochs 2247\n",
      "training loss 0.0007067703624966478\n",
      "epochs 2248\n",
      "training loss 0.0006077262864159392\n",
      "epochs 2249\n",
      "training loss 0.0006662397062452652\n",
      "testing loss 0.00274570977252558\n",
      "epochs 2250\n",
      "training loss 0.0006223316020424277\n",
      "epochs 2251\n",
      "training loss 0.0006353128764256099\n",
      "epochs 2252\n",
      "training loss 0.0006012611152529207\n",
      "epochs 2253\n",
      "training loss 0.0006186095490806812\n",
      "epochs 2254\n",
      "training loss 0.0008147122545591003\n",
      "epochs 2255\n",
      "training loss 0.0007575537283490143\n",
      "epochs 2256\n",
      "training loss 0.000683488960145749\n",
      "epochs 2257\n",
      "training loss 0.0006600088087981991\n",
      "epochs 2258\n",
      "training loss 0.0007016593266609705\n",
      "epochs 2259\n",
      "training loss 0.0006314483201407225\n",
      "testing loss 0.0027965824144515904\n",
      "epochs 2260\n",
      "training loss 0.0006225813129962079\n",
      "epochs 2261\n",
      "training loss 0.0005694509385327744\n",
      "epochs 2262\n",
      "training loss 0.0006072469374821677\n",
      "epochs 2263\n",
      "training loss 0.0006102089455923049\n",
      "epochs 2264\n",
      "training loss 0.0006069769524816299\n",
      "epochs 2265\n",
      "training loss 0.000643827913256113\n",
      "epochs 2266\n",
      "training loss 0.0006926535485605327\n",
      "epochs 2267\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss 0.0006395481563297789\n",
      "epochs 2268\n",
      "training loss 0.0005817448105174753\n",
      "epochs 2269\n",
      "training loss 0.0006350281529445597\n",
      "testing loss 0.0027067925399565634\n",
      "epochs 2270\n",
      "training loss 0.0006353202247889543\n",
      "epochs 2271\n",
      "training loss 0.0005942338144853937\n",
      "epochs 2272\n",
      "training loss 0.0005901470490395853\n",
      "epochs 2273\n",
      "training loss 0.0006416961340174238\n",
      "epochs 2274\n",
      "training loss 0.000584642333120085\n",
      "epochs 2275\n",
      "training loss 0.000667179823838214\n",
      "epochs 2276\n",
      "training loss 0.0006564515848052448\n",
      "epochs 2277\n",
      "training loss 0.0006504858750920731\n",
      "epochs 2278\n",
      "training loss 0.0006416006020651026\n",
      "epochs 2279\n",
      "training loss 0.0005983270236431114\n",
      "testing loss 0.0027794436789414984\n",
      "epochs 2280\n",
      "training loss 0.0005789264161875726\n",
      "epochs 2281\n",
      "training loss 0.0006252348171419671\n",
      "epochs 2282\n",
      "training loss 0.0011949632712250637\n",
      "epochs 2283\n",
      "training loss 0.0007145558206129559\n",
      "epochs 2284\n",
      "training loss 0.0006379377546983468\n",
      "epochs 2285\n",
      "training loss 0.000595977990856213\n",
      "epochs 2286\n",
      "training loss 0.0006585347647162998\n",
      "epochs 2287\n",
      "training loss 0.0006010671159306309\n",
      "epochs 2288\n",
      "training loss 0.0006996097992702265\n",
      "epochs 2289\n",
      "training loss 0.0005792748853727032\n",
      "testing loss 0.0028035090633516087\n",
      "epochs 2290\n",
      "training loss 0.0005546275212777648\n",
      "epochs 2291\n",
      "training loss 0.0005857131438963908\n",
      "epochs 2292\n",
      "training loss 0.0006631895790788088\n",
      "epochs 2293\n",
      "training loss 0.0007641210474107856\n",
      "epochs 2294\n",
      "training loss 0.0005909254056409336\n",
      "epochs 2295\n",
      "training loss 0.0006550984958888776\n",
      "epochs 2296\n",
      "training loss 0.0006176809625315132\n",
      "epochs 2297\n",
      "training loss 0.0006626986743320391\n",
      "epochs 2298\n",
      "training loss 0.0006699782291442824\n",
      "epochs 2299\n",
      "training loss 0.0005855128061313658\n",
      "testing loss 0.0027325815844831737\n",
      "epochs 2300\n",
      "training loss 0.0006209118248389518\n",
      "epochs 2301\n",
      "training loss 0.0007243086047835738\n",
      "epochs 2302\n",
      "training loss 0.0006280426647390967\n",
      "epochs 2303\n",
      "training loss 0.0006375680756323481\n",
      "epochs 2304\n",
      "training loss 0.0007061319162794545\n",
      "epochs 2305\n",
      "training loss 0.0005989169476710905\n",
      "epochs 2306\n",
      "training loss 0.0006324693523977223\n",
      "epochs 2307\n",
      "training loss 0.0009917724132927073\n",
      "epochs 2308\n",
      "training loss 0.0006806768858585914\n",
      "epochs 2309\n",
      "training loss 0.0006880139224167551\n",
      "testing loss 0.0028738389629705523\n",
      "epochs 2310\n",
      "training loss 0.0006780139478256128\n",
      "epochs 2311\n",
      "training loss 0.000701365865484633\n",
      "epochs 2312\n",
      "training loss 0.0006713798052191134\n",
      "epochs 2313\n",
      "training loss 0.0010649308809617076\n",
      "epochs 2314\n",
      "training loss 0.0014552475841564485\n",
      "epochs 2315\n",
      "training loss 0.00182444389465783\n",
      "epochs 2316\n",
      "training loss 0.0012496165527132734\n",
      "epochs 2317\n",
      "training loss 0.0011890165174824375\n",
      "epochs 2318\n",
      "training loss 0.000897814698130215\n",
      "epochs 2319\n",
      "training loss 0.0009132961015957252\n",
      "testing loss 0.0027818558783045846\n",
      "epochs 2320\n",
      "training loss 0.0008363407066284387\n",
      "epochs 2321\n",
      "training loss 0.0007866393234425063\n",
      "epochs 2322\n",
      "training loss 0.0007463305617829835\n",
      "epochs 2323\n",
      "training loss 0.0007514594157975122\n",
      "epochs 2324\n",
      "training loss 0.0006918947810043884\n",
      "epochs 2325\n",
      "training loss 0.0006937632036620417\n",
      "epochs 2326\n",
      "training loss 0.0006666024867303692\n",
      "epochs 2327\n",
      "training loss 0.0007090788099477436\n",
      "epochs 2328\n",
      "training loss 0.0009833003155813526\n",
      "epochs 2329\n",
      "training loss 0.0007050276751096408\n",
      "testing loss 0.0027619074771662922\n",
      "epochs 2330\n",
      "training loss 0.0007890845454506021\n",
      "epochs 2331\n",
      "training loss 0.0007020822566251714\n",
      "epochs 2332\n",
      "training loss 0.0007397878819886924\n",
      "epochs 2333\n",
      "training loss 0.0006703407277910769\n",
      "epochs 2334\n",
      "training loss 0.0007122166844553351\n",
      "epochs 2335\n",
      "training loss 0.0007275824423909109\n",
      "epochs 2336\n",
      "training loss 0.0010853800641324677\n",
      "epochs 2337\n",
      "training loss 0.001934704422281268\n",
      "epochs 2338\n",
      "training loss 0.001036708220987408\n",
      "epochs 2339\n",
      "training loss 0.0008086815970386506\n",
      "testing loss 0.00300650423184592\n",
      "epochs 2340\n",
      "training loss 0.0007648745369120844\n",
      "epochs 2341\n",
      "training loss 0.0006937372340222023\n",
      "epochs 2342\n",
      "training loss 0.0006778505425560528\n",
      "epochs 2343\n",
      "training loss 0.0006895417889465484\n",
      "epochs 2344\n",
      "training loss 0.0010307427273856583\n",
      "epochs 2345\n",
      "training loss 0.0007186207762320659\n",
      "epochs 2346\n",
      "training loss 0.0006726524528288665\n",
      "epochs 2347\n",
      "training loss 0.0006915836238145183\n",
      "epochs 2348\n",
      "training loss 0.0006989322020318415\n",
      "epochs 2349\n",
      "training loss 0.0007428332983153819\n",
      "testing loss 0.0028240359772214708\n",
      "epochs 2350\n",
      "training loss 0.0007884878964031732\n",
      "epochs 2351\n",
      "training loss 0.0007376539122665692\n",
      "epochs 2352\n",
      "training loss 0.0007049344514714593\n",
      "epochs 2353\n",
      "training loss 0.0007012574199238923\n",
      "epochs 2354\n",
      "training loss 0.0006984914267311116\n",
      "epochs 2355\n",
      "training loss 0.0006651794344171213\n",
      "epochs 2356\n",
      "training loss 0.0007067702545736291\n",
      "epochs 2357\n",
      "training loss 0.0007105230205688104\n",
      "epochs 2358\n",
      "training loss 0.0007214353450448012\n",
      "epochs 2359\n",
      "training loss 0.0007947848644992195\n",
      "testing loss 0.002805024649244436\n",
      "epochs 2360\n",
      "training loss 0.0007330416774272489\n",
      "epochs 2361\n",
      "training loss 0.0007580741005029677\n",
      "epochs 2362\n",
      "training loss 0.0007729151900638302\n",
      "epochs 2363\n",
      "training loss 0.0006393824259383961\n",
      "epochs 2364\n",
      "training loss 0.0006851809103562748\n",
      "epochs 2365\n",
      "training loss 0.0006570235216044637\n",
      "epochs 2366\n",
      "training loss 0.000813189547191909\n",
      "epochs 2367\n",
      "training loss 0.0006636411262468058\n",
      "epochs 2368\n",
      "training loss 0.0007244185620627301\n",
      "epochs 2369\n",
      "training loss 0.0006450320934412554\n",
      "testing loss 0.0027870445624522283\n",
      "epochs 2370\n",
      "training loss 0.0005981965624942447\n",
      "epochs 2371\n",
      "training loss 0.000574777016910161\n",
      "epochs 2372\n",
      "training loss 0.0005903274828807301\n",
      "epochs 2373\n",
      "training loss 0.0007086907823762564\n",
      "epochs 2374\n",
      "training loss 0.0006401296546661485\n",
      "epochs 2375\n",
      "training loss 0.0006199033436751825\n",
      "epochs 2376\n",
      "training loss 0.0006085428712524384\n",
      "epochs 2377\n",
      "training loss 0.0006705550339793373\n",
      "epochs 2378\n",
      "training loss 0.0006193500115659292\n",
      "epochs 2379\n",
      "training loss 0.0006107875529186953\n",
      "testing loss 0.0028718068918332142\n",
      "epochs 2380\n",
      "training loss 0.0006735544042424001\n",
      "epochs 2381\n",
      "training loss 0.0006731005883910113\n",
      "epochs 2382\n",
      "training loss 0.001007264832779199\n",
      "epochs 2383\n",
      "training loss 0.0015817358690005442\n",
      "epochs 2384\n",
      "training loss 0.0012965096423677013\n",
      "epochs 2385\n",
      "training loss 0.0009262698336637446\n",
      "epochs 2386\n",
      "training loss 0.0008760612328129178\n",
      "epochs 2387\n",
      "training loss 0.0011691635207939713\n",
      "epochs 2388\n",
      "training loss 0.0015011109053624347\n",
      "epochs 2389\n",
      "training loss 0.0009197888119708136\n",
      "testing loss 0.0026624262690418633\n",
      "epochs 2390\n",
      "training loss 0.000776423321644801\n",
      "epochs 2391\n",
      "training loss 0.0007902152538561407\n",
      "epochs 2392\n",
      "training loss 0.0006764748112134364\n",
      "epochs 2393\n",
      "training loss 0.0006237015998419827\n",
      "epochs 2394\n",
      "training loss 0.0005711942068463911\n",
      "epochs 2395\n",
      "training loss 0.0006151289031925784\n",
      "epochs 2396\n",
      "training loss 0.0006160871058526962\n",
      "epochs 2397\n",
      "training loss 0.0005970264687330256\n",
      "epochs 2398\n",
      "training loss 0.0006521135617449517\n",
      "epochs 2399\n",
      "training loss 0.0005760736688108136\n",
      "testing loss 0.002780778253870415\n",
      "epochs 2400\n",
      "training loss 0.0006118837082659469\n",
      "epochs 2401\n",
      "training loss 0.0006401324075877406\n",
      "epochs 2402\n",
      "training loss 0.0006945312847093166\n",
      "epochs 2403\n",
      "training loss 0.0006293754491779535\n",
      "epochs 2404\n",
      "training loss 0.000589984718754061\n",
      "epochs 2405\n",
      "training loss 0.0007094412743599411\n",
      "epochs 2406\n",
      "training loss 0.0005779416120956485\n",
      "epochs 2407\n",
      "training loss 0.0005713326450101861\n",
      "epochs 2408\n",
      "training loss 0.0005805351181199214\n",
      "epochs 2409\n",
      "training loss 0.0006289570622420714\n",
      "testing loss 0.0027699783648337827\n",
      "epochs 2410\n",
      "training loss 0.0006786762348568706\n",
      "epochs 2411\n",
      "training loss 0.0006299473667810289\n",
      "epochs 2412\n",
      "training loss 0.0006424241865939803\n",
      "epochs 2413\n",
      "training loss 0.0005575960449305416\n",
      "epochs 2414\n",
      "training loss 0.000595745118193351\n",
      "epochs 2415\n",
      "training loss 0.0005975152245732619\n",
      "epochs 2416\n",
      "training loss 0.0006809376160179669\n",
      "epochs 2417\n",
      "training loss 0.0005947060608460729\n",
      "epochs 2418\n",
      "training loss 0.0005924031552419881\n",
      "epochs 2419\n",
      "training loss 0.0006223791316937157\n",
      "testing loss 0.0028111709790396774\n",
      "epochs 2420\n",
      "training loss 0.0005787957966926374\n",
      "epochs 2421\n",
      "training loss 0.0006372195364741784\n",
      "epochs 2422\n",
      "training loss 0.0006188804213499712\n",
      "epochs 2423\n",
      "training loss 0.0005894260009323278\n",
      "epochs 2424\n",
      "training loss 0.0005634444546185174\n",
      "epochs 2425\n",
      "training loss 0.0006375902716819152\n",
      "epochs 2426\n",
      "training loss 0.0006117139215613673\n",
      "epochs 2427\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss 0.0006617132423404537\n",
      "epochs 2428\n",
      "training loss 0.0005745273423140534\n",
      "epochs 2429\n",
      "training loss 0.0005917076208440468\n",
      "testing loss 0.0028474660122152816\n",
      "epochs 2430\n",
      "training loss 0.0006199946283259483\n",
      "epochs 2431\n",
      "training loss 0.0005638350889732138\n",
      "epochs 2432\n",
      "training loss 0.0005980109598481954\n",
      "epochs 2433\n",
      "training loss 0.0006113787639729034\n",
      "epochs 2434\n",
      "training loss 0.0005821349044609249\n",
      "epochs 2435\n",
      "training loss 0.0006479676114041415\n",
      "epochs 2436\n",
      "training loss 0.0006165951975171191\n",
      "epochs 2437\n",
      "training loss 0.0006802969325212111\n",
      "epochs 2438\n",
      "training loss 0.0006303371803900143\n",
      "epochs 2439\n",
      "training loss 0.0006549588984372462\n",
      "testing loss 0.0028616869025401346\n",
      "epochs 2440\n",
      "training loss 0.0006214183564849855\n",
      "epochs 2441\n",
      "training loss 0.0006072302916834533\n",
      "epochs 2442\n",
      "training loss 0.0006628929799080099\n",
      "epochs 2443\n",
      "training loss 0.0007023367287533069\n",
      "epochs 2444\n",
      "training loss 0.0007926908602632333\n",
      "epochs 2445\n",
      "training loss 0.0007950577578481887\n",
      "epochs 2446\n",
      "training loss 0.0007570895713493568\n",
      "epochs 2447\n",
      "training loss 0.0007351024271311709\n",
      "epochs 2448\n",
      "training loss 0.000756245780623685\n",
      "epochs 2449\n",
      "training loss 0.0007676325197399546\n",
      "testing loss 0.0028453453106257456\n",
      "epochs 2450\n",
      "training loss 0.0008089849473250391\n",
      "epochs 2451\n",
      "training loss 0.0007852403213316716\n",
      "epochs 2452\n",
      "training loss 0.0007874054804523575\n",
      "epochs 2453\n",
      "training loss 0.0007669753340174837\n",
      "epochs 2454\n",
      "training loss 0.0007259724969553866\n",
      "epochs 2455\n",
      "training loss 0.0007622925430008332\n",
      "epochs 2456\n",
      "training loss 0.0007793283384395225\n",
      "epochs 2457\n",
      "training loss 0.0008047395340686432\n",
      "epochs 2458\n",
      "training loss 0.0007384331800655029\n",
      "epochs 2459\n",
      "training loss 0.0008502158546525883\n",
      "testing loss 0.0027864765444380753\n",
      "epochs 2460\n",
      "training loss 0.0008107205064851213\n",
      "epochs 2461\n",
      "training loss 0.0007254780752451292\n",
      "epochs 2462\n",
      "training loss 0.0007764909894659968\n",
      "epochs 2463\n",
      "training loss 0.0007894451331522734\n",
      "epochs 2464\n",
      "training loss 0.0009087660071428718\n",
      "epochs 2465\n",
      "training loss 0.0009567409044869052\n",
      "epochs 2466\n",
      "training loss 0.0008613195717561209\n",
      "epochs 2467\n",
      "training loss 0.0007984394237319839\n",
      "epochs 2468\n",
      "training loss 0.0007045787676325277\n",
      "epochs 2469\n",
      "training loss 0.0008274011619461242\n",
      "testing loss 0.002780332989208004\n",
      "epochs 2470\n",
      "training loss 0.0007946497944182232\n",
      "epochs 2471\n",
      "training loss 0.0007710262457557068\n",
      "epochs 2472\n",
      "training loss 0.000819622957937442\n",
      "epochs 2473\n",
      "training loss 0.0007661350081514816\n",
      "epochs 2474\n",
      "training loss 0.0009812145939947453\n",
      "epochs 2475\n",
      "training loss 0.0007426202438572156\n",
      "epochs 2476\n",
      "training loss 0.0006961069985556113\n",
      "epochs 2477\n",
      "training loss 0.0011393529894453188\n",
      "epochs 2478\n",
      "training loss 0.0026063372771677456\n",
      "epochs 2479\n",
      "training loss 0.0017808277432744513\n",
      "testing loss 0.0031359594167500787\n",
      "epochs 2480\n",
      "training loss 0.0016216074229227974\n",
      "epochs 2481\n",
      "training loss 0.0017828643767836881\n",
      "epochs 2482\n",
      "training loss 0.002139991832582852\n",
      "epochs 2483\n",
      "training loss 0.0017030195031940687\n",
      "epochs 2484\n",
      "training loss 0.0017249096030338262\n",
      "epochs 2485\n",
      "training loss 0.0013757233626823476\n",
      "epochs 2486\n",
      "training loss 0.001492522796598266\n",
      "epochs 2487\n",
      "training loss 0.0011747534559136625\n",
      "epochs 2488\n",
      "training loss 0.0012253351440748037\n",
      "epochs 2489\n",
      "training loss 0.001211269957680074\n",
      "testing loss 0.002774758529453043\n",
      "epochs 2490\n",
      "training loss 0.0011512640429134156\n",
      "epochs 2491\n",
      "training loss 0.0010992772660485687\n",
      "epochs 2492\n",
      "training loss 0.0009628427546651111\n",
      "epochs 2493\n",
      "training loss 0.001141586230917746\n",
      "epochs 2494\n",
      "training loss 0.0009149111568323396\n",
      "epochs 2495\n",
      "training loss 0.0011064523442133151\n",
      "epochs 2496\n",
      "training loss 0.0011211455266039512\n",
      "epochs 2497\n",
      "training loss 0.0014205683436029587\n",
      "epochs 2498\n",
      "training loss 0.005250190428916739\n",
      "epochs 2499\n",
      "training loss 0.0025481461405069046\n",
      "testing loss 0.003049001139786808\n",
      "epochs 2500\n",
      "training loss 0.0015812894796682266\n",
      "epochs 2501\n",
      "training loss 0.0013419896658611878\n",
      "epochs 2502\n",
      "training loss 0.0012979733571551718\n",
      "epochs 2503\n",
      "training loss 0.0010693532347149785\n",
      "epochs 2504\n",
      "training loss 0.0010712506882223586\n",
      "epochs 2505\n",
      "training loss 0.001036214638069006\n",
      "epochs 2506\n",
      "training loss 0.0011172101352226532\n",
      "epochs 2507\n",
      "training loss 0.000938366275878006\n",
      "epochs 2508\n",
      "training loss 0.0008302147246863252\n",
      "epochs 2509\n",
      "training loss 0.0009826064804401872\n",
      "testing loss 0.002958744198351385\n",
      "epochs 2510\n",
      "training loss 0.000792642701650746\n",
      "epochs 2511\n",
      "training loss 0.001053503875147925\n",
      "epochs 2512\n",
      "training loss 0.001216512176598844\n",
      "epochs 2513\n",
      "training loss 0.0012536614309355198\n",
      "epochs 2514\n",
      "training loss 0.0012144047165739613\n",
      "epochs 2515\n",
      "training loss 0.001173578224928291\n",
      "epochs 2516\n",
      "training loss 0.0010114575806639999\n",
      "epochs 2517\n",
      "training loss 0.0010231540036440112\n",
      "epochs 2518\n",
      "training loss 0.001388051477402426\n",
      "epochs 2519\n",
      "training loss 0.0010675622746886227\n",
      "testing loss 0.0027775521037591527\n",
      "epochs 2520\n",
      "training loss 0.0008451291406845623\n",
      "epochs 2521\n",
      "training loss 0.0008213441992514005\n",
      "epochs 2522\n",
      "training loss 0.0007169602105661513\n",
      "epochs 2523\n",
      "training loss 0.0007945258381966173\n",
      "epochs 2524\n",
      "training loss 0.0008508099793629172\n",
      "epochs 2525\n",
      "training loss 0.0008673287548958452\n",
      "epochs 2526\n",
      "training loss 0.0007512127562343938\n",
      "epochs 2527\n",
      "training loss 0.0008589794314721186\n",
      "epochs 2528\n",
      "training loss 0.0007991217464947434\n",
      "epochs 2529\n",
      "training loss 0.0007221922644634807\n",
      "testing loss 0.002691137364154008\n",
      "epochs 2530\n",
      "training loss 0.0006490799750195743\n",
      "epochs 2531\n",
      "training loss 0.0007852050398814698\n",
      "epochs 2532\n",
      "training loss 0.00072480525643109\n",
      "epochs 2533\n",
      "training loss 0.0013304431721041586\n",
      "epochs 2534\n",
      "training loss 0.0008818204148451722\n",
      "epochs 2535\n",
      "training loss 0.0011042985006442187\n",
      "epochs 2536\n",
      "training loss 0.0007304312894120812\n",
      "epochs 2537\n",
      "training loss 0.0007304259111303666\n",
      "epochs 2538\n",
      "training loss 0.0007482635331981303\n",
      "epochs 2539\n",
      "training loss 0.0007215070801484186\n",
      "testing loss 0.0028471946274590885\n",
      "epochs 2540\n",
      "training loss 0.0007908194001033721\n",
      "epochs 2541\n",
      "training loss 0.0006896697251390847\n",
      "epochs 2542\n",
      "training loss 0.000988084968235372\n",
      "epochs 2543\n",
      "training loss 0.0013474390955605065\n",
      "epochs 2544\n",
      "training loss 0.0009269406965057617\n",
      "epochs 2545\n",
      "training loss 0.0008346581173244026\n",
      "epochs 2546\n",
      "training loss 0.0007203794864719694\n",
      "epochs 2547\n",
      "training loss 0.0007385752911503939\n",
      "epochs 2548\n",
      "training loss 0.0006844987233819038\n",
      "epochs 2549\n",
      "training loss 0.000655012426839145\n",
      "testing loss 0.0026492387905109223\n",
      "epochs 2550\n",
      "training loss 0.0006838384013457399\n",
      "epochs 2551\n",
      "training loss 0.0007255537097312589\n",
      "epochs 2552\n",
      "training loss 0.000657480757200162\n",
      "epochs 2553\n",
      "training loss 0.0006753583247617657\n",
      "epochs 2554\n",
      "training loss 0.0007006103450844296\n",
      "epochs 2555\n",
      "training loss 0.0006628498185735966\n",
      "epochs 2556\n",
      "training loss 0.0006724442510142368\n",
      "epochs 2557\n",
      "training loss 0.0006270946904388469\n",
      "epochs 2558\n",
      "training loss 0.000759478069018816\n",
      "epochs 2559\n",
      "training loss 0.0007769796497678231\n",
      "testing loss 0.0028108751540838455\n",
      "epochs 2560\n",
      "training loss 0.0007711903582748852\n",
      "epochs 2561\n",
      "training loss 0.0006720293357495592\n",
      "epochs 2562\n",
      "training loss 0.0010463695293419788\n",
      "epochs 2563\n",
      "training loss 0.0007002678077730228\n",
      "epochs 2564\n",
      "training loss 0.0006549716752842012\n",
      "epochs 2565\n",
      "training loss 0.0006941633347116162\n",
      "epochs 2566\n",
      "training loss 0.0005943383679174645\n",
      "epochs 2567\n",
      "training loss 0.0007186684882909478\n",
      "epochs 2568\n",
      "training loss 0.0008980434703375963\n",
      "epochs 2569\n",
      "training loss 0.0008223767438868066\n",
      "testing loss 0.002718718846308741\n",
      "epochs 2570\n",
      "training loss 0.0006723695247622326\n",
      "epochs 2571\n",
      "training loss 0.0006165539928624197\n",
      "epochs 2572\n",
      "training loss 0.0006550730924910405\n",
      "epochs 2573\n",
      "training loss 0.0006312113731185195\n",
      "epochs 2574\n",
      "training loss 0.0005950993472762621\n",
      "epochs 2575\n",
      "training loss 0.0006436897551171668\n",
      "epochs 2576\n",
      "training loss 0.000645745049445185\n",
      "epochs 2577\n",
      "training loss 0.000661315145816705\n",
      "epochs 2578\n",
      "training loss 0.0006346023029550106\n",
      "epochs 2579\n",
      "training loss 0.0007752707572356659\n",
      "testing loss 0.002708627808102611\n",
      "epochs 2580\n",
      "training loss 0.0006826175132619166\n",
      "epochs 2581\n",
      "training loss 0.0006146146786699247\n",
      "epochs 2582\n",
      "training loss 0.0011403659685220468\n",
      "epochs 2583\n",
      "training loss 0.0009651818902919629\n",
      "epochs 2584\n",
      "training loss 0.0008365379917643409\n",
      "epochs 2585\n",
      "training loss 0.0008501919314808759\n",
      "epochs 2586\n",
      "training loss 0.0008199658173371366\n",
      "epochs 2587\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss 0.0008141536044988691\n",
      "epochs 2588\n",
      "training loss 0.000657595713526622\n",
      "epochs 2589\n",
      "training loss 0.0006899808485366653\n",
      "testing loss 0.0027425258584710247\n",
      "epochs 2590\n",
      "training loss 0.0007655908605565054\n",
      "epochs 2591\n",
      "training loss 0.0007890535097096489\n",
      "epochs 2592\n",
      "training loss 0.0008411475311820381\n",
      "epochs 2593\n",
      "training loss 0.0009673101919325278\n",
      "epochs 2594\n",
      "training loss 0.0007637150261528495\n",
      "epochs 2595\n",
      "training loss 0.0007754878948993222\n",
      "epochs 2596\n",
      "training loss 0.0006294016880945707\n",
      "epochs 2597\n",
      "training loss 0.000704157714378853\n",
      "epochs 2598\n",
      "training loss 0.0005920377754929015\n",
      "epochs 2599\n",
      "training loss 0.000684194535188275\n",
      "testing loss 0.002701906856819855\n",
      "epochs 2600\n",
      "training loss 0.0006157937748032115\n",
      "epochs 2601\n",
      "training loss 0.0006598582346909495\n",
      "epochs 2602\n",
      "training loss 0.0006452596856608115\n",
      "epochs 2603\n",
      "training loss 0.0007596192806272691\n",
      "epochs 2604\n",
      "training loss 0.0006384455518744671\n",
      "epochs 2605\n",
      "training loss 0.0006734541613618506\n",
      "epochs 2606\n",
      "training loss 0.0006969446555384376\n",
      "epochs 2607\n",
      "training loss 0.0007887388451985936\n",
      "epochs 2608\n",
      "training loss 0.00072490144520998\n",
      "epochs 2609\n",
      "training loss 0.0006335691525353158\n",
      "testing loss 0.002740057694712482\n",
      "epochs 2610\n",
      "training loss 0.0007316904370906539\n",
      "epochs 2611\n",
      "training loss 0.0006303744705352865\n",
      "epochs 2612\n",
      "training loss 0.0006288453060100393\n",
      "epochs 2613\n",
      "training loss 0.0005943149437570214\n",
      "epochs 2614\n",
      "training loss 0.0006616876827196238\n",
      "epochs 2615\n",
      "training loss 0.0005749031173498412\n",
      "epochs 2616\n",
      "training loss 0.0006377795969644182\n",
      "epochs 2617\n",
      "training loss 0.0005597669511288971\n",
      "epochs 2618\n",
      "training loss 0.0007801896380826741\n",
      "epochs 2619\n",
      "training loss 0.0006027381774639614\n",
      "testing loss 0.0028085555565041482\n",
      "epochs 2620\n",
      "training loss 0.0009185694862938399\n",
      "epochs 2621\n",
      "training loss 0.0006660889177958235\n",
      "epochs 2622\n",
      "training loss 0.000608490153290487\n",
      "epochs 2623\n",
      "training loss 0.0006471806752324207\n",
      "epochs 2624\n",
      "training loss 0.0006939220139763876\n",
      "epochs 2625\n",
      "training loss 0.0006310642326440334\n",
      "epochs 2626\n",
      "training loss 0.0006889276987431418\n",
      "epochs 2627\n",
      "training loss 0.000713669152691179\n",
      "epochs 2628\n",
      "training loss 0.0005930582835713379\n",
      "epochs 2629\n",
      "training loss 0.0007863993887219148\n",
      "testing loss 0.0026995563604670795\n",
      "epochs 2630\n",
      "training loss 0.0005947167973287437\n",
      "epochs 2631\n",
      "training loss 0.0006516620021923459\n",
      "epochs 2632\n",
      "training loss 0.0006474170254934069\n",
      "epochs 2633\n",
      "training loss 0.0006094958665384415\n",
      "epochs 2634\n",
      "training loss 0.0009392944104774178\n",
      "epochs 2635\n",
      "training loss 0.0006408166287340915\n",
      "epochs 2636\n",
      "training loss 0.000696754488898696\n",
      "epochs 2637\n",
      "training loss 0.0007365055390744043\n",
      "epochs 2638\n",
      "training loss 0.0006199704671928257\n",
      "epochs 2639\n",
      "training loss 0.0006239829447133166\n",
      "testing loss 0.002719476522633423\n",
      "epochs 2640\n",
      "training loss 0.0006870003078326775\n",
      "epochs 2641\n",
      "training loss 0.000691362574560664\n",
      "epochs 2642\n",
      "training loss 0.0006386760179424732\n",
      "epochs 2643\n",
      "training loss 0.0009790919778626525\n",
      "epochs 2644\n",
      "training loss 0.0006645454182629233\n",
      "epochs 2645\n",
      "training loss 0.0006553686003124279\n",
      "epochs 2646\n",
      "training loss 0.0006258967657195614\n",
      "epochs 2647\n",
      "training loss 0.0006307356892327713\n",
      "epochs 2648\n",
      "training loss 0.000692580792611312\n",
      "epochs 2649\n",
      "training loss 0.0006581967990062735\n",
      "testing loss 0.0028084321302553335\n",
      "epochs 2650\n",
      "training loss 0.0006293375458176273\n",
      "epochs 2651\n",
      "training loss 0.0007236851096198551\n",
      "epochs 2652\n",
      "training loss 0.0006342156185827991\n",
      "epochs 2653\n",
      "training loss 0.0006517978999190496\n",
      "epochs 2654\n",
      "training loss 0.0006135082607282083\n",
      "epochs 2655\n",
      "training loss 0.0006271240007384231\n",
      "epochs 2656\n",
      "training loss 0.0007270756700411609\n",
      "epochs 2657\n",
      "training loss 0.0006470870292790823\n",
      "epochs 2658\n",
      "training loss 0.0006347415514260609\n",
      "epochs 2659\n",
      "training loss 0.0006663855849050473\n",
      "testing loss 0.0029904019601101465\n",
      "epochs 2660\n",
      "training loss 0.0006844789530348746\n",
      "epochs 2661\n",
      "training loss 0.0007251297439714628\n",
      "epochs 2662\n",
      "training loss 0.000685286115130302\n",
      "epochs 2663\n",
      "training loss 0.0009483650797697797\n",
      "epochs 2664\n",
      "training loss 0.0009415615947123073\n",
      "epochs 2665\n",
      "training loss 0.0007467449110710433\n",
      "epochs 2666\n",
      "training loss 0.0007000503649172234\n",
      "epochs 2667\n",
      "training loss 0.000613690592864483\n",
      "epochs 2668\n",
      "training loss 0.0005915376137818937\n",
      "epochs 2669\n",
      "training loss 0.0006226030295844951\n",
      "testing loss 0.00279456559207013\n",
      "epochs 2670\n",
      "training loss 0.0006372816758060482\n",
      "epochs 2671\n",
      "training loss 0.0005903107966551144\n",
      "epochs 2672\n",
      "training loss 0.0005942989902579336\n",
      "epochs 2673\n",
      "training loss 0.0006203139142422034\n",
      "epochs 2674\n",
      "training loss 0.0006261078821633883\n",
      "epochs 2675\n",
      "training loss 0.0006700969186341136\n",
      "epochs 2676\n",
      "training loss 0.0006316601488764729\n",
      "epochs 2677\n",
      "training loss 0.0005925571511281615\n",
      "epochs 2678\n",
      "training loss 0.0006364184304524077\n",
      "epochs 2679\n",
      "training loss 0.0006592689036203429\n",
      "testing loss 0.0027750673388454612\n",
      "epochs 2680\n",
      "training loss 0.0005955940372902209\n",
      "epochs 2681\n",
      "training loss 0.0010080014885011155\n",
      "epochs 2682\n",
      "training loss 0.000729812461741999\n",
      "epochs 2683\n",
      "training loss 0.0007933317539444912\n",
      "epochs 2684\n",
      "training loss 0.0006573445610928499\n",
      "epochs 2685\n",
      "training loss 0.0006132047868611172\n",
      "epochs 2686\n",
      "training loss 0.0005738114694693893\n",
      "epochs 2687\n",
      "training loss 0.0006202718702648797\n",
      "epochs 2688\n",
      "training loss 0.0007402476138791981\n",
      "epochs 2689\n",
      "training loss 0.0007349985905910211\n",
      "testing loss 0.002914161917155754\n",
      "epochs 2690\n",
      "training loss 0.000695385738671545\n",
      "epochs 2691\n",
      "training loss 0.0007413238087756769\n",
      "epochs 2692\n",
      "training loss 0.0007353119928450649\n",
      "epochs 2693\n",
      "training loss 0.0008027520368482895\n",
      "epochs 2694\n",
      "training loss 0.0006836852660129486\n",
      "epochs 2695\n",
      "training loss 0.0006804541476094942\n",
      "epochs 2696\n",
      "training loss 0.0006729097045939642\n",
      "epochs 2697\n",
      "training loss 0.0005996443207749366\n",
      "epochs 2698\n",
      "training loss 0.0006266766909642943\n",
      "epochs 2699\n",
      "training loss 0.0006329283075078778\n",
      "testing loss 0.002822972495184802\n",
      "epochs 2700\n",
      "training loss 0.0006163779624573615\n",
      "epochs 2701\n",
      "training loss 0.0007846385064870289\n",
      "epochs 2702\n",
      "training loss 0.0008309303790311072\n",
      "epochs 2703\n",
      "training loss 0.0007869997700480999\n",
      "epochs 2704\n",
      "training loss 0.0008738357495016909\n",
      "epochs 2705\n",
      "training loss 0.000613415760881944\n",
      "epochs 2706\n",
      "training loss 0.0006692284568832864\n",
      "epochs 2707\n",
      "training loss 0.0006035417276767216\n",
      "epochs 2708\n",
      "training loss 0.0006892559689853204\n",
      "epochs 2709\n",
      "training loss 0.0006578245577416567\n",
      "testing loss 0.002900083161682445\n",
      "epochs 2710\n",
      "training loss 0.0006958547608762708\n",
      "epochs 2711\n",
      "training loss 0.0006839609358142665\n",
      "epochs 2712\n",
      "training loss 0.0008575014603192603\n",
      "epochs 2713\n",
      "training loss 0.0005942482483929935\n",
      "epochs 2714\n",
      "training loss 0.0005844166870533254\n",
      "epochs 2715\n",
      "training loss 0.0005852457485869413\n",
      "epochs 2716\n",
      "training loss 0.0006643060654420179\n",
      "epochs 2717\n",
      "training loss 0.0006229573652703078\n",
      "epochs 2718\n",
      "training loss 0.0006412128990588252\n",
      "epochs 2719\n",
      "training loss 0.0006187087612079406\n",
      "testing loss 0.002890037707918396\n",
      "epochs 2720\n",
      "training loss 0.0006148839538554608\n",
      "epochs 2721\n",
      "training loss 0.0006031398734857688\n",
      "epochs 2722\n",
      "training loss 0.0005853162594719884\n",
      "epochs 2723\n",
      "training loss 0.0006378774117539696\n",
      "epochs 2724\n",
      "training loss 0.0006278980302017205\n",
      "epochs 2725\n",
      "training loss 0.0006550479665968997\n",
      "epochs 2726\n",
      "training loss 0.0008817538717233698\n",
      "epochs 2727\n",
      "training loss 0.0006029333137817918\n",
      "epochs 2728\n",
      "training loss 0.0005807576851960339\n",
      "epochs 2729\n",
      "training loss 0.0006210005171257311\n",
      "testing loss 0.002814540731165796\n",
      "epochs 2730\n",
      "training loss 0.0006526767452796609\n",
      "epochs 2731\n",
      "training loss 0.0006221172098695983\n",
      "epochs 2732\n",
      "training loss 0.0006626806947109672\n",
      "epochs 2733\n",
      "training loss 0.0006122866808755273\n",
      "epochs 2734\n",
      "training loss 0.0006031348445384811\n",
      "epochs 2735\n",
      "training loss 0.0006474118019308396\n",
      "epochs 2736\n",
      "training loss 0.0005887225780694103\n",
      "epochs 2737\n",
      "training loss 0.0006881181060797945\n",
      "epochs 2738\n",
      "training loss 0.0006590389067520837\n",
      "epochs 2739\n",
      "training loss 0.0006171354092834489\n",
      "testing loss 0.0029063877490256643\n",
      "epochs 2740\n",
      "training loss 0.0006091492083369497\n",
      "epochs 2741\n",
      "training loss 0.0006368005122617171\n",
      "epochs 2742\n",
      "training loss 0.0006478127780530353\n",
      "epochs 2743\n",
      "training loss 0.000693755903819825\n",
      "epochs 2744\n",
      "training loss 0.0012347016821998968\n",
      "epochs 2745\n",
      "training loss 0.001761089311028041\n",
      "epochs 2746\n",
      "training loss 0.0010798958123634686\n",
      "epochs 2747\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss 0.0008129589492278202\n",
      "epochs 2748\n",
      "training loss 0.0007217850164215909\n",
      "epochs 2749\n",
      "training loss 0.0006644009116408627\n",
      "testing loss 0.002857895283167191\n",
      "epochs 2750\n",
      "training loss 0.0006543390907907694\n",
      "epochs 2751\n",
      "training loss 0.0006306897031460354\n",
      "epochs 2752\n",
      "training loss 0.00064927248288113\n",
      "epochs 2753\n",
      "training loss 0.0006266294806147572\n",
      "epochs 2754\n",
      "training loss 0.000583774075449917\n",
      "epochs 2755\n",
      "training loss 0.0006585813379219499\n",
      "epochs 2756\n",
      "training loss 0.0006198895890633703\n",
      "epochs 2757\n",
      "training loss 0.0007099963253644213\n",
      "epochs 2758\n",
      "training loss 0.0006196274910239633\n",
      "epochs 2759\n",
      "training loss 0.000705719802413266\n",
      "testing loss 0.002932163547387624\n",
      "epochs 2760\n",
      "training loss 0.0006908007270598495\n",
      "epochs 2761\n",
      "training loss 0.0006696796491437826\n",
      "epochs 2762\n",
      "training loss 0.0005705528101730967\n",
      "epochs 2763\n",
      "training loss 0.0006184108513032332\n",
      "epochs 2764\n",
      "training loss 0.0006051921429173415\n",
      "epochs 2765\n",
      "training loss 0.0006128218668791831\n",
      "epochs 2766\n",
      "training loss 0.0005878548691258695\n",
      "epochs 2767\n",
      "training loss 0.000646450035953413\n",
      "epochs 2768\n",
      "training loss 0.0006589906588819523\n",
      "epochs 2769\n",
      "training loss 0.0006353688181454378\n",
      "testing loss 0.002841018691843917\n",
      "epochs 2770\n",
      "training loss 0.0006521592152164825\n",
      "epochs 2771\n",
      "training loss 0.0006823148454559293\n",
      "epochs 2772\n",
      "training loss 0.0006328820420597541\n",
      "epochs 2773\n",
      "training loss 0.0006350814256042887\n",
      "epochs 2774\n",
      "training loss 0.0006030568838689906\n",
      "epochs 2775\n",
      "training loss 0.0006336711520841487\n",
      "epochs 2776\n",
      "training loss 0.0005614298030820401\n",
      "epochs 2777\n",
      "training loss 0.0006068745035484241\n",
      "epochs 2778\n",
      "training loss 0.0006088194770647898\n",
      "epochs 2779\n",
      "training loss 0.0007058706557934418\n",
      "testing loss 0.0027475660263910785\n",
      "epochs 2780\n",
      "training loss 0.0007556176925393666\n",
      "epochs 2781\n",
      "training loss 0.0008578583123806388\n",
      "epochs 2782\n",
      "training loss 0.0006870721988054417\n",
      "epochs 2783\n",
      "training loss 0.000773175951803958\n",
      "epochs 2784\n",
      "training loss 0.0006831959362345603\n",
      "epochs 2785\n",
      "training loss 0.0006269934606819065\n",
      "epochs 2786\n",
      "training loss 0.0006312628975138068\n",
      "epochs 2787\n",
      "training loss 0.0006991638069530796\n",
      "epochs 2788\n",
      "training loss 0.0006778442785978928\n",
      "epochs 2789\n",
      "training loss 0.000608235880864167\n",
      "testing loss 0.002777177839645627\n",
      "epochs 2790\n",
      "training loss 0.0006195530929640898\n",
      "epochs 2791\n",
      "training loss 0.0005973884331608774\n",
      "epochs 2792\n",
      "training loss 0.0005563124435766965\n",
      "epochs 2793\n",
      "training loss 0.0010799191131201321\n",
      "epochs 2794\n",
      "training loss 0.0006200809806293743\n",
      "epochs 2795\n",
      "training loss 0.0005841737560535806\n",
      "epochs 2796\n",
      "training loss 0.0006490367261082851\n",
      "epochs 2797\n",
      "training loss 0.0006249890814706581\n",
      "epochs 2798\n",
      "training loss 0.0008110500699458332\n",
      "epochs 2799\n",
      "training loss 0.0006253512735099258\n",
      "testing loss 0.002766377425088765\n",
      "epochs 2800\n",
      "training loss 0.0005952994175337391\n",
      "epochs 2801\n",
      "training loss 0.0006124544549927308\n",
      "epochs 2802\n",
      "training loss 0.0005774625102348207\n",
      "epochs 2803\n",
      "training loss 0.0005884943591001922\n",
      "epochs 2804\n",
      "training loss 0.0007810180371281858\n",
      "epochs 2805\n",
      "training loss 0.0005653102589929674\n",
      "epochs 2806\n",
      "training loss 0.0006358869704467423\n",
      "epochs 2807\n",
      "training loss 0.0005748518463082634\n",
      "epochs 2808\n",
      "training loss 0.0006985980163697764\n",
      "epochs 2809\n",
      "training loss 0.0006553560841614862\n",
      "testing loss 0.002795789460981833\n",
      "epochs 2810\n",
      "training loss 0.0006016030598723394\n",
      "epochs 2811\n",
      "training loss 0.0005912377296820974\n",
      "epochs 2812\n",
      "training loss 0.0005772236111329013\n",
      "epochs 2813\n",
      "training loss 0.0006436618127418529\n",
      "epochs 2814\n",
      "training loss 0.000658741340874114\n",
      "epochs 2815\n",
      "training loss 0.0006558709274722676\n",
      "epochs 2816\n",
      "training loss 0.0006629408229783596\n",
      "epochs 2817\n",
      "training loss 0.0006473143012680419\n",
      "epochs 2818\n",
      "training loss 0.0007043842999951059\n",
      "epochs 2819\n",
      "training loss 0.0006331795001916281\n",
      "testing loss 0.002919646610377079\n",
      "epochs 2820\n",
      "training loss 0.000625622439294442\n",
      "epochs 2821\n",
      "training loss 0.0007138815002535727\n",
      "epochs 2822\n",
      "training loss 0.0005851525106179983\n",
      "epochs 2823\n",
      "training loss 0.0006078603692666987\n",
      "epochs 2824\n",
      "training loss 0.0006006301265163205\n",
      "epochs 2825\n",
      "training loss 0.0005965288266706589\n",
      "epochs 2826\n",
      "training loss 0.0006063832836133629\n",
      "epochs 2827\n",
      "training loss 0.0006806440222378549\n",
      "epochs 2828\n",
      "training loss 0.0006407530882606696\n",
      "epochs 2829\n",
      "training loss 0.0006318387146763175\n",
      "testing loss 0.0028717786408894766\n",
      "epochs 2830\n",
      "training loss 0.0006370389462331179\n",
      "epochs 2831\n",
      "training loss 0.0006261223461478949\n",
      "epochs 2832\n",
      "training loss 0.000579288935357433\n",
      "epochs 2833\n",
      "training loss 0.0006073540998205236\n",
      "epochs 2834\n",
      "training loss 0.0006731743235204731\n",
      "epochs 2835\n",
      "training loss 0.0006444733557156867\n",
      "epochs 2836\n",
      "training loss 0.0006243597055639573\n",
      "epochs 2837\n",
      "training loss 0.0006593935318838941\n",
      "epochs 2838\n",
      "training loss 0.0006656974963992438\n",
      "epochs 2839\n",
      "training loss 0.0007085177188811366\n",
      "testing loss 0.002888178641508261\n",
      "epochs 2840\n",
      "training loss 0.0006459785879576879\n",
      "epochs 2841\n",
      "training loss 0.0006322231011728453\n",
      "epochs 2842\n",
      "training loss 0.0006439014734087461\n",
      "epochs 2843\n",
      "training loss 0.0006119129658424745\n",
      "epochs 2844\n",
      "training loss 0.0006523325713422138\n",
      "epochs 2845\n",
      "training loss 0.0005935678490484275\n",
      "epochs 2846\n",
      "training loss 0.0006093012419703352\n",
      "epochs 2847\n",
      "training loss 0.0006064597675067267\n",
      "epochs 2848\n",
      "training loss 0.0005661790728205277\n",
      "epochs 2849\n",
      "training loss 0.0006179942997663613\n",
      "testing loss 0.002897381972841892\n",
      "epochs 2850\n",
      "training loss 0.0006240947039530395\n",
      "epochs 2851\n",
      "training loss 0.0005776957902628476\n",
      "epochs 2852\n",
      "training loss 0.0006293070198802453\n",
      "epochs 2853\n",
      "training loss 0.0005893414392663975\n",
      "epochs 2854\n",
      "training loss 0.0006130733156589491\n",
      "epochs 2855\n",
      "training loss 0.0010718763951002692\n",
      "epochs 2856\n",
      "training loss 0.000815204756566547\n",
      "epochs 2857\n",
      "training loss 0.000668595965628266\n",
      "epochs 2858\n",
      "training loss 0.0006300935621329478\n",
      "epochs 2859\n",
      "training loss 0.0006597350586996921\n",
      "testing loss 0.002893569530400692\n",
      "epochs 2860\n",
      "training loss 0.0006453404823172339\n",
      "epochs 2861\n",
      "training loss 0.0005861000660530894\n",
      "epochs 2862\n",
      "training loss 0.0005802312413992015\n",
      "epochs 2863\n",
      "training loss 0.0006853298675643966\n",
      "epochs 2864\n",
      "training loss 0.0005836196197409149\n",
      "epochs 2865\n",
      "training loss 0.0006317890778723198\n",
      "epochs 2866\n",
      "training loss 0.0006116525316752471\n",
      "epochs 2867\n",
      "training loss 0.000592003982495743\n",
      "epochs 2868\n",
      "training loss 0.0006037334499117779\n",
      "epochs 2869\n",
      "training loss 0.0006071468244630866\n",
      "testing loss 0.0027659485865457\n",
      "epochs 2870\n",
      "training loss 0.0005824946834476478\n",
      "epochs 2871\n",
      "training loss 0.0005944358462879666\n",
      "epochs 2872\n",
      "training loss 0.0006543842638279439\n",
      "epochs 2873\n",
      "training loss 0.0006248193329814425\n",
      "epochs 2874\n",
      "training loss 0.0005934392386908702\n",
      "epochs 2875\n",
      "training loss 0.000605325379810865\n",
      "epochs 2876\n",
      "training loss 0.0005943693948122687\n",
      "epochs 2877\n",
      "training loss 0.0006538741381684641\n",
      "epochs 2878\n",
      "training loss 0.0005863059400920516\n",
      "epochs 2879\n",
      "training loss 0.0006482357695864338\n",
      "testing loss 0.002878221896219444\n",
      "epochs 2880\n",
      "training loss 0.0006696488225257936\n",
      "epochs 2881\n",
      "training loss 0.0006290898167550859\n",
      "epochs 2882\n",
      "training loss 0.0010125774440446183\n",
      "epochs 2883\n",
      "training loss 0.0007693776062025906\n",
      "epochs 2884\n",
      "training loss 0.0005945820053706744\n",
      "epochs 2885\n",
      "training loss 0.0005725139548922789\n",
      "epochs 2886\n",
      "training loss 0.0006252705295765518\n",
      "epochs 2887\n",
      "training loss 0.0005603537098278141\n",
      "epochs 2888\n",
      "training loss 0.0011988301867779094\n",
      "epochs 2889\n",
      "training loss 0.0008942790281333278\n",
      "testing loss 0.0027867809672020905\n",
      "epochs 2890\n",
      "training loss 0.0006146579137812213\n",
      "epochs 2891\n",
      "training loss 0.0007542878472335399\n",
      "epochs 2892\n",
      "training loss 0.0006511399683777503\n",
      "epochs 2893\n",
      "training loss 0.0006003366487976843\n",
      "epochs 2894\n",
      "training loss 0.0005831432116209418\n",
      "epochs 2895\n",
      "training loss 0.0005921978986642315\n",
      "epochs 2896\n",
      "training loss 0.0005794118897526562\n",
      "epochs 2897\n",
      "training loss 0.000645004525656124\n",
      "epochs 2898\n",
      "training loss 0.0006712776834165003\n",
      "epochs 2899\n",
      "training loss 0.000656078027852876\n",
      "testing loss 0.0028947773311082405\n",
      "epochs 2900\n",
      "training loss 0.0006927346326283386\n",
      "epochs 2901\n",
      "training loss 0.0006559168320859706\n",
      "epochs 2902\n",
      "training loss 0.000669130164578608\n",
      "epochs 2903\n",
      "training loss 0.0008852309491633973\n",
      "epochs 2904\n",
      "training loss 0.0012077095548234495\n",
      "epochs 2905\n",
      "training loss 0.0008393154215240302\n",
      "epochs 2906\n",
      "training loss 0.000721808857854886\n",
      "epochs 2907\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss 0.0006436267598761432\n",
      "epochs 2908\n",
      "training loss 0.0006258439429749743\n",
      "epochs 2909\n",
      "training loss 0.0006197605412637413\n",
      "testing loss 0.002816512451279274\n",
      "epochs 2910\n",
      "training loss 0.0006403297615466826\n",
      "epochs 2911\n",
      "training loss 0.0006302974670191259\n",
      "epochs 2912\n",
      "training loss 0.000593653373883069\n",
      "epochs 2913\n",
      "training loss 0.0006402982700521291\n",
      "epochs 2914\n",
      "training loss 0.0006100299627849929\n",
      "epochs 2915\n",
      "training loss 0.0006079465008587053\n",
      "epochs 2916\n",
      "training loss 0.0006139618985066162\n",
      "epochs 2917\n",
      "training loss 0.0006041865241020284\n",
      "epochs 2918\n",
      "training loss 0.0006052566931786802\n",
      "epochs 2919\n",
      "training loss 0.000632605494543525\n",
      "testing loss 0.002898435396512191\n",
      "epochs 2920\n",
      "training loss 0.0006882469783718259\n",
      "epochs 2921\n",
      "training loss 0.0006635952974446004\n",
      "epochs 2922\n",
      "training loss 0.0005989236258944117\n",
      "epochs 2923\n",
      "training loss 0.0006063772110858689\n",
      "epochs 2924\n",
      "training loss 0.0006459946422144137\n",
      "epochs 2925\n",
      "training loss 0.0005911295597673617\n",
      "epochs 2926\n",
      "training loss 0.0005924357649782463\n",
      "epochs 2927\n",
      "training loss 0.0006494295177733565\n",
      "epochs 2928\n",
      "training loss 0.0007178284539055578\n",
      "epochs 2929\n",
      "training loss 0.0005945044086317568\n",
      "testing loss 0.0030135445301718218\n",
      "epochs 2930\n",
      "training loss 0.000632873039068456\n",
      "epochs 2931\n",
      "training loss 0.0006369327058404185\n",
      "epochs 2932\n",
      "training loss 0.0006402024283076673\n",
      "epochs 2933\n",
      "training loss 0.0006065069876312587\n",
      "epochs 2934\n",
      "training loss 0.0005712432488353249\n",
      "epochs 2935\n",
      "training loss 0.0005999885560161969\n",
      "epochs 2936\n",
      "training loss 0.0006013039964297928\n",
      "epochs 2937\n",
      "training loss 0.0006001973079728376\n",
      "epochs 2938\n",
      "training loss 0.0006142025415383642\n",
      "epochs 2939\n",
      "training loss 0.0007330360855110341\n",
      "testing loss 0.002825073867289891\n",
      "epochs 2940\n",
      "training loss 0.0007599040426775292\n",
      "epochs 2941\n",
      "training loss 0.000728344439233775\n",
      "epochs 2942\n",
      "training loss 0.0006874122460143454\n",
      "epochs 2943\n",
      "training loss 0.0006435688449343027\n",
      "epochs 2944\n",
      "training loss 0.000597388737910713\n",
      "epochs 2945\n",
      "training loss 0.0005979266037667697\n",
      "epochs 2946\n",
      "training loss 0.0005728874214812349\n",
      "epochs 2947\n",
      "training loss 0.0006008583167355541\n",
      "epochs 2948\n",
      "training loss 0.00060202519049851\n",
      "epochs 2949\n",
      "training loss 0.0006241768467279667\n",
      "testing loss 0.0028036269479008486\n",
      "epochs 2950\n",
      "training loss 0.0006913732948548821\n",
      "epochs 2951\n",
      "training loss 0.0007593347506999607\n",
      "epochs 2952\n",
      "training loss 0.0006584586014073783\n",
      "epochs 2953\n",
      "training loss 0.0006157027536792268\n",
      "epochs 2954\n",
      "training loss 0.0006898000596995582\n",
      "epochs 2955\n",
      "training loss 0.000624712773508146\n",
      "epochs 2956\n",
      "training loss 0.000589603432832784\n",
      "epochs 2957\n",
      "training loss 0.0005558285024300173\n",
      "epochs 2958\n",
      "training loss 0.000616606536599465\n",
      "epochs 2959\n",
      "training loss 0.0005765601902907165\n",
      "testing loss 0.0028350375686005975\n",
      "epochs 2960\n",
      "training loss 0.0006145208550859129\n",
      "epochs 2961\n",
      "training loss 0.0006604921635336563\n",
      "epochs 2962\n",
      "training loss 0.0006154371043532736\n",
      "epochs 2963\n",
      "training loss 0.0006703339846370215\n",
      "epochs 2964\n",
      "training loss 0.0006062417568166183\n",
      "epochs 2965\n",
      "training loss 0.000644912421321185\n",
      "epochs 2966\n",
      "training loss 0.000640433189925514\n",
      "epochs 2967\n",
      "training loss 0.000704020294495278\n",
      "epochs 2968\n",
      "training loss 0.0009672281756575325\n",
      "epochs 2969\n",
      "training loss 0.0006269641895707708\n",
      "testing loss 0.0028608775894150983\n",
      "epochs 2970\n",
      "training loss 0.0005720585174533032\n",
      "epochs 2971\n",
      "training loss 0.0005717257122328012\n",
      "epochs 2972\n",
      "training loss 0.0006058922574089664\n",
      "epochs 2973\n",
      "training loss 0.0006161192410815179\n",
      "epochs 2974\n",
      "training loss 0.0005648194536769135\n",
      "epochs 2975\n",
      "training loss 0.0006604701139763179\n",
      "epochs 2976\n",
      "training loss 0.0005639811472982837\n",
      "epochs 2977\n",
      "training loss 0.000625986177994414\n",
      "epochs 2978\n",
      "training loss 0.0008236914727161709\n",
      "epochs 2979\n",
      "training loss 0.000826372271301055\n",
      "testing loss 0.0028693775909767877\n",
      "epochs 2980\n",
      "training loss 0.0008229098460915864\n",
      "epochs 2981\n",
      "training loss 0.0012435502174351432\n",
      "epochs 2982\n",
      "training loss 0.000679153126861198\n",
      "epochs 2983\n",
      "training loss 0.0006760371208302733\n",
      "epochs 2984\n",
      "training loss 0.0005912458692892457\n",
      "epochs 2985\n",
      "training loss 0.0005728809587943359\n",
      "epochs 2986\n",
      "training loss 0.0005945259115855439\n",
      "epochs 2987\n",
      "training loss 0.0006078692466426799\n",
      "epochs 2988\n",
      "training loss 0.0006058238763227708\n",
      "epochs 2989\n",
      "training loss 0.0006922601665919335\n",
      "testing loss 0.00293257147286761\n",
      "epochs 2990\n",
      "training loss 0.0006208658961637235\n",
      "epochs 2991\n",
      "training loss 0.0006391913263837731\n",
      "epochs 2992\n",
      "training loss 0.0006644505947986816\n",
      "epochs 2993\n",
      "training loss 0.0006472912637727748\n",
      "epochs 2994\n",
      "training loss 0.0006306786566943009\n",
      "epochs 2995\n",
      "training loss 0.0006100842969826108\n",
      "epochs 2996\n",
      "training loss 0.0006151706907200404\n",
      "epochs 2997\n",
      "training loss 0.0006110369109995889\n",
      "epochs 2998\n",
      "training loss 0.0006104813869915178\n",
      "epochs 2999\n",
      "training loss 0.000669504186484572\n",
      "testing loss 0.002817151773265226\n",
      "epochs 3000\n",
      "training loss 0.0006494781120586857\n",
      "epochs 3001\n",
      "training loss 0.0006968690360907613\n",
      "epochs 3002\n",
      "training loss 0.0006073398368205242\n",
      "epochs 3003\n",
      "training loss 0.0006793060463479519\n",
      "epochs 3004\n",
      "training loss 0.0005827172592814479\n",
      "epochs 3005\n",
      "training loss 0.0005718297722266766\n",
      "epochs 3006\n",
      "training loss 0.0005958273960489746\n",
      "epochs 3007\n",
      "training loss 0.0006563695183725841\n",
      "epochs 3008\n",
      "training loss 0.0013707583331563835\n",
      "epochs 3009\n",
      "training loss 0.0007211043238271831\n",
      "testing loss 0.0028628440299698858\n",
      "epochs 3010\n",
      "training loss 0.0006084631740838844\n",
      "epochs 3011\n",
      "training loss 0.0006088043710267834\n",
      "epochs 3012\n",
      "training loss 0.000610842109862347\n",
      "epochs 3013\n",
      "training loss 0.0006036795137908683\n",
      "epochs 3014\n",
      "training loss 0.0006274697145250397\n",
      "epochs 3015\n",
      "training loss 0.0006084480507074258\n",
      "epochs 3016\n",
      "training loss 0.0019292150183381246\n",
      "epochs 3017\n",
      "training loss 0.0008337696853035772\n",
      "epochs 3018\n",
      "training loss 0.0006339772972228758\n",
      "epochs 3019\n",
      "training loss 0.0005943601887133878\n",
      "testing loss 0.002818188701875191\n",
      "epochs 3020\n",
      "training loss 0.0006141763046563611\n",
      "epochs 3021\n",
      "training loss 0.0007353424872901562\n",
      "epochs 3022\n",
      "training loss 0.0005917703779909681\n",
      "epochs 3023\n",
      "training loss 0.0006484964951458119\n",
      "epochs 3024\n",
      "training loss 0.0006461068578269673\n",
      "epochs 3025\n",
      "training loss 0.0005890027554259893\n",
      "epochs 3026\n",
      "training loss 0.0005923412538715284\n",
      "epochs 3027\n",
      "training loss 0.0005968171354074676\n",
      "epochs 3028\n",
      "training loss 0.0005756912170555499\n",
      "epochs 3029\n",
      "training loss 0.000602599809361667\n",
      "testing loss 0.002951148072594499\n",
      "epochs 3030\n",
      "training loss 0.0005942586626104534\n",
      "epochs 3031\n",
      "training loss 0.0005608642118024756\n",
      "epochs 3032\n",
      "training loss 0.0006077471323662344\n",
      "epochs 3033\n",
      "training loss 0.0007518424086717147\n",
      "epochs 3034\n",
      "training loss 0.0005990387265015631\n",
      "epochs 3035\n",
      "training loss 0.0006912652797477552\n",
      "epochs 3036\n",
      "training loss 0.0005814858880686633\n",
      "epochs 3037\n",
      "training loss 0.0006225914168907584\n",
      "epochs 3038\n",
      "training loss 0.0006216347590336537\n",
      "epochs 3039\n",
      "training loss 0.0005923576039434793\n",
      "testing loss 0.0028165329729887187\n",
      "epochs 3040\n",
      "training loss 0.0005986158327181118\n",
      "epochs 3041\n",
      "training loss 0.000663167829229001\n",
      "epochs 3042\n",
      "training loss 0.0007568215438246863\n",
      "epochs 3043\n",
      "training loss 0.0006557810919976434\n",
      "epochs 3044\n",
      "training loss 0.000618490440460307\n",
      "epochs 3045\n",
      "training loss 0.0006063212736121925\n",
      "epochs 3046\n",
      "training loss 0.000601201571115805\n",
      "epochs 3047\n",
      "training loss 0.0006353239456119474\n",
      "epochs 3048\n",
      "training loss 0.0005849187051287164\n",
      "epochs 3049\n",
      "training loss 0.0006204116062472056\n",
      "testing loss 0.002929476813862351\n",
      "epochs 3050\n",
      "training loss 0.0006358830432873219\n",
      "epochs 3051\n",
      "training loss 0.0006197733649068249\n",
      "epochs 3052\n",
      "training loss 0.0006269528320884349\n",
      "epochs 3053\n",
      "training loss 0.0006410416998896227\n",
      "epochs 3054\n",
      "training loss 0.000596840073648942\n",
      "epochs 3055\n",
      "training loss 0.0006592000070690406\n",
      "epochs 3056\n",
      "training loss 0.0005941794909916161\n",
      "epochs 3057\n",
      "training loss 0.0006094013563163386\n",
      "epochs 3058\n",
      "training loss 0.0007151077499883504\n",
      "epochs 3059\n",
      "training loss 0.0005910895854350757\n",
      "testing loss 0.0028943402543234647\n",
      "epochs 3060\n",
      "training loss 0.0006285637575003536\n",
      "epochs 3061\n",
      "training loss 0.0010258918563519693\n",
      "epochs 3062\n",
      "training loss 0.0010947980738413381\n",
      "epochs 3063\n",
      "training loss 0.000720802998247395\n",
      "epochs 3064\n",
      "training loss 0.0008277865558421086\n",
      "epochs 3065\n",
      "training loss 0.0005768360696573059\n",
      "epochs 3066\n",
      "training loss 0.000605356594332491\n",
      "epochs 3067\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss 0.0005756406484866702\n",
      "epochs 3068\n",
      "training loss 0.0005806404894669356\n",
      "epochs 3069\n",
      "training loss 0.0005771500883994788\n",
      "testing loss 0.002761631655830441\n",
      "epochs 3070\n",
      "training loss 0.0006711885694337947\n",
      "epochs 3071\n",
      "training loss 0.0006148324705947667\n",
      "epochs 3072\n",
      "training loss 0.00059362059615844\n",
      "epochs 3073\n",
      "training loss 0.0006978673049061924\n",
      "epochs 3074\n",
      "training loss 0.0006101815411070855\n",
      "epochs 3075\n",
      "training loss 0.0005933301019805023\n",
      "epochs 3076\n",
      "training loss 0.0005880951383193576\n",
      "epochs 3077\n",
      "training loss 0.0006113170603138754\n",
      "epochs 3078\n",
      "training loss 0.000589519974856643\n",
      "epochs 3079\n",
      "training loss 0.0005769783501459517\n",
      "testing loss 0.002838620217104198\n",
      "epochs 3080\n",
      "training loss 0.0005927887978032231\n",
      "epochs 3081\n",
      "training loss 0.0006933961519023183\n",
      "epochs 3082\n",
      "training loss 0.0006064478625362246\n",
      "epochs 3083\n",
      "training loss 0.0006609939940706869\n",
      "epochs 3084\n",
      "training loss 0.0005993269844614762\n",
      "epochs 3085\n",
      "training loss 0.0006102708521819925\n",
      "epochs 3086\n",
      "training loss 0.0005791294580434469\n",
      "epochs 3087\n",
      "training loss 0.0006058005963545576\n",
      "epochs 3088\n",
      "training loss 0.0006557615351966529\n",
      "epochs 3089\n",
      "training loss 0.0008398253497374626\n",
      "testing loss 0.002770804175496075\n",
      "epochs 3090\n",
      "training loss 0.0006859228286522761\n",
      "epochs 3091\n",
      "training loss 0.0007002230114933375\n",
      "epochs 3092\n",
      "training loss 0.0006195843012049499\n",
      "epochs 3093\n",
      "training loss 0.0006281783957158904\n",
      "epochs 3094\n",
      "training loss 0.0006224074357438345\n",
      "epochs 3095\n",
      "training loss 0.0006050261992453045\n",
      "epochs 3096\n",
      "training loss 0.0006714361466079565\n",
      "epochs 3097\n",
      "training loss 0.0006142972775141915\n",
      "epochs 3098\n",
      "training loss 0.0006164943493830498\n",
      "epochs 3099\n",
      "training loss 0.0006696011411630489\n",
      "testing loss 0.0028844145035820334\n",
      "epochs 3100\n",
      "training loss 0.0007361173737683761\n",
      "epochs 3101\n",
      "training loss 0.0005651522036974452\n",
      "epochs 3102\n",
      "training loss 0.0006456147819385216\n",
      "epochs 3103\n",
      "training loss 0.0006014700654517622\n",
      "epochs 3104\n",
      "training loss 0.0006486055792215928\n",
      "epochs 3105\n",
      "training loss 0.0006199295021803048\n",
      "epochs 3106\n",
      "training loss 0.0006373154289070743\n",
      "epochs 3107\n",
      "training loss 0.0005754226993657592\n",
      "epochs 3108\n",
      "training loss 0.0005866071606680502\n",
      "epochs 3109\n",
      "training loss 0.000562434310378722\n",
      "testing loss 0.0027434878944624084\n",
      "epochs 3110\n",
      "training loss 0.0007184308914306339\n",
      "epochs 3111\n",
      "training loss 0.0006618693166293521\n",
      "epochs 3112\n",
      "training loss 0.0007077226074522865\n",
      "epochs 3113\n",
      "training loss 0.0006143570030858247\n",
      "epochs 3114\n",
      "training loss 0.0006228470383105816\n",
      "epochs 3115\n",
      "training loss 0.0005612158688743482\n",
      "epochs 3116\n",
      "training loss 0.0006080558282920474\n",
      "epochs 3117\n",
      "training loss 0.0006031618331662326\n",
      "epochs 3118\n",
      "training loss 0.0006023342166510679\n",
      "epochs 3119\n",
      "training loss 0.0005356447478737908\n",
      "testing loss 0.002806758785088619\n",
      "epochs 3120\n",
      "training loss 0.0006000383415239606\n",
      "epochs 3121\n",
      "training loss 0.0005902908035620515\n",
      "epochs 3122\n",
      "training loss 0.0005676353381774006\n",
      "epochs 3123\n",
      "training loss 0.0006271084474391193\n",
      "epochs 3124\n",
      "training loss 0.0005605857796141861\n",
      "epochs 3125\n",
      "training loss 0.0006040625290015972\n",
      "epochs 3126\n",
      "training loss 0.001038318282838254\n",
      "epochs 3127\n",
      "training loss 0.0014336428925781411\n",
      "epochs 3128\n",
      "training loss 0.000798279165568419\n",
      "epochs 3129\n",
      "training loss 0.0008834128915247335\n",
      "testing loss 0.0026408463381296884\n",
      "epochs 3130\n",
      "training loss 0.0006456671598102716\n",
      "epochs 3131\n",
      "training loss 0.0006094383018156429\n",
      "epochs 3132\n",
      "training loss 0.0005788712198442657\n",
      "epochs 3133\n",
      "training loss 0.0005488231066737528\n",
      "epochs 3134\n",
      "training loss 0.0005752466306568754\n",
      "epochs 3135\n",
      "training loss 0.000578760684203883\n",
      "epochs 3136\n",
      "training loss 0.0006057365963236913\n",
      "epochs 3137\n",
      "training loss 0.0006295357404261159\n",
      "epochs 3138\n",
      "training loss 0.0005293859618802281\n",
      "epochs 3139\n",
      "training loss 0.0005218936348904354\n",
      "testing loss 0.0027000702106796787\n",
      "epochs 3140\n",
      "training loss 0.0006192798411691601\n",
      "epochs 3141\n",
      "training loss 0.0007613669548538941\n",
      "epochs 3142\n",
      "training loss 0.0008755064726698193\n",
      "epochs 3143\n",
      "training loss 0.0005717116457057726\n",
      "epochs 3144\n",
      "training loss 0.0006690542017234246\n",
      "epochs 3145\n",
      "training loss 0.0005801864374233664\n",
      "epochs 3146\n",
      "training loss 0.0005382221603644361\n",
      "epochs 3147\n",
      "training loss 0.0005547140229926487\n",
      "epochs 3148\n",
      "training loss 0.0005485956977464055\n",
      "epochs 3149\n",
      "training loss 0.0005427837931964331\n",
      "testing loss 0.002656715133158054\n",
      "epochs 3150\n",
      "training loss 0.0005493232330886257\n",
      "epochs 3151\n",
      "training loss 0.0006642122166464813\n",
      "epochs 3152\n",
      "training loss 0.0005794433532933786\n",
      "epochs 3153\n",
      "training loss 0.0005805890526485242\n",
      "epochs 3154\n",
      "training loss 0.0005910341267149873\n",
      "epochs 3155\n",
      "training loss 0.0005935187521249078\n",
      "epochs 3156\n",
      "training loss 0.0005619396082455389\n",
      "epochs 3157\n",
      "training loss 0.0007019934832192051\n",
      "epochs 3158\n",
      "training loss 0.000606495867048795\n",
      "epochs 3159\n",
      "training loss 0.0006068625774356256\n",
      "testing loss 0.0027992234562015067\n",
      "epochs 3160\n",
      "training loss 0.000608687118505408\n",
      "epochs 3161\n",
      "training loss 0.0005744629285487949\n",
      "epochs 3162\n",
      "training loss 0.0005630952058222688\n",
      "epochs 3163\n",
      "training loss 0.0006293789871952759\n",
      "epochs 3164\n",
      "training loss 0.000557916600799958\n",
      "epochs 3165\n",
      "training loss 0.0006010928248744572\n",
      "epochs 3166\n",
      "training loss 0.000802261375282158\n",
      "epochs 3167\n",
      "training loss 0.0006058268473903991\n",
      "epochs 3168\n",
      "training loss 0.0005853813589022617\n",
      "epochs 3169\n",
      "training loss 0.0005947086003100879\n",
      "testing loss 0.0027528428584040004\n",
      "epochs 3170\n",
      "training loss 0.0006192013428307289\n",
      "epochs 3171\n",
      "training loss 0.0006368783398851254\n",
      "epochs 3172\n",
      "training loss 0.0006073690390201586\n",
      "epochs 3173\n",
      "training loss 0.0005720633275468627\n",
      "epochs 3174\n",
      "training loss 0.0006135753830073906\n",
      "epochs 3175\n",
      "training loss 0.002860911301528967\n",
      "epochs 3176\n",
      "training loss 0.0021226094067195787\n",
      "epochs 3177\n",
      "training loss 0.0010656673233145084\n",
      "epochs 3178\n",
      "training loss 0.0008398882762881386\n",
      "epochs 3179\n",
      "training loss 0.0006902900184391457\n",
      "testing loss 0.002783241948849317\n",
      "epochs 3180\n",
      "training loss 0.0006337110802395366\n",
      "epochs 3181\n",
      "training loss 0.0006469570442299588\n",
      "epochs 3182\n",
      "training loss 0.0009331306310633825\n",
      "epochs 3183\n",
      "training loss 0.0007368141748464035\n",
      "epochs 3184\n",
      "training loss 0.0006710883760032185\n",
      "epochs 3185\n",
      "training loss 0.0006283074006116963\n",
      "epochs 3186\n",
      "training loss 0.0006226679152033453\n",
      "epochs 3187\n",
      "training loss 0.0007289582364527243\n",
      "epochs 3188\n",
      "training loss 0.0008887881692640461\n",
      "epochs 3189\n",
      "training loss 0.0006782584371629785\n",
      "testing loss 0.0027776429555973316\n",
      "epochs 3190\n",
      "training loss 0.0006706903945678692\n",
      "epochs 3191\n",
      "training loss 0.0006264288134633714\n",
      "epochs 3192\n",
      "training loss 0.0007047492246098228\n",
      "epochs 3193\n",
      "training loss 0.0007322943858033765\n",
      "epochs 3194\n",
      "training loss 0.0006902018264020966\n",
      "epochs 3195\n",
      "training loss 0.0006431396511004032\n",
      "epochs 3196\n",
      "training loss 0.0006436478549339964\n",
      "epochs 3197\n",
      "training loss 0.0006719926657193371\n",
      "epochs 3198\n",
      "training loss 0.0006489855288435906\n",
      "epochs 3199\n",
      "training loss 0.0005779663919284374\n",
      "testing loss 0.0028763092160125838\n",
      "epochs 3200\n",
      "training loss 0.0005981161703722195\n",
      "epochs 3201\n",
      "training loss 0.000590096218801616\n",
      "epochs 3202\n",
      "training loss 0.0005768301602528009\n",
      "epochs 3203\n",
      "training loss 0.0005749224904163155\n",
      "epochs 3204\n",
      "training loss 0.000574674632288459\n",
      "epochs 3205\n",
      "training loss 0.0006139165933079746\n",
      "epochs 3206\n",
      "training loss 0.0006437370189859059\n",
      "epochs 3207\n",
      "training loss 0.0006235500061275908\n",
      "epochs 3208\n",
      "training loss 0.0005872470504883111\n",
      "epochs 3209\n",
      "training loss 0.0006506526487098163\n",
      "testing loss 0.0028187447604855376\n",
      "epochs 3210\n",
      "training loss 0.0006571823687187897\n",
      "epochs 3211\n",
      "training loss 0.000680561422382405\n",
      "epochs 3212\n",
      "training loss 0.0006068047975744815\n",
      "epochs 3213\n",
      "training loss 0.0005897490224004143\n",
      "epochs 3214\n",
      "training loss 0.0005932765953401302\n",
      "epochs 3215\n",
      "training loss 0.0005710004725547276\n",
      "epochs 3216\n",
      "training loss 0.0006128980724726971\n",
      "epochs 3217\n",
      "training loss 0.0006089298155245097\n",
      "epochs 3218\n",
      "training loss 0.0007283854245924388\n",
      "epochs 3219\n",
      "training loss 0.0005839548355370398\n",
      "testing loss 0.002869532382898429\n",
      "epochs 3220\n",
      "training loss 0.0006168060767072278\n",
      "epochs 3221\n",
      "training loss 0.000595687251109177\n",
      "epochs 3222\n",
      "training loss 0.0005797645334355352\n",
      "epochs 3223\n",
      "training loss 0.0006017506077119905\n",
      "epochs 3224\n",
      "training loss 0.0005989386127747901\n",
      "epochs 3225\n",
      "training loss 0.0006324941758420262\n",
      "epochs 3226\n",
      "training loss 0.0005888999113353042\n",
      "epochs 3227\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss 0.000578146157177635\n",
      "epochs 3228\n",
      "training loss 0.0006079823017547807\n",
      "epochs 3229\n",
      "training loss 0.0007697775627176439\n",
      "testing loss 0.0029283543695292785\n",
      "epochs 3230\n",
      "training loss 0.0005852847214909214\n",
      "epochs 3231\n",
      "training loss 0.0006614387498731162\n",
      "epochs 3232\n",
      "training loss 0.0005769433035610079\n",
      "epochs 3233\n",
      "training loss 0.0006865987861684685\n",
      "epochs 3234\n",
      "training loss 0.0006277957536799601\n",
      "epochs 3235\n",
      "training loss 0.0005758534217257574\n",
      "epochs 3236\n",
      "training loss 0.0005678561071852523\n",
      "epochs 3237\n",
      "training loss 0.0005749116229221768\n",
      "epochs 3238\n",
      "training loss 0.0006778570580102311\n",
      "epochs 3239\n",
      "training loss 0.0006871878427430693\n",
      "testing loss 0.002821804770658202\n",
      "epochs 3240\n",
      "training loss 0.0005726614771665592\n",
      "epochs 3241\n",
      "training loss 0.0005929863600889759\n",
      "epochs 3242\n",
      "training loss 0.0005719152536267262\n",
      "epochs 3243\n",
      "training loss 0.000583945853511115\n",
      "epochs 3244\n",
      "training loss 0.0006405603854299883\n",
      "epochs 3245\n",
      "training loss 0.0005798308926458983\n",
      "epochs 3246\n",
      "training loss 0.0007432712108253482\n",
      "epochs 3247\n",
      "training loss 0.0008903235531628619\n",
      "epochs 3248\n",
      "training loss 0.0007298796138327036\n",
      "epochs 3249\n",
      "training loss 0.0007429552521226831\n",
      "testing loss 0.002847758648960012\n",
      "epochs 3250\n",
      "training loss 0.0008671719808765548\n",
      "epochs 3251\n",
      "training loss 0.0008994044808035371\n",
      "epochs 3252\n",
      "training loss 0.0006350779660523085\n",
      "epochs 3253\n",
      "training loss 0.0006848427193348316\n",
      "epochs 3254\n",
      "training loss 0.0008959442710236428\n",
      "epochs 3255\n",
      "training loss 0.0006287914447275509\n",
      "epochs 3256\n",
      "training loss 0.0005793913850867923\n",
      "epochs 3257\n",
      "training loss 0.0005683689169432843\n",
      "epochs 3258\n",
      "training loss 0.000592340493102708\n",
      "epochs 3259\n",
      "training loss 0.0005591195316434665\n",
      "testing loss 0.0029028137420891976\n",
      "epochs 3260\n",
      "training loss 0.0006788131070753565\n",
      "epochs 3261\n",
      "training loss 0.0006145150451121235\n",
      "epochs 3262\n",
      "training loss 0.000579103888691853\n",
      "epochs 3263\n",
      "training loss 0.0005825052415477226\n",
      "epochs 3264\n",
      "training loss 0.0006006299632164086\n",
      "epochs 3265\n",
      "training loss 0.000700861594914303\n",
      "epochs 3266\n",
      "training loss 0.0006962873028006722\n",
      "epochs 3267\n",
      "training loss 0.0007244510945721069\n",
      "epochs 3268\n",
      "training loss 0.0007023174356560203\n",
      "epochs 3269\n",
      "training loss 0.0006847075309808221\n",
      "testing loss 0.0028143295888617267\n",
      "epochs 3270\n",
      "training loss 0.0012993332305371104\n",
      "epochs 3271\n",
      "training loss 0.001389980519092769\n",
      "epochs 3272\n",
      "training loss 0.0011611788176774333\n",
      "epochs 3273\n",
      "training loss 0.001217592659666087\n",
      "epochs 3274\n",
      "training loss 0.0012397237447066385\n",
      "epochs 3275\n",
      "training loss 0.00094272163287895\n",
      "epochs 3276\n",
      "training loss 0.0011295445518508711\n",
      "epochs 3277\n",
      "training loss 0.0008545100530057488\n",
      "epochs 3278\n",
      "training loss 0.0010151516361831543\n",
      "epochs 3279\n",
      "training loss 0.0007146952759069716\n",
      "testing loss 0.0029400791972875595\n",
      "epochs 3280\n",
      "training loss 0.0007991348549838272\n",
      "epochs 3281\n",
      "training loss 0.0008815156175941795\n",
      "epochs 3282\n",
      "training loss 0.0008547553003696289\n",
      "epochs 3283\n",
      "training loss 0.0009443151597733295\n",
      "epochs 3284\n",
      "training loss 0.001001761854951069\n",
      "epochs 3285\n",
      "training loss 0.000838655303126218\n",
      "epochs 3286\n",
      "training loss 0.0007137147945742544\n",
      "epochs 3287\n",
      "training loss 0.0006473319022739334\n",
      "epochs 3288\n",
      "training loss 0.0006663015520619087\n",
      "epochs 3289\n",
      "training loss 0.0006060359822083717\n",
      "testing loss 0.0028808241035518443\n",
      "epochs 3290\n",
      "training loss 0.0006315329877835186\n",
      "epochs 3291\n",
      "training loss 0.0006187680779105635\n",
      "epochs 3292\n",
      "training loss 0.0006009196178063377\n",
      "epochs 3293\n",
      "training loss 0.000596519807313985\n",
      "epochs 3294\n",
      "training loss 0.0005914712290946213\n",
      "epochs 3295\n",
      "training loss 0.0005964149017167196\n",
      "epochs 3296\n",
      "training loss 0.0006619606389647129\n",
      "epochs 3297\n",
      "training loss 0.0006658525450656185\n",
      "epochs 3298\n",
      "training loss 0.0006481432511632565\n",
      "epochs 3299\n",
      "training loss 0.0006191006523350362\n",
      "testing loss 0.002888885940960113\n",
      "epochs 3300\n",
      "training loss 0.0006035853003570668\n",
      "epochs 3301\n",
      "training loss 0.0005764331157131001\n",
      "epochs 3302\n",
      "training loss 0.0006362999960855159\n",
      "epochs 3303\n",
      "training loss 0.0006149477326441386\n",
      "epochs 3304\n",
      "training loss 0.0005828372331436633\n",
      "epochs 3305\n",
      "training loss 0.0006604309066051567\n",
      "epochs 3306\n",
      "training loss 0.0005675300253918932\n",
      "epochs 3307\n",
      "training loss 0.0011254665997349246\n",
      "epochs 3308\n",
      "training loss 0.0007163906500194969\n",
      "epochs 3309\n",
      "training loss 0.0006136545201262465\n",
      "testing loss 0.002829472448491881\n",
      "epochs 3310\n",
      "training loss 0.0005747610650918416\n",
      "epochs 3311\n",
      "training loss 0.0005688466442010073\n",
      "epochs 3312\n",
      "training loss 0.0006447251683375642\n",
      "epochs 3313\n",
      "training loss 0.0006049099338657044\n",
      "epochs 3314\n",
      "training loss 0.0005675016900264067\n",
      "epochs 3315\n",
      "training loss 0.0006449201668323921\n",
      "epochs 3316\n",
      "training loss 0.0005931481197094233\n",
      "epochs 3317\n",
      "training loss 0.0005889060753319797\n",
      "epochs 3318\n",
      "training loss 0.0006135212229019863\n",
      "epochs 3319\n",
      "training loss 0.0005662299858584524\n",
      "testing loss 0.0028360729627575436\n",
      "epochs 3320\n",
      "training loss 0.0006196169405758075\n",
      "epochs 3321\n",
      "training loss 0.0006129204843683015\n",
      "epochs 3322\n",
      "training loss 0.0006258341286148831\n",
      "epochs 3323\n",
      "training loss 0.0007380907052963701\n",
      "epochs 3324\n",
      "training loss 0.0018816247064405117\n",
      "epochs 3325\n",
      "training loss 0.004208103423134217\n",
      "epochs 3326\n",
      "training loss 0.003002005500264613\n",
      "epochs 3327\n",
      "training loss 0.0021165341190501233\n",
      "epochs 3328\n",
      "training loss 0.001454867585526785\n",
      "epochs 3329\n",
      "training loss 0.0024281899406897373\n",
      "testing loss 0.0034473311116403724\n",
      "epochs 3330\n",
      "training loss 0.001593465963873933\n",
      "epochs 3331\n",
      "training loss 0.0015352357015803479\n",
      "epochs 3332\n",
      "training loss 0.0013799807318630643\n",
      "epochs 3333\n",
      "training loss 0.0011998506811890456\n",
      "epochs 3334\n",
      "training loss 0.001141883611380431\n",
      "epochs 3335\n",
      "training loss 0.0010384224396090002\n",
      "epochs 3336\n",
      "training loss 0.000976174022690294\n",
      "epochs 3337\n",
      "training loss 0.0008815057812956385\n",
      "epochs 3338\n",
      "training loss 0.0008705016513076246\n",
      "epochs 3339\n",
      "training loss 0.0008110153531453269\n",
      "testing loss 0.0027483967153507398\n",
      "epochs 3340\n",
      "training loss 0.0007863777087566847\n",
      "epochs 3341\n",
      "training loss 0.0007714697069242189\n",
      "epochs 3342\n",
      "training loss 0.0007695300162396193\n",
      "epochs 3343\n",
      "training loss 0.0007739080577744822\n",
      "epochs 3344\n",
      "training loss 0.0007184360406855489\n",
      "epochs 3345\n",
      "training loss 0.0007511768168076239\n",
      "epochs 3346\n",
      "training loss 0.0006868018035205098\n",
      "epochs 3347\n",
      "training loss 0.0007489929807239345\n",
      "epochs 3348\n",
      "training loss 0.0007179132668905832\n",
      "epochs 3349\n",
      "training loss 0.000657615528723627\n",
      "testing loss 0.002798571643099215\n",
      "epochs 3350\n",
      "training loss 0.0007671262789553026\n",
      "epochs 3351\n",
      "training loss 0.0007949747769006366\n",
      "epochs 3352\n",
      "training loss 0.0007029471447086952\n",
      "epochs 3353\n",
      "training loss 0.0008170226143707031\n",
      "epochs 3354\n",
      "training loss 0.0009458240241114486\n",
      "epochs 3355\n",
      "training loss 0.0006460286813999008\n",
      "epochs 3356\n",
      "training loss 0.0006418704924118454\n",
      "epochs 3357\n",
      "training loss 0.0007363613705521614\n",
      "epochs 3358\n",
      "training loss 0.0008024051017623316\n",
      "epochs 3359\n",
      "training loss 0.0006200488005505767\n",
      "testing loss 0.0027785515986508457\n",
      "epochs 3360\n",
      "training loss 0.000609795277280801\n",
      "epochs 3361\n",
      "training loss 0.0006175093589163751\n",
      "epochs 3362\n",
      "training loss 0.0006141612826567709\n",
      "epochs 3363\n",
      "training loss 0.0005807474601977026\n",
      "epochs 3364\n",
      "training loss 0.0005920586823047022\n",
      "epochs 3365\n",
      "training loss 0.0005970825138643361\n",
      "epochs 3366\n",
      "training loss 0.0005968573203665631\n",
      "epochs 3367\n",
      "training loss 0.000566817701445315\n",
      "epochs 3368\n",
      "training loss 0.0006389729986476817\n",
      "epochs 3369\n",
      "training loss 0.0006663750463107312\n",
      "testing loss 0.0028566918926188024\n",
      "epochs 3370\n",
      "training loss 0.0005870827805961406\n",
      "epochs 3371\n",
      "training loss 0.000617334876056636\n",
      "epochs 3372\n",
      "training loss 0.0006497208312816216\n",
      "epochs 3373\n",
      "training loss 0.0005993104716203823\n",
      "epochs 3374\n",
      "training loss 0.0006010272950790313\n",
      "epochs 3375\n",
      "training loss 0.0005937598233987326\n",
      "epochs 3376\n",
      "training loss 0.0010103118300896512\n",
      "epochs 3377\n",
      "training loss 0.0007966700771478172\n",
      "epochs 3378\n",
      "training loss 0.0009286715344760827\n",
      "epochs 3379\n",
      "training loss 0.0018868438920217048\n",
      "testing loss 0.003910012425960484\n",
      "epochs 3380\n",
      "training loss 0.0018528608586157935\n",
      "epochs 3381\n",
      "training loss 0.0012444436184263655\n",
      "epochs 3382\n",
      "training loss 0.0010463534164352846\n",
      "epochs 3383\n",
      "training loss 0.0010295666902507216\n",
      "epochs 3384\n",
      "training loss 0.0010515651930127813\n",
      "epochs 3385\n",
      "training loss 0.0008417660067753872\n",
      "epochs 3386\n",
      "training loss 0.0007341914111571415\n",
      "epochs 3387\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss 0.0007169523799549902\n",
      "epochs 3388\n",
      "training loss 0.0006811322795975908\n",
      "epochs 3389\n",
      "training loss 0.0006544840834202602\n",
      "testing loss 0.002715631501653384\n",
      "epochs 3390\n",
      "training loss 0.0005810496462424113\n",
      "epochs 3391\n",
      "training loss 0.0005996547369385495\n",
      "epochs 3392\n",
      "training loss 0.0006038910262767894\n",
      "epochs 3393\n",
      "training loss 0.0005904548323081982\n",
      "epochs 3394\n",
      "training loss 0.0006027130692621189\n",
      "epochs 3395\n",
      "training loss 0.0006043876482897062\n",
      "epochs 3396\n",
      "training loss 0.0006430598348626828\n",
      "epochs 3397\n",
      "training loss 0.0006830927305133012\n",
      "epochs 3398\n",
      "training loss 0.0006490643718279898\n",
      "epochs 3399\n",
      "training loss 0.0005693586155210301\n",
      "testing loss 0.002793170681804524\n",
      "epochs 3400\n",
      "training loss 0.0005763493772698028\n",
      "epochs 3401\n",
      "training loss 0.0005581589090308078\n",
      "epochs 3402\n",
      "training loss 0.0006314576707856792\n",
      "epochs 3403\n",
      "training loss 0.0005856677761554752\n",
      "epochs 3404\n",
      "training loss 0.0005687053528002896\n",
      "epochs 3405\n",
      "training loss 0.000763557455714758\n",
      "epochs 3406\n",
      "training loss 0.0006785535041807576\n",
      "epochs 3407\n",
      "training loss 0.0006424009117565336\n",
      "epochs 3408\n",
      "training loss 0.0006088364259325715\n",
      "epochs 3409\n",
      "training loss 0.0006052651554933468\n",
      "testing loss 0.0027271600036406296\n",
      "epochs 3410\n",
      "training loss 0.000590208281287329\n",
      "epochs 3411\n",
      "training loss 0.0006147703352436638\n",
      "epochs 3412\n",
      "training loss 0.0006317475795254711\n",
      "epochs 3413\n",
      "training loss 0.0006022456506872974\n",
      "epochs 3414\n",
      "training loss 0.0006008003937437179\n",
      "epochs 3415\n",
      "training loss 0.0006889488186586738\n",
      "epochs 3416\n",
      "training loss 0.0005723562583965631\n",
      "epochs 3417\n",
      "training loss 0.0009058398940518362\n",
      "epochs 3418\n",
      "training loss 0.0009656760176908406\n",
      "epochs 3419\n",
      "training loss 0.0007125858712331378\n",
      "testing loss 0.002645658244088239\n",
      "epochs 3420\n",
      "training loss 0.0006116881784714056\n",
      "epochs 3421\n",
      "training loss 0.0005762942406380022\n",
      "epochs 3422\n",
      "training loss 0.0006310750530766589\n",
      "epochs 3423\n",
      "training loss 0.0006404061698939334\n",
      "epochs 3424\n",
      "training loss 0.0007992460087046457\n",
      "epochs 3425\n",
      "training loss 0.0005985741915944171\n",
      "epochs 3426\n",
      "training loss 0.0005493396289836287\n",
      "epochs 3427\n",
      "training loss 0.0005711857158702014\n",
      "epochs 3428\n",
      "training loss 0.0005714356990199887\n",
      "epochs 3429\n",
      "training loss 0.0005720170817371899\n",
      "testing loss 0.0026760554743653284\n",
      "epochs 3430\n",
      "training loss 0.0005494472974986348\n",
      "epochs 3431\n",
      "training loss 0.0005833067839057963\n",
      "epochs 3432\n",
      "training loss 0.0006402712224205633\n",
      "epochs 3433\n",
      "training loss 0.0006402852816937497\n",
      "epochs 3434\n",
      "training loss 0.0007533926213702249\n",
      "epochs 3435\n",
      "training loss 0.0013393451331259745\n",
      "epochs 3436\n",
      "training loss 0.0012494232959367369\n",
      "epochs 3437\n",
      "training loss 0.0011889805666441353\n",
      "epochs 3438\n",
      "training loss 0.0008911354166326767\n",
      "epochs 3439\n",
      "training loss 0.0008217362544745614\n",
      "testing loss 0.0028286997116573737\n",
      "epochs 3440\n",
      "training loss 0.0010286988465803306\n",
      "epochs 3441\n",
      "training loss 0.0013462613815495511\n",
      "epochs 3442\n",
      "training loss 0.0012809222009093825\n",
      "epochs 3443\n",
      "training loss 0.001352590821735776\n",
      "epochs 3444\n",
      "training loss 0.0013602626547825985\n",
      "epochs 3445\n",
      "training loss 0.0009853257727773866\n",
      "epochs 3446\n",
      "training loss 0.0008794489345126885\n",
      "epochs 3447\n",
      "training loss 0.0008544916917618058\n",
      "epochs 3448\n",
      "training loss 0.0008999874769698681\n",
      "epochs 3449\n",
      "training loss 0.0007296729311672546\n",
      "testing loss 0.002658911286324844\n",
      "epochs 3450\n",
      "training loss 0.0006924040308066482\n",
      "epochs 3451\n",
      "training loss 0.0007034741961475077\n",
      "epochs 3452\n",
      "training loss 0.000921917724437972\n",
      "epochs 3453\n",
      "training loss 0.0008706852041240102\n",
      "epochs 3454\n",
      "training loss 0.0008670008662765375\n",
      "epochs 3455\n",
      "training loss 0.0007852141545111693\n",
      "epochs 3456\n",
      "training loss 0.000797747974220301\n",
      "epochs 3457\n",
      "training loss 0.0006612217706439897\n",
      "epochs 3458\n",
      "training loss 0.0005624539809411896\n",
      "epochs 3459\n",
      "training loss 0.0006001710265947048\n",
      "testing loss 0.002676873830731641\n",
      "epochs 3460\n",
      "training loss 0.0005574036441073898\n",
      "epochs 3461\n",
      "training loss 0.0005619587988159577\n",
      "epochs 3462\n",
      "training loss 0.0005625489654053444\n",
      "epochs 3463\n",
      "training loss 0.0005962588436162739\n",
      "epochs 3464\n",
      "training loss 0.000557968917014049\n",
      "epochs 3465\n",
      "training loss 0.000567735075765915\n",
      "epochs 3466\n",
      "training loss 0.0005707627159329613\n",
      "epochs 3467\n",
      "training loss 0.000595369068573096\n",
      "epochs 3468\n",
      "training loss 0.0008557230938476508\n",
      "epochs 3469\n",
      "training loss 0.0010084179786457128\n",
      "testing loss 0.002686154205477565\n",
      "epochs 3470\n",
      "training loss 0.0007325290851960224\n",
      "epochs 3471\n",
      "training loss 0.000585041378393322\n",
      "epochs 3472\n",
      "training loss 0.0005407476274715595\n",
      "epochs 3473\n",
      "training loss 0.0005811940509568345\n",
      "epochs 3474\n",
      "training loss 0.0005856867199183348\n",
      "epochs 3475\n",
      "training loss 0.0006882240188111322\n",
      "epochs 3476\n",
      "training loss 0.000705643993923384\n",
      "epochs 3477\n",
      "training loss 0.0007261730722395143\n",
      "epochs 3478\n",
      "training loss 0.000654260723640729\n",
      "epochs 3479\n",
      "training loss 0.0006169314758242094\n",
      "testing loss 0.0025798538902028073\n",
      "epochs 3480\n",
      "training loss 0.0005918929972056028\n",
      "epochs 3481\n",
      "training loss 0.000549780477707396\n",
      "epochs 3482\n",
      "training loss 0.000508431800093366\n",
      "epochs 3483\n",
      "training loss 0.0005646275219650469\n",
      "epochs 3484\n",
      "training loss 0.0006454390878640511\n",
      "epochs 3485\n",
      "training loss 0.0005674889761640331\n",
      "epochs 3486\n",
      "training loss 0.0005449718903816704\n",
      "epochs 3487\n",
      "training loss 0.0007569968992685701\n",
      "epochs 3488\n",
      "training loss 0.0005903894197242476\n",
      "epochs 3489\n",
      "training loss 0.0005549652545109935\n",
      "testing loss 0.0026045687759215846\n",
      "epochs 3490\n",
      "training loss 0.0005445927997207478\n",
      "epochs 3491\n",
      "training loss 0.0006431675600815043\n",
      "epochs 3492\n",
      "training loss 0.0006583049017787376\n",
      "epochs 3493\n",
      "training loss 0.0006101888981838866\n",
      "epochs 3494\n",
      "training loss 0.0007211105965430308\n",
      "epochs 3495\n",
      "training loss 0.000581093628809074\n",
      "epochs 3496\n",
      "training loss 0.0006891646136538236\n",
      "epochs 3497\n",
      "training loss 0.0005567790981980839\n",
      "epochs 3498\n",
      "training loss 0.0005509316866211083\n",
      "epochs 3499\n",
      "training loss 0.0005745129122102979\n",
      "testing loss 0.0026150650467809474\n",
      "epochs 3500\n",
      "training loss 0.0006281273767895612\n",
      "epochs 3501\n",
      "training loss 0.0005953851070836764\n",
      "epochs 3502\n",
      "training loss 0.0006537665499764916\n",
      "epochs 3503\n",
      "training loss 0.0005666144517049375\n",
      "epochs 3504\n",
      "training loss 0.0005784927400983984\n",
      "epochs 3505\n",
      "training loss 0.0005568592098971834\n",
      "epochs 3506\n",
      "training loss 0.0005556930884107449\n",
      "epochs 3507\n",
      "training loss 0.0006133586703127358\n",
      "epochs 3508\n",
      "training loss 0.00060438003812458\n",
      "epochs 3509\n",
      "training loss 0.0005491642614205206\n",
      "testing loss 0.0026905533534818137\n",
      "epochs 3510\n",
      "training loss 0.0005443426558364319\n",
      "epochs 3511\n",
      "training loss 0.0005102100655419531\n",
      "epochs 3512\n",
      "training loss 0.0006043541529654642\n",
      "epochs 3513\n",
      "training loss 0.0005950044518043669\n",
      "epochs 3514\n",
      "training loss 0.0005480917556335906\n",
      "epochs 3515\n",
      "training loss 0.0005308646473596241\n",
      "epochs 3516\n",
      "training loss 0.0005424712655611484\n",
      "epochs 3517\n",
      "training loss 0.0005655801422627908\n",
      "epochs 3518\n",
      "training loss 0.0005600464378666178\n",
      "epochs 3519\n",
      "training loss 0.000662772867868946\n",
      "testing loss 0.002805734078023345\n",
      "epochs 3520\n",
      "training loss 0.0007407073785004554\n",
      "epochs 3521\n",
      "training loss 0.0007055789980815163\n",
      "epochs 3522\n",
      "training loss 0.0007228193263945065\n",
      "epochs 3523\n",
      "training loss 0.0007504055842312795\n",
      "epochs 3524\n",
      "training loss 0.0008356351470666737\n",
      "epochs 3525\n",
      "training loss 0.0005761968522328362\n",
      "epochs 3526\n",
      "training loss 0.000568645952324635\n",
      "epochs 3527\n",
      "training loss 0.000583337242170138\n",
      "epochs 3528\n",
      "training loss 0.0005827688048190315\n",
      "epochs 3529\n",
      "training loss 0.0006503008229418808\n",
      "testing loss 0.002839708409324975\n",
      "epochs 3530\n",
      "training loss 0.0006132485506182826\n",
      "epochs 3531\n",
      "training loss 0.0006318744836377948\n",
      "epochs 3532\n",
      "training loss 0.0005851021192374846\n",
      "epochs 3533\n",
      "training loss 0.0005378168592714962\n",
      "epochs 3534\n",
      "training loss 0.000594534894761468\n",
      "epochs 3535\n",
      "training loss 0.0005001377580244389\n",
      "epochs 3536\n",
      "training loss 0.0005529865318743688\n",
      "epochs 3537\n",
      "training loss 0.0008034012293673792\n",
      "epochs 3538\n",
      "training loss 0.0007177187366224259\n",
      "epochs 3539\n",
      "training loss 0.0005885078578813732\n",
      "testing loss 0.0028489946399267154\n",
      "epochs 3540\n",
      "training loss 0.0005229744842767116\n",
      "epochs 3541\n",
      "training loss 0.0005549970029861777\n",
      "epochs 3542\n",
      "training loss 0.0005511729384448357\n",
      "epochs 3543\n",
      "training loss 0.0005520361440792669\n",
      "epochs 3544\n",
      "training loss 0.0005347834532729444\n",
      "epochs 3545\n",
      "training loss 0.0005448514602350858\n",
      "epochs 3546\n",
      "training loss 0.0005572265013875468\n",
      "epochs 3547\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss 0.0006180277515675499\n",
      "epochs 3548\n",
      "training loss 0.0005950507920909118\n",
      "epochs 3549\n",
      "training loss 0.0006935129235470299\n",
      "testing loss 0.0030080147053722743\n",
      "epochs 3550\n",
      "training loss 0.0011556180920112187\n",
      "epochs 3551\n",
      "training loss 0.0006723235759177842\n",
      "epochs 3552\n",
      "training loss 0.0006145532755145809\n",
      "epochs 3553\n",
      "training loss 0.0005520854162449996\n",
      "epochs 3554\n",
      "training loss 0.000506183583948246\n",
      "epochs 3555\n",
      "training loss 0.0005670535618065655\n",
      "epochs 3556\n",
      "training loss 0.0005554073280725617\n",
      "epochs 3557\n",
      "training loss 0.0005801362043004597\n",
      "epochs 3558\n",
      "training loss 0.0005550209670270988\n",
      "epochs 3559\n",
      "training loss 0.000533965403248774\n",
      "testing loss 0.002714116136619412\n",
      "epochs 3560\n",
      "training loss 0.0005627103211106251\n",
      "epochs 3561\n",
      "training loss 0.00055323625238199\n",
      "epochs 3562\n",
      "training loss 0.0005289282179848039\n",
      "epochs 3563\n",
      "training loss 0.000525515046894924\n",
      "epochs 3564\n",
      "training loss 0.0005229226858277259\n",
      "epochs 3565\n",
      "training loss 0.0005529915460485875\n",
      "epochs 3566\n",
      "training loss 0.0006863034351008426\n",
      "epochs 3567\n",
      "training loss 0.0005902133774653496\n",
      "epochs 3568\n",
      "training loss 0.0005494931083431575\n",
      "epochs 3569\n",
      "training loss 0.0005799342512286135\n",
      "testing loss 0.0027304130481681553\n",
      "epochs 3570\n",
      "training loss 0.0005444771334908245\n",
      "epochs 3571\n",
      "training loss 0.0006047916670448761\n",
      "epochs 3572\n",
      "training loss 0.0005531499021131783\n",
      "epochs 3573\n",
      "training loss 0.0005309723679784482\n",
      "epochs 3574\n",
      "training loss 0.0007931279213313512\n",
      "epochs 3575\n",
      "training loss 0.0006977271028202718\n",
      "epochs 3576\n",
      "training loss 0.0008186216393236558\n",
      "epochs 3577\n",
      "training loss 0.0008647339911260968\n",
      "epochs 3578\n",
      "training loss 0.0007621000676046446\n",
      "epochs 3579\n",
      "training loss 0.0007169029773085585\n",
      "testing loss 0.0028306068435595337\n",
      "epochs 3580\n",
      "training loss 0.0007079239558898434\n",
      "epochs 3581\n",
      "training loss 0.0006692118636306975\n",
      "epochs 3582\n",
      "training loss 0.0007115302918447708\n",
      "epochs 3583\n",
      "training loss 0.000721915800631822\n",
      "epochs 3584\n",
      "training loss 0.000686716401381956\n",
      "epochs 3585\n",
      "training loss 0.0007175985669949315\n",
      "epochs 3586\n",
      "training loss 0.001012058811220496\n",
      "epochs 3587\n",
      "training loss 0.0007006159061275841\n",
      "epochs 3588\n",
      "training loss 0.0008274438865461576\n",
      "epochs 3589\n",
      "training loss 0.0009679378595593807\n",
      "testing loss 0.00266558759357014\n",
      "epochs 3590\n",
      "training loss 0.0006468029183053941\n",
      "epochs 3591\n",
      "training loss 0.00056760198713385\n",
      "epochs 3592\n",
      "training loss 0.0005756433840698102\n",
      "epochs 3593\n",
      "training loss 0.00051221076378211\n",
      "epochs 3594\n",
      "training loss 0.0005419004602728576\n",
      "epochs 3595\n",
      "training loss 0.0005209426711225673\n",
      "epochs 3596\n",
      "training loss 0.0005049384723659491\n",
      "epochs 3597\n",
      "training loss 0.000533084426054697\n",
      "epochs 3598\n",
      "training loss 0.0005489219027666211\n",
      "epochs 3599\n",
      "training loss 0.0005051209632021383\n",
      "testing loss 0.002646090620088371\n",
      "epochs 3600\n",
      "training loss 0.0006563249994196723\n",
      "epochs 3601\n",
      "training loss 0.0007159080959489926\n",
      "epochs 3602\n",
      "training loss 0.001040212993685575\n",
      "epochs 3603\n",
      "training loss 0.001670881738712145\n",
      "epochs 3604\n",
      "training loss 0.0009367396633245481\n",
      "epochs 3605\n",
      "training loss 0.0006512068303147654\n",
      "epochs 3606\n",
      "training loss 0.0005634257637670598\n",
      "epochs 3607\n",
      "training loss 0.0005136744262888394\n",
      "epochs 3608\n",
      "training loss 0.0005154047914324923\n",
      "epochs 3609\n",
      "training loss 0.00047486377749054217\n",
      "testing loss 0.0025746042461213753\n",
      "epochs 3610\n",
      "training loss 0.0005073713728383828\n",
      "epochs 3611\n",
      "training loss 0.0005647809234784639\n",
      "epochs 3612\n",
      "training loss 0.0005595936104839266\n",
      "epochs 3613\n",
      "training loss 0.0006025901602476405\n",
      "epochs 3614\n",
      "training loss 0.0005375899156515902\n",
      "epochs 3615\n",
      "training loss 0.0005144080358393219\n",
      "epochs 3616\n",
      "training loss 0.0005147833909484131\n",
      "epochs 3617\n",
      "training loss 0.0005432919586377394\n",
      "epochs 3618\n",
      "training loss 0.0005648384828935731\n",
      "epochs 3619\n",
      "training loss 0.0006161207388230178\n",
      "testing loss 0.002701910293548771\n",
      "epochs 3620\n",
      "training loss 0.0006774834855771015\n",
      "epochs 3621\n",
      "training loss 0.0007666584102884161\n",
      "epochs 3622\n",
      "training loss 0.0008262330069069363\n",
      "epochs 3623\n",
      "training loss 0.0007639729343906702\n",
      "epochs 3624\n",
      "training loss 0.000494381727344331\n",
      "epochs 3625\n",
      "training loss 0.000511351410822524\n",
      "epochs 3626\n",
      "training loss 0.0006579633762014005\n",
      "epochs 3627\n",
      "training loss 0.000606131498856855\n",
      "epochs 3628\n",
      "training loss 0.0005354832995493294\n",
      "epochs 3629\n",
      "training loss 0.0005271586424622991\n",
      "testing loss 0.0026578351282283454\n",
      "epochs 3630\n",
      "training loss 0.0005213285229836894\n",
      "epochs 3631\n",
      "training loss 0.0005518585857673404\n",
      "epochs 3632\n",
      "training loss 0.000532299246285875\n",
      "epochs 3633\n",
      "training loss 0.0005872589470549716\n",
      "epochs 3634\n",
      "training loss 0.0005169899629621474\n",
      "epochs 3635\n",
      "training loss 0.0005173078219060953\n",
      "epochs 3636\n",
      "training loss 0.0007944680291431811\n",
      "epochs 3637\n",
      "training loss 0.0007208946084364468\n",
      "epochs 3638\n",
      "training loss 0.0005865151974291889\n",
      "epochs 3639\n",
      "training loss 0.0006140043463106451\n",
      "testing loss 0.0027277470638163073\n",
      "epochs 3640\n",
      "training loss 0.0005966849703133661\n",
      "epochs 3641\n",
      "training loss 0.000588101063116162\n",
      "epochs 3642\n",
      "training loss 0.0005655975757226189\n",
      "epochs 3643\n",
      "training loss 0.0005201985207662315\n",
      "epochs 3644\n",
      "training loss 0.0005039747857126354\n",
      "epochs 3645\n",
      "training loss 0.0005038141863531006\n",
      "epochs 3646\n",
      "training loss 0.0005090510774132057\n",
      "epochs 3647\n",
      "training loss 0.0005994661867556284\n",
      "epochs 3648\n",
      "training loss 0.0005532614198530313\n",
      "epochs 3649\n",
      "training loss 0.0005475047850694031\n",
      "testing loss 0.0026598780730521265\n",
      "epochs 3650\n",
      "training loss 0.0004913080245713592\n",
      "epochs 3651\n",
      "training loss 0.0005733121251425561\n",
      "epochs 3652\n",
      "training loss 0.0006152463328138582\n",
      "epochs 3653\n",
      "training loss 0.000579901363280967\n",
      "epochs 3654\n",
      "training loss 0.0005480615249806647\n",
      "epochs 3655\n",
      "training loss 0.0005295601630785806\n",
      "epochs 3656\n",
      "training loss 0.0005146544074602878\n",
      "epochs 3657\n",
      "training loss 0.0007969218615504791\n",
      "epochs 3658\n",
      "training loss 0.0006299465923891389\n",
      "epochs 3659\n",
      "training loss 0.00048500699494288823\n",
      "testing loss 0.0027036274211969993\n",
      "epochs 3660\n",
      "training loss 0.0005082563243418547\n",
      "epochs 3661\n",
      "training loss 0.0005745440731242605\n",
      "epochs 3662\n",
      "training loss 0.0005100451220155306\n",
      "epochs 3663\n",
      "training loss 0.0005156808149913117\n",
      "epochs 3664\n",
      "training loss 0.0005323312436916941\n",
      "epochs 3665\n",
      "training loss 0.0005887029463415371\n",
      "epochs 3666\n",
      "training loss 0.0005913886993891336\n",
      "epochs 3667\n",
      "training loss 0.0005005197819799332\n",
      "epochs 3668\n",
      "training loss 0.0005196446656726448\n",
      "epochs 3669\n",
      "training loss 0.0004907803612444154\n",
      "testing loss 0.0027372284353948495\n",
      "epochs 3670\n",
      "training loss 0.0005147937558928228\n",
      "epochs 3671\n",
      "training loss 0.0005861532105321184\n",
      "epochs 3672\n",
      "training loss 0.0005350109693271569\n",
      "epochs 3673\n",
      "training loss 0.0005700921388215592\n",
      "epochs 3674\n",
      "training loss 0.0005278326224218658\n",
      "epochs 3675\n",
      "training loss 0.000542743407872061\n",
      "epochs 3676\n",
      "training loss 0.0005429423761647478\n",
      "epochs 3677\n",
      "training loss 0.0004909118087389039\n",
      "epochs 3678\n",
      "training loss 0.0005179423105331155\n",
      "epochs 3679\n",
      "training loss 0.0005417583906764057\n",
      "testing loss 0.002855227866741756\n",
      "epochs 3680\n",
      "training loss 0.000511550877595711\n",
      "epochs 3681\n",
      "training loss 0.0006197837764704402\n",
      "epochs 3682\n",
      "training loss 0.0005542869612575993\n",
      "epochs 3683\n",
      "training loss 0.000530353472193018\n",
      "epochs 3684\n",
      "training loss 0.0005588477921861827\n",
      "epochs 3685\n",
      "training loss 0.0005236956737454312\n",
      "epochs 3686\n",
      "training loss 0.0005239182356907774\n",
      "epochs 3687\n",
      "training loss 0.0005217800244170957\n",
      "epochs 3688\n",
      "training loss 0.0005003995556486233\n",
      "epochs 3689\n",
      "training loss 0.000526212391922658\n",
      "testing loss 0.002621388073155247\n",
      "epochs 3690\n",
      "training loss 0.0005252482382811346\n",
      "epochs 3691\n",
      "training loss 0.0005526985070989453\n",
      "epochs 3692\n",
      "training loss 0.000537391282893338\n",
      "epochs 3693\n",
      "training loss 0.001541815918592855\n",
      "epochs 3694\n",
      "training loss 0.003659786321760628\n",
      "epochs 3695\n",
      "training loss 0.0022301208153565196\n",
      "epochs 3696\n",
      "training loss 0.0018459681512102892\n",
      "epochs 3697\n",
      "training loss 0.001544635338279897\n",
      "epochs 3698\n",
      "training loss 0.001304270689181791\n",
      "epochs 3699\n",
      "training loss 0.001292412895192661\n",
      "testing loss 0.002711710660447571\n",
      "epochs 3700\n",
      "training loss 0.00106360964764739\n",
      "epochs 3701\n",
      "training loss 0.0009706860396156149\n",
      "epochs 3702\n",
      "training loss 0.0008710933000692888\n",
      "epochs 3703\n",
      "training loss 0.0008081292145635004\n",
      "epochs 3704\n",
      "training loss 0.0007937754890782402\n",
      "epochs 3705\n",
      "training loss 0.0007267689539719724\n",
      "epochs 3706\n",
      "training loss 0.0007148773046203331\n",
      "epochs 3707\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss 0.0007120528841167575\n",
      "epochs 3708\n",
      "training loss 0.0006759037840637268\n",
      "epochs 3709\n",
      "training loss 0.0007238997112252639\n",
      "testing loss 0.002544318044274147\n",
      "epochs 3710\n",
      "training loss 0.0005992964863894638\n",
      "epochs 3711\n",
      "training loss 0.0007000166506507918\n",
      "epochs 3712\n",
      "training loss 0.0006820363645253584\n",
      "epochs 3713\n",
      "training loss 0.0007109137240119312\n",
      "epochs 3714\n",
      "training loss 0.0007482770804562082\n",
      "epochs 3715\n",
      "training loss 0.0007774787215448032\n",
      "epochs 3716\n",
      "training loss 0.0007497229346917733\n",
      "epochs 3717\n",
      "training loss 0.0005642706064767796\n",
      "epochs 3718\n",
      "training loss 0.0006808482260354101\n",
      "epochs 3719\n",
      "training loss 0.0009359633565086328\n",
      "testing loss 0.0029108478482944744\n",
      "epochs 3720\n",
      "training loss 0.0006240027067449657\n",
      "epochs 3721\n",
      "training loss 0.0007047444012470396\n",
      "epochs 3722\n",
      "training loss 0.0005405153544891433\n",
      "epochs 3723\n",
      "training loss 0.000642554404208363\n",
      "epochs 3724\n",
      "training loss 0.0005657597301466996\n",
      "epochs 3725\n",
      "training loss 0.0005093251708307584\n",
      "epochs 3726\n",
      "training loss 0.000639512043518487\n",
      "epochs 3727\n",
      "training loss 0.0005698421242679427\n",
      "epochs 3728\n",
      "training loss 0.0005588593836491616\n",
      "epochs 3729\n",
      "training loss 0.0006093636795943518\n",
      "testing loss 0.0026780439508543846\n",
      "epochs 3730\n",
      "training loss 0.0005909312257435637\n",
      "epochs 3731\n",
      "training loss 0.0006238900196326665\n",
      "epochs 3732\n",
      "training loss 0.0005555007488029446\n",
      "epochs 3733\n",
      "training loss 0.000545192735466404\n",
      "epochs 3734\n",
      "training loss 0.0005783079132596229\n",
      "epochs 3735\n",
      "training loss 0.0005167412443693705\n",
      "epochs 3736\n",
      "training loss 0.0006399224614894363\n",
      "epochs 3737\n",
      "training loss 0.0005199522349086808\n",
      "epochs 3738\n",
      "training loss 0.0005722980344587354\n",
      "epochs 3739\n",
      "training loss 0.0005684266899928938\n",
      "testing loss 0.0027397213729118256\n",
      "epochs 3740\n",
      "training loss 0.0006316600667842095\n",
      "epochs 3741\n",
      "training loss 0.0006435571536867622\n",
      "epochs 3742\n",
      "training loss 0.0007827903180684623\n",
      "epochs 3743\n",
      "training loss 0.0009638977931114622\n",
      "epochs 3744\n",
      "training loss 0.0008240159072681107\n",
      "epochs 3745\n",
      "training loss 0.0006933850866082863\n",
      "epochs 3746\n",
      "training loss 0.0006861151750716112\n",
      "epochs 3747\n",
      "training loss 0.0007646014201093895\n",
      "epochs 3748\n",
      "training loss 0.000802819463435\n",
      "epochs 3749\n",
      "training loss 0.0007285648648341195\n",
      "testing loss 0.0024751337019706817\n",
      "epochs 3750\n",
      "training loss 0.0007954543077112331\n",
      "epochs 3751\n",
      "training loss 0.0007151998360117608\n",
      "epochs 3752\n",
      "training loss 0.0007333978500159168\n",
      "epochs 3753\n",
      "training loss 0.0008575351521164734\n",
      "epochs 3754\n",
      "training loss 0.0008453017745222217\n",
      "epochs 3755\n",
      "training loss 0.0007029207574421579\n",
      "epochs 3756\n",
      "training loss 0.0007212575188714807\n",
      "epochs 3757\n",
      "training loss 0.0007631566957924459\n",
      "epochs 3758\n",
      "training loss 0.0007060991603163521\n",
      "epochs 3759\n",
      "training loss 0.0007150012621688614\n",
      "testing loss 0.0026647268661548853\n",
      "epochs 3760\n",
      "training loss 0.0009022357682187936\n",
      "epochs 3761\n",
      "training loss 0.0006778425460795966\n",
      "epochs 3762\n",
      "training loss 0.0005572829269917291\n",
      "epochs 3763\n",
      "training loss 0.0006026217676267469\n",
      "epochs 3764\n",
      "training loss 0.0005693481832574261\n",
      "epochs 3765\n",
      "training loss 0.0005766879297448973\n",
      "epochs 3766\n",
      "training loss 0.0005390948861360402\n",
      "epochs 3767\n",
      "training loss 0.0005354250011269263\n",
      "epochs 3768\n",
      "training loss 0.0005688704083189594\n",
      "epochs 3769\n",
      "training loss 0.0006584620052286195\n",
      "testing loss 0.0030054620104670157\n",
      "epochs 3770\n",
      "training loss 0.00153474292118459\n",
      "epochs 3771\n",
      "training loss 0.0010771462166579977\n",
      "epochs 3772\n",
      "training loss 0.0012081392558070754\n",
      "epochs 3773\n",
      "training loss 0.0008065822315940175\n",
      "epochs 3774\n",
      "training loss 0.0006197837736396725\n",
      "epochs 3775\n",
      "training loss 0.000603412180910054\n",
      "epochs 3776\n",
      "training loss 0.0005595603519710952\n",
      "epochs 3777\n",
      "training loss 0.0006802896299366881\n",
      "epochs 3778\n",
      "training loss 0.0005336865820068481\n",
      "epochs 3779\n",
      "training loss 0.000527084880617467\n",
      "testing loss 0.002637057886326831\n",
      "epochs 3780\n",
      "training loss 0.0008966887571797975\n",
      "epochs 3781\n",
      "training loss 0.001344700868748904\n",
      "epochs 3782\n",
      "training loss 0.0013500207168719587\n",
      "epochs 3783\n",
      "training loss 0.0019314287102634037\n",
      "epochs 3784\n",
      "training loss 0.001378919407608565\n",
      "epochs 3785\n",
      "training loss 0.000906156946138527\n",
      "epochs 3786\n",
      "training loss 0.0008064274548582654\n",
      "epochs 3787\n",
      "training loss 0.0007572573386550256\n",
      "epochs 3788\n",
      "training loss 0.0007170784990600449\n",
      "epochs 3789\n",
      "training loss 0.0006943999288609325\n",
      "testing loss 0.002571813008790928\n",
      "epochs 3790\n",
      "training loss 0.0006782026142469327\n",
      "epochs 3791\n",
      "training loss 0.0008896082312563621\n",
      "epochs 3792\n",
      "training loss 0.0005576311398154595\n",
      "epochs 3793\n",
      "training loss 0.000516655001050501\n",
      "epochs 3794\n",
      "training loss 0.0004977545047059973\n",
      "epochs 3795\n",
      "training loss 0.0005291698714236992\n",
      "epochs 3796\n",
      "training loss 0.0005366439751694743\n",
      "epochs 3797\n",
      "training loss 0.0005327031055449771\n",
      "epochs 3798\n",
      "training loss 0.0005992739287093225\n",
      "epochs 3799\n",
      "training loss 0.0004938724974901373\n",
      "testing loss 0.002663222463563719\n",
      "epochs 3800\n",
      "training loss 0.0005172526810281431\n",
      "epochs 3801\n",
      "training loss 0.0005113336935782335\n",
      "epochs 3802\n",
      "training loss 0.0005920743176078078\n",
      "epochs 3803\n",
      "training loss 0.0006774938841368777\n",
      "epochs 3804\n",
      "training loss 0.0005938769970124582\n",
      "epochs 3805\n",
      "training loss 0.0005689674873742923\n",
      "epochs 3806\n",
      "training loss 0.0005241314653911569\n",
      "epochs 3807\n",
      "training loss 0.0005647898840967078\n",
      "epochs 3808\n",
      "training loss 0.0005293884160673659\n",
      "epochs 3809\n",
      "training loss 0.000576366053853116\n",
      "testing loss 0.0026197650714229184\n",
      "epochs 3810\n",
      "training loss 0.000521510943227609\n",
      "epochs 3811\n",
      "training loss 0.0005237509978271307\n",
      "epochs 3812\n",
      "training loss 0.0005800009864003123\n",
      "epochs 3813\n",
      "training loss 0.0005993512744829908\n",
      "epochs 3814\n",
      "training loss 0.0005911330565616296\n",
      "epochs 3815\n",
      "training loss 0.0006544342932240375\n",
      "epochs 3816\n",
      "training loss 0.0005937315557062863\n",
      "epochs 3817\n",
      "training loss 0.000556245854631842\n",
      "epochs 3818\n",
      "training loss 0.0005734334303502072\n",
      "epochs 3819\n",
      "training loss 0.0005534287912050675\n",
      "testing loss 0.002737826989313046\n",
      "epochs 3820\n",
      "training loss 0.0005245694704318425\n",
      "epochs 3821\n",
      "training loss 0.000585666013914118\n",
      "epochs 3822\n",
      "training loss 0.0005322820943105105\n",
      "epochs 3823\n",
      "training loss 0.000774193397124431\n",
      "epochs 3824\n",
      "training loss 0.0005403151356163619\n",
      "epochs 3825\n",
      "training loss 0.0005467100859595616\n",
      "epochs 3826\n",
      "training loss 0.0005808997098540485\n",
      "epochs 3827\n",
      "training loss 0.0005623024539267616\n",
      "epochs 3828\n",
      "training loss 0.0005037621890426837\n",
      "epochs 3829\n",
      "training loss 0.0005381211922765854\n",
      "testing loss 0.002627527534859321\n",
      "epochs 3830\n",
      "training loss 0.0005364382987534825\n",
      "epochs 3831\n",
      "training loss 0.0005225529119310091\n",
      "epochs 3832\n",
      "training loss 0.0005823991307068764\n",
      "epochs 3833\n",
      "training loss 0.0005789338993219982\n",
      "epochs 3834\n",
      "training loss 0.0005204964883478308\n",
      "epochs 3835\n",
      "training loss 0.0005267578655553806\n",
      "epochs 3836\n",
      "training loss 0.0005400420617174901\n",
      "epochs 3837\n",
      "training loss 0.0006163164247520902\n",
      "epochs 3838\n",
      "training loss 0.0005882928664704054\n",
      "epochs 3839\n",
      "training loss 0.0005388418806994215\n",
      "testing loss 0.0026114606092096115\n",
      "epochs 3840\n",
      "training loss 0.0004984997059848431\n",
      "epochs 3841\n",
      "training loss 0.00054488071285777\n",
      "epochs 3842\n",
      "training loss 0.000549411543221765\n",
      "epochs 3843\n",
      "training loss 0.0005299882889169022\n",
      "epochs 3844\n",
      "training loss 0.0005412394675216708\n",
      "epochs 3845\n",
      "training loss 0.000563878834861158\n",
      "epochs 3846\n",
      "training loss 0.0005498437313002033\n",
      "epochs 3847\n",
      "training loss 0.0005384575296759515\n",
      "epochs 3848\n",
      "training loss 0.000543503618677427\n",
      "epochs 3849\n",
      "training loss 0.0004841014715428195\n",
      "testing loss 0.0026451630591322398\n",
      "epochs 3850\n",
      "training loss 0.0006100449957538079\n",
      "epochs 3851\n",
      "training loss 0.0008908928562865782\n",
      "epochs 3852\n",
      "training loss 0.0006112691746050871\n",
      "epochs 3853\n",
      "training loss 0.0005746384058041515\n",
      "epochs 3854\n",
      "training loss 0.0007273597544764018\n",
      "epochs 3855\n",
      "training loss 0.000564781323855171\n",
      "epochs 3856\n",
      "training loss 0.0006089087993743062\n",
      "epochs 3857\n",
      "training loss 0.0005199133030508325\n",
      "epochs 3858\n",
      "training loss 0.0005577696761715093\n",
      "epochs 3859\n",
      "training loss 0.0005483998517904963\n",
      "testing loss 0.0025477743206433422\n",
      "epochs 3860\n",
      "training loss 0.0006122369978946313\n",
      "epochs 3861\n",
      "training loss 0.0007693904412572066\n",
      "epochs 3862\n",
      "training loss 0.001705050404221782\n",
      "epochs 3863\n",
      "training loss 0.001646760436791168\n",
      "epochs 3864\n",
      "training loss 0.0011532036948518822\n",
      "epochs 3865\n",
      "training loss 0.000998139934912239\n",
      "epochs 3866\n",
      "training loss 0.0008834960055183676\n",
      "epochs 3867\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss 0.0008790927508663341\n",
      "epochs 3868\n",
      "training loss 0.000811785838664382\n",
      "epochs 3869\n",
      "training loss 0.0008419305997289219\n",
      "testing loss 0.002634064994541043\n",
      "epochs 3870\n",
      "training loss 0.0008421936839370278\n",
      "epochs 3871\n",
      "training loss 0.0007951962191888943\n",
      "epochs 3872\n",
      "training loss 0.0008281622208318019\n",
      "epochs 3873\n",
      "training loss 0.0008827279476480032\n",
      "epochs 3874\n",
      "training loss 0.0008512136880605621\n",
      "epochs 3875\n",
      "training loss 0.000849750499884346\n",
      "epochs 3876\n",
      "training loss 0.0008536200769780639\n",
      "epochs 3877\n",
      "training loss 0.0008411266246356217\n",
      "epochs 3878\n",
      "training loss 0.0008210112261309891\n",
      "epochs 3879\n",
      "training loss 0.0008840240683374037\n",
      "testing loss 0.002538709367083795\n",
      "epochs 3880\n",
      "training loss 0.0008321648041114755\n",
      "epochs 3881\n",
      "training loss 0.0008269300884078893\n",
      "epochs 3882\n",
      "training loss 0.0008300928331559133\n",
      "epochs 3883\n",
      "training loss 0.0007902439265252914\n",
      "epochs 3884\n",
      "training loss 0.0008317419123626384\n",
      "epochs 3885\n",
      "training loss 0.0008456568816806951\n",
      "epochs 3886\n",
      "training loss 0.0008030848824072312\n",
      "epochs 3887\n",
      "training loss 0.0007956943090433272\n",
      "epochs 3888\n",
      "training loss 0.001361850185403289\n",
      "epochs 3889\n",
      "training loss 0.001132660294178092\n",
      "testing loss 0.002672231462635496\n",
      "epochs 3890\n",
      "training loss 0.0007061853976198402\n",
      "epochs 3891\n",
      "training loss 0.0006328831313745512\n",
      "epochs 3892\n",
      "training loss 0.0005493083060966765\n",
      "epochs 3893\n",
      "training loss 0.0005474190870271628\n",
      "epochs 3894\n",
      "training loss 0.0005158992331350465\n",
      "epochs 3895\n",
      "training loss 0.0005332671461830702\n",
      "epochs 3896\n",
      "training loss 0.0005131876077552504\n",
      "epochs 3897\n",
      "training loss 0.0006109751516098218\n",
      "epochs 3898\n",
      "training loss 0.0007809583688795985\n",
      "epochs 3899\n",
      "training loss 0.0007651117376418427\n",
      "testing loss 0.0026003916955103846\n",
      "epochs 3900\n",
      "training loss 0.0005997701345993869\n",
      "epochs 3901\n",
      "training loss 0.0005376139118040326\n",
      "epochs 3902\n",
      "training loss 0.0005603774109611848\n",
      "epochs 3903\n",
      "training loss 0.0005650855270872532\n",
      "epochs 3904\n",
      "training loss 0.0006275011732003802\n",
      "epochs 3905\n",
      "training loss 0.0005841439872580979\n",
      "epochs 3906\n",
      "training loss 0.0007577579126850415\n",
      "epochs 3907\n",
      "training loss 0.0007117604858052314\n",
      "epochs 3908\n",
      "training loss 0.0006843974610711348\n",
      "epochs 3909\n",
      "training loss 0.0007144776651512628\n",
      "testing loss 0.00275774814885321\n",
      "epochs 3910\n",
      "training loss 0.0009227858291582224\n",
      "epochs 3911\n",
      "training loss 0.000996906686458159\n",
      "epochs 3912\n",
      "training loss 0.0007312900572873674\n",
      "epochs 3913\n",
      "training loss 0.0006529973568798165\n",
      "epochs 3914\n",
      "training loss 0.0008017396437404762\n",
      "epochs 3915\n",
      "training loss 0.0005910805431668757\n",
      "epochs 3916\n",
      "training loss 0.0005753170080535329\n",
      "epochs 3917\n",
      "training loss 0.0005687035266012746\n",
      "epochs 3918\n",
      "training loss 0.000544240369672369\n",
      "epochs 3919\n",
      "training loss 0.000531539031322819\n",
      "testing loss 0.002548914930307643\n",
      "epochs 3920\n",
      "training loss 0.0006261690078150356\n",
      "epochs 3921\n",
      "training loss 0.0006843526557683775\n",
      "epochs 3922\n",
      "training loss 0.0006206030797285501\n",
      "epochs 3923\n",
      "training loss 0.0005582261403830083\n",
      "epochs 3924\n",
      "training loss 0.000546952636397973\n",
      "epochs 3925\n",
      "training loss 0.0005349197422648217\n",
      "epochs 3926\n",
      "training loss 0.0005464472858013025\n",
      "epochs 3927\n",
      "training loss 0.0005139819968960285\n",
      "epochs 3928\n",
      "training loss 0.0007394213947902029\n",
      "epochs 3929\n",
      "training loss 0.0006914640403328616\n",
      "testing loss 0.002676598344605865\n",
      "epochs 3930\n",
      "training loss 0.0005641119070046816\n",
      "epochs 3931\n",
      "training loss 0.0006195400555095831\n",
      "epochs 3932\n",
      "training loss 0.0004988444016681627\n",
      "epochs 3933\n",
      "training loss 0.0005738877749359263\n",
      "epochs 3934\n",
      "training loss 0.0005315480267948904\n",
      "epochs 3935\n",
      "training loss 0.0005332192914358037\n",
      "epochs 3936\n",
      "training loss 0.0004939398734326443\n",
      "epochs 3937\n",
      "training loss 0.0005387791686678606\n",
      "epochs 3938\n",
      "training loss 0.0005898304778295583\n",
      "epochs 3939\n",
      "training loss 0.0005005050428801904\n",
      "testing loss 0.0025904705976664438\n",
      "epochs 3940\n",
      "training loss 0.0005338419481615131\n",
      "epochs 3941\n",
      "training loss 0.0012768046032725112\n",
      "epochs 3942\n",
      "training loss 0.0013139772639888703\n",
      "epochs 3943\n",
      "training loss 0.0012776219674547438\n",
      "epochs 3944\n",
      "training loss 0.0010650320383571484\n",
      "epochs 3945\n",
      "training loss 0.001537463129717449\n",
      "epochs 3946\n",
      "training loss 0.0011644391131574588\n",
      "epochs 3947\n",
      "training loss 0.0009938900686813218\n",
      "epochs 3948\n",
      "training loss 0.0009406581996072446\n",
      "epochs 3949\n",
      "training loss 0.0009966459677987775\n",
      "testing loss 0.0026059210240999436\n",
      "epochs 3950\n",
      "training loss 0.000771742624069329\n",
      "epochs 3951\n",
      "training loss 0.0008672153036531887\n",
      "epochs 3952\n",
      "training loss 0.0007784676768691039\n",
      "epochs 3953\n",
      "training loss 0.0007381640165183682\n",
      "epochs 3954\n",
      "training loss 0.0007428373712593389\n",
      "epochs 3955\n",
      "training loss 0.0007567648513321864\n",
      "epochs 3956\n",
      "training loss 0.0007175168115044109\n",
      "epochs 3957\n",
      "training loss 0.0007550970159894235\n",
      "epochs 3958\n",
      "training loss 0.0007772637968337995\n",
      "epochs 3959\n",
      "training loss 0.000662405467217103\n",
      "testing loss 0.002584425790288241\n",
      "epochs 3960\n",
      "training loss 0.0006439320673730146\n",
      "epochs 3961\n",
      "training loss 0.0007465548649158521\n",
      "epochs 3962\n",
      "training loss 0.0006731706244147759\n",
      "epochs 3963\n",
      "training loss 0.0006378886908594248\n",
      "epochs 3964\n",
      "training loss 0.0006671183704367434\n",
      "epochs 3965\n",
      "training loss 0.0007596594704517467\n",
      "epochs 3966\n",
      "training loss 0.0006493637772626597\n",
      "epochs 3967\n",
      "training loss 0.0006170746649008267\n",
      "epochs 3968\n",
      "training loss 0.0008351040911530979\n",
      "epochs 3969\n",
      "training loss 0.0008928402576285576\n",
      "testing loss 0.002737269876772498\n",
      "epochs 3970\n",
      "training loss 0.0008971236951721374\n",
      "epochs 3971\n",
      "training loss 0.0006712974362923851\n",
      "epochs 3972\n",
      "training loss 0.0008049198449483158\n",
      "epochs 3973\n",
      "training loss 0.000887964770681222\n",
      "epochs 3974\n",
      "training loss 0.0007879176237415182\n",
      "epochs 3975\n",
      "training loss 0.0006761586053493662\n",
      "epochs 3976\n",
      "training loss 0.0006391257688999006\n",
      "epochs 3977\n",
      "training loss 0.0006297837958230968\n",
      "epochs 3978\n",
      "training loss 0.0007307695675680929\n",
      "epochs 3979\n",
      "training loss 0.0006810754837820697\n",
      "testing loss 0.002639497706669891\n",
      "epochs 3980\n",
      "training loss 0.0006540779731700644\n",
      "epochs 3981\n",
      "training loss 0.0009327990212230051\n",
      "epochs 3982\n",
      "training loss 0.0009842323852132576\n",
      "epochs 3983\n",
      "training loss 0.0006617901838451092\n",
      "epochs 3984\n",
      "training loss 0.0006621417377708837\n",
      "epochs 3985\n",
      "training loss 0.0006779794706672849\n",
      "epochs 3986\n",
      "training loss 0.0006666364922120284\n",
      "epochs 3987\n",
      "training loss 0.0006519383907432762\n",
      "epochs 3988\n",
      "training loss 0.0006653084329437001\n",
      "epochs 3989\n",
      "training loss 0.0007088433362516691\n",
      "testing loss 0.002735073001583021\n",
      "epochs 3990\n",
      "training loss 0.0006821182854388668\n",
      "epochs 3991\n",
      "training loss 0.0006476969716116491\n",
      "epochs 3992\n",
      "training loss 0.0009521772668521433\n",
      "epochs 3993\n",
      "training loss 0.0012839787617915997\n",
      "epochs 3994\n",
      "training loss 0.0011292598109429073\n",
      "epochs 3995\n",
      "training loss 0.0014021607877695113\n",
      "epochs 3996\n",
      "training loss 0.001112701445708255\n",
      "epochs 3997\n",
      "training loss 0.0010880131343815555\n",
      "epochs 3998\n",
      "training loss 0.0007656129677907357\n",
      "epochs 3999\n",
      "training loss 0.0007456761469397875\n",
      "testing loss 0.002607733329530171\n",
      "epochs 4000\n",
      "training loss 0.0007436598654118816\n",
      "epochs 4001\n",
      "training loss 0.000989004533039406\n",
      "epochs 4002\n",
      "training loss 0.003202059931803982\n",
      "epochs 4003\n",
      "training loss 0.0024388471850417667\n",
      "epochs 4004\n",
      "training loss 0.0023517570887213873\n",
      "epochs 4005\n",
      "training loss 0.0018096593032395723\n",
      "epochs 4006\n",
      "training loss 0.001799171433450037\n",
      "epochs 4007\n",
      "training loss 0.0016369140700941006\n",
      "epochs 4008\n",
      "training loss 0.0015088311654139072\n",
      "epochs 4009\n",
      "training loss 0.0018762211562318326\n",
      "testing loss 0.0027948960406765184\n",
      "epochs 4010\n",
      "training loss 0.0011416164352091476\n",
      "epochs 4011\n",
      "training loss 0.0010529482308322263\n",
      "epochs 4012\n",
      "training loss 0.000830606325482808\n",
      "epochs 4013\n",
      "training loss 0.0007437158963893537\n",
      "epochs 4014\n",
      "training loss 0.0007622946747458373\n",
      "epochs 4015\n",
      "training loss 0.0008578596557568374\n",
      "epochs 4016\n",
      "training loss 0.000824592086149657\n",
      "epochs 4017\n",
      "training loss 0.0007149316210371915\n",
      "epochs 4018\n",
      "training loss 0.0007374452734521752\n",
      "epochs 4019\n",
      "training loss 0.003144469834888201\n",
      "testing loss 0.0033251460458330333\n",
      "epochs 4020\n",
      "training loss 0.0017678031439030979\n",
      "epochs 4021\n",
      "training loss 0.0010508596293817877\n",
      "epochs 4022\n",
      "training loss 0.001017051269470128\n",
      "epochs 4023\n",
      "training loss 0.0022451668254299356\n",
      "epochs 4024\n",
      "training loss 0.0015626998850368076\n",
      "epochs 4025\n",
      "training loss 0.000998574996573743\n",
      "epochs 4026\n",
      "training loss 0.0009472582701205822\n",
      "epochs 4027\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss 0.0010508150196673863\n",
      "epochs 4028\n",
      "training loss 0.0016437548382199259\n",
      "epochs 4029\n",
      "training loss 0.0010533381977449751\n",
      "testing loss 0.0027121432176758107\n",
      "epochs 4030\n",
      "training loss 0.0008390825056919607\n",
      "epochs 4031\n",
      "training loss 0.0007637609671242252\n",
      "epochs 4032\n",
      "training loss 0.0007110263992703907\n",
      "epochs 4033\n",
      "training loss 0.0006848759369784542\n",
      "epochs 4034\n",
      "training loss 0.0007901556401882932\n",
      "epochs 4035\n",
      "training loss 0.0008036272474147073\n",
      "epochs 4036\n",
      "training loss 0.0007530696355521192\n",
      "epochs 4037\n",
      "training loss 0.0006518803431976609\n",
      "epochs 4038\n",
      "training loss 0.0006896703472002877\n",
      "epochs 4039\n",
      "training loss 0.0006189930447699973\n",
      "testing loss 0.0026343930388820617\n",
      "epochs 4040\n",
      "training loss 0.0005987547717950984\n",
      "epochs 4041\n",
      "training loss 0.0005934583083344312\n",
      "epochs 4042\n",
      "training loss 0.0005961024199929485\n",
      "epochs 4043\n",
      "training loss 0.0005791026622617453\n",
      "epochs 4044\n",
      "training loss 0.0005565204726260348\n",
      "epochs 4045\n",
      "training loss 0.0005841501328547833\n",
      "epochs 4046\n",
      "training loss 0.0005724459151789761\n",
      "epochs 4047\n",
      "training loss 0.0005479851801487643\n",
      "epochs 4048\n",
      "training loss 0.001152703754913832\n",
      "epochs 4049\n",
      "training loss 0.0005753276634170167\n",
      "testing loss 0.002576404124009588\n",
      "epochs 4050\n",
      "training loss 0.0005680290490458224\n",
      "epochs 4051\n",
      "training loss 0.0005943059098042015\n",
      "epochs 4052\n",
      "training loss 0.000564070947653696\n",
      "epochs 4053\n",
      "training loss 0.0005529703307715683\n",
      "epochs 4054\n",
      "training loss 0.0005700489624486924\n",
      "epochs 4055\n",
      "training loss 0.0005451945357462023\n",
      "epochs 4056\n",
      "training loss 0.0005423713298188947\n",
      "epochs 4057\n",
      "training loss 0.0005771343821502577\n",
      "epochs 4058\n",
      "training loss 0.0005992375603327839\n",
      "epochs 4059\n",
      "training loss 0.000772173229217852\n",
      "testing loss 0.002631152942050116\n",
      "epochs 4060\n",
      "training loss 0.0014461975067529805\n",
      "epochs 4061\n",
      "training loss 0.0007794047325444734\n",
      "epochs 4062\n",
      "training loss 0.0005579193666369278\n",
      "epochs 4063\n",
      "training loss 0.0005627757895137764\n",
      "epochs 4064\n",
      "training loss 0.0005063380744226141\n",
      "epochs 4065\n",
      "training loss 0.0005472330261505914\n",
      "epochs 4066\n",
      "training loss 0.0005507493232579274\n",
      "epochs 4067\n",
      "training loss 0.0005297192873427571\n",
      "epochs 4068\n",
      "training loss 0.0005396590610586764\n",
      "epochs 4069\n",
      "training loss 0.0005526666654738113\n",
      "testing loss 0.0027023477798512746\n",
      "epochs 4070\n",
      "training loss 0.0005762477650053765\n",
      "epochs 4071\n",
      "training loss 0.0004861284600957198\n",
      "epochs 4072\n",
      "training loss 0.0005128165453284594\n",
      "epochs 4073\n",
      "training loss 0.0005619487916982781\n",
      "epochs 4074\n",
      "training loss 0.0005529570664133378\n",
      "epochs 4075\n",
      "training loss 0.0006183316553574859\n",
      "epochs 4076\n",
      "training loss 0.0005466181843783593\n",
      "epochs 4077\n",
      "training loss 0.000496895153692564\n",
      "epochs 4078\n",
      "training loss 0.0005349585428900484\n",
      "epochs 4079\n",
      "training loss 0.000526510454069591\n",
      "testing loss 0.0026469011394742955\n",
      "epochs 4080\n",
      "training loss 0.0005750919638787563\n",
      "epochs 4081\n",
      "training loss 0.0005665213211282443\n",
      "epochs 4082\n",
      "training loss 0.0019070128615666748\n",
      "epochs 4083\n",
      "training loss 0.0006570926692979382\n",
      "epochs 4084\n",
      "training loss 0.0004996129275882747\n",
      "epochs 4085\n",
      "training loss 0.0005041715538795856\n",
      "epochs 4086\n",
      "training loss 0.0005768948677102087\n",
      "epochs 4087\n",
      "training loss 0.000891976104129253\n",
      "epochs 4088\n",
      "training loss 0.0007123897552042973\n",
      "epochs 4089\n",
      "training loss 0.0005946646324722634\n",
      "testing loss 0.002674521470495255\n",
      "epochs 4090\n",
      "training loss 0.0004992814630901265\n",
      "epochs 4091\n",
      "training loss 0.0005506986158929686\n",
      "epochs 4092\n",
      "training loss 0.0005252077364087484\n",
      "epochs 4093\n",
      "training loss 0.0005157465678423864\n",
      "epochs 4094\n",
      "training loss 0.0005099750520225536\n",
      "epochs 4095\n",
      "training loss 0.0005563254918235051\n",
      "epochs 4096\n",
      "training loss 0.000519593389588762\n",
      "epochs 4097\n",
      "training loss 0.0006436509228669571\n",
      "epochs 4098\n",
      "training loss 0.0006257728318787126\n",
      "epochs 4099\n",
      "training loss 0.0006119880523981306\n",
      "testing loss 0.0025630322667268097\n",
      "epochs 4100\n",
      "training loss 0.0005969464571723335\n",
      "epochs 4101\n",
      "training loss 0.0005706302851005415\n",
      "epochs 4102\n",
      "training loss 0.0006193977575940236\n",
      "epochs 4103\n",
      "training loss 0.0005742111226499907\n",
      "epochs 4104\n",
      "training loss 0.0006074665266791172\n",
      "epochs 4105\n",
      "training loss 0.0006417540226862016\n",
      "epochs 4106\n",
      "training loss 0.0006456473869863207\n",
      "epochs 4107\n",
      "training loss 0.0005653430073483816\n",
      "epochs 4108\n",
      "training loss 0.000570122978354926\n",
      "epochs 4109\n",
      "training loss 0.000632084196640071\n",
      "testing loss 0.002680970264222235\n",
      "epochs 4110\n",
      "training loss 0.0006306436559324094\n",
      "epochs 4111\n",
      "training loss 0.0006130434208058421\n",
      "epochs 4112\n",
      "training loss 0.0006109519461261839\n",
      "epochs 4113\n",
      "training loss 0.0005871556190799322\n",
      "epochs 4114\n",
      "training loss 0.0006400750037763936\n",
      "epochs 4115\n",
      "training loss 0.0006296562911457125\n",
      "epochs 4116\n",
      "training loss 0.0006067579563305144\n",
      "epochs 4117\n",
      "training loss 0.000760206424310594\n",
      "epochs 4118\n",
      "training loss 0.0007778012160477894\n",
      "epochs 4119\n",
      "training loss 0.0006285454667602187\n",
      "testing loss 0.0026140739428744723\n",
      "epochs 4120\n",
      "training loss 0.0005775867996908622\n",
      "epochs 4121\n",
      "training loss 0.0005086194369998565\n",
      "epochs 4122\n",
      "training loss 0.0004985957019176833\n",
      "epochs 4123\n",
      "training loss 0.0005225950885121074\n",
      "epochs 4124\n",
      "training loss 0.00048009383613894775\n",
      "epochs 4125\n",
      "training loss 0.0005131036003005597\n",
      "epochs 4126\n",
      "training loss 0.0005173837566305247\n",
      "epochs 4127\n",
      "training loss 0.0005144911804406318\n",
      "epochs 4128\n",
      "training loss 0.0005043925189181008\n",
      "epochs 4129\n",
      "training loss 0.0005155049761938424\n",
      "testing loss 0.00259080637784688\n",
      "epochs 4130\n",
      "training loss 0.0005129750221429851\n",
      "epochs 4131\n",
      "training loss 0.0005662262061201064\n",
      "epochs 4132\n",
      "training loss 0.0005984740975945566\n",
      "epochs 4133\n",
      "training loss 0.000509442573382822\n",
      "epochs 4134\n",
      "training loss 0.0005850502019847169\n",
      "epochs 4135\n",
      "training loss 0.0005032027849367053\n",
      "epochs 4136\n",
      "training loss 0.0004914269167264658\n",
      "epochs 4137\n",
      "training loss 0.0005397333196147789\n",
      "epochs 4138\n",
      "training loss 0.0005261714342524408\n",
      "epochs 4139\n",
      "training loss 0.0006057971800602463\n",
      "testing loss 0.0026669472824214094\n",
      "epochs 4140\n",
      "training loss 0.000490132447524636\n",
      "epochs 4141\n",
      "training loss 0.0005389850956067941\n",
      "epochs 4142\n",
      "training loss 0.0005609163075705316\n",
      "epochs 4143\n",
      "training loss 0.0009629070248573701\n",
      "epochs 4144\n",
      "training loss 0.00148529997329004\n",
      "epochs 4145\n",
      "training loss 0.0013318954790747049\n",
      "epochs 4146\n",
      "training loss 0.0010585746160668738\n",
      "epochs 4147\n",
      "training loss 0.0010062598177135603\n",
      "epochs 4148\n",
      "training loss 0.0007613245227075491\n",
      "epochs 4149\n",
      "training loss 0.0006412368061305462\n",
      "testing loss 0.0027413770621675495\n",
      "epochs 4150\n",
      "training loss 0.0005850111247404085\n",
      "epochs 4151\n",
      "training loss 0.0005935922350506596\n",
      "epochs 4152\n",
      "training loss 0.0005640195739083276\n",
      "epochs 4153\n",
      "training loss 0.0005632840728742498\n",
      "epochs 4154\n",
      "training loss 0.0005296091815367579\n",
      "epochs 4155\n",
      "training loss 0.0004983873115031553\n",
      "epochs 4156\n",
      "training loss 0.0005040628700035887\n",
      "epochs 4157\n",
      "training loss 0.0004826718814830978\n",
      "epochs 4158\n",
      "training loss 0.0005094197043182334\n",
      "epochs 4159\n",
      "training loss 0.0005121927690341231\n",
      "testing loss 0.0026941899864947596\n",
      "epochs 4160\n",
      "training loss 0.0004797880288346538\n",
      "epochs 4161\n",
      "training loss 0.0004969388610997597\n",
      "epochs 4162\n",
      "training loss 0.0005430287987065975\n",
      "epochs 4163\n",
      "training loss 0.0005537161027154911\n",
      "epochs 4164\n",
      "training loss 0.0005230305082657258\n",
      "epochs 4165\n",
      "training loss 0.0004773647300608875\n",
      "epochs 4166\n",
      "training loss 0.0004950766023503203\n",
      "epochs 4167\n",
      "training loss 0.0004949383270441297\n",
      "epochs 4168\n",
      "training loss 0.0005185895438955695\n",
      "epochs 4169\n",
      "training loss 0.000519973355310751\n",
      "testing loss 0.002542310990046393\n",
      "epochs 4170\n",
      "training loss 0.0019091725511133876\n",
      "epochs 4171\n",
      "training loss 0.001019419232662201\n",
      "epochs 4172\n",
      "training loss 0.0008093042251912985\n",
      "epochs 4173\n",
      "training loss 0.0006213727168134473\n",
      "epochs 4174\n",
      "training loss 0.0005356713554094401\n",
      "epochs 4175\n",
      "training loss 0.0005087996389834341\n",
      "epochs 4176\n",
      "training loss 0.0005153474533480329\n",
      "epochs 4177\n",
      "training loss 0.0004919369870975138\n",
      "epochs 4178\n",
      "training loss 0.0004650157463020648\n",
      "epochs 4179\n",
      "training loss 0.0004976800839999821\n",
      "testing loss 0.0026770544416726905\n",
      "epochs 4180\n",
      "training loss 0.0005208729464832501\n",
      "epochs 4181\n",
      "training loss 0.0005272856267207333\n",
      "epochs 4182\n",
      "training loss 0.0004900246147366416\n",
      "epochs 4183\n",
      "training loss 0.0005025132443355312\n",
      "epochs 4184\n",
      "training loss 0.0004943273043313763\n",
      "epochs 4185\n",
      "training loss 0.00048669241333386\n",
      "epochs 4186\n",
      "training loss 0.0005766621939972394\n",
      "epochs 4187\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss 0.0004621964341841955\n",
      "epochs 4188\n",
      "training loss 0.0005136856826596913\n",
      "epochs 4189\n",
      "training loss 0.000492288328804172\n",
      "testing loss 0.00251078255043583\n",
      "epochs 4190\n",
      "training loss 0.0005017190901484725\n",
      "epochs 4191\n",
      "training loss 0.0005670343170092528\n",
      "epochs 4192\n",
      "training loss 0.0004902618918971281\n",
      "epochs 4193\n",
      "training loss 0.0005506381664409565\n",
      "epochs 4194\n",
      "training loss 0.0006575042759259387\n",
      "epochs 4195\n",
      "training loss 0.0005289743909906698\n",
      "epochs 4196\n",
      "training loss 0.0005401296164779598\n",
      "epochs 4197\n",
      "training loss 0.0005044838727457522\n",
      "epochs 4198\n",
      "training loss 0.0004951117277544524\n",
      "epochs 4199\n",
      "training loss 0.0005359033040035697\n",
      "testing loss 0.0026715069006903905\n",
      "epochs 4200\n",
      "training loss 0.0005344069880606057\n",
      "epochs 4201\n",
      "training loss 0.0005009394079959162\n",
      "epochs 4202\n",
      "training loss 0.0005280530688106606\n",
      "epochs 4203\n",
      "training loss 0.0004954763862770051\n",
      "epochs 4204\n",
      "training loss 0.0005158828000862174\n",
      "epochs 4205\n",
      "training loss 0.0005745037132767977\n",
      "epochs 4206\n",
      "training loss 0.0005008555173103932\n",
      "epochs 4207\n",
      "training loss 0.0004924255535416985\n",
      "epochs 4208\n",
      "training loss 0.0004935364167617866\n",
      "epochs 4209\n",
      "training loss 0.0005240663703839581\n",
      "testing loss 0.002676398779021193\n",
      "epochs 4210\n",
      "training loss 0.0005483334616186114\n",
      "epochs 4211\n",
      "training loss 0.000494530776906249\n",
      "epochs 4212\n",
      "training loss 0.0005461613810939664\n",
      "epochs 4213\n",
      "training loss 0.00048353935441138127\n",
      "epochs 4214\n",
      "training loss 0.0005467568578497198\n",
      "epochs 4215\n",
      "training loss 0.0005040823235700196\n",
      "epochs 4216\n",
      "training loss 0.0004776224895064807\n",
      "epochs 4217\n",
      "training loss 0.0006262909663992574\n",
      "epochs 4218\n",
      "training loss 0.0004983891641521561\n",
      "epochs 4219\n",
      "training loss 0.0005104292402968184\n",
      "testing loss 0.002587567762214136\n",
      "epochs 4220\n",
      "training loss 0.0005232504252124985\n",
      "epochs 4221\n",
      "training loss 0.0004984081070304007\n",
      "epochs 4222\n",
      "training loss 0.000536752360311017\n",
      "epochs 4223\n",
      "training loss 0.000640188913072649\n",
      "epochs 4224\n",
      "training loss 0.0006912958893697075\n",
      "epochs 4225\n",
      "training loss 0.0005513157306832055\n",
      "epochs 4226\n",
      "training loss 0.0005871336963763715\n",
      "epochs 4227\n",
      "training loss 0.0008216578139899452\n",
      "epochs 4228\n",
      "training loss 0.0005141363100935691\n",
      "epochs 4229\n",
      "training loss 0.0005134894815308968\n",
      "testing loss 0.002564428407816111\n",
      "epochs 4230\n",
      "training loss 0.0004981693907783828\n",
      "epochs 4231\n",
      "training loss 0.0005542207376587015\n",
      "epochs 4232\n",
      "training loss 0.0005548918009544567\n",
      "epochs 4233\n",
      "training loss 0.0005136795984552805\n",
      "epochs 4234\n",
      "training loss 0.0005634282809830098\n",
      "epochs 4235\n",
      "training loss 0.0005731009312064633\n",
      "epochs 4236\n",
      "training loss 0.0006371155382264236\n",
      "epochs 4237\n",
      "training loss 0.0009356876534457944\n",
      "epochs 4238\n",
      "training loss 0.0007082428281601677\n",
      "epochs 4239\n",
      "training loss 0.0006004053222491069\n",
      "testing loss 0.00266716273745905\n",
      "epochs 4240\n",
      "training loss 0.0006197071339656234\n",
      "epochs 4241\n",
      "training loss 0.0006028356963498264\n",
      "epochs 4242\n",
      "training loss 0.0006051256706531932\n",
      "epochs 4243\n",
      "training loss 0.0005890846338779821\n",
      "epochs 4244\n",
      "training loss 0.0006302740054394721\n",
      "epochs 4245\n",
      "training loss 0.0006395639082251292\n",
      "epochs 4246\n",
      "training loss 0.0006000191590035374\n",
      "epochs 4247\n",
      "training loss 0.0006061121500288292\n",
      "epochs 4248\n",
      "training loss 0.0006656457273194731\n",
      "epochs 4249\n",
      "training loss 0.0006190585317500615\n",
      "testing loss 0.0026309014370678166\n",
      "epochs 4250\n",
      "training loss 0.0006106227582729617\n",
      "epochs 4251\n",
      "training loss 0.0006404896563104435\n",
      "epochs 4252\n",
      "training loss 0.0006437894440076305\n",
      "epochs 4253\n",
      "training loss 0.0008384249785965971\n",
      "epochs 4254\n",
      "training loss 0.000653286566508447\n",
      "epochs 4255\n",
      "training loss 0.0005923797032161755\n",
      "epochs 4256\n",
      "training loss 0.0005491559780192191\n",
      "epochs 4257\n",
      "training loss 0.0005301400063004582\n",
      "epochs 4258\n",
      "training loss 0.0005615793443129236\n",
      "epochs 4259\n",
      "training loss 0.0005362965492107042\n",
      "testing loss 0.002605196819657209\n",
      "epochs 4260\n",
      "training loss 0.0005509781510191248\n",
      "epochs 4261\n",
      "training loss 0.0005987906779603478\n",
      "epochs 4262\n",
      "training loss 0.0005555381357250877\n",
      "epochs 4263\n",
      "training loss 0.0005274842010059402\n",
      "epochs 4264\n",
      "training loss 0.0005616461353038231\n",
      "epochs 4265\n",
      "training loss 0.0005683711816459091\n",
      "epochs 4266\n",
      "training loss 0.0005820859739334693\n",
      "epochs 4267\n",
      "training loss 0.0005710738947958966\n",
      "epochs 4268\n",
      "training loss 0.0005563032341162791\n",
      "epochs 4269\n",
      "training loss 0.0005512536403590015\n",
      "testing loss 0.002750415153923636\n",
      "epochs 4270\n",
      "training loss 0.0005442838175335508\n",
      "epochs 4271\n",
      "training loss 0.0007279271483357633\n",
      "epochs 4272\n",
      "training loss 0.0006233761210906062\n",
      "epochs 4273\n",
      "training loss 0.0006205571870571484\n",
      "epochs 4274\n",
      "training loss 0.0013604548555943199\n",
      "epochs 4275\n",
      "training loss 0.0007109807181988749\n",
      "epochs 4276\n",
      "training loss 0.0005658633666754188\n",
      "epochs 4277\n",
      "training loss 0.0005780215006948683\n",
      "epochs 4278\n",
      "training loss 0.0005385152706140398\n",
      "epochs 4279\n",
      "training loss 0.0005377047668857993\n",
      "testing loss 0.0026196204026804324\n",
      "epochs 4280\n",
      "training loss 0.0005606273956148174\n",
      "epochs 4281\n",
      "training loss 0.0008427309384357218\n",
      "epochs 4282\n",
      "training loss 0.0006947508839024146\n",
      "epochs 4283\n",
      "training loss 0.001517956988676522\n",
      "epochs 4284\n",
      "training loss 0.0010359901121016423\n",
      "epochs 4285\n",
      "training loss 0.0006897413345389238\n",
      "epochs 4286\n",
      "training loss 0.0006273852122167697\n",
      "epochs 4287\n",
      "training loss 0.0005971655733656919\n",
      "epochs 4288\n",
      "training loss 0.0009594085765365614\n",
      "epochs 4289\n",
      "training loss 0.0008082360967443152\n",
      "testing loss 0.0025745555878194143\n",
      "epochs 4290\n",
      "training loss 0.0005685424626419904\n",
      "epochs 4291\n",
      "training loss 0.0006496426356584117\n",
      "epochs 4292\n",
      "training loss 0.0015436302826988956\n",
      "epochs 4293\n",
      "training loss 0.0018640279225505447\n",
      "epochs 4294\n",
      "training loss 0.0021580204671591318\n",
      "epochs 4295\n",
      "training loss 0.0011438834845402637\n",
      "epochs 4296\n",
      "training loss 0.0009396123892866856\n",
      "epochs 4297\n",
      "training loss 0.0008539167105603827\n",
      "epochs 4298\n",
      "training loss 0.0016223039676394246\n",
      "epochs 4299\n",
      "training loss 0.0010988510659284392\n",
      "testing loss 0.002647045203022236\n",
      "epochs 4300\n",
      "training loss 0.0009841062820312712\n",
      "epochs 4301\n",
      "training loss 0.0008289830311198682\n",
      "epochs 4302\n",
      "training loss 0.000705039546553238\n",
      "epochs 4303\n",
      "training loss 0.0006907003283986148\n",
      "epochs 4304\n",
      "training loss 0.0006539784962775633\n",
      "epochs 4305\n",
      "training loss 0.0006441227241778763\n",
      "epochs 4306\n",
      "training loss 0.0006367108002793339\n",
      "epochs 4307\n",
      "training loss 0.0006540921897277813\n",
      "epochs 4308\n",
      "training loss 0.0006761857598424128\n",
      "epochs 4309\n",
      "training loss 0.00065070856406812\n",
      "testing loss 0.0025801650229478187\n",
      "epochs 4310\n",
      "training loss 0.0007033408340809748\n",
      "epochs 4311\n",
      "training loss 0.000665261713290052\n",
      "epochs 4312\n",
      "training loss 0.0006778748292160308\n",
      "epochs 4313\n",
      "training loss 0.0010800872835448141\n",
      "epochs 4314\n",
      "training loss 0.0014692329236173204\n",
      "epochs 4315\n",
      "training loss 0.0012573490162043179\n",
      "epochs 4316\n",
      "training loss 0.0010441056521514594\n",
      "epochs 4317\n",
      "training loss 0.0008406432002809714\n",
      "epochs 4318\n",
      "training loss 0.0008023336805200832\n",
      "epochs 4319\n",
      "training loss 0.0006625767141555105\n",
      "testing loss 0.0027182273259584574\n",
      "epochs 4320\n",
      "training loss 0.0006969108521912847\n",
      "epochs 4321\n",
      "training loss 0.000603247506881563\n",
      "epochs 4322\n",
      "training loss 0.000627965532334544\n",
      "epochs 4323\n",
      "training loss 0.0006255050338231491\n",
      "epochs 4324\n",
      "training loss 0.000611131970656011\n",
      "epochs 4325\n",
      "training loss 0.0009911202913713514\n",
      "epochs 4326\n",
      "training loss 0.001004114215570788\n",
      "epochs 4327\n",
      "training loss 0.0008048645251127679\n",
      "epochs 4328\n",
      "training loss 0.0007634918473655285\n",
      "epochs 4329\n",
      "training loss 0.0007297858820717193\n",
      "testing loss 0.0028523335130951296\n",
      "epochs 4330\n",
      "training loss 0.0007114029808980512\n",
      "epochs 4331\n",
      "training loss 0.0006666661157537433\n",
      "epochs 4332\n",
      "training loss 0.0007242288082727658\n",
      "epochs 4333\n",
      "training loss 0.0006012396338837374\n",
      "epochs 4334\n",
      "training loss 0.0007312447876502451\n",
      "epochs 4335\n",
      "training loss 0.0005659375144777349\n",
      "epochs 4336\n",
      "training loss 0.0005533523223501571\n",
      "epochs 4337\n",
      "training loss 0.0005336639064960012\n",
      "epochs 4338\n",
      "training loss 0.000632668599521028\n",
      "epochs 4339\n",
      "training loss 0.0006886730627843255\n",
      "testing loss 0.0026269664245670834\n",
      "epochs 4340\n",
      "training loss 0.001015155372884985\n",
      "epochs 4341\n",
      "training loss 0.0006280457761951108\n",
      "epochs 4342\n",
      "training loss 0.0006678160258758485\n",
      "epochs 4343\n",
      "training loss 0.0005945846616038571\n",
      "epochs 4344\n",
      "training loss 0.0005480286500368573\n",
      "epochs 4345\n",
      "training loss 0.0005273928838898074\n",
      "epochs 4346\n",
      "training loss 0.0005427976668774119\n",
      "epochs 4347\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss 0.0005412132033050671\n",
      "epochs 4348\n",
      "training loss 0.0005116787188690677\n",
      "epochs 4349\n",
      "training loss 0.0006683489794653238\n",
      "testing loss 0.002787947686924104\n",
      "epochs 4350\n",
      "training loss 0.0005854594196216982\n",
      "epochs 4351\n",
      "training loss 0.0005421503594726901\n",
      "epochs 4352\n",
      "training loss 0.0005009907023913275\n",
      "epochs 4353\n",
      "training loss 0.0005203266055740722\n",
      "epochs 4354\n",
      "training loss 0.0005223098247082717\n",
      "epochs 4355\n",
      "training loss 0.0005498267176786103\n",
      "epochs 4356\n",
      "training loss 0.0005377853611423308\n",
      "epochs 4357\n",
      "training loss 0.0005223551763491959\n",
      "epochs 4358\n",
      "training loss 0.00047899530613143847\n",
      "epochs 4359\n",
      "training loss 0.0005162203291503254\n",
      "testing loss 0.0026665888062070604\n",
      "epochs 4360\n",
      "training loss 0.000857847503448007\n",
      "epochs 4361\n",
      "training loss 0.000691132872092246\n",
      "epochs 4362\n",
      "training loss 0.0006885399953830184\n",
      "epochs 4363\n",
      "training loss 0.0009904496748061244\n",
      "epochs 4364\n",
      "training loss 0.000967997173785082\n",
      "epochs 4365\n",
      "training loss 0.0013202530384809627\n",
      "epochs 4366\n",
      "training loss 0.0017301481262084358\n",
      "epochs 4367\n",
      "training loss 0.000954907587241087\n",
      "epochs 4368\n",
      "training loss 0.0009148855998653545\n",
      "epochs 4369\n",
      "training loss 0.0012056255917628168\n",
      "testing loss 0.0027268333938501193\n",
      "epochs 4370\n",
      "training loss 0.00081322144145163\n",
      "epochs 4371\n",
      "training loss 0.0007423441068023036\n",
      "epochs 4372\n",
      "training loss 0.0006731395906199755\n",
      "epochs 4373\n",
      "training loss 0.0006341159515865543\n",
      "epochs 4374\n",
      "training loss 0.0006458172358793282\n",
      "epochs 4375\n",
      "training loss 0.0006301224489673677\n",
      "epochs 4376\n",
      "training loss 0.0005471773912152134\n",
      "epochs 4377\n",
      "training loss 0.0005584056068092902\n",
      "epochs 4378\n",
      "training loss 0.0005570193979992478\n",
      "epochs 4379\n",
      "training loss 0.0005756196791325953\n",
      "testing loss 0.0026826958001941337\n",
      "epochs 4380\n",
      "training loss 0.0005714316614606279\n",
      "epochs 4381\n",
      "training loss 0.0005796517911232657\n",
      "epochs 4382\n",
      "training loss 0.0006351586915856924\n",
      "epochs 4383\n",
      "training loss 0.0006289805604447823\n",
      "epochs 4384\n",
      "training loss 0.0006324383577029009\n",
      "epochs 4385\n",
      "training loss 0.0005975872817651672\n",
      "epochs 4386\n",
      "training loss 0.0005873007223747478\n",
      "epochs 4387\n",
      "training loss 0.000572476786293095\n",
      "epochs 4388\n",
      "training loss 0.000617145649939464\n",
      "epochs 4389\n",
      "training loss 0.0005435330459230939\n",
      "testing loss 0.0026783103685568462\n",
      "epochs 4390\n",
      "training loss 0.0009960983717979689\n",
      "epochs 4391\n",
      "training loss 0.0007053616115756865\n",
      "epochs 4392\n",
      "training loss 0.0006992038852276172\n",
      "epochs 4393\n",
      "training loss 0.000663917557878482\n",
      "epochs 4394\n",
      "training loss 0.0009568062048132239\n",
      "epochs 4395\n",
      "training loss 0.0007818868503365156\n",
      "epochs 4396\n",
      "training loss 0.0005973600123415908\n",
      "epochs 4397\n",
      "training loss 0.0005286904638399593\n",
      "epochs 4398\n",
      "training loss 0.0005083334791271644\n",
      "epochs 4399\n",
      "training loss 0.0007069083919683556\n",
      "testing loss 0.0026949129978868554\n",
      "epochs 4400\n",
      "training loss 0.0006099054207713952\n",
      "epochs 4401\n",
      "training loss 0.0006981903298242771\n",
      "epochs 4402\n",
      "training loss 0.0010312596420222458\n",
      "epochs 4403\n",
      "training loss 0.0006807261917281522\n",
      "epochs 4404\n",
      "training loss 0.0006523818052925827\n",
      "epochs 4405\n",
      "training loss 0.000580902732494726\n",
      "epochs 4406\n",
      "training loss 0.0005836843984982843\n",
      "epochs 4407\n",
      "training loss 0.0005919535034498919\n",
      "epochs 4408\n",
      "training loss 0.000544021942682485\n",
      "epochs 4409\n",
      "training loss 0.0005774713286069876\n",
      "testing loss 0.002644570718985051\n",
      "epochs 4410\n",
      "training loss 0.0005661530961037689\n",
      "epochs 4411\n",
      "training loss 0.0009528334159828655\n",
      "epochs 4412\n",
      "training loss 0.0006221796727936013\n",
      "epochs 4413\n",
      "training loss 0.0006047200656065712\n",
      "epochs 4414\n",
      "training loss 0.0005778994457760831\n",
      "epochs 4415\n",
      "training loss 0.0005569795014246121\n",
      "epochs 4416\n",
      "training loss 0.0006023151922113287\n",
      "epochs 4417\n",
      "training loss 0.0006473052902267482\n",
      "epochs 4418\n",
      "training loss 0.0005841865524505251\n",
      "epochs 4419\n",
      "training loss 0.0005600077583451719\n",
      "testing loss 0.0026747233282645886\n",
      "epochs 4420\n",
      "training loss 0.0005770699332657873\n",
      "epochs 4421\n",
      "training loss 0.0006195770649665451\n",
      "epochs 4422\n",
      "training loss 0.0005686612515625371\n",
      "epochs 4423\n",
      "training loss 0.0006121486487499747\n",
      "epochs 4424\n",
      "training loss 0.0005552844478080677\n",
      "epochs 4425\n",
      "training loss 0.0006461789845496042\n",
      "epochs 4426\n",
      "training loss 0.0006303960066621325\n",
      "epochs 4427\n",
      "training loss 0.0006860639432184738\n",
      "epochs 4428\n",
      "training loss 0.0006065733134031783\n",
      "epochs 4429\n",
      "training loss 0.0006132815387043366\n",
      "testing loss 0.0025733116665749367\n",
      "epochs 4430\n",
      "training loss 0.0006162659661408435\n",
      "epochs 4431\n",
      "training loss 0.0006451694929786876\n",
      "epochs 4432\n",
      "training loss 0.000651432939654352\n",
      "epochs 4433\n",
      "training loss 0.0006342628240227236\n",
      "epochs 4434\n",
      "training loss 0.0006331369922337855\n",
      "epochs 4435\n",
      "training loss 0.0006025545614860714\n",
      "epochs 4436\n",
      "training loss 0.0008320031031409964\n",
      "epochs 4437\n",
      "training loss 0.0006522177742464371\n",
      "epochs 4438\n",
      "training loss 0.0006451627553092446\n",
      "epochs 4439\n",
      "training loss 0.0006469966717932011\n",
      "testing loss 0.0026819629079483927\n",
      "epochs 4440\n",
      "training loss 0.0006186027283458985\n",
      "epochs 4441\n",
      "training loss 0.0007881721171888729\n",
      "epochs 4442\n",
      "training loss 0.0006734502416331955\n",
      "epochs 4443\n",
      "training loss 0.0006485995396017733\n",
      "epochs 4444\n",
      "training loss 0.0006064889164525438\n",
      "epochs 4445\n",
      "training loss 0.000599866937920253\n",
      "epochs 4446\n",
      "training loss 0.0006365720747926167\n",
      "epochs 4447\n",
      "training loss 0.0006272663729616347\n",
      "epochs 4448\n",
      "training loss 0.0006568443539568667\n",
      "epochs 4449\n",
      "training loss 0.0006326379545144793\n",
      "testing loss 0.0026483820125473836\n",
      "epochs 4450\n",
      "training loss 0.0006503833777704318\n",
      "epochs 4451\n",
      "training loss 0.000676874816824617\n",
      "epochs 4452\n",
      "training loss 0.0006847934082460428\n",
      "epochs 4453\n",
      "training loss 0.0006373622640471984\n",
      "epochs 4454\n",
      "training loss 0.0006187666847305457\n",
      "epochs 4455\n",
      "training loss 0.0006122337043848692\n",
      "epochs 4456\n",
      "training loss 0.0005930283532894038\n",
      "epochs 4457\n",
      "training loss 0.0006359388911495082\n",
      "epochs 4458\n",
      "training loss 0.0006085728162632106\n",
      "epochs 4459\n",
      "training loss 0.0006373803484951369\n",
      "testing loss 0.00260105179432872\n",
      "epochs 4460\n",
      "training loss 0.0007780353615830418\n",
      "epochs 4461\n",
      "training loss 0.0009093064317475483\n",
      "epochs 4462\n",
      "training loss 0.0006832467981417434\n",
      "epochs 4463\n",
      "training loss 0.0007337149855217933\n",
      "epochs 4464\n",
      "training loss 0.0006610221043016795\n",
      "epochs 4465\n",
      "training loss 0.0006317980029290445\n",
      "epochs 4466\n",
      "training loss 0.0005988261988315743\n",
      "epochs 4467\n",
      "training loss 0.0006086518128167578\n",
      "epochs 4468\n",
      "training loss 0.0005816893835550621\n",
      "epochs 4469\n",
      "training loss 0.000618856213597643\n",
      "testing loss 0.0026553843656706736\n",
      "epochs 4470\n",
      "training loss 0.0006400794790432106\n",
      "epochs 4471\n",
      "training loss 0.000580599134604625\n",
      "epochs 4472\n",
      "training loss 0.0006213452507590303\n",
      "epochs 4473\n",
      "training loss 0.0006408075183505436\n",
      "epochs 4474\n",
      "training loss 0.0006050773648407854\n",
      "epochs 4475\n",
      "training loss 0.0006236676694641292\n",
      "epochs 4476\n",
      "training loss 0.0006292224157527995\n",
      "epochs 4477\n",
      "training loss 0.0005872697001684027\n",
      "epochs 4478\n",
      "training loss 0.0006185248413648298\n",
      "epochs 4479\n",
      "training loss 0.0006526351439636371\n",
      "testing loss 0.0026550424257986882\n",
      "epochs 4480\n",
      "training loss 0.0006280372898189187\n",
      "epochs 4481\n",
      "training loss 0.0006011006531856196\n",
      "epochs 4482\n",
      "training loss 0.0006219420555871444\n",
      "epochs 4483\n",
      "training loss 0.0006193925020083966\n",
      "epochs 4484\n",
      "training loss 0.0005986699473543098\n",
      "epochs 4485\n",
      "training loss 0.0005857466678821558\n",
      "epochs 4486\n",
      "training loss 0.0006099280823053265\n",
      "epochs 4487\n",
      "training loss 0.0006160135862154258\n",
      "epochs 4488\n",
      "training loss 0.0006236362490041527\n",
      "epochs 4489\n",
      "training loss 0.0006151687725210749\n",
      "testing loss 0.002643734462318136\n",
      "epochs 4490\n",
      "training loss 0.0005677519324568234\n",
      "epochs 4491\n",
      "training loss 0.0006077434291028471\n",
      "epochs 4492\n",
      "training loss 0.0006020501314196736\n",
      "epochs 4493\n",
      "training loss 0.0006072364884993418\n",
      "epochs 4494\n",
      "training loss 0.0006302916810184004\n",
      "epochs 4495\n",
      "training loss 0.0006005162133277595\n",
      "epochs 4496\n",
      "training loss 0.0006230233745270135\n",
      "epochs 4497\n",
      "training loss 0.0006065461761601224\n",
      "epochs 4498\n",
      "training loss 0.0005689384379476524\n",
      "epochs 4499\n",
      "training loss 0.0005968119611179507\n",
      "testing loss 0.002671824084555215\n",
      "epochs 4500\n",
      "training loss 0.0006091430311152814\n",
      "epochs 4501\n",
      "training loss 0.0006342417854917629\n",
      "epochs 4502\n",
      "training loss 0.0006143827436104032\n",
      "epochs 4503\n",
      "training loss 0.0006124216775334862\n",
      "epochs 4504\n",
      "training loss 0.0006524558595911031\n",
      "epochs 4505\n",
      "training loss 0.0005816588076369379\n",
      "epochs 4506\n",
      "training loss 0.0018354866092481104\n",
      "epochs 4507\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss 0.0014639694817253817\n",
      "epochs 4508\n",
      "training loss 0.0010894535684046593\n",
      "epochs 4509\n",
      "training loss 0.0009495681686939722\n",
      "testing loss 0.0030029305564041467\n",
      "epochs 4510\n",
      "training loss 0.0008567712746707773\n",
      "epochs 4511\n",
      "training loss 0.0007641043067813531\n",
      "epochs 4512\n",
      "training loss 0.0007612964180496304\n",
      "epochs 4513\n",
      "training loss 0.0006915159382125628\n",
      "epochs 4514\n",
      "training loss 0.0006545721815112061\n",
      "epochs 4515\n",
      "training loss 0.000656036991805778\n",
      "epochs 4516\n",
      "training loss 0.0006328986557469474\n",
      "epochs 4517\n",
      "training loss 0.0006193125748399668\n",
      "epochs 4518\n",
      "training loss 0.0006124319566702498\n",
      "epochs 4519\n",
      "training loss 0.0006022515768994858\n",
      "testing loss 0.002753398462912028\n",
      "epochs 4520\n",
      "training loss 0.0005905875171135579\n",
      "epochs 4521\n",
      "training loss 0.0005944579092029901\n",
      "epochs 4522\n",
      "training loss 0.0006124960123433938\n",
      "epochs 4523\n",
      "training loss 0.0005956625064840613\n",
      "epochs 4524\n",
      "training loss 0.0005995892257200367\n",
      "epochs 4525\n",
      "training loss 0.00059290345902215\n",
      "epochs 4526\n",
      "training loss 0.0006045439396631029\n",
      "epochs 4527\n",
      "training loss 0.0006020900857596627\n",
      "epochs 4528\n",
      "training loss 0.0005903724812064603\n",
      "epochs 4529\n",
      "training loss 0.000602107669780948\n",
      "testing loss 0.0026796610418257983\n",
      "epochs 4530\n",
      "training loss 0.0006255151175484797\n",
      "epochs 4531\n",
      "training loss 0.0006234307701226697\n",
      "epochs 4532\n",
      "training loss 0.0005942818093556616\n",
      "epochs 4533\n",
      "training loss 0.0006310926746940778\n",
      "epochs 4534\n",
      "training loss 0.0005843311215263981\n",
      "epochs 4535\n",
      "training loss 0.0006152015375957108\n",
      "epochs 4536\n",
      "training loss 0.0006006716661746854\n",
      "epochs 4537\n",
      "training loss 0.0006470351058340102\n",
      "epochs 4538\n",
      "training loss 0.0006232804749345005\n",
      "epochs 4539\n",
      "training loss 0.0006025655623801381\n",
      "testing loss 0.0026600334037042467\n",
      "epochs 4540\n",
      "training loss 0.0006080687609196875\n",
      "epochs 4541\n",
      "training loss 0.0006284759645130893\n",
      "epochs 4542\n",
      "training loss 0.0005653190591420672\n",
      "epochs 4543\n",
      "training loss 0.0006147802338190943\n",
      "epochs 4544\n",
      "training loss 0.0005800259989752833\n",
      "epochs 4545\n",
      "training loss 0.0005995259133887995\n",
      "epochs 4546\n",
      "training loss 0.0005971574856854387\n",
      "epochs 4547\n",
      "training loss 0.0006105070616122856\n",
      "epochs 4548\n",
      "training loss 0.0006871976032301126\n",
      "epochs 4549\n",
      "training loss 0.0006233100892762204\n",
      "testing loss 0.002686539489828737\n",
      "epochs 4550\n",
      "training loss 0.0006314779077670721\n",
      "epochs 4551\n",
      "training loss 0.0006060567071433477\n",
      "epochs 4552\n",
      "training loss 0.0006271200869366878\n",
      "epochs 4553\n",
      "training loss 0.0006407329198369321\n",
      "epochs 4554\n",
      "training loss 0.0006056040102413552\n",
      "epochs 4555\n",
      "training loss 0.0006471705108302105\n",
      "epochs 4556\n",
      "training loss 0.001190174361361802\n",
      "epochs 4557\n",
      "training loss 0.0008316524163147543\n",
      "epochs 4558\n",
      "training loss 0.0006875861870474536\n",
      "epochs 4559\n",
      "training loss 0.0006477345772990589\n",
      "testing loss 0.0027713377184749757\n",
      "epochs 4560\n",
      "training loss 0.0006348651656555436\n",
      "epochs 4561\n",
      "training loss 0.0005901744931555526\n",
      "epochs 4562\n",
      "training loss 0.0005781359907408106\n",
      "epochs 4563\n",
      "training loss 0.0006109949171799305\n",
      "epochs 4564\n",
      "training loss 0.0005556934806489949\n",
      "epochs 4565\n",
      "training loss 0.0006258481167650308\n",
      "epochs 4566\n",
      "training loss 0.0006187815476763756\n",
      "epochs 4567\n",
      "training loss 0.0008103406381592336\n",
      "epochs 4568\n",
      "training loss 0.0006672873114494715\n",
      "epochs 4569\n",
      "training loss 0.0006244157774990996\n",
      "testing loss 0.0027335904446159696\n",
      "epochs 4570\n",
      "training loss 0.0005858852343151125\n",
      "epochs 4571\n",
      "training loss 0.0006013081183814157\n",
      "epochs 4572\n",
      "training loss 0.0006015112277334074\n",
      "epochs 4573\n",
      "training loss 0.0005932505641310931\n",
      "epochs 4574\n",
      "training loss 0.0006071965816631732\n",
      "epochs 4575\n",
      "training loss 0.0005754869651349437\n",
      "epochs 4576\n",
      "training loss 0.0005534262263968355\n",
      "epochs 4577\n",
      "training loss 0.0005910290691061766\n",
      "epochs 4578\n",
      "training loss 0.0005889146047889179\n",
      "epochs 4579\n",
      "training loss 0.0006065168456913264\n",
      "testing loss 0.002753018104745379\n",
      "epochs 4580\n",
      "training loss 0.0006205939595257767\n",
      "epochs 4581\n",
      "training loss 0.00061769529479686\n",
      "epochs 4582\n",
      "training loss 0.0006293449685328546\n",
      "epochs 4583\n",
      "training loss 0.0005714264686826594\n",
      "epochs 4584\n",
      "training loss 0.000586006244326769\n",
      "epochs 4585\n",
      "training loss 0.0005905829664775507\n",
      "epochs 4586\n",
      "training loss 0.0006184988259903997\n",
      "epochs 4587\n",
      "training loss 0.0006193521422493954\n",
      "epochs 4588\n",
      "training loss 0.0006619969485143601\n",
      "epochs 4589\n",
      "training loss 0.0005956591338897266\n",
      "testing loss 0.002761038491693953\n",
      "epochs 4590\n",
      "training loss 0.0005962884181503229\n",
      "epochs 4591\n",
      "training loss 0.0005821919247917095\n",
      "epochs 4592\n",
      "training loss 0.0006017749922103772\n",
      "epochs 4593\n",
      "training loss 0.0006085960087430094\n",
      "epochs 4594\n",
      "training loss 0.0005979375709570083\n",
      "epochs 4595\n",
      "training loss 0.0006377146658763618\n",
      "epochs 4596\n",
      "training loss 0.0006106245182143201\n",
      "epochs 4597\n",
      "training loss 0.0006352941699164685\n",
      "epochs 4598\n",
      "training loss 0.0006074672929325501\n",
      "epochs 4599\n",
      "training loss 0.0005928764149290439\n",
      "testing loss 0.0026837512623710254\n",
      "epochs 4600\n",
      "training loss 0.0005573961776037245\n",
      "epochs 4601\n",
      "training loss 0.0005909006693754289\n",
      "epochs 4602\n",
      "training loss 0.0006057976767715169\n",
      "epochs 4603\n",
      "training loss 0.0005762324317982618\n",
      "epochs 4604\n",
      "training loss 0.0006400420450595545\n",
      "epochs 4605\n",
      "training loss 0.0006263085223782501\n",
      "epochs 4606\n",
      "training loss 0.0005972547486522107\n",
      "epochs 4607\n",
      "training loss 0.0006169447328401361\n",
      "epochs 4608\n",
      "training loss 0.0005798481964211809\n",
      "epochs 4609\n",
      "training loss 0.0005747030918538785\n",
      "testing loss 0.002709490186799027\n",
      "epochs 4610\n",
      "training loss 0.0005916260146765225\n",
      "epochs 4611\n",
      "training loss 0.0005730821957704144\n",
      "epochs 4612\n",
      "training loss 0.000595528451233287\n",
      "epochs 4613\n",
      "training loss 0.0005891246062641154\n",
      "epochs 4614\n",
      "training loss 0.0005700973223995327\n",
      "epochs 4615\n",
      "training loss 0.0006562242543432398\n",
      "epochs 4616\n",
      "training loss 0.0005975766368401393\n",
      "epochs 4617\n",
      "training loss 0.0005695353201795709\n",
      "epochs 4618\n",
      "training loss 0.0006389446384245162\n",
      "epochs 4619\n",
      "training loss 0.0006119829704624099\n",
      "testing loss 0.0027049773782227477\n",
      "epochs 4620\n",
      "training loss 0.0006088403023150962\n",
      "epochs 4621\n",
      "training loss 0.00058043016767268\n",
      "epochs 4622\n",
      "training loss 0.0005432379012361259\n",
      "epochs 4623\n",
      "training loss 0.0005682287528073432\n",
      "epochs 4624\n",
      "training loss 0.0006013693740714545\n",
      "epochs 4625\n",
      "training loss 0.0006449249940874808\n",
      "epochs 4626\n",
      "training loss 0.000613081517542987\n",
      "epochs 4627\n",
      "training loss 0.0006490337885675618\n",
      "epochs 4628\n",
      "training loss 0.0010570943359806454\n",
      "epochs 4629\n",
      "training loss 0.0007020294947420901\n",
      "testing loss 0.0026620796709057233\n",
      "epochs 4630\n",
      "training loss 0.000647164786664067\n",
      "epochs 4631\n",
      "training loss 0.0006260041659308659\n",
      "epochs 4632\n",
      "training loss 0.0005990561381998645\n",
      "epochs 4633\n",
      "training loss 0.0005869709302410823\n",
      "epochs 4634\n",
      "training loss 0.0005809065690695798\n",
      "epochs 4635\n",
      "training loss 0.0005933510869922609\n",
      "epochs 4636\n",
      "training loss 0.000578093602117519\n",
      "epochs 4637\n",
      "training loss 0.0006016310236111035\n",
      "epochs 4638\n",
      "training loss 0.0005737374920439043\n",
      "epochs 4639\n",
      "training loss 0.0008008676716607733\n",
      "testing loss 0.0026985673458440928\n",
      "epochs 4640\n",
      "training loss 0.0006655982725066062\n",
      "epochs 4641\n",
      "training loss 0.0007523213921710679\n",
      "epochs 4642\n",
      "training loss 0.0014513741646494185\n",
      "epochs 4643\n",
      "training loss 0.0009596982169726518\n",
      "epochs 4644\n",
      "training loss 0.000912197852984218\n",
      "epochs 4645\n",
      "training loss 0.0008876901878947024\n",
      "epochs 4646\n",
      "training loss 0.0008270931992776081\n",
      "epochs 4647\n",
      "training loss 0.0014080110933641567\n",
      "epochs 4648\n",
      "training loss 0.0009477450771541773\n",
      "epochs 4649\n",
      "training loss 0.0008727354464605224\n",
      "testing loss 0.0026878410362446985\n",
      "epochs 4650\n",
      "training loss 0.0008122093664513374\n",
      "epochs 4651\n",
      "training loss 0.000868385286041391\n",
      "epochs 4652\n",
      "training loss 0.000792162521621269\n",
      "epochs 4653\n",
      "training loss 0.000760094810324639\n",
      "epochs 4654\n",
      "training loss 0.000801245272895576\n",
      "epochs 4655\n",
      "training loss 0.0008077698598380872\n",
      "epochs 4656\n",
      "training loss 0.0008221239350116203\n",
      "epochs 4657\n",
      "training loss 0.0008017683392326916\n",
      "epochs 4658\n",
      "training loss 0.000770936516169487\n",
      "epochs 4659\n",
      "training loss 0.0009831008653504645\n",
      "testing loss 0.0027923900968434803\n",
      "epochs 4660\n",
      "training loss 0.0007660893168184329\n",
      "epochs 4661\n",
      "training loss 0.000778813117840483\n",
      "epochs 4662\n",
      "training loss 0.0006882119935330026\n",
      "epochs 4663\n",
      "training loss 0.000712683329611343\n",
      "epochs 4664\n",
      "training loss 0.000691942315255674\n",
      "epochs 4665\n",
      "training loss 0.0006852751396246832\n",
      "epochs 4666\n",
      "training loss 0.000674792099832543\n",
      "epochs 4667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss 0.0007377393793358573\n",
      "epochs 4668\n",
      "training loss 0.0007002964269229718\n",
      "epochs 4669\n",
      "training loss 0.0007743202342714061\n",
      "testing loss 0.0027513485195458675\n",
      "epochs 4670\n",
      "training loss 0.0008280759369975698\n",
      "epochs 4671\n",
      "training loss 0.0006387207921067858\n",
      "epochs 4672\n",
      "training loss 0.000729546924939062\n",
      "epochs 4673\n",
      "training loss 0.0006817465676008908\n",
      "epochs 4674\n",
      "training loss 0.0005302772529764344\n",
      "epochs 4675\n",
      "training loss 0.0005462586233607496\n",
      "epochs 4676\n",
      "training loss 0.0009647218220708694\n",
      "epochs 4677\n",
      "training loss 0.0008462271477077383\n",
      "epochs 4678\n",
      "training loss 0.0009845951647252853\n",
      "epochs 4679\n",
      "training loss 0.0005882695780098891\n",
      "testing loss 0.002769529246081142\n",
      "epochs 4680\n",
      "training loss 0.00053993703775875\n",
      "epochs 4681\n",
      "training loss 0.0005316823627339749\n",
      "epochs 4682\n",
      "training loss 0.000589782869712928\n",
      "epochs 4683\n",
      "training loss 0.0007770311797361843\n",
      "epochs 4684\n",
      "training loss 0.0005769974832164016\n",
      "epochs 4685\n",
      "training loss 0.0006562265894612111\n",
      "epochs 4686\n",
      "training loss 0.0006751671835417806\n",
      "epochs 4687\n",
      "training loss 0.0008338595857973972\n",
      "epochs 4688\n",
      "training loss 0.0005522038717541877\n",
      "epochs 4689\n",
      "training loss 0.0005819279357994762\n",
      "testing loss 0.0027366771452716743\n",
      "epochs 4690\n",
      "training loss 0.0005291493037732539\n",
      "epochs 4691\n",
      "training loss 0.0005205771361235643\n",
      "epochs 4692\n",
      "training loss 0.0005086188175040368\n",
      "epochs 4693\n",
      "training loss 0.0004893029975566141\n",
      "epochs 4694\n",
      "training loss 0.0005380818164747457\n",
      "epochs 4695\n",
      "training loss 0.0005417502679654021\n",
      "epochs 4696\n",
      "training loss 0.0005453917173821604\n",
      "epochs 4697\n",
      "training loss 0.0009367117102896245\n",
      "epochs 4698\n",
      "training loss 0.0006789174380267781\n",
      "epochs 4699\n",
      "training loss 0.0007097751536798638\n",
      "testing loss 0.0026983141982498586\n",
      "epochs 4700\n",
      "training loss 0.0006516309089514237\n",
      "epochs 4701\n",
      "training loss 0.000613889477737984\n",
      "epochs 4702\n",
      "training loss 0.0006834702469135343\n",
      "epochs 4703\n",
      "training loss 0.0006840440951886453\n",
      "epochs 4704\n",
      "training loss 0.00111014047582028\n",
      "epochs 4705\n",
      "training loss 0.0006821757847001623\n",
      "epochs 4706\n",
      "training loss 0.0009527617485522884\n",
      "epochs 4707\n",
      "training loss 0.0006375971578782011\n",
      "epochs 4708\n",
      "training loss 0.0006209290548373512\n",
      "epochs 4709\n",
      "training loss 0.0005646004112604383\n",
      "testing loss 0.0027283709248567514\n",
      "epochs 4710\n",
      "training loss 0.0006025687361130418\n",
      "epochs 4711\n",
      "training loss 0.0005565332220499276\n",
      "epochs 4712\n",
      "training loss 0.0006038017696056991\n",
      "epochs 4713\n",
      "training loss 0.0006163255993586803\n",
      "epochs 4714\n",
      "training loss 0.0006125356170835715\n",
      "epochs 4715\n",
      "training loss 0.000629633850057816\n",
      "epochs 4716\n",
      "training loss 0.0006088725881053752\n",
      "epochs 4717\n",
      "training loss 0.0005928365833736039\n",
      "epochs 4718\n",
      "training loss 0.0005776029979628949\n",
      "epochs 4719\n",
      "training loss 0.0005878824235533158\n",
      "testing loss 0.0027404069501728297\n",
      "epochs 4720\n",
      "training loss 0.0005747781680595401\n",
      "epochs 4721\n",
      "training loss 0.0007212977202844135\n",
      "epochs 4722\n",
      "training loss 0.0006803433529096358\n",
      "epochs 4723\n",
      "training loss 0.000593246707121635\n",
      "epochs 4724\n",
      "training loss 0.0006266588502277629\n",
      "epochs 4725\n",
      "training loss 0.000560763377114553\n",
      "epochs 4726\n",
      "training loss 0.000571281611664634\n",
      "epochs 4727\n",
      "training loss 0.000595567043885549\n",
      "epochs 4728\n",
      "training loss 0.0009289911672498431\n",
      "epochs 4729\n",
      "training loss 0.0005912381193549641\n",
      "testing loss 0.0027647837604303574\n",
      "epochs 4730\n",
      "training loss 0.0005305391441044146\n",
      "epochs 4731\n",
      "training loss 0.0004903909330621452\n",
      "epochs 4732\n",
      "training loss 0.0004915256490385992\n",
      "epochs 4733\n",
      "training loss 0.0005056346554520022\n",
      "epochs 4734\n",
      "training loss 0.0005217651442212752\n",
      "epochs 4735\n",
      "training loss 0.0005332649092573536\n",
      "epochs 4736\n",
      "training loss 0.0005033045447548982\n",
      "epochs 4737\n",
      "training loss 0.0005663186628413939\n",
      "epochs 4738\n",
      "training loss 0.0005625987379977304\n",
      "epochs 4739\n",
      "training loss 0.0006462123183431642\n",
      "testing loss 0.002789628597848276\n",
      "epochs 4740\n",
      "training loss 0.0006749268199598818\n",
      "epochs 4741\n",
      "training loss 0.0005501071590042778\n",
      "epochs 4742\n",
      "training loss 0.00048226095892780525\n",
      "epochs 4743\n",
      "training loss 0.0004898069454194259\n",
      "epochs 4744\n",
      "training loss 0.0004761668550569598\n",
      "epochs 4745\n",
      "training loss 0.0005054172905307762\n",
      "epochs 4746\n",
      "training loss 0.0005030901479820712\n",
      "epochs 4747\n",
      "training loss 0.0005021750197871828\n",
      "epochs 4748\n",
      "training loss 0.0005626027619340217\n",
      "epochs 4749\n",
      "training loss 0.0005153436020885716\n",
      "testing loss 0.0027631661955412504\n",
      "epochs 4750\n",
      "training loss 0.0005169560173689176\n",
      "epochs 4751\n",
      "training loss 0.0005151975341211993\n",
      "epochs 4752\n",
      "training loss 0.0005189962957569576\n",
      "epochs 4753\n",
      "training loss 0.0005071722200150264\n",
      "epochs 4754\n",
      "training loss 0.0005297982738116943\n",
      "epochs 4755\n",
      "training loss 0.0005031279037001693\n",
      "epochs 4756\n",
      "training loss 0.0005186901346951621\n",
      "epochs 4757\n",
      "training loss 0.0006213489199647437\n",
      "epochs 4758\n",
      "training loss 0.0005154351857391761\n",
      "epochs 4759\n",
      "training loss 0.0005159608310383622\n",
      "testing loss 0.002706534206926664\n",
      "epochs 4760\n",
      "training loss 0.0005135132599796104\n",
      "epochs 4761\n",
      "training loss 0.0005178466153693439\n",
      "epochs 4762\n",
      "training loss 0.0004948229379640569\n",
      "epochs 4763\n",
      "training loss 0.0005089167546548833\n",
      "epochs 4764\n",
      "training loss 0.0005026716306539518\n",
      "epochs 4765\n",
      "training loss 0.000495834219376316\n",
      "epochs 4766\n",
      "training loss 0.0005691698728459053\n",
      "epochs 4767\n",
      "training loss 0.0005460583195649371\n",
      "epochs 4768\n",
      "training loss 0.0005672912643783609\n",
      "epochs 4769\n",
      "training loss 0.0005279092354690062\n",
      "testing loss 0.0027189802069626486\n",
      "epochs 4770\n",
      "training loss 0.0005075866841703319\n",
      "epochs 4771\n",
      "training loss 0.0005245981817586648\n",
      "epochs 4772\n",
      "training loss 0.0005080892009473771\n",
      "epochs 4773\n",
      "training loss 0.0004725299165569993\n",
      "epochs 4774\n",
      "training loss 0.0005081070561031315\n",
      "epochs 4775\n",
      "training loss 0.0005308529987505221\n",
      "epochs 4776\n",
      "training loss 0.0005364096357266343\n",
      "epochs 4777\n",
      "training loss 0.0005252490248364795\n",
      "epochs 4778\n",
      "training loss 0.0005677164039336779\n",
      "epochs 4779\n",
      "training loss 0.0005022152893154636\n",
      "testing loss 0.0027356255623670494\n",
      "epochs 4780\n",
      "training loss 0.0005115032988482956\n",
      "epochs 4781\n",
      "training loss 0.000503161799135734\n",
      "epochs 4782\n",
      "training loss 0.0004974670601494916\n",
      "epochs 4783\n",
      "training loss 0.0005029693101164757\n",
      "epochs 4784\n",
      "training loss 0.0004856714701575813\n",
      "epochs 4785\n",
      "training loss 0.0006077067518187829\n",
      "epochs 4786\n",
      "training loss 0.0007303109219846935\n",
      "epochs 4787\n",
      "training loss 0.0006607131237067893\n",
      "epochs 4788\n",
      "training loss 0.0006499900820517862\n",
      "epochs 4789\n",
      "training loss 0.0006568720020208009\n",
      "testing loss 0.002676151292844418\n",
      "epochs 4790\n",
      "training loss 0.0007573853347359911\n",
      "epochs 4791\n",
      "training loss 0.0008053635473513132\n",
      "epochs 4792\n",
      "training loss 0.0008167959864698577\n",
      "epochs 4793\n",
      "training loss 0.0006409559558474071\n",
      "epochs 4794\n",
      "training loss 0.0008369435713340537\n",
      "epochs 4795\n",
      "training loss 0.0006790071086091836\n",
      "epochs 4796\n",
      "training loss 0.0005905595454132597\n",
      "epochs 4797\n",
      "training loss 0.0005875892871191108\n",
      "epochs 4798\n",
      "training loss 0.0005820249812394426\n",
      "epochs 4799\n",
      "training loss 0.0005826345484068272\n",
      "testing loss 0.0026101345928709503\n",
      "epochs 4800\n",
      "training loss 0.0005921927382631685\n",
      "epochs 4801\n",
      "training loss 0.0005916967211499255\n",
      "epochs 4802\n",
      "training loss 0.0006152423505429292\n",
      "epochs 4803\n",
      "training loss 0.0005714886305722093\n",
      "epochs 4804\n",
      "training loss 0.0006200058702775773\n",
      "epochs 4805\n",
      "training loss 0.0006511270749385505\n",
      "epochs 4806\n",
      "training loss 0.0006220863253093327\n",
      "epochs 4807\n",
      "training loss 0.00058125573488895\n",
      "epochs 4808\n",
      "training loss 0.0009210899880574874\n",
      "epochs 4809\n",
      "training loss 0.0010436468955488892\n",
      "testing loss 0.003033416936874178\n",
      "epochs 4810\n",
      "training loss 0.0008958914522598229\n",
      "epochs 4811\n",
      "training loss 0.0006899219876761041\n",
      "epochs 4812\n",
      "training loss 0.0006724380035983755\n",
      "epochs 4813\n",
      "training loss 0.0006803497242158148\n",
      "epochs 4814\n",
      "training loss 0.0006379136992767057\n",
      "epochs 4815\n",
      "training loss 0.0006491882233111907\n",
      "epochs 4816\n",
      "training loss 0.0006350063727524608\n",
      "epochs 4817\n",
      "training loss 0.0011132543197639093\n",
      "epochs 4818\n",
      "training loss 0.000789169373474081\n",
      "epochs 4819\n",
      "training loss 0.0006741370530204571\n",
      "testing loss 0.002683360895376441\n",
      "epochs 4820\n",
      "training loss 0.0006910503296483037\n",
      "epochs 4821\n",
      "training loss 0.0009683815321508558\n",
      "epochs 4822\n",
      "training loss 0.0007128026717700528\n",
      "epochs 4823\n",
      "training loss 0.0007222560235252462\n",
      "epochs 4824\n",
      "training loss 0.000757209536896192\n",
      "epochs 4825\n",
      "training loss 0.0007776109715619359\n",
      "epochs 4826\n",
      "training loss 0.0006888851378853277\n",
      "epochs 4827\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss 0.0011903125474103486\n",
      "epochs 4828\n",
      "training loss 0.0015055937504984643\n",
      "epochs 4829\n",
      "training loss 0.0010259906300640804\n",
      "testing loss 0.0027813734990339858\n",
      "epochs 4830\n",
      "training loss 0.0008647363463248265\n",
      "epochs 4831\n",
      "training loss 0.0007166970980503684\n",
      "epochs 4832\n",
      "training loss 0.0007361564899357404\n",
      "epochs 4833\n",
      "training loss 0.0006630168425373586\n",
      "epochs 4834\n",
      "training loss 0.0005747732792352538\n",
      "epochs 4835\n",
      "training loss 0.0005861339570655796\n",
      "epochs 4836\n",
      "training loss 0.0005785014864629118\n",
      "epochs 4837\n",
      "training loss 0.0005605765078768791\n",
      "epochs 4838\n",
      "training loss 0.0005551848069079628\n",
      "epochs 4839\n",
      "training loss 0.0005999845643683498\n",
      "testing loss 0.0026988951138019273\n",
      "epochs 4840\n",
      "training loss 0.0005653619717227686\n",
      "epochs 4841\n",
      "training loss 0.0005814755766434556\n",
      "epochs 4842\n",
      "training loss 0.0006113472924706467\n",
      "epochs 4843\n",
      "training loss 0.0005763976770668293\n",
      "epochs 4844\n",
      "training loss 0.0005936324077136079\n",
      "epochs 4845\n",
      "training loss 0.0005711750122067437\n",
      "epochs 4846\n",
      "training loss 0.0005498143911006433\n",
      "epochs 4847\n",
      "training loss 0.000584674356268198\n",
      "epochs 4848\n",
      "training loss 0.0006602693117000049\n",
      "epochs 4849\n",
      "training loss 0.0007069367915568845\n",
      "testing loss 0.0027533750010964773\n",
      "epochs 4850\n",
      "training loss 0.000598981615409289\n",
      "epochs 4851\n",
      "training loss 0.0005603469924160525\n",
      "epochs 4852\n",
      "training loss 0.0005700487528834208\n",
      "epochs 4853\n",
      "training loss 0.000572861520531743\n",
      "epochs 4854\n",
      "training loss 0.0006165284397877402\n",
      "epochs 4855\n",
      "training loss 0.0007333224695027271\n",
      "epochs 4856\n",
      "training loss 0.0006527148206975866\n",
      "epochs 4857\n",
      "training loss 0.0006301126837918654\n",
      "epochs 4858\n",
      "training loss 0.0005959975920648719\n",
      "epochs 4859\n",
      "training loss 0.000718077907259477\n",
      "testing loss 0.002630972823603673\n",
      "epochs 4860\n",
      "training loss 0.0006923349216823837\n",
      "epochs 4861\n",
      "training loss 0.000606943622668837\n",
      "epochs 4862\n",
      "training loss 0.0006149280897701176\n",
      "epochs 4863\n",
      "training loss 0.0005944117092163695\n",
      "epochs 4864\n",
      "training loss 0.000585576223554854\n",
      "epochs 4865\n",
      "training loss 0.0005785391063926215\n",
      "epochs 4866\n",
      "training loss 0.0005746753968611235\n",
      "epochs 4867\n",
      "training loss 0.000574854580564481\n",
      "epochs 4868\n",
      "training loss 0.0006015076200968917\n",
      "epochs 4869\n",
      "training loss 0.0006059259454023353\n",
      "testing loss 0.0026945453120646536\n",
      "epochs 4870\n",
      "training loss 0.0005938717827383474\n",
      "epochs 4871\n",
      "training loss 0.0006961842626793237\n",
      "epochs 4872\n",
      "training loss 0.0006627670655028448\n",
      "epochs 4873\n",
      "training loss 0.0006602069513913312\n",
      "epochs 4874\n",
      "training loss 0.0006279637873431776\n",
      "epochs 4875\n",
      "training loss 0.0006319985236324325\n",
      "epochs 4876\n",
      "training loss 0.0005953322368352688\n",
      "epochs 4877\n",
      "training loss 0.0006527394218381642\n",
      "epochs 4878\n",
      "training loss 0.0012174305293035316\n",
      "epochs 4879\n",
      "training loss 0.0014086202060164018\n",
      "testing loss 0.0029115268538692793\n",
      "epochs 4880\n",
      "training loss 0.0017940270828400203\n",
      "epochs 4881\n",
      "training loss 0.0016706699436802223\n",
      "epochs 4882\n",
      "training loss 0.0015720822393687549\n",
      "epochs 4883\n",
      "training loss 0.0014592610617340926\n",
      "epochs 4884\n",
      "training loss 0.0015820491813777133\n",
      "epochs 4885\n",
      "training loss 0.0013409406804808027\n",
      "epochs 4886\n",
      "training loss 0.001227217882455505\n",
      "epochs 4887\n",
      "training loss 0.001161278216635361\n",
      "epochs 4888\n",
      "training loss 0.0011030564955640924\n",
      "epochs 4889\n",
      "training loss 0.0011513765263873631\n",
      "testing loss 0.002821068786801308\n",
      "epochs 4890\n",
      "training loss 0.001050702822454823\n",
      "epochs 4891\n",
      "training loss 0.000982259045281422\n",
      "epochs 4892\n",
      "training loss 0.0009050849735090016\n",
      "epochs 4893\n",
      "training loss 0.0009373490199535848\n",
      "epochs 4894\n",
      "training loss 0.0010324157572756197\n",
      "epochs 4895\n",
      "training loss 0.0008818877226281005\n",
      "epochs 4896\n",
      "training loss 0.0007879259487639513\n",
      "epochs 4897\n",
      "training loss 0.0007860040721005129\n",
      "epochs 4898\n",
      "training loss 0.0007712446388206091\n",
      "epochs 4899\n",
      "training loss 0.0007380871203944574\n",
      "testing loss 0.0029440013004849988\n",
      "epochs 4900\n",
      "training loss 0.0008075317407895933\n",
      "epochs 4901\n",
      "training loss 0.0008684019671362403\n",
      "epochs 4902\n",
      "training loss 0.0008126279628640295\n",
      "epochs 4903\n",
      "training loss 0.0007711692296901271\n",
      "epochs 4904\n",
      "training loss 0.000678901119093272\n",
      "epochs 4905\n",
      "training loss 0.0007248697230078586\n",
      "epochs 4906\n",
      "training loss 0.0007625914077588717\n",
      "epochs 4907\n",
      "training loss 0.000823110608471767\n",
      "epochs 4908\n",
      "training loss 0.0007188339580747789\n",
      "epochs 4909\n",
      "training loss 0.0006756165453571101\n",
      "testing loss 0.0027396334347592546\n",
      "epochs 4910\n",
      "training loss 0.0007222698556293243\n",
      "epochs 4911\n",
      "training loss 0.0006800224542961737\n",
      "epochs 4912\n",
      "training loss 0.0009365781066347605\n",
      "epochs 4913\n",
      "training loss 0.0008007575775316908\n",
      "epochs 4914\n",
      "training loss 0.0006926455107725602\n",
      "epochs 4915\n",
      "training loss 0.0007258829289883104\n",
      "epochs 4916\n",
      "training loss 0.0008490167096070379\n",
      "epochs 4917\n",
      "training loss 0.0008690142508675444\n",
      "epochs 4918\n",
      "training loss 0.0007096598383766744\n",
      "epochs 4919\n",
      "training loss 0.0008810754848777183\n",
      "testing loss 0.002862277583975398\n",
      "epochs 4920\n",
      "training loss 0.000848557614550804\n",
      "epochs 4921\n",
      "training loss 0.0007362149099926932\n",
      "epochs 4922\n",
      "training loss 0.0007187742462146767\n",
      "epochs 4923\n",
      "training loss 0.0006880439022813547\n",
      "epochs 4924\n",
      "training loss 0.0008893798912718247\n",
      "epochs 4925\n",
      "training loss 0.000769482828491993\n",
      "epochs 4926\n",
      "training loss 0.0008683889790432454\n",
      "epochs 4927\n",
      "training loss 0.0008162698802420739\n",
      "epochs 4928\n",
      "training loss 0.000756468400599769\n",
      "epochs 4929\n",
      "training loss 0.0007250050842156209\n",
      "testing loss 0.0028705742880569918\n",
      "epochs 4930\n",
      "training loss 0.0009104379054334433\n",
      "epochs 4931\n",
      "training loss 0.0007720593619408047\n",
      "epochs 4932\n",
      "training loss 0.0008313412493941201\n",
      "epochs 4933\n",
      "training loss 0.0008455416644812989\n",
      "epochs 4934\n",
      "training loss 0.0007921830483140441\n",
      "epochs 4935\n",
      "training loss 0.000960967267738191\n",
      "epochs 4936\n",
      "training loss 0.0010656362912889376\n",
      "epochs 4937\n",
      "training loss 0.000803758244463285\n",
      "epochs 4938\n",
      "training loss 0.0008214335244801462\n",
      "epochs 4939\n",
      "training loss 0.0006989989284458528\n",
      "testing loss 0.0026820018604325115\n",
      "epochs 4940\n",
      "training loss 0.000660709995266169\n",
      "epochs 4941\n",
      "training loss 0.0007307738353927141\n",
      "epochs 4942\n",
      "training loss 0.000765946644976152\n",
      "epochs 4943\n",
      "training loss 0.0007708345992436864\n",
      "epochs 4944\n",
      "training loss 0.0006919114505992438\n",
      "epochs 4945\n",
      "training loss 0.0007006837234486993\n",
      "epochs 4946\n",
      "training loss 0.0006664345507286375\n",
      "epochs 4947\n",
      "training loss 0.0007671372106724835\n",
      "epochs 4948\n",
      "training loss 0.0006970008292927557\n",
      "epochs 4949\n",
      "training loss 0.000646210741959399\n",
      "testing loss 0.0027733990177016784\n",
      "epochs 4950\n",
      "training loss 0.0007095096450961424\n",
      "epochs 4951\n",
      "training loss 0.0007099428499509555\n",
      "epochs 4952\n",
      "training loss 0.000641961783343377\n",
      "epochs 4953\n",
      "training loss 0.0006956629629181782\n",
      "epochs 4954\n",
      "training loss 0.0007837033132798856\n",
      "epochs 4955\n",
      "training loss 0.0007177207752174803\n",
      "epochs 4956\n",
      "training loss 0.0006802004366040252\n",
      "epochs 4957\n",
      "training loss 0.000705012165775698\n",
      "epochs 4958\n",
      "training loss 0.0006834244592459222\n",
      "epochs 4959\n",
      "training loss 0.0007032389050359501\n",
      "testing loss 0.002800707095170539\n",
      "epochs 4960\n",
      "training loss 0.0006752279236782512\n",
      "epochs 4961\n",
      "training loss 0.0006541634164432114\n",
      "epochs 4962\n",
      "training loss 0.0006998881667931664\n",
      "epochs 4963\n",
      "training loss 0.0007119200912999176\n",
      "epochs 4964\n",
      "training loss 0.0006479473454958411\n",
      "epochs 4965\n",
      "training loss 0.0012798277771958124\n",
      "epochs 4966\n",
      "training loss 0.0013268912827814037\n",
      "epochs 4967\n",
      "training loss 0.0009727537699042335\n",
      "epochs 4968\n",
      "training loss 0.0007375224483182433\n",
      "epochs 4969\n",
      "training loss 0.000649576219921156\n",
      "testing loss 0.0027273601905198385\n",
      "epochs 4970\n",
      "training loss 0.0008750428245006565\n",
      "epochs 4971\n",
      "training loss 0.000673715519509349\n",
      "epochs 4972\n",
      "training loss 0.0006478281075447673\n",
      "epochs 4973\n",
      "training loss 0.000785639798208522\n",
      "epochs 4974\n",
      "training loss 0.0008674023433561553\n",
      "epochs 4975\n",
      "training loss 0.000965164336259123\n",
      "epochs 4976\n",
      "training loss 0.0007829039387148735\n",
      "epochs 4977\n",
      "training loss 0.0008057146285388811\n",
      "epochs 4978\n",
      "training loss 0.0007684599101475488\n",
      "epochs 4979\n",
      "training loss 0.0007071389591478456\n",
      "testing loss 0.0027637085860846102\n",
      "epochs 4980\n",
      "training loss 0.0006842850994971216\n",
      "epochs 4981\n",
      "training loss 0.0007830204803597092\n",
      "epochs 4982\n",
      "training loss 0.0006182536355957196\n",
      "epochs 4983\n",
      "training loss 0.0006135426036904546\n",
      "epochs 4984\n",
      "training loss 0.0006625926889738176\n",
      "epochs 4985\n",
      "training loss 0.0006441863725743169\n",
      "epochs 4986\n",
      "training loss 0.000566670492147789\n",
      "epochs 4987\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss 0.0006880876179154691\n",
      "epochs 4988\n",
      "training loss 0.0007107929212655476\n",
      "epochs 4989\n",
      "training loss 0.0005741168275662333\n",
      "testing loss 0.002716942537569355\n",
      "epochs 4990\n",
      "training loss 0.000697603566259978\n",
      "epochs 4991\n",
      "training loss 0.0007319155251423299\n",
      "epochs 4992\n",
      "training loss 0.0006312580019664472\n",
      "epochs 4993\n",
      "training loss 0.0007068665371216992\n",
      "epochs 4994\n",
      "training loss 0.0006171861995368245\n",
      "epochs 4995\n",
      "training loss 0.0006871266663145263\n",
      "epochs 4996\n",
      "training loss 0.0006398525504617581\n",
      "epochs 4997\n",
      "training loss 0.0006529701044156689\n",
      "epochs 4998\n",
      "training loss 0.0005363159961425232\n",
      "epochs 4999\n",
      "training loss 0.0006590182949593545\n",
      "testing loss 0.002709425448321123\n",
      "epochs 5000\n",
      "training loss 0.0005712712265510045\n",
      "epochs 5001\n",
      "training loss 0.0006122852870762789\n",
      "epochs 5002\n",
      "training loss 0.0006865847836875591\n",
      "epochs 5003\n",
      "training loss 0.0005901035887937948\n",
      "epochs 5004\n",
      "training loss 0.0008541722667840873\n",
      "epochs 5005\n",
      "training loss 0.0007112572075074431\n",
      "epochs 5006\n",
      "training loss 0.0008102068840313737\n",
      "epochs 5007\n",
      "training loss 0.0008004743401152238\n",
      "epochs 5008\n",
      "training loss 0.000907710053739322\n",
      "epochs 5009\n",
      "training loss 0.0006369645553386252\n",
      "testing loss 0.002770049348457036\n",
      "epochs 5010\n",
      "training loss 0.0007223496073786181\n",
      "epochs 5011\n",
      "training loss 0.0009202915423381281\n",
      "epochs 5012\n",
      "training loss 0.000726576443102726\n",
      "epochs 5013\n",
      "training loss 0.0015228916558304004\n",
      "epochs 5014\n",
      "training loss 0.0009404872399032977\n",
      "epochs 5015\n",
      "training loss 0.0007772133898840634\n",
      "epochs 5016\n",
      "training loss 0.0006537359567199151\n",
      "epochs 5017\n",
      "training loss 0.0007007902638143138\n",
      "epochs 5018\n",
      "training loss 0.0006360762818407912\n",
      "epochs 5019\n",
      "training loss 0.0005852083915647822\n",
      "testing loss 0.0027318230499051087\n",
      "epochs 5020\n",
      "training loss 0.0006720967996670188\n",
      "epochs 5021\n",
      "training loss 0.000628680910856398\n",
      "epochs 5022\n",
      "training loss 0.0006286273945737234\n",
      "epochs 5023\n",
      "training loss 0.000663042052204531\n",
      "epochs 5024\n",
      "training loss 0.0005839771393327026\n",
      "epochs 5025\n",
      "training loss 0.0007536461039681248\n",
      "epochs 5026\n",
      "training loss 0.000640928051023996\n",
      "epochs 5027\n",
      "training loss 0.0005541262420327445\n",
      "epochs 5028\n",
      "training loss 0.0006323196423823144\n",
      "epochs 5029\n",
      "training loss 0.0006892661477182921\n",
      "testing loss 0.0027183252221620676\n",
      "epochs 5030\n",
      "training loss 0.0006631919045544776\n",
      "epochs 5031\n",
      "training loss 0.0006354010241434522\n",
      "epochs 5032\n",
      "training loss 0.0007882856666237841\n",
      "epochs 5033\n",
      "training loss 0.0006771957024784708\n",
      "epochs 5034\n",
      "training loss 0.0006487894243147439\n",
      "epochs 5035\n",
      "training loss 0.0006599834085849756\n",
      "epochs 5036\n",
      "training loss 0.0006739779265447432\n",
      "epochs 5037\n",
      "training loss 0.0006228022231885988\n",
      "epochs 5038\n",
      "training loss 0.0007504262675893546\n",
      "epochs 5039\n",
      "training loss 0.0006042982398186977\n",
      "testing loss 0.0026652433299327416\n",
      "epochs 5040\n",
      "training loss 0.0008155497450574009\n",
      "epochs 5041\n",
      "training loss 0.0007117143498647301\n",
      "epochs 5042\n",
      "training loss 0.0006268107870842774\n",
      "epochs 5043\n",
      "training loss 0.0006698714898730059\n",
      "epochs 5044\n",
      "training loss 0.0006819754041197758\n",
      "epochs 5045\n",
      "training loss 0.0006181370777624311\n",
      "epochs 5046\n",
      "training loss 0.0007214658545283459\n",
      "epochs 5047\n",
      "training loss 0.0005807203808084618\n",
      "epochs 5048\n",
      "training loss 0.0006643971438005873\n",
      "epochs 5049\n",
      "training loss 0.0006578153766773777\n",
      "testing loss 0.0029372804755252516\n",
      "epochs 5050\n",
      "training loss 0.0006733809962782352\n",
      "epochs 5051\n",
      "training loss 0.0007736028492660191\n",
      "epochs 5052\n",
      "training loss 0.0006699523572543902\n",
      "epochs 5053\n",
      "training loss 0.0007590022130754682\n",
      "epochs 5054\n",
      "training loss 0.0006828607322038137\n",
      "epochs 5055\n",
      "training loss 0.0006136726571203104\n",
      "epochs 5056\n",
      "training loss 0.0006262317838042545\n",
      "epochs 5057\n",
      "training loss 0.0007165689447733339\n",
      "epochs 5058\n",
      "training loss 0.0005446952757231699\n",
      "epochs 5059\n",
      "training loss 0.000685407278622645\n",
      "testing loss 0.002791485469705749\n",
      "epochs 5060\n",
      "training loss 0.0008807644531262422\n",
      "epochs 5061\n",
      "training loss 0.0005956779107257531\n",
      "epochs 5062\n",
      "training loss 0.0007392906012030539\n",
      "epochs 5063\n",
      "training loss 0.0005978188576710363\n",
      "epochs 5064\n",
      "training loss 0.00065547992454277\n",
      "epochs 5065\n",
      "training loss 0.0006387596330704524\n",
      "epochs 5066\n",
      "training loss 0.0006023814232409918\n",
      "epochs 5067\n",
      "training loss 0.0007173461760118275\n",
      "epochs 5068\n",
      "training loss 0.0006743104145423393\n",
      "epochs 5069\n",
      "training loss 0.0005972331122100342\n",
      "testing loss 0.0026640791944657445\n",
      "epochs 5070\n",
      "training loss 0.0006787686365108801\n",
      "epochs 5071\n",
      "training loss 0.0005856748054824532\n",
      "epochs 5072\n",
      "training loss 0.0005918916895678465\n",
      "epochs 5073\n",
      "training loss 0.0010497763528775899\n",
      "epochs 5074\n",
      "training loss 0.0007307122068374919\n",
      "epochs 5075\n",
      "training loss 0.0007286961571671532\n",
      "epochs 5076\n",
      "training loss 0.0007420213822994415\n",
      "epochs 5077\n",
      "training loss 0.0006628378731761931\n",
      "epochs 5078\n",
      "training loss 0.0007313474289871933\n",
      "epochs 5079\n",
      "training loss 0.0005852220917727776\n",
      "testing loss 0.0029259116421057347\n",
      "epochs 5080\n",
      "training loss 0.0006343727423788238\n",
      "epochs 5081\n",
      "training loss 0.0005639077600878649\n",
      "epochs 5082\n",
      "training loss 0.0005927060650786142\n",
      "epochs 5083\n",
      "training loss 0.0007010919898592705\n",
      "epochs 5084\n",
      "training loss 0.000575489969198708\n",
      "epochs 5085\n",
      "training loss 0.00071120919096411\n",
      "epochs 5086\n",
      "training loss 0.0006834521313271511\n",
      "epochs 5087\n",
      "training loss 0.0006272074377049598\n",
      "epochs 5088\n",
      "training loss 0.0006790180490840521\n",
      "epochs 5089\n",
      "training loss 0.000635182465345947\n",
      "testing loss 0.0028918908788419678\n",
      "epochs 5090\n",
      "training loss 0.0007369649759458384\n",
      "epochs 5091\n",
      "training loss 0.0005544672730218868\n",
      "epochs 5092\n",
      "training loss 0.000641639383317263\n",
      "epochs 5093\n",
      "training loss 0.000686773963097064\n",
      "epochs 5094\n",
      "training loss 0.0005969453474229321\n",
      "epochs 5095\n",
      "training loss 0.0006490792438853532\n",
      "epochs 5096\n",
      "training loss 0.0007169954465471468\n",
      "epochs 5097\n",
      "training loss 0.0006321670049107931\n",
      "epochs 5098\n",
      "training loss 0.0006908331590769728\n",
      "epochs 5099\n",
      "training loss 0.0005727706893345788\n",
      "testing loss 0.0028748845232399642\n",
      "epochs 5100\n",
      "training loss 0.0008013765232978632\n",
      "epochs 5101\n",
      "training loss 0.0006711825151293677\n",
      "epochs 5102\n",
      "training loss 0.0006193262571787411\n",
      "epochs 5103\n",
      "training loss 0.0006807902593435974\n",
      "epochs 5104\n",
      "training loss 0.0006586318345716376\n",
      "epochs 5105\n",
      "training loss 0.0006066219906653858\n",
      "epochs 5106\n",
      "training loss 0.000632255595643781\n",
      "epochs 5107\n",
      "training loss 0.0005848906014438741\n",
      "epochs 5108\n",
      "training loss 0.0007271059405902191\n",
      "epochs 5109\n",
      "training loss 0.0005879866671932459\n",
      "testing loss 0.0026884457469647026\n",
      "epochs 5110\n",
      "training loss 0.0007012227189579928\n",
      "epochs 5111\n",
      "training loss 0.000678089323915728\n",
      "epochs 5112\n",
      "training loss 0.0006204787642648302\n",
      "epochs 5113\n",
      "training loss 0.0006665306999652412\n",
      "epochs 5114\n",
      "training loss 0.0005954932696561083\n",
      "epochs 5115\n",
      "training loss 0.0006380670006517151\n",
      "epochs 5116\n",
      "training loss 0.0007985752829779392\n",
      "epochs 5117\n",
      "training loss 0.0006455388150141096\n",
      "epochs 5118\n",
      "training loss 0.0005906683203161306\n",
      "epochs 5119\n",
      "training loss 0.000830380438889255\n",
      "testing loss 0.0029527092998986072\n",
      "epochs 5120\n",
      "training loss 0.0016964462634047215\n",
      "epochs 5121\n",
      "training loss 0.0019136130714953218\n",
      "epochs 5122\n",
      "training loss 0.0019147848290402589\n",
      "epochs 5123\n",
      "training loss 0.0014552017516388607\n",
      "epochs 5124\n",
      "training loss 0.0024557563431679887\n",
      "epochs 5125\n",
      "training loss 0.0016517328462169979\n",
      "epochs 5126\n",
      "training loss 0.0015035448300420083\n",
      "epochs 5127\n",
      "training loss 0.0015052703165344464\n",
      "epochs 5128\n",
      "training loss 0.0019983475572092737\n",
      "epochs 5129\n",
      "training loss 0.001388892057772137\n",
      "testing loss 0.00304524077173547\n",
      "epochs 5130\n",
      "training loss 0.0012133410596784125\n",
      "epochs 5131\n",
      "training loss 0.0016900005102466146\n",
      "epochs 5132\n",
      "training loss 0.0013603447286460243\n",
      "epochs 5133\n",
      "training loss 0.0011265160751919685\n",
      "epochs 5134\n",
      "training loss 0.0011525269111938277\n",
      "epochs 5135\n",
      "training loss 0.0010045686859487468\n",
      "epochs 5136\n",
      "training loss 0.0009408378780757199\n",
      "epochs 5137\n",
      "training loss 0.0009786300118771979\n",
      "epochs 5138\n",
      "training loss 0.0009255108123115833\n",
      "epochs 5139\n",
      "training loss 0.0009651908822255747\n",
      "testing loss 0.0026783100089903737\n",
      "epochs 5140\n",
      "training loss 0.0008266798556197752\n",
      "epochs 5141\n",
      "training loss 0.000660677044510864\n",
      "epochs 5142\n",
      "training loss 0.0007466431815066802\n",
      "epochs 5143\n",
      "training loss 0.0008093571217127688\n",
      "epochs 5144\n",
      "training loss 0.0008349460746921701\n",
      "epochs 5145\n",
      "training loss 0.0007959018581890782\n",
      "epochs 5146\n",
      "training loss 0.0007298938859442368\n",
      "epochs 5147\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss 0.0009996113236455705\n",
      "epochs 5148\n",
      "training loss 0.0009928355480000762\n",
      "epochs 5149\n",
      "training loss 0.0008389580915052172\n",
      "testing loss 0.0028586145651407855\n",
      "epochs 5150\n",
      "training loss 0.0011938739738548826\n",
      "epochs 5151\n",
      "training loss 0.0014403362228219486\n",
      "epochs 5152\n",
      "training loss 0.0028912270060205397\n",
      "epochs 5153\n",
      "training loss 0.0014105283722103117\n",
      "epochs 5154\n",
      "training loss 0.0014515849067242164\n",
      "epochs 5155\n",
      "training loss 0.001088132768463185\n",
      "epochs 5156\n",
      "training loss 0.000927772045211221\n",
      "epochs 5157\n",
      "training loss 0.0007764756222896697\n",
      "epochs 5158\n",
      "training loss 0.0007060114135944474\n",
      "epochs 5159\n",
      "training loss 0.0006472255930581942\n",
      "testing loss 0.0026068645599628434\n",
      "epochs 5160\n",
      "training loss 0.0006158214406921361\n",
      "epochs 5161\n",
      "training loss 0.0006173047119267511\n",
      "epochs 5162\n",
      "training loss 0.0005430069103260952\n",
      "epochs 5163\n",
      "training loss 0.00055468947103666\n",
      "epochs 5164\n",
      "training loss 0.0005134181517578299\n",
      "epochs 5165\n",
      "training loss 0.0005555130088578706\n",
      "epochs 5166\n",
      "training loss 0.0005464646701650031\n",
      "epochs 5167\n",
      "training loss 0.0005214720552024293\n",
      "epochs 5168\n",
      "training loss 0.0006372487804276365\n",
      "epochs 5169\n",
      "training loss 0.0005619944210198218\n",
      "testing loss 0.002627755098741713\n",
      "epochs 5170\n",
      "training loss 0.0005516724844638677\n",
      "epochs 5171\n",
      "training loss 0.0005545539855405031\n",
      "epochs 5172\n",
      "training loss 0.0005858807677175216\n",
      "epochs 5173\n",
      "training loss 0.0005798909526019666\n",
      "epochs 5174\n",
      "training loss 0.0007510520567364515\n",
      "epochs 5175\n",
      "training loss 0.0006574002257512888\n",
      "epochs 5176\n",
      "training loss 0.0006088252729732022\n",
      "epochs 5177\n",
      "training loss 0.0005731466072356741\n",
      "epochs 5178\n",
      "training loss 0.0006636962634978369\n",
      "epochs 5179\n",
      "training loss 0.0006258636407835811\n",
      "testing loss 0.0029768142688207013\n",
      "epochs 5180\n",
      "training loss 0.0006285704256390649\n",
      "epochs 5181\n",
      "training loss 0.0005987332919739912\n",
      "epochs 5182\n",
      "training loss 0.0006117848986384705\n",
      "epochs 5183\n",
      "training loss 0.0005930856321931259\n",
      "epochs 5184\n",
      "training loss 0.0005779335520153803\n",
      "epochs 5185\n",
      "training loss 0.0005475901336887551\n",
      "epochs 5186\n",
      "training loss 0.000558708771680394\n",
      "epochs 5187\n",
      "training loss 0.0005542389246335078\n",
      "epochs 5188\n",
      "training loss 0.0005213325790315017\n",
      "epochs 5189\n",
      "training loss 0.0005242270384780711\n",
      "testing loss 0.0026423006379606984\n",
      "epochs 5190\n",
      "training loss 0.0005361284386744513\n",
      "epochs 5191\n",
      "training loss 0.00048073761755710974\n",
      "epochs 5192\n",
      "training loss 0.00047359147231521985\n",
      "epochs 5193\n",
      "training loss 0.000519392009216607\n",
      "epochs 5194\n",
      "training loss 0.0005434719489329695\n",
      "epochs 5195\n",
      "training loss 0.0005270440434318002\n",
      "epochs 5196\n",
      "training loss 0.0005126154141523239\n",
      "epochs 5197\n",
      "training loss 0.0004992660740638112\n",
      "epochs 5198\n",
      "training loss 0.0005095064066637783\n",
      "epochs 5199\n",
      "training loss 0.0005540682984293809\n",
      "testing loss 0.002601729221691556\n",
      "epochs 5200\n",
      "training loss 0.000505616324992658\n",
      "epochs 5201\n",
      "training loss 0.0005557093365750584\n",
      "epochs 5202\n",
      "training loss 0.0005399636854559161\n",
      "epochs 5203\n",
      "training loss 0.0004931931186815593\n",
      "epochs 5204\n",
      "training loss 0.0005023185045021023\n",
      "epochs 5205\n",
      "training loss 0.0005781222472751462\n",
      "epochs 5206\n",
      "training loss 0.0005402108253649291\n",
      "epochs 5207\n",
      "training loss 0.0005016703306170786\n",
      "epochs 5208\n",
      "training loss 0.0005045924502025757\n",
      "epochs 5209\n",
      "training loss 0.0004871180751658183\n",
      "testing loss 0.0025866838260421676\n",
      "epochs 5210\n",
      "training loss 0.0004882610754724196\n",
      "epochs 5211\n",
      "training loss 0.0005138215397825708\n",
      "epochs 5212\n",
      "training loss 0.0005212759381120509\n",
      "epochs 5213\n",
      "training loss 0.0005036411527579645\n",
      "epochs 5214\n",
      "training loss 0.000499326737061862\n",
      "epochs 5215\n",
      "training loss 0.0005062047889637322\n",
      "epochs 5216\n",
      "training loss 0.0005052175561615795\n",
      "epochs 5217\n",
      "training loss 0.00048465815006180647\n",
      "epochs 5218\n",
      "training loss 0.0005341108262434172\n",
      "epochs 5219\n",
      "training loss 0.0004941142536770541\n",
      "testing loss 0.00263594624261101\n",
      "epochs 5220\n",
      "training loss 0.00048441495916220193\n",
      "epochs 5221\n",
      "training loss 0.0007083393369927311\n",
      "epochs 5222\n",
      "training loss 0.0006527809267311631\n",
      "epochs 5223\n",
      "training loss 0.0005144912809328853\n",
      "epochs 5224\n",
      "training loss 0.0005227905779682089\n",
      "epochs 5225\n",
      "training loss 0.00053383328963926\n",
      "epochs 5226\n",
      "training loss 0.0005229634164172964\n",
      "epochs 5227\n",
      "training loss 0.0004848702806281634\n",
      "epochs 5228\n",
      "training loss 0.0004875031452042852\n",
      "epochs 5229\n",
      "training loss 0.00048576237283163\n",
      "testing loss 0.0026020736772903895\n",
      "epochs 5230\n",
      "training loss 0.0005027794907765469\n",
      "epochs 5231\n",
      "training loss 0.0005057806518540285\n",
      "epochs 5232\n",
      "training loss 0.0005262635970604252\n",
      "epochs 5233\n",
      "training loss 0.0004819737985096079\n",
      "epochs 5234\n",
      "training loss 0.0005525749739886496\n",
      "epochs 5235\n",
      "training loss 0.000623573681784052\n",
      "epochs 5236\n",
      "training loss 0.0005390884920510274\n",
      "epochs 5237\n",
      "training loss 0.0004985899350246398\n",
      "epochs 5238\n",
      "training loss 0.0005010840424448308\n",
      "epochs 5239\n",
      "training loss 0.0005161314966520833\n",
      "testing loss 0.0026309488185166205\n",
      "epochs 5240\n",
      "training loss 0.0008891650562607725\n",
      "epochs 5241\n",
      "training loss 0.0015149751965078246\n",
      "epochs 5242\n",
      "training loss 0.0006988085712600602\n",
      "epochs 5243\n",
      "training loss 0.0006543884482333793\n",
      "epochs 5244\n",
      "training loss 0.0005172762720269578\n",
      "epochs 5245\n",
      "training loss 0.0005190451477306094\n",
      "epochs 5246\n",
      "training loss 0.0005137851904252527\n",
      "epochs 5247\n",
      "training loss 0.000461295007347302\n",
      "epochs 5248\n",
      "training loss 0.0004720257671789116\n",
      "epochs 5249\n",
      "training loss 0.0005399073429170736\n",
      "testing loss 0.0026532673844175928\n",
      "epochs 5250\n",
      "training loss 0.0005110355258967421\n",
      "epochs 5251\n",
      "training loss 0.0004929923520552271\n",
      "epochs 5252\n",
      "training loss 0.0004661325843881612\n",
      "epochs 5253\n",
      "training loss 0.0004920223595130068\n",
      "epochs 5254\n",
      "training loss 0.0004911551213615197\n",
      "epochs 5255\n",
      "training loss 0.0004650523076131147\n",
      "epochs 5256\n",
      "training loss 0.000483964476805169\n",
      "epochs 5257\n",
      "training loss 0.0005015890836032068\n",
      "epochs 5258\n",
      "training loss 0.0004919891999885836\n",
      "epochs 5259\n",
      "training loss 0.0005172122016692064\n",
      "testing loss 0.0026764015758786587\n",
      "epochs 5260\n",
      "training loss 0.000478289348846811\n",
      "epochs 5261\n",
      "training loss 0.00048073828897982453\n",
      "epochs 5262\n",
      "training loss 0.0005097699322504923\n",
      "epochs 5263\n",
      "training loss 0.0004950068807186938\n",
      "epochs 5264\n",
      "training loss 0.000476653953217321\n",
      "epochs 5265\n",
      "training loss 0.0004721308179414834\n",
      "epochs 5266\n",
      "training loss 0.0005396621480108576\n",
      "epochs 5267\n",
      "training loss 0.0004772107485939372\n",
      "epochs 5268\n",
      "training loss 0.0005009643296324748\n",
      "epochs 5269\n",
      "training loss 0.00048072550700210305\n",
      "testing loss 0.0026717013667060183\n",
      "epochs 5270\n",
      "training loss 0.00048387810017483303\n",
      "epochs 5271\n",
      "training loss 0.0006332507968800974\n",
      "epochs 5272\n",
      "training loss 0.0006304252998886409\n",
      "epochs 5273\n",
      "training loss 0.0007447588241037751\n",
      "epochs 5274\n",
      "training loss 0.0005225424947943199\n",
      "epochs 5275\n",
      "training loss 0.0004880555098102142\n",
      "epochs 5276\n",
      "training loss 0.0005039851693224196\n",
      "epochs 5277\n",
      "training loss 0.0004956559190936358\n",
      "epochs 5278\n",
      "training loss 0.0005282432641119252\n",
      "epochs 5279\n",
      "training loss 0.0004658093569817242\n",
      "testing loss 0.0026481221260747324\n",
      "epochs 5280\n",
      "training loss 0.0005421171080367781\n",
      "epochs 5281\n",
      "training loss 0.0005195565160971112\n",
      "epochs 5282\n",
      "training loss 0.000490192767911333\n",
      "epochs 5283\n",
      "training loss 0.0006795054195288817\n",
      "epochs 5284\n",
      "training loss 0.0007788468415722942\n",
      "epochs 5285\n",
      "training loss 0.0006086953301202098\n",
      "epochs 5286\n",
      "training loss 0.0004943185544284032\n",
      "epochs 5287\n",
      "training loss 0.0004885392506800784\n",
      "epochs 5288\n",
      "training loss 0.000450598262285808\n",
      "epochs 5289\n",
      "training loss 0.0005084111078891416\n",
      "testing loss 0.0026827220101543563\n",
      "epochs 5290\n",
      "training loss 0.0005971683429180444\n",
      "epochs 5291\n",
      "training loss 0.0005030092586180065\n",
      "epochs 5292\n",
      "training loss 0.0005083199550459971\n",
      "epochs 5293\n",
      "training loss 0.00047742263942965416\n",
      "epochs 5294\n",
      "training loss 0.00046781665091063135\n",
      "epochs 5295\n",
      "training loss 0.0004747335705799999\n",
      "epochs 5296\n",
      "training loss 0.0004904545606701354\n",
      "epochs 5297\n",
      "training loss 0.0004880031866961269\n",
      "epochs 5298\n",
      "training loss 0.0005046372888553152\n",
      "epochs 5299\n",
      "training loss 0.0005168677424434516\n",
      "testing loss 0.0027593510928861005\n",
      "epochs 5300\n",
      "training loss 0.00047425692476400126\n",
      "epochs 5301\n",
      "training loss 0.0004934396096370763\n",
      "epochs 5302\n",
      "training loss 0.0004882270169138659\n",
      "epochs 5303\n",
      "training loss 0.0006148672985029053\n",
      "epochs 5304\n",
      "training loss 0.0005289996141039888\n",
      "epochs 5305\n",
      "training loss 0.0005032123253315597\n",
      "epochs 5306\n",
      "training loss 0.0004896152507843546\n",
      "epochs 5307\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss 0.0005386946392903744\n",
      "epochs 5308\n",
      "training loss 0.0004857299023337583\n",
      "epochs 5309\n",
      "training loss 0.00047809888435723007\n",
      "testing loss 0.0027540434343436507\n",
      "epochs 5310\n",
      "training loss 0.0005214579303792783\n",
      "epochs 5311\n",
      "training loss 0.00048211717724766143\n",
      "epochs 5312\n",
      "training loss 0.0005319738126498588\n",
      "epochs 5313\n",
      "training loss 0.000452850905574694\n",
      "epochs 5314\n",
      "training loss 0.0005192230901423287\n",
      "epochs 5315\n",
      "training loss 0.0004715559704938343\n",
      "epochs 5316\n",
      "training loss 0.000473664018876092\n",
      "epochs 5317\n",
      "training loss 0.0005301894990449183\n",
      "epochs 5318\n",
      "training loss 0.0004712598451227799\n",
      "epochs 5319\n",
      "training loss 0.0004808833859054128\n",
      "testing loss 0.0026831754907661824\n",
      "epochs 5320\n",
      "training loss 0.0005812790137956253\n",
      "epochs 5321\n",
      "training loss 0.00048501061823708785\n",
      "epochs 5322\n",
      "training loss 0.0004968874924851576\n",
      "epochs 5323\n",
      "training loss 0.0004820218745875243\n",
      "epochs 5324\n",
      "training loss 0.0004713228864080094\n",
      "epochs 5325\n",
      "training loss 0.00049073994071237\n",
      "epochs 5326\n",
      "training loss 0.000516816292444278\n",
      "epochs 5327\n",
      "training loss 0.0004896779619313007\n",
      "epochs 5328\n",
      "training loss 0.00045724849550670587\n",
      "epochs 5329\n",
      "training loss 0.0005158558872699635\n",
      "testing loss 0.002686106601518625\n",
      "epochs 5330\n",
      "training loss 0.00046488903715886676\n",
      "epochs 5331\n",
      "training loss 0.00046943003351737866\n",
      "epochs 5332\n",
      "training loss 0.00047491425105178087\n",
      "epochs 5333\n",
      "training loss 0.0005729772011808892\n",
      "epochs 5334\n",
      "training loss 0.000503600914633513\n",
      "epochs 5335\n",
      "training loss 0.0005025147742770136\n",
      "epochs 5336\n",
      "training loss 0.00051447390223072\n",
      "epochs 5337\n",
      "training loss 0.0004941205811505644\n",
      "epochs 5338\n",
      "training loss 0.0004775959131977376\n",
      "epochs 5339\n",
      "training loss 0.0004288411481089403\n",
      "testing loss 0.0027996222360607845\n",
      "epochs 5340\n",
      "training loss 0.0004641085945913359\n",
      "epochs 5341\n",
      "training loss 0.0004638968400747762\n",
      "epochs 5342\n",
      "training loss 0.0005627065388511266\n",
      "epochs 5343\n",
      "training loss 0.00048293165900067947\n",
      "epochs 5344\n",
      "training loss 0.00048510052023475314\n",
      "epochs 5345\n",
      "training loss 0.00046077333357097373\n",
      "epochs 5346\n",
      "training loss 0.00048438814303435745\n",
      "epochs 5347\n",
      "training loss 0.0005114071462501554\n",
      "epochs 5348\n",
      "training loss 0.0004890906807788192\n",
      "epochs 5349\n",
      "training loss 0.000479696457568658\n",
      "testing loss 0.0027393536945203886\n",
      "epochs 5350\n",
      "training loss 0.0005474655500982568\n",
      "epochs 5351\n",
      "training loss 0.00044951197826784774\n",
      "epochs 5352\n",
      "training loss 0.0004959660011667781\n",
      "epochs 5353\n",
      "training loss 0.00046284302372391986\n",
      "epochs 5354\n",
      "training loss 0.0004820391738512709\n",
      "epochs 5355\n",
      "training loss 0.0004912426925758268\n",
      "epochs 5356\n",
      "training loss 0.0004771082376492264\n",
      "epochs 5357\n",
      "training loss 0.0005073172907560135\n",
      "epochs 5358\n",
      "training loss 0.00046943456283416655\n",
      "epochs 5359\n",
      "training loss 0.000536865092450215\n",
      "testing loss 0.0027089539167292893\n",
      "epochs 5360\n",
      "training loss 0.0004746266530145888\n",
      "epochs 5361\n",
      "training loss 0.00048622299181396496\n",
      "epochs 5362\n",
      "training loss 0.0004788141203676223\n",
      "epochs 5363\n",
      "training loss 0.0004862360297992407\n",
      "epochs 5364\n",
      "training loss 0.0004713356612203501\n",
      "epochs 5365\n",
      "training loss 0.0005507627513583772\n",
      "epochs 5366\n",
      "training loss 0.0008325859841304664\n",
      "epochs 5367\n",
      "training loss 0.001282784679751011\n",
      "epochs 5368\n",
      "training loss 0.0011879001428460913\n",
      "epochs 5369\n",
      "training loss 0.0009716519761984845\n",
      "testing loss 0.002758708005566282\n",
      "epochs 5370\n",
      "training loss 0.0008924988582857678\n",
      "epochs 5371\n",
      "training loss 0.0010046795099735895\n",
      "epochs 5372\n",
      "training loss 0.0009005984688980228\n",
      "epochs 5373\n",
      "training loss 0.0008302254704574525\n",
      "epochs 5374\n",
      "training loss 0.0016914361742492142\n",
      "epochs 5375\n",
      "training loss 0.0011084925448437049\n",
      "epochs 5376\n",
      "training loss 0.0014244351984712218\n",
      "epochs 5377\n",
      "training loss 0.0009229287597503638\n",
      "epochs 5378\n",
      "training loss 0.0010086425123092262\n",
      "epochs 5379\n",
      "training loss 0.0007953545411073498\n",
      "testing loss 0.002650292892444958\n",
      "epochs 5380\n",
      "training loss 0.000694146403801517\n",
      "epochs 5381\n",
      "training loss 0.0006244566337924484\n",
      "epochs 5382\n",
      "training loss 0.0006128898061002324\n",
      "epochs 5383\n",
      "training loss 0.0005825471767616433\n",
      "epochs 5384\n",
      "training loss 0.0006008063740943386\n",
      "epochs 5385\n",
      "training loss 0.0006350599898812347\n",
      "epochs 5386\n",
      "training loss 0.0004795047425874438\n",
      "epochs 5387\n",
      "training loss 0.0005323136403858039\n",
      "epochs 5388\n",
      "training loss 0.0007922198378557401\n",
      "epochs 5389\n",
      "training loss 0.0007483744380767755\n",
      "testing loss 0.0027504726189208476\n",
      "epochs 5390\n",
      "training loss 0.0006817335120117785\n",
      "epochs 5391\n",
      "training loss 0.0009633366767448688\n",
      "epochs 5392\n",
      "training loss 0.000824454813731387\n",
      "epochs 5393\n",
      "training loss 0.0007954113041036578\n",
      "epochs 5394\n",
      "training loss 0.0007992795510904008\n",
      "epochs 5395\n",
      "training loss 0.0008060075368309014\n",
      "epochs 5396\n",
      "training loss 0.0007649518500434625\n",
      "epochs 5397\n",
      "training loss 0.0007444111766374322\n",
      "epochs 5398\n",
      "training loss 0.0007351065405020292\n",
      "epochs 5399\n",
      "training loss 0.000757642068470599\n",
      "testing loss 0.0028311214389127566\n",
      "epochs 5400\n",
      "training loss 0.0007355260663796046\n",
      "epochs 5401\n",
      "training loss 0.000767459720390846\n",
      "epochs 5402\n",
      "training loss 0.0007273540590602429\n",
      "epochs 5403\n",
      "training loss 0.0007749874723153783\n",
      "epochs 5404\n",
      "training loss 0.0007483293060857327\n",
      "epochs 5405\n",
      "training loss 0.0007792020183499608\n",
      "epochs 5406\n",
      "training loss 0.0007712063727239401\n",
      "epochs 5407\n",
      "training loss 0.0007706566642627324\n",
      "epochs 5408\n",
      "training loss 0.0007693198971991006\n",
      "epochs 5409\n",
      "training loss 0.0007611513079432799\n",
      "testing loss 0.002870059762470398\n",
      "epochs 5410\n",
      "training loss 0.0006781866182863294\n",
      "epochs 5411\n",
      "training loss 0.001483758068894741\n",
      "epochs 5412\n",
      "training loss 0.0012600286450629096\n",
      "epochs 5413\n",
      "training loss 0.000748796004318635\n",
      "epochs 5414\n",
      "training loss 0.000598168246767209\n",
      "epochs 5415\n",
      "training loss 0.0006680345388503015\n",
      "epochs 5416\n",
      "training loss 0.0005681722670493472\n",
      "epochs 5417\n",
      "training loss 0.0005182233996622797\n",
      "epochs 5418\n",
      "training loss 0.0005061918676591629\n",
      "epochs 5419\n",
      "training loss 0.0005402830033952308\n",
      "testing loss 0.002726346391405091\n",
      "epochs 5420\n",
      "training loss 0.0009672937068683421\n",
      "epochs 5421\n",
      "training loss 0.0014245502759014626\n",
      "epochs 5422\n",
      "training loss 0.0007194566245312522\n",
      "epochs 5423\n",
      "training loss 0.0006071708342385985\n",
      "epochs 5424\n",
      "training loss 0.0005634165562527951\n",
      "epochs 5425\n",
      "training loss 0.0005358805412696929\n",
      "epochs 5426\n",
      "training loss 0.000525621994183396\n",
      "epochs 5427\n",
      "training loss 0.0005371053364321782\n",
      "epochs 5428\n",
      "training loss 0.0005109782448699443\n",
      "epochs 5429\n",
      "training loss 0.00048625055951063485\n",
      "testing loss 0.002632164244840569\n",
      "epochs 5430\n",
      "training loss 0.0004693931487468878\n",
      "epochs 5431\n",
      "training loss 0.0004991836356505819\n",
      "epochs 5432\n",
      "training loss 0.0005056883858114843\n",
      "epochs 5433\n",
      "training loss 0.0005020909671286704\n",
      "epochs 5434\n",
      "training loss 0.00047804551686678296\n",
      "epochs 5435\n",
      "training loss 0.001662919095326017\n",
      "epochs 5436\n",
      "training loss 0.0009912731889196555\n",
      "epochs 5437\n",
      "training loss 0.0007389612440345385\n",
      "epochs 5438\n",
      "training loss 0.0006801685503058384\n",
      "epochs 5439\n",
      "training loss 0.0006478730228051577\n",
      "testing loss 0.002432115549380158\n",
      "epochs 5440\n",
      "training loss 0.0006673942903186956\n",
      "epochs 5441\n",
      "training loss 0.0005765617795898593\n",
      "epochs 5442\n",
      "training loss 0.0006498386455334633\n",
      "epochs 5443\n",
      "training loss 0.0006350651481592218\n",
      "epochs 5444\n",
      "training loss 0.000924199927664761\n",
      "epochs 5445\n",
      "training loss 0.0011613065309470129\n",
      "epochs 5446\n",
      "training loss 0.0007122235170439577\n",
      "epochs 5447\n",
      "training loss 0.000723983411497428\n",
      "epochs 5448\n",
      "training loss 0.0006347132775413104\n",
      "epochs 5449\n",
      "training loss 0.000664179355237282\n",
      "testing loss 0.0023526369692288764\n",
      "epochs 5450\n",
      "training loss 0.0005888627049630638\n",
      "epochs 5451\n",
      "training loss 0.0006756429041390474\n",
      "epochs 5452\n",
      "training loss 0.00060967608816047\n",
      "epochs 5453\n",
      "training loss 0.0006190484151170564\n",
      "epochs 5454\n",
      "training loss 0.0006139636919748797\n",
      "epochs 5455\n",
      "training loss 0.0006192192499133784\n",
      "epochs 5456\n",
      "training loss 0.0005469088033754605\n",
      "epochs 5457\n",
      "training loss 0.0006433771697607594\n",
      "epochs 5458\n",
      "training loss 0.0007693562162141273\n",
      "epochs 5459\n",
      "training loss 0.0006232898677755883\n",
      "testing loss 0.0023217749214691527\n",
      "epochs 5460\n",
      "training loss 0.0005823179121776046\n",
      "epochs 5461\n",
      "training loss 0.0006333783472920726\n",
      "epochs 5462\n",
      "training loss 0.000630553715365534\n",
      "epochs 5463\n",
      "training loss 0.0005936526601757617\n",
      "epochs 5464\n",
      "training loss 0.0006334636872421984\n",
      "epochs 5465\n",
      "training loss 0.0008174619968452613\n",
      "epochs 5466\n",
      "training loss 0.0011047785808006726\n",
      "epochs 5467\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss 0.0008409113376748134\n",
      "epochs 5468\n",
      "training loss 0.0006884279830549705\n",
      "epochs 5469\n",
      "training loss 0.0007027984168812191\n",
      "testing loss 0.002286079014380667\n",
      "epochs 5470\n",
      "training loss 0.000643445804466049\n",
      "epochs 5471\n",
      "training loss 0.0006799010724808715\n",
      "epochs 5472\n",
      "training loss 0.0006006004440592529\n",
      "epochs 5473\n",
      "training loss 0.0006612169490504365\n",
      "epochs 5474\n",
      "training loss 0.000563996603024563\n",
      "epochs 5475\n",
      "training loss 0.0005831546551763083\n",
      "epochs 5476\n",
      "training loss 0.0006011154980853053\n",
      "epochs 5477\n",
      "training loss 0.0006118412924849777\n",
      "epochs 5478\n",
      "training loss 0.0006275343914632332\n",
      "epochs 5479\n",
      "training loss 0.0005905602104667472\n",
      "testing loss 0.002473748093371854\n",
      "epochs 5480\n",
      "training loss 0.0005903075558684008\n",
      "epochs 5481\n",
      "training loss 0.0006204686172010723\n",
      "epochs 5482\n",
      "training loss 0.0005747371315701346\n",
      "epochs 5483\n",
      "training loss 0.0005819331863427982\n",
      "epochs 5484\n",
      "training loss 0.0005786293605554815\n",
      "epochs 5485\n",
      "training loss 0.000573635783710299\n",
      "epochs 5486\n",
      "training loss 0.0005808547799090506\n",
      "epochs 5487\n",
      "training loss 0.0005630107694178095\n",
      "epochs 5488\n",
      "training loss 0.000603755889849675\n",
      "epochs 5489\n",
      "training loss 0.0005880164449233392\n",
      "testing loss 0.0024527111685180916\n",
      "epochs 5490\n",
      "training loss 0.0005685022724636669\n",
      "epochs 5491\n",
      "training loss 0.0006199351689349407\n",
      "epochs 5492\n",
      "training loss 0.0006188350469744438\n",
      "epochs 5493\n",
      "training loss 0.0005640714230457474\n",
      "epochs 5494\n",
      "training loss 0.0006142174775533854\n",
      "epochs 5495\n",
      "training loss 0.000589778690438259\n",
      "epochs 5496\n",
      "training loss 0.0005785031171620322\n",
      "epochs 5497\n",
      "training loss 0.00061860505161003\n",
      "epochs 5498\n",
      "training loss 0.0005706534893457186\n",
      "epochs 5499\n",
      "training loss 0.0006338682583509166\n",
      "testing loss 0.0026922271374764965\n",
      "epochs 5500\n",
      "training loss 0.0005961436924091498\n",
      "epochs 5501\n",
      "training loss 0.0006404143731048936\n",
      "epochs 5502\n",
      "training loss 0.0008086142946518731\n",
      "epochs 5503\n",
      "training loss 0.0006706104378533014\n",
      "epochs 5504\n",
      "training loss 0.0006137135851559283\n",
      "epochs 5505\n",
      "training loss 0.0005637838881700597\n",
      "epochs 5506\n",
      "training loss 0.0005559131057613097\n",
      "epochs 5507\n",
      "training loss 0.0005422506610916696\n",
      "epochs 5508\n",
      "training loss 0.0005210493153419719\n",
      "epochs 5509\n",
      "training loss 0.0006201922934924147\n",
      "testing loss 0.002333748169203705\n",
      "epochs 5510\n",
      "training loss 0.000571317980129634\n",
      "epochs 5511\n",
      "training loss 0.000542033730516363\n",
      "epochs 5512\n",
      "training loss 0.0005083446173134648\n",
      "epochs 5513\n",
      "training loss 0.0005960395872999141\n",
      "epochs 5514\n",
      "training loss 0.0005861053153579505\n",
      "epochs 5515\n",
      "training loss 0.0006449207589936111\n",
      "epochs 5516\n",
      "training loss 0.0005646060813766109\n",
      "epochs 5517\n",
      "training loss 0.0007310012430816005\n",
      "epochs 5518\n",
      "training loss 0.000587759856973268\n",
      "epochs 5519\n",
      "training loss 0.0005699123756069758\n",
      "testing loss 0.002726246622235825\n",
      "epochs 5520\n",
      "training loss 0.0005475645837986892\n",
      "epochs 5521\n",
      "training loss 0.0007349096935158907\n",
      "epochs 5522\n",
      "training loss 0.0008239479194817028\n",
      "epochs 5523\n",
      "training loss 0.0005970236270845581\n",
      "epochs 5524\n",
      "training loss 0.0006067824223019341\n",
      "epochs 5525\n",
      "training loss 0.0005542210994661987\n",
      "epochs 5526\n",
      "training loss 0.0005843949696688848\n",
      "epochs 5527\n",
      "training loss 0.0005686660053061271\n",
      "epochs 5528\n",
      "training loss 0.0005617636518827484\n",
      "epochs 5529\n",
      "training loss 0.0005424817965477761\n",
      "testing loss 0.002681140252884398\n",
      "epochs 5530\n",
      "training loss 0.0005983986203044959\n",
      "epochs 5531\n",
      "training loss 0.0005445996806093444\n",
      "epochs 5532\n",
      "training loss 0.0006233921982588581\n",
      "epochs 5533\n",
      "training loss 0.00061790531007205\n",
      "epochs 5534\n",
      "training loss 0.0005827208553295084\n",
      "epochs 5535\n",
      "training loss 0.0005056184974299478\n",
      "epochs 5536\n",
      "training loss 0.0006026946512258988\n",
      "epochs 5537\n",
      "training loss 0.0005759379010340397\n",
      "epochs 5538\n",
      "training loss 0.0005615700468333229\n",
      "epochs 5539\n",
      "training loss 0.0005496216581930551\n",
      "testing loss 0.0027186800820706743\n",
      "epochs 5540\n",
      "training loss 0.0005891618484632597\n",
      "epochs 5541\n",
      "training loss 0.0005435892119812623\n",
      "epochs 5542\n",
      "training loss 0.0005636381050486876\n",
      "epochs 5543\n",
      "training loss 0.0005835156112316271\n",
      "epochs 5544\n",
      "training loss 0.0005947372660792424\n",
      "epochs 5545\n",
      "training loss 0.0006369786101887371\n",
      "epochs 5546\n",
      "training loss 0.0005670810537801994\n",
      "epochs 5547\n",
      "training loss 0.0005980679897328211\n",
      "epochs 5548\n",
      "training loss 0.000588856515666402\n",
      "epochs 5549\n",
      "training loss 0.0006048388902655602\n",
      "testing loss 0.0026253868222190398\n",
      "epochs 5550\n",
      "training loss 0.0005378221419263394\n",
      "epochs 5551\n",
      "training loss 0.0006420223287761064\n",
      "epochs 5552\n",
      "training loss 0.0005630462047910052\n",
      "epochs 5553\n",
      "training loss 0.0005565557132070279\n",
      "epochs 5554\n",
      "training loss 0.0005710254620412495\n",
      "epochs 5555\n",
      "training loss 0.0005597030031133873\n",
      "epochs 5556\n",
      "training loss 0.0006230977361407527\n",
      "epochs 5557\n",
      "training loss 0.0005530785792401077\n",
      "epochs 5558\n",
      "training loss 0.0006034116792007092\n",
      "epochs 5559\n",
      "training loss 0.0005647143201143863\n",
      "testing loss 0.0027149359213439286\n",
      "epochs 5560\n",
      "training loss 0.0005944578279068802\n",
      "epochs 5561\n",
      "training loss 0.0005579278949438665\n",
      "epochs 5562\n",
      "training loss 0.0005546540096557861\n",
      "epochs 5563\n",
      "training loss 0.0005415272912241258\n",
      "epochs 5564\n",
      "training loss 0.0006405251765182089\n",
      "epochs 5565\n",
      "training loss 0.000563035992265744\n",
      "epochs 5566\n",
      "training loss 0.0007151238208758364\n",
      "epochs 5567\n",
      "training loss 0.0007654203422753972\n",
      "epochs 5568\n",
      "training loss 0.0007018345413626225\n",
      "epochs 5569\n",
      "training loss 0.0005868497351679872\n",
      "testing loss 0.0025884594461973096\n",
      "epochs 5570\n",
      "training loss 0.0005903056391732807\n",
      "epochs 5571\n",
      "training loss 0.0005722672659599457\n",
      "epochs 5572\n",
      "training loss 0.0006029148834494246\n",
      "epochs 5573\n",
      "training loss 0.0005706171722768446\n",
      "epochs 5574\n",
      "training loss 0.0006132267770607953\n",
      "epochs 5575\n",
      "training loss 0.000556112808726677\n",
      "epochs 5576\n",
      "training loss 0.0005669686336446791\n",
      "epochs 5577\n",
      "training loss 0.0008202240157286469\n",
      "epochs 5578\n",
      "training loss 0.0007720926531843875\n",
      "epochs 5579\n",
      "training loss 0.0007740500926055683\n",
      "testing loss 0.002755433887801404\n",
      "epochs 5580\n",
      "training loss 0.00067261645130213\n",
      "epochs 5581\n",
      "training loss 0.0007050239203616659\n",
      "epochs 5582\n",
      "training loss 0.0006718370424071185\n",
      "epochs 5583\n",
      "training loss 0.0005363510242390154\n",
      "epochs 5584\n",
      "training loss 0.000586413202922661\n",
      "epochs 5585\n",
      "training loss 0.0006403203382748419\n",
      "epochs 5586\n",
      "training loss 0.0005179192403955583\n",
      "epochs 5587\n",
      "training loss 0.0005351171039199134\n",
      "epochs 5588\n",
      "training loss 0.0005694817011046441\n",
      "epochs 5589\n",
      "training loss 0.0005619562326365725\n",
      "testing loss 0.0026633872618363735\n",
      "epochs 5590\n",
      "training loss 0.0006300720827983789\n",
      "epochs 5591\n",
      "training loss 0.0005546066783351603\n",
      "epochs 5592\n",
      "training loss 0.0005470163059367099\n",
      "epochs 5593\n",
      "training loss 0.0005707195553062399\n",
      "epochs 5594\n",
      "training loss 0.0005731572766645351\n",
      "epochs 5595\n",
      "training loss 0.000545717802360133\n",
      "epochs 5596\n",
      "training loss 0.0005806289011885704\n",
      "epochs 5597\n",
      "training loss 0.0005606594579513709\n",
      "epochs 5598\n",
      "training loss 0.0006097105688130268\n",
      "epochs 5599\n",
      "training loss 0.0005977084280075194\n",
      "testing loss 0.0026513256189571893\n",
      "epochs 5600\n",
      "training loss 0.000539816482616079\n",
      "epochs 5601\n",
      "training loss 0.0005647327168313871\n",
      "epochs 5602\n",
      "training loss 0.0006492552972903991\n",
      "epochs 5603\n",
      "training loss 0.0006421878862252748\n",
      "epochs 5604\n",
      "training loss 0.0006147079345080888\n",
      "epochs 5605\n",
      "training loss 0.0006195671197719091\n",
      "epochs 5606\n",
      "training loss 0.0005474748750893812\n",
      "epochs 5607\n",
      "training loss 0.0005367484348765956\n",
      "epochs 5608\n",
      "training loss 0.0005819631412612575\n",
      "epochs 5609\n",
      "training loss 0.0008569653989891536\n",
      "testing loss 0.00276663414440415\n",
      "epochs 5610\n",
      "training loss 0.0008050901030641796\n",
      "epochs 5611\n",
      "training loss 0.0007570454378231601\n",
      "epochs 5612\n",
      "training loss 0.0006711614524484202\n",
      "epochs 5613\n",
      "training loss 0.0006195391057870184\n",
      "epochs 5614\n",
      "training loss 0.0006202161812795309\n",
      "epochs 5615\n",
      "training loss 0.0005420073884536476\n",
      "epochs 5616\n",
      "training loss 0.0005738793150981815\n",
      "epochs 5617\n",
      "training loss 0.0006297629772074022\n",
      "epochs 5618\n",
      "training loss 0.0007917952678155007\n",
      "epochs 5619\n",
      "training loss 0.002969016838326235\n",
      "testing loss 0.0033793151213503477\n",
      "epochs 5620\n",
      "training loss 0.0018655232953170944\n",
      "epochs 5621\n",
      "training loss 0.0016284308670156586\n",
      "epochs 5622\n",
      "training loss 0.0013110942924168742\n",
      "epochs 5623\n",
      "training loss 0.0011390707639398444\n",
      "epochs 5624\n",
      "training loss 0.0009737132697636516\n",
      "epochs 5625\n",
      "training loss 0.0012960390813753439\n",
      "epochs 5626\n",
      "training loss 0.0019190473157182156\n",
      "epochs 5627\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss 0.0017494203104909316\n",
      "epochs 5628\n",
      "training loss 0.001573016730987815\n",
      "epochs 5629\n",
      "training loss 0.0016627285359172564\n",
      "testing loss 0.0028331945547074447\n",
      "epochs 5630\n",
      "training loss 0.0014051798380604213\n",
      "epochs 5631\n",
      "training loss 0.0011641435114784296\n",
      "epochs 5632\n",
      "training loss 0.0010706176968945309\n",
      "epochs 5633\n",
      "training loss 0.0008086235372853496\n",
      "epochs 5634\n",
      "training loss 0.0008155880710867298\n",
      "epochs 5635\n",
      "training loss 0.0008877694077250522\n",
      "epochs 5636\n",
      "training loss 0.0010553280133640784\n",
      "epochs 5637\n",
      "training loss 0.0008390922668866961\n",
      "epochs 5638\n",
      "training loss 0.0009173805947312207\n",
      "epochs 5639\n",
      "training loss 0.0018620104481194362\n",
      "testing loss 0.004009278738831586\n",
      "epochs 5640\n",
      "training loss 0.0020733597337361707\n",
      "epochs 5641\n",
      "training loss 0.0010681192003690148\n",
      "epochs 5642\n",
      "training loss 0.0010464639998448723\n",
      "epochs 5643\n",
      "training loss 0.0009181272979092566\n",
      "epochs 5644\n",
      "training loss 0.0008002273612945853\n",
      "epochs 5645\n",
      "training loss 0.0008210069866140449\n",
      "epochs 5646\n",
      "training loss 0.0007384055606188609\n",
      "epochs 5647\n",
      "training loss 0.002680031061232639\n",
      "epochs 5648\n",
      "training loss 0.001298500171163343\n",
      "epochs 5649\n",
      "training loss 0.0010182701125896697\n",
      "testing loss 0.002625291144511669\n",
      "epochs 5650\n",
      "training loss 0.0009270862241503485\n",
      "epochs 5651\n",
      "training loss 0.0010308171284532225\n",
      "epochs 5652\n",
      "training loss 0.0008343069863330154\n",
      "epochs 5653\n",
      "training loss 0.0007157846122002087\n",
      "epochs 5654\n",
      "training loss 0.0009110825544819066\n",
      "epochs 5655\n",
      "training loss 0.0007136051239987897\n",
      "epochs 5656\n",
      "training loss 0.0007478292560131264\n",
      "epochs 5657\n",
      "training loss 0.0008098877772496374\n",
      "epochs 5658\n",
      "training loss 0.0006995594118704799\n",
      "epochs 5659\n",
      "training loss 0.0007858447137672318\n",
      "testing loss 0.0029101248835510713\n",
      "epochs 5660\n",
      "training loss 0.0007601176637315437\n",
      "epochs 5661\n",
      "training loss 0.0006558576669178813\n",
      "epochs 5662\n",
      "training loss 0.0007841868575883174\n",
      "epochs 5663\n",
      "training loss 0.0007355066000747191\n",
      "epochs 5664\n",
      "training loss 0.0007409295670498491\n",
      "epochs 5665\n",
      "training loss 0.0007615962606609875\n",
      "epochs 5666\n",
      "training loss 0.000747706015887288\n",
      "epochs 5667\n",
      "training loss 0.0007659677943493605\n",
      "epochs 5668\n",
      "training loss 0.0009508557975225683\n",
      "epochs 5669\n",
      "training loss 0.0014715892044964635\n",
      "testing loss 0.002967746508083181\n",
      "epochs 5670\n",
      "training loss 0.0007560617804575405\n",
      "epochs 5671\n",
      "training loss 0.0007711373441880937\n",
      "epochs 5672\n",
      "training loss 0.0006845883895412347\n",
      "epochs 5673\n",
      "training loss 0.0006903747592395947\n",
      "epochs 5674\n",
      "training loss 0.0006726771917924466\n",
      "epochs 5675\n",
      "training loss 0.0007974953555373198\n",
      "epochs 5676\n",
      "training loss 0.0007651718451017316\n",
      "epochs 5677\n",
      "training loss 0.0007817018441862984\n",
      "epochs 5678\n",
      "training loss 0.0008394828440952695\n",
      "epochs 5679\n",
      "training loss 0.000829324712566352\n",
      "testing loss 0.002858306721335026\n",
      "epochs 5680\n",
      "training loss 0.0006847560289315879\n",
      "epochs 5681\n",
      "training loss 0.0007393789290284914\n",
      "epochs 5682\n",
      "training loss 0.0006743051023413583\n",
      "epochs 5683\n",
      "training loss 0.0006654435829938839\n",
      "epochs 5684\n",
      "training loss 0.0007339068120529473\n",
      "epochs 5685\n",
      "training loss 0.0007850583669259623\n",
      "epochs 5686\n",
      "training loss 0.0007777027366470579\n",
      "epochs 5687\n",
      "training loss 0.0009904537854346766\n",
      "epochs 5688\n",
      "training loss 0.0007985939522447931\n",
      "epochs 5689\n",
      "training loss 0.0007737738394891804\n",
      "testing loss 0.00290051585431574\n",
      "epochs 5690\n",
      "training loss 0.0006724989226039805\n",
      "epochs 5691\n",
      "training loss 0.0012464760041032779\n",
      "epochs 5692\n",
      "training loss 0.0020441044170457566\n",
      "epochs 5693\n",
      "training loss 0.0015020618169380234\n",
      "epochs 5694\n",
      "training loss 0.0012817651880508724\n",
      "epochs 5695\n",
      "training loss 0.0011222969292483283\n",
      "epochs 5696\n",
      "training loss 0.0011135369695306934\n",
      "epochs 5697\n",
      "training loss 0.00154563804228909\n",
      "epochs 5698\n",
      "training loss 0.001193657527960084\n",
      "epochs 5699\n",
      "training loss 0.0030025792852012966\n",
      "testing loss 0.003109293257493975\n",
      "epochs 5700\n",
      "training loss 0.0015550822135107732\n",
      "epochs 5701\n",
      "training loss 0.0013184410316967278\n",
      "epochs 5702\n",
      "training loss 0.0013208599695843845\n",
      "epochs 5703\n",
      "training loss 0.0011170545051873613\n",
      "epochs 5704\n",
      "training loss 0.0010694475627064104\n",
      "epochs 5705\n",
      "training loss 0.0009144680076675054\n",
      "epochs 5706\n",
      "training loss 0.0009456661909869604\n",
      "epochs 5707\n",
      "training loss 0.0008867845462216206\n",
      "epochs 5708\n",
      "training loss 0.00102247630812491\n",
      "epochs 5709\n",
      "training loss 0.0008617641962374671\n",
      "testing loss 0.0025691766546154064\n",
      "epochs 5710\n",
      "training loss 0.0008842078903421057\n",
      "epochs 5711\n",
      "training loss 0.0008614093838769116\n",
      "epochs 5712\n",
      "training loss 0.0009208597987854859\n",
      "epochs 5713\n",
      "training loss 0.000894872471159409\n",
      "epochs 5714\n",
      "training loss 0.0009519802478968667\n",
      "epochs 5715\n",
      "training loss 0.0011051039725059422\n",
      "epochs 5716\n",
      "training loss 0.0010085522470002185\n",
      "epochs 5717\n",
      "training loss 0.0012648474025408424\n",
      "epochs 5718\n",
      "training loss 0.001047985184259039\n",
      "epochs 5719\n",
      "training loss 0.0011427719375128522\n",
      "testing loss 0.002802569552486538\n",
      "epochs 5720\n",
      "training loss 0.0009766139921953047\n",
      "epochs 5721\n",
      "training loss 0.0009282740476289282\n",
      "epochs 5722\n",
      "training loss 0.0007954403002764803\n",
      "epochs 5723\n",
      "training loss 0.0009655940316696751\n",
      "epochs 5724\n",
      "training loss 0.000877229428279007\n",
      "epochs 5725\n",
      "training loss 0.0008033001214219115\n",
      "epochs 5726\n",
      "training loss 0.0008569544916873441\n",
      "epochs 5727\n",
      "training loss 0.0007038705390106638\n",
      "epochs 5728\n",
      "training loss 0.0007578774013359802\n",
      "epochs 5729\n",
      "training loss 0.0008277397791750299\n",
      "testing loss 0.0025226170017965243\n",
      "epochs 5730\n",
      "training loss 0.0008016855249465882\n",
      "epochs 5731\n",
      "training loss 0.0007281618104861217\n",
      "epochs 5732\n",
      "training loss 0.0007781894201884119\n",
      "epochs 5733\n",
      "training loss 0.0008407890135677118\n",
      "epochs 5734\n",
      "training loss 0.0008502627679042088\n",
      "epochs 5735\n",
      "training loss 0.00077930956124965\n",
      "epochs 5736\n",
      "training loss 0.0008928220897614334\n",
      "epochs 5737\n",
      "training loss 0.0007769466494740834\n",
      "epochs 5738\n",
      "training loss 0.0008738136627905263\n",
      "epochs 5739\n",
      "training loss 0.0007143342399709267\n",
      "testing loss 0.0025199907699745175\n",
      "epochs 5740\n",
      "training loss 0.0007169941432440037\n",
      "epochs 5741\n",
      "training loss 0.0007535777919703534\n",
      "epochs 5742\n",
      "training loss 0.0006909990552451891\n",
      "epochs 5743\n",
      "training loss 0.0008816253010850219\n",
      "epochs 5744\n",
      "training loss 0.0007124896137196696\n",
      "epochs 5745\n",
      "training loss 0.0007142735122190647\n",
      "epochs 5746\n",
      "training loss 0.000742131973228256\n",
      "epochs 5747\n",
      "training loss 0.0007067373441567639\n",
      "epochs 5748\n",
      "training loss 0.0007734860754982317\n",
      "epochs 5749\n",
      "training loss 0.0007634426279228441\n",
      "testing loss 0.0025846394241691717\n",
      "epochs 5750\n",
      "training loss 0.0006012471041027853\n",
      "epochs 5751\n",
      "training loss 0.0007394075615361254\n",
      "epochs 5752\n",
      "training loss 0.0007319292823195254\n",
      "epochs 5753\n",
      "training loss 0.0029912054672126733\n",
      "epochs 5754\n",
      "training loss 0.002351038817508786\n",
      "epochs 5755\n",
      "training loss 0.0019108543264832471\n",
      "epochs 5756\n",
      "training loss 0.001492933856445792\n",
      "epochs 5757\n",
      "training loss 0.0017943761354286825\n",
      "epochs 5758\n",
      "training loss 0.0023121133248185837\n",
      "epochs 5759\n",
      "training loss 0.0019787268304070713\n",
      "testing loss 0.003035592238488112\n",
      "epochs 5760\n",
      "training loss 0.0014998938652649974\n",
      "epochs 5761\n",
      "training loss 0.0012281353167529956\n",
      "epochs 5762\n",
      "training loss 0.001175149893342152\n",
      "epochs 5763\n",
      "training loss 0.0011260388855147247\n",
      "epochs 5764\n",
      "training loss 0.0009897797899943491\n",
      "epochs 5765\n",
      "training loss 0.000994238435428046\n",
      "epochs 5766\n",
      "training loss 0.0009893751665164283\n",
      "epochs 5767\n",
      "training loss 0.0009929057950929577\n",
      "epochs 5768\n",
      "training loss 0.0010532546448938855\n",
      "epochs 5769\n",
      "training loss 0.0010602672133732045\n",
      "testing loss 0.0025426158054025036\n",
      "epochs 5770\n",
      "training loss 0.0008456654922568203\n",
      "epochs 5771\n",
      "training loss 0.0009128787961015676\n",
      "epochs 5772\n",
      "training loss 0.0009941103536278962\n",
      "epochs 5773\n",
      "training loss 0.0008719066051075569\n",
      "epochs 5774\n",
      "training loss 0.0007960683178569907\n",
      "epochs 5775\n",
      "training loss 0.0008185218273390277\n",
      "epochs 5776\n",
      "training loss 0.0007927672670181773\n",
      "epochs 5777\n",
      "training loss 0.0007505175264978266\n",
      "epochs 5778\n",
      "training loss 0.0007440799040122574\n",
      "epochs 5779\n",
      "training loss 0.0032981436755005725\n",
      "testing loss 0.003517722271726275\n",
      "epochs 5780\n",
      "training loss 0.0021211862088871786\n",
      "epochs 5781\n",
      "training loss 0.0015750169967397435\n",
      "epochs 5782\n",
      "training loss 0.0013369880801549403\n",
      "epochs 5783\n",
      "training loss 0.0011963662121722356\n",
      "epochs 5784\n",
      "training loss 0.0011005575677888089\n",
      "epochs 5785\n",
      "training loss 0.001106236735871911\n",
      "epochs 5786\n",
      "training loss 0.0009873010256004982\n",
      "epochs 5787\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss 0.0009996723273972836\n",
      "epochs 5788\n",
      "training loss 0.0009266366209236107\n",
      "epochs 5789\n",
      "training loss 0.002128185409419861\n",
      "testing loss 0.0027118120961723492\n",
      "epochs 5790\n",
      "training loss 0.0017686186691478608\n",
      "epochs 5791\n",
      "training loss 0.0012175091351226742\n",
      "epochs 5792\n",
      "training loss 0.0010398393430524875\n",
      "epochs 5793\n",
      "training loss 0.0015204354093090197\n",
      "epochs 5794\n",
      "training loss 0.0012465381674082118\n",
      "epochs 5795\n",
      "training loss 0.0009116952722937457\n",
      "epochs 5796\n",
      "training loss 0.0008438298793468557\n",
      "epochs 5797\n",
      "training loss 0.0017663887179121206\n",
      "epochs 5798\n",
      "training loss 0.001835018861154236\n",
      "epochs 5799\n",
      "training loss 0.0011355783439157842\n",
      "testing loss 0.0027715802842467126\n",
      "epochs 5800\n",
      "training loss 0.0008962222870006184\n",
      "epochs 5801\n",
      "training loss 0.000971134073004738\n",
      "epochs 5802\n",
      "training loss 0.0028607153311962018\n",
      "epochs 5803\n",
      "training loss 0.0031823454712061805\n",
      "epochs 5804\n",
      "training loss 0.0027777327838181135\n",
      "epochs 5805\n",
      "training loss 0.0023189171142720456\n",
      "epochs 5806\n",
      "training loss 0.0020385815637783463\n",
      "epochs 5807\n",
      "training loss 0.001858009276154386\n",
      "epochs 5808\n",
      "training loss 0.0015818631335934425\n",
      "epochs 5809\n",
      "training loss 0.0015347624341971425\n",
      "testing loss 0.0029269487432745807\n",
      "epochs 5810\n",
      "training loss 0.001555244860046127\n",
      "epochs 5811\n",
      "training loss 0.0012617684532053156\n",
      "epochs 5812\n",
      "training loss 0.0012673720484599471\n",
      "epochs 5813\n",
      "training loss 0.0013415194910032374\n",
      "epochs 5814\n",
      "training loss 0.0011939503266483172\n",
      "epochs 5815\n",
      "training loss 0.0011162500216174123\n",
      "epochs 5816\n",
      "training loss 0.001573745713383101\n",
      "epochs 5817\n",
      "training loss 0.0010926917599235297\n",
      "epochs 5818\n",
      "training loss 0.0011109865497370283\n",
      "epochs 5819\n",
      "training loss 0.0013534750768703927\n",
      "testing loss 0.002894733258001242\n",
      "epochs 5820\n",
      "training loss 0.0011162052483377146\n",
      "epochs 5821\n",
      "training loss 0.0008495336482166893\n",
      "epochs 5822\n",
      "training loss 0.0006729264607926191\n",
      "epochs 5823\n",
      "training loss 0.000701842049885496\n",
      "epochs 5824\n",
      "training loss 0.000621906063437326\n",
      "epochs 5825\n",
      "training loss 0.0006890640197580788\n",
      "epochs 5826\n",
      "training loss 0.0005976985746359107\n",
      "epochs 5827\n",
      "training loss 0.000960101516182056\n",
      "epochs 5828\n",
      "training loss 0.0007714244674524649\n",
      "epochs 5829\n",
      "training loss 0.0006904923089031175\n",
      "testing loss 0.0025888545742483\n",
      "epochs 5830\n",
      "training loss 0.0007604364508134525\n",
      "epochs 5831\n",
      "training loss 0.0007022226174110065\n",
      "epochs 5832\n",
      "training loss 0.0006032405949429832\n",
      "epochs 5833\n",
      "training loss 0.0006051812863039662\n",
      "epochs 5834\n",
      "training loss 0.0005657783542097317\n",
      "epochs 5835\n",
      "training loss 0.0005973133039667829\n",
      "epochs 5836\n",
      "training loss 0.000533514667803416\n",
      "epochs 5837\n",
      "training loss 0.0005501430021849458\n",
      "epochs 5838\n",
      "training loss 0.0005873376526586756\n",
      "epochs 5839\n",
      "training loss 0.0009719364017412338\n",
      "testing loss 0.0027828505547578507\n",
      "epochs 5840\n",
      "training loss 0.0008580832277554849\n",
      "epochs 5841\n",
      "training loss 0.0006976629102087401\n",
      "epochs 5842\n",
      "training loss 0.0006393596305622292\n",
      "epochs 5843\n",
      "training loss 0.0006495592746802954\n",
      "epochs 5844\n",
      "training loss 0.0007451730128342291\n",
      "epochs 5845\n",
      "training loss 0.0006543866122151388\n",
      "epochs 5846\n",
      "training loss 0.0006349605976463803\n",
      "epochs 5847\n",
      "training loss 0.0005921769507178374\n",
      "epochs 5848\n",
      "training loss 0.0005873166610123052\n",
      "epochs 5849\n",
      "training loss 0.0005754787650201356\n",
      "testing loss 0.002594922896076641\n",
      "epochs 5850\n",
      "training loss 0.0005812600882558328\n",
      "epochs 5851\n",
      "training loss 0.0005939807321757396\n",
      "epochs 5852\n",
      "training loss 0.0005622899096450658\n",
      "epochs 5853\n",
      "training loss 0.0006805013963070876\n",
      "epochs 5854\n",
      "training loss 0.0005942881092291869\n",
      "epochs 5855\n",
      "training loss 0.000580361374621322\n",
      "epochs 5856\n",
      "training loss 0.0007931028900025441\n",
      "epochs 5857\n",
      "training loss 0.0008124349782835001\n",
      "epochs 5858\n",
      "training loss 0.000854248259804639\n",
      "epochs 5859\n",
      "training loss 0.0006848883912948139\n",
      "testing loss 0.0025837762485231863\n",
      "epochs 5860\n",
      "training loss 0.0006924896986835203\n",
      "epochs 5861\n",
      "training loss 0.0005330706842698009\n",
      "epochs 5862\n",
      "training loss 0.0008270183722679659\n",
      "epochs 5863\n",
      "training loss 0.0007235667400952361\n",
      "epochs 5864\n",
      "training loss 0.0006240171471987157\n",
      "epochs 5865\n",
      "training loss 0.0005938866051688145\n",
      "epochs 5866\n",
      "training loss 0.0005673786499119989\n",
      "epochs 5867\n",
      "training loss 0.0005861428953030665\n",
      "epochs 5868\n",
      "training loss 0.0006127041157003843\n",
      "epochs 5869\n",
      "training loss 0.0006599928887375549\n",
      "testing loss 0.002492210756762759\n",
      "epochs 5870\n",
      "training loss 0.0006949838068998648\n",
      "epochs 5871\n",
      "training loss 0.0006502744612407143\n",
      "epochs 5872\n",
      "training loss 0.0005925181495184277\n",
      "epochs 5873\n",
      "training loss 0.000626169496564772\n",
      "epochs 5874\n",
      "training loss 0.0005618194824949439\n",
      "epochs 5875\n",
      "training loss 0.0005398434820361322\n",
      "epochs 5876\n",
      "training loss 0.0005258980823191036\n",
      "epochs 5877\n",
      "training loss 0.000566612911855768\n",
      "epochs 5878\n",
      "training loss 0.0005680345085351856\n",
      "epochs 5879\n",
      "training loss 0.0005987368452066901\n",
      "testing loss 0.0025880373960710957\n",
      "epochs 5880\n",
      "training loss 0.0005339364002644166\n",
      "epochs 5881\n",
      "training loss 0.0006319602067146371\n",
      "epochs 5882\n",
      "training loss 0.0006498521103454318\n",
      "epochs 5883\n",
      "training loss 0.0006325351030814905\n",
      "epochs 5884\n",
      "training loss 0.0005481571301791002\n",
      "epochs 5885\n",
      "training loss 0.0007329837304623486\n",
      "epochs 5886\n",
      "training loss 0.0005829145838711751\n",
      "epochs 5887\n",
      "training loss 0.0005588717560501809\n",
      "epochs 5888\n",
      "training loss 0.0005692126707805145\n",
      "epochs 5889\n",
      "training loss 0.0005731003923875232\n",
      "testing loss 0.0025418165807797183\n",
      "epochs 5890\n",
      "training loss 0.000528270957070066\n",
      "epochs 5891\n",
      "training loss 0.0005416148263461447\n",
      "epochs 5892\n",
      "training loss 0.0005439315828081435\n",
      "epochs 5893\n",
      "training loss 0.0005200901031593218\n",
      "epochs 5894\n",
      "training loss 0.0005341392778473026\n",
      "epochs 5895\n",
      "training loss 0.000584844225418887\n",
      "epochs 5896\n",
      "training loss 0.0006026365170764842\n",
      "epochs 5897\n",
      "training loss 0.0005359866571086133\n",
      "epochs 5898\n",
      "training loss 0.0005378675504480021\n",
      "epochs 5899\n",
      "training loss 0.000628416411441363\n",
      "testing loss 0.0025764106172599323\n",
      "epochs 5900\n",
      "training loss 0.0005917594403468672\n",
      "epochs 5901\n",
      "training loss 0.0005629304635457377\n",
      "epochs 5902\n",
      "training loss 0.0006099517616771705\n",
      "epochs 5903\n",
      "training loss 0.0005613132521487478\n",
      "epochs 5904\n",
      "training loss 0.0005589017155686376\n",
      "epochs 5905\n",
      "training loss 0.0005109198093322307\n",
      "epochs 5906\n",
      "training loss 0.0005334841191314308\n",
      "epochs 5907\n",
      "training loss 0.0005404571899089759\n",
      "epochs 5908\n",
      "training loss 0.0005256711030492169\n",
      "epochs 5909\n",
      "training loss 0.0005229590922427055\n",
      "testing loss 0.002623998623172891\n",
      "epochs 5910\n",
      "training loss 0.0005137274466563967\n",
      "epochs 5911\n",
      "training loss 0.0006872601668232921\n",
      "epochs 5912\n",
      "training loss 0.0005767538774324054\n",
      "epochs 5913\n",
      "training loss 0.0005463000947268437\n",
      "epochs 5914\n",
      "training loss 0.0006128156114133262\n",
      "epochs 5915\n",
      "training loss 0.0005979027748507756\n",
      "epochs 5916\n",
      "training loss 0.0005389026392358823\n",
      "epochs 5917\n",
      "training loss 0.0005414109824983952\n",
      "epochs 5918\n",
      "training loss 0.000582329780082742\n",
      "epochs 5919\n",
      "training loss 0.002606423908036406\n",
      "testing loss 0.00347951424336193\n",
      "epochs 5920\n",
      "training loss 0.001987054504738628\n",
      "epochs 5921\n",
      "training loss 0.0014357704437114186\n",
      "epochs 5922\n",
      "training loss 0.0014116621165257514\n",
      "epochs 5923\n",
      "training loss 0.001140953883058802\n",
      "epochs 5924\n",
      "training loss 0.001249007681207052\n",
      "epochs 5925\n",
      "training loss 0.0012080507564548074\n",
      "epochs 5926\n",
      "training loss 0.0010143572447423774\n",
      "epochs 5927\n",
      "training loss 0.0011416515629132785\n",
      "epochs 5928\n",
      "training loss 0.0015567093992946914\n",
      "epochs 5929\n",
      "training loss 0.0009511706256873816\n",
      "testing loss 0.0026295194856439394\n",
      "epochs 5930\n",
      "training loss 0.0007180477646257343\n",
      "epochs 5931\n",
      "training loss 0.0007452592150185053\n",
      "epochs 5932\n",
      "training loss 0.000870956126993273\n",
      "epochs 5933\n",
      "training loss 0.0006740942966627484\n",
      "epochs 5934\n",
      "training loss 0.0006356761920142715\n",
      "epochs 5935\n",
      "training loss 0.0006515147146064007\n",
      "epochs 5936\n",
      "training loss 0.0009831684501063202\n",
      "epochs 5937\n",
      "training loss 0.0010074213469870909\n",
      "epochs 5938\n",
      "training loss 0.0007126210141526451\n",
      "epochs 5939\n",
      "training loss 0.0005963522788543413\n",
      "testing loss 0.0026325747347601975\n",
      "epochs 5940\n",
      "training loss 0.0006036637108532378\n",
      "epochs 5941\n",
      "training loss 0.0005135796111399778\n",
      "epochs 5942\n",
      "training loss 0.0005855528966135892\n",
      "epochs 5943\n",
      "training loss 0.0006126612577004228\n",
      "epochs 5944\n",
      "training loss 0.0005391724450134398\n",
      "epochs 5945\n",
      "training loss 0.0005170230424289215\n",
      "epochs 5946\n",
      "training loss 0.0005626931343698947\n",
      "epochs 5947\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss 0.0005237687080829633\n",
      "epochs 5948\n",
      "training loss 0.0005272320375457905\n",
      "epochs 5949\n",
      "training loss 0.0005113014138917974\n",
      "testing loss 0.0027211980137921182\n",
      "epochs 5950\n",
      "training loss 0.0005241932436232215\n",
      "epochs 5951\n",
      "training loss 0.0005293279904999564\n",
      "epochs 5952\n",
      "training loss 0.0005033390643747415\n",
      "epochs 5953\n",
      "training loss 0.0005264426789446068\n",
      "epochs 5954\n",
      "training loss 0.0005645184148008168\n",
      "epochs 5955\n",
      "training loss 0.0005790772437369933\n",
      "epochs 5956\n",
      "training loss 0.000607569706569621\n",
      "epochs 5957\n",
      "training loss 0.0005473948869709843\n",
      "epochs 5958\n",
      "training loss 0.0016098375127708829\n",
      "epochs 5959\n",
      "training loss 0.0015537223159788477\n",
      "testing loss 0.002712873449707602\n",
      "epochs 5960\n",
      "training loss 0.0015045252205247745\n",
      "epochs 5961\n",
      "training loss 0.001090013700991014\n",
      "epochs 5962\n",
      "training loss 0.001292596482332105\n",
      "epochs 5963\n",
      "training loss 0.0009689179424615435\n",
      "epochs 5964\n",
      "training loss 0.0008110596561637398\n",
      "epochs 5965\n",
      "training loss 0.0007000650735862134\n",
      "epochs 5966\n",
      "training loss 0.0006973082107692776\n",
      "epochs 5967\n",
      "training loss 0.0006996539505771829\n",
      "epochs 5968\n",
      "training loss 0.000646190773900938\n",
      "epochs 5969\n",
      "training loss 0.0005911176459507105\n",
      "testing loss 0.002680012074064675\n",
      "epochs 5970\n",
      "training loss 0.0005757642159200242\n",
      "epochs 5971\n",
      "training loss 0.0005673794557077182\n",
      "epochs 5972\n",
      "training loss 0.0005563844702493875\n",
      "epochs 5973\n",
      "training loss 0.000608998840433435\n",
      "epochs 5974\n",
      "training loss 0.0005676466459443787\n",
      "epochs 5975\n",
      "training loss 0.000505077099395027\n",
      "epochs 5976\n",
      "training loss 0.000524728379646135\n",
      "epochs 5977\n",
      "training loss 0.0005299606516010391\n",
      "epochs 5978\n",
      "training loss 0.0005566316215699329\n",
      "epochs 5979\n",
      "training loss 0.0005208060782654693\n",
      "testing loss 0.0026586264877989626\n",
      "epochs 5980\n",
      "training loss 0.000539819537633662\n",
      "epochs 5981\n",
      "training loss 0.000577437059510086\n",
      "epochs 5982\n",
      "training loss 0.0011116954615469853\n",
      "epochs 5983\n",
      "training loss 0.001037451796167131\n",
      "epochs 5984\n",
      "training loss 0.0007697381817850378\n",
      "epochs 5985\n",
      "training loss 0.0006442086981315063\n",
      "epochs 5986\n",
      "training loss 0.0005699893464808463\n",
      "epochs 5987\n",
      "training loss 0.0005376522576487355\n",
      "epochs 5988\n",
      "training loss 0.0005486963513536566\n",
      "epochs 5989\n",
      "training loss 0.0004960563506911252\n",
      "testing loss 0.002737864023834097\n",
      "epochs 5990\n",
      "training loss 0.0005397600373734457\n",
      "epochs 5991\n",
      "training loss 0.0004934614637829816\n",
      "epochs 5992\n",
      "training loss 0.0005089884417239113\n",
      "epochs 5993\n",
      "training loss 0.0005233933067085125\n",
      "epochs 5994\n",
      "training loss 0.0004945368418260548\n",
      "epochs 5995\n",
      "training loss 0.0005283406952439913\n",
      "epochs 5996\n",
      "training loss 0.0005558748880088454\n",
      "epochs 5997\n",
      "training loss 0.0005133477391534992\n",
      "epochs 5998\n",
      "training loss 0.0005838381163499921\n",
      "epochs 5999\n",
      "training loss 0.0005673281729892236\n",
      "testing loss 0.0026360943579900984\n",
      "epochs 6000\n",
      "training loss 0.0005475906222615686\n",
      "epochs 6001\n",
      "training loss 0.0005192792308120493\n",
      "epochs 6002\n",
      "training loss 0.0005462850408811167\n",
      "epochs 6003\n",
      "training loss 0.0005282254392984621\n",
      "epochs 6004\n",
      "training loss 0.0005383019605906267\n",
      "epochs 6005\n",
      "training loss 0.0005181194513952671\n",
      "epochs 6006\n",
      "training loss 0.0005176896336424733\n",
      "epochs 6007\n",
      "training loss 0.0005390625049842742\n",
      "epochs 6008\n",
      "training loss 0.0005834778652442931\n",
      "epochs 6009\n",
      "training loss 0.0005545384902719375\n",
      "testing loss 0.0025475424365966138\n",
      "epochs 6010\n",
      "training loss 0.0005464420600271979\n",
      "epochs 6011\n",
      "training loss 0.0005284914347742285\n",
      "epochs 6012\n",
      "training loss 0.0005392826039847949\n",
      "epochs 6013\n",
      "training loss 0.0005233253781913035\n",
      "epochs 6014\n",
      "training loss 0.0005432034639739304\n",
      "epochs 6015\n",
      "training loss 0.0005683954956404876\n",
      "epochs 6016\n",
      "training loss 0.0005733620766040764\n",
      "epochs 6017\n",
      "training loss 0.0005630161802533527\n",
      "epochs 6018\n",
      "training loss 0.0005194101375414449\n",
      "epochs 6019\n",
      "training loss 0.0005479595128703001\n",
      "testing loss 0.002565243519621353\n",
      "epochs 6020\n",
      "training loss 0.001302668994195663\n",
      "epochs 6021\n",
      "training loss 0.0009927469800901528\n",
      "epochs 6022\n",
      "training loss 0.000753794668849535\n",
      "epochs 6023\n",
      "training loss 0.000665349497652321\n",
      "epochs 6024\n",
      "training loss 0.0006254076645256651\n",
      "epochs 6025\n",
      "training loss 0.0005906498433645577\n",
      "epochs 6026\n",
      "training loss 0.0005700196400298921\n",
      "epochs 6027\n",
      "training loss 0.0005365077812736996\n",
      "epochs 6028\n",
      "training loss 0.000508878465867842\n",
      "epochs 6029\n",
      "training loss 0.0005927456155034365\n",
      "testing loss 0.002572568443088614\n",
      "epochs 6030\n",
      "training loss 0.0005093373290665085\n",
      "epochs 6031\n",
      "training loss 0.0006180988432907452\n",
      "epochs 6032\n",
      "training loss 0.0005059651207776123\n",
      "epochs 6033\n",
      "training loss 0.0005293676594631763\n",
      "epochs 6034\n",
      "training loss 0.0005622121168754847\n",
      "epochs 6035\n",
      "training loss 0.0005176604405543725\n",
      "epochs 6036\n",
      "training loss 0.0005003820405388393\n",
      "epochs 6037\n",
      "training loss 0.0004966788337669282\n",
      "epochs 6038\n",
      "training loss 0.0004874465091502164\n",
      "epochs 6039\n",
      "training loss 0.0005104778797859694\n",
      "testing loss 0.002627784228579848\n",
      "epochs 6040\n",
      "training loss 0.0005614157293011692\n",
      "epochs 6041\n",
      "training loss 0.0005340436338142727\n",
      "epochs 6042\n",
      "training loss 0.0005398271149795751\n",
      "epochs 6043\n",
      "training loss 0.0005154240629451751\n",
      "epochs 6044\n",
      "training loss 0.0012521745121682566\n",
      "epochs 6045\n",
      "training loss 0.002339452009550423\n",
      "epochs 6046\n",
      "training loss 0.0015373720734742525\n",
      "epochs 6047\n",
      "training loss 0.0009443755656138266\n",
      "epochs 6048\n",
      "training loss 0.000823836189965041\n",
      "epochs 6049\n",
      "training loss 0.0006054722634816434\n",
      "testing loss 0.0027294239513939314\n",
      "epochs 6050\n",
      "training loss 0.0005589248238330973\n",
      "epochs 6051\n",
      "training loss 0.0005153026904183295\n",
      "epochs 6052\n",
      "training loss 0.0005342557626998612\n",
      "epochs 6053\n",
      "training loss 0.0005244350546120318\n",
      "epochs 6054\n",
      "training loss 0.0005065838982900293\n",
      "epochs 6055\n",
      "training loss 0.0005102780127245367\n",
      "epochs 6056\n",
      "training loss 0.0005038919306457846\n",
      "epochs 6057\n",
      "training loss 0.00048272669094007485\n",
      "epochs 6058\n",
      "training loss 0.0004972154823044106\n",
      "epochs 6059\n",
      "training loss 0.000512526368108043\n",
      "testing loss 0.002541036305433892\n",
      "epochs 6060\n",
      "training loss 0.0005166967583241332\n",
      "epochs 6061\n",
      "training loss 0.0005483693286838819\n",
      "epochs 6062\n",
      "training loss 0.0005805416767433071\n",
      "epochs 6063\n",
      "training loss 0.0005636815579521744\n",
      "epochs 6064\n",
      "training loss 0.0005706814038998937\n",
      "epochs 6065\n",
      "training loss 0.0005077370717565283\n",
      "epochs 6066\n",
      "training loss 0.0005201576480190454\n",
      "epochs 6067\n",
      "training loss 0.000544278044625126\n",
      "epochs 6068\n",
      "training loss 0.0004841051334946906\n",
      "epochs 6069\n",
      "training loss 0.000505644703173506\n",
      "testing loss 0.0026194256654418742\n",
      "epochs 6070\n",
      "training loss 0.0005327527413758984\n",
      "epochs 6071\n",
      "training loss 0.0006212651356099326\n",
      "epochs 6072\n",
      "training loss 0.0005556935885720136\n",
      "epochs 6073\n",
      "training loss 0.0005536943999271965\n",
      "epochs 6074\n",
      "training loss 0.000519991412070243\n",
      "epochs 6075\n",
      "training loss 0.0005307868016016101\n",
      "epochs 6076\n",
      "training loss 0.0005183750535304853\n",
      "epochs 6077\n",
      "training loss 0.0005184763505181587\n",
      "epochs 6078\n",
      "training loss 0.0005272677490957602\n",
      "epochs 6079\n",
      "training loss 0.0004877871127818969\n",
      "testing loss 0.0026430785920180328\n",
      "epochs 6080\n",
      "training loss 0.0005317521071886661\n",
      "epochs 6081\n",
      "training loss 0.0005401879803618659\n",
      "epochs 6082\n",
      "training loss 0.0005509634191732243\n",
      "epochs 6083\n",
      "training loss 0.0006522472686343756\n",
      "epochs 6084\n",
      "training loss 0.0006800360114619385\n",
      "epochs 6085\n",
      "training loss 0.0006788241685655444\n",
      "epochs 6086\n",
      "training loss 0.0006709907538827939\n",
      "epochs 6087\n",
      "training loss 0.0006677504413227599\n",
      "epochs 6088\n",
      "training loss 0.0006899371578486913\n",
      "epochs 6089\n",
      "training loss 0.0006749574720433497\n",
      "testing loss 0.0026827993070383076\n",
      "epochs 6090\n",
      "training loss 0.000656151579690129\n",
      "epochs 6091\n",
      "training loss 0.0006812734780252817\n",
      "epochs 6092\n",
      "training loss 0.0006640211279726216\n",
      "epochs 6093\n",
      "training loss 0.0006526988446408186\n",
      "epochs 6094\n",
      "training loss 0.0006554414898827304\n",
      "epochs 6095\n",
      "training loss 0.000686403071577873\n",
      "epochs 6096\n",
      "training loss 0.0006774520468940579\n",
      "epochs 6097\n",
      "training loss 0.0006643036181548763\n",
      "epochs 6098\n",
      "training loss 0.0006439721084052646\n",
      "epochs 6099\n",
      "training loss 0.0007110260678051849\n",
      "testing loss 0.003000315211066012\n",
      "epochs 6100\n",
      "training loss 0.0013040845334745016\n",
      "epochs 6101\n",
      "training loss 0.0010464477119613495\n",
      "epochs 6102\n",
      "training loss 0.0008909118113725087\n",
      "epochs 6103\n",
      "training loss 0.0009204107239392323\n",
      "epochs 6104\n",
      "training loss 0.0007519199540145062\n",
      "epochs 6105\n",
      "training loss 0.0007387882544932248\n",
      "epochs 6106\n",
      "training loss 0.0006257962183545606\n",
      "epochs 6107\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss 0.0007521291154593874\n",
      "epochs 6108\n",
      "training loss 0.0005937201182547628\n",
      "epochs 6109\n",
      "training loss 0.0005687390624667237\n",
      "testing loss 0.0026776268533331917\n",
      "epochs 6110\n",
      "training loss 0.0005496695933518167\n",
      "epochs 6111\n",
      "training loss 0.0005417707791774163\n",
      "epochs 6112\n",
      "training loss 0.0005428122478080093\n",
      "epochs 6113\n",
      "training loss 0.00058107955365705\n",
      "epochs 6114\n",
      "training loss 0.0005571327854611693\n",
      "epochs 6115\n",
      "training loss 0.0005134042855960778\n",
      "epochs 6116\n",
      "training loss 0.0005163112622551269\n",
      "epochs 6117\n",
      "training loss 0.0006464369079143398\n",
      "epochs 6118\n",
      "training loss 0.0005492010801545087\n",
      "epochs 6119\n",
      "training loss 0.000557838697541975\n",
      "testing loss 0.0025668110490400108\n",
      "epochs 6120\n",
      "training loss 0.0005306298546843361\n",
      "epochs 6121\n",
      "training loss 0.0005550070332807678\n",
      "epochs 6122\n",
      "training loss 0.0005219917424875212\n",
      "epochs 6123\n",
      "training loss 0.0005252001125763218\n",
      "epochs 6124\n",
      "training loss 0.0005818243338591999\n",
      "epochs 6125\n",
      "training loss 0.0006767860059994401\n",
      "epochs 6126\n",
      "training loss 0.000619766467918237\n",
      "epochs 6127\n",
      "training loss 0.0005508436696493494\n",
      "epochs 6128\n",
      "training loss 0.0005082147220527544\n",
      "epochs 6129\n",
      "training loss 0.0005150781541894329\n",
      "testing loss 0.002562992967473647\n",
      "epochs 6130\n",
      "training loss 0.0005533363822087543\n",
      "epochs 6131\n",
      "training loss 0.00048339283573271363\n",
      "epochs 6132\n",
      "training loss 0.0005070069567887763\n",
      "epochs 6133\n",
      "training loss 0.0005550995009712802\n",
      "epochs 6134\n",
      "training loss 0.0005196990653317659\n",
      "epochs 6135\n",
      "training loss 0.0005682416785349871\n",
      "epochs 6136\n",
      "training loss 0.00056061193051162\n",
      "epochs 6137\n",
      "training loss 0.0005475132159802405\n",
      "epochs 6138\n",
      "training loss 0.0005592214576808005\n",
      "epochs 6139\n",
      "training loss 0.0005357538175303489\n",
      "testing loss 0.0026022799594611827\n",
      "epochs 6140\n",
      "training loss 0.0005004868707669146\n",
      "epochs 6141\n",
      "training loss 0.0005595074679226952\n",
      "epochs 6142\n",
      "training loss 0.0005730292856701053\n",
      "epochs 6143\n",
      "training loss 0.0006031360400070671\n",
      "epochs 6144\n",
      "training loss 0.0005413066876392619\n",
      "epochs 6145\n",
      "training loss 0.0005854917565427188\n",
      "epochs 6146\n",
      "training loss 0.0005679148944458531\n",
      "epochs 6147\n",
      "training loss 0.0005210585375408441\n",
      "epochs 6148\n",
      "training loss 0.0005613518612548471\n",
      "epochs 6149\n",
      "training loss 0.00047618571248140445\n",
      "testing loss 0.002646799870528915\n",
      "epochs 6150\n",
      "training loss 0.0005373652292150823\n",
      "epochs 6151\n",
      "training loss 0.000530045723159002\n",
      "epochs 6152\n",
      "training loss 0.0005029945290721047\n",
      "epochs 6153\n",
      "training loss 0.0005611454729007778\n",
      "epochs 6154\n",
      "training loss 0.0005145606901185264\n",
      "epochs 6155\n",
      "training loss 0.000567520292150989\n",
      "epochs 6156\n",
      "training loss 0.0006424587239061219\n",
      "epochs 6157\n",
      "training loss 0.0005351758896766689\n",
      "epochs 6158\n",
      "training loss 0.0005462803920528548\n",
      "epochs 6159\n",
      "training loss 0.0005443337946489035\n",
      "testing loss 0.002617318671137253\n",
      "epochs 6160\n",
      "training loss 0.0005040346320342035\n",
      "epochs 6161\n",
      "training loss 0.0005155675795946927\n",
      "epochs 6162\n",
      "training loss 0.0005880974632642575\n",
      "epochs 6163\n",
      "training loss 0.0005487961203460001\n",
      "epochs 6164\n",
      "training loss 0.0005072324355748569\n",
      "epochs 6165\n",
      "training loss 0.0006256731893863008\n",
      "epochs 6166\n",
      "training loss 0.0005439921180678016\n",
      "epochs 6167\n",
      "training loss 0.0005376793736168028\n",
      "epochs 6168\n",
      "training loss 0.0005193673995394956\n",
      "epochs 6169\n",
      "training loss 0.00052630428695771\n",
      "testing loss 0.002605128935488694\n",
      "epochs 6170\n",
      "training loss 0.000490968452223738\n",
      "epochs 6171\n",
      "training loss 0.00053819263881882\n",
      "epochs 6172\n",
      "training loss 0.0004969868052815934\n",
      "epochs 6173\n",
      "training loss 0.0005628629352283129\n",
      "epochs 6174\n",
      "training loss 0.0005730045629392086\n",
      "epochs 6175\n",
      "training loss 0.0005397486947084094\n",
      "epochs 6176\n",
      "training loss 0.0005262780739603094\n",
      "epochs 6177\n",
      "training loss 0.000498914627795671\n",
      "epochs 6178\n",
      "training loss 0.0005147572463317448\n",
      "epochs 6179\n",
      "training loss 0.00048695702544883417\n",
      "testing loss 0.002625742525106679\n",
      "epochs 6180\n",
      "training loss 0.000532460198429835\n",
      "epochs 6181\n",
      "training loss 0.000503291492438861\n",
      "epochs 6182\n",
      "training loss 0.00047190282994521765\n",
      "epochs 6183\n",
      "training loss 0.000541989055782766\n",
      "epochs 6184\n",
      "training loss 0.0006019415889936004\n",
      "epochs 6185\n",
      "training loss 0.0005008958363771087\n",
      "epochs 6186\n",
      "training loss 0.0005209249499859713\n",
      "epochs 6187\n",
      "training loss 0.0005050255732305099\n",
      "epochs 6188\n",
      "training loss 0.0005367065513241855\n",
      "epochs 6189\n",
      "training loss 0.0005361277327517552\n",
      "testing loss 0.0027429824278042618\n",
      "epochs 6190\n",
      "training loss 0.0005397800113588265\n",
      "epochs 6191\n",
      "training loss 0.0005075636468077571\n",
      "epochs 6192\n",
      "training loss 0.000530808147359328\n",
      "epochs 6193\n",
      "training loss 0.0005241374506071595\n",
      "epochs 6194\n",
      "training loss 0.0005092262088725949\n",
      "epochs 6195\n",
      "training loss 0.0005183566161211987\n",
      "epochs 6196\n",
      "training loss 0.0005341349018342782\n",
      "epochs 6197\n",
      "training loss 0.0005681756558763656\n",
      "epochs 6198\n",
      "training loss 0.0005237427352585102\n",
      "epochs 6199\n",
      "training loss 0.0004878978744413885\n",
      "testing loss 0.0026385026735398945\n",
      "epochs 6200\n",
      "training loss 0.0004897727904378473\n",
      "epochs 6201\n",
      "training loss 0.0005214224223791987\n",
      "epochs 6202\n",
      "training loss 0.0005415680556944472\n",
      "epochs 6203\n",
      "training loss 0.0005340897600240099\n",
      "epochs 6204\n",
      "training loss 0.0005357402741203458\n",
      "epochs 6205\n",
      "training loss 0.0005163613005858311\n",
      "epochs 6206\n",
      "training loss 0.00048336807951914276\n",
      "epochs 6207\n",
      "training loss 0.0004972069773513054\n",
      "epochs 6208\n",
      "training loss 0.0005272047952104836\n",
      "epochs 6209\n",
      "training loss 0.0004853960561868947\n",
      "testing loss 0.002680035831046733\n",
      "epochs 6210\n",
      "training loss 0.0005326625409091633\n",
      "epochs 6211\n",
      "training loss 0.0005478386222816563\n",
      "epochs 6212\n",
      "training loss 0.0006444874042850328\n",
      "epochs 6213\n",
      "training loss 0.0005518309003284263\n",
      "epochs 6214\n",
      "training loss 0.0005244274501084409\n",
      "epochs 6215\n",
      "training loss 0.0005102366594545328\n",
      "epochs 6216\n",
      "training loss 0.00048422145964733485\n",
      "epochs 6217\n",
      "training loss 0.000668558768190636\n",
      "epochs 6218\n",
      "training loss 0.0005371057416742673\n",
      "epochs 6219\n",
      "training loss 0.0005188782580513903\n",
      "testing loss 0.002606279683606501\n",
      "epochs 6220\n",
      "training loss 0.0005539426982394309\n",
      "epochs 6221\n",
      "training loss 0.0005155133555316307\n",
      "epochs 6222\n",
      "training loss 0.0005744198052528227\n",
      "epochs 6223\n",
      "training loss 0.0005311969215015663\n",
      "epochs 6224\n",
      "training loss 0.0005017115172256339\n",
      "epochs 6225\n",
      "training loss 0.0004958337766265547\n",
      "epochs 6226\n",
      "training loss 0.0005058931194933692\n",
      "epochs 6227\n",
      "training loss 0.00048509217530848475\n",
      "epochs 6228\n",
      "training loss 0.0006604009818520657\n",
      "epochs 6229\n",
      "training loss 0.0005507603173404592\n",
      "testing loss 0.002553830276027071\n",
      "epochs 6230\n",
      "training loss 0.0005250904795085292\n",
      "epochs 6231\n",
      "training loss 0.0005006434081517171\n",
      "epochs 6232\n",
      "training loss 0.0005216322599352538\n",
      "epochs 6233\n",
      "training loss 0.0004998863535638796\n",
      "epochs 6234\n",
      "training loss 0.0005102808173961009\n",
      "epochs 6235\n",
      "training loss 0.0005068754666558492\n",
      "epochs 6236\n",
      "training loss 0.0005030330142436555\n",
      "epochs 6237\n",
      "training loss 0.0005018680510719768\n",
      "epochs 6238\n",
      "training loss 0.0005143880161193503\n",
      "epochs 6239\n",
      "training loss 0.0005015194276100064\n",
      "testing loss 0.002617536163855846\n",
      "epochs 6240\n",
      "training loss 0.0006037679385700996\n",
      "epochs 6241\n",
      "training loss 0.0005651616466961982\n",
      "epochs 6242\n",
      "training loss 0.0005885348685360358\n",
      "epochs 6243\n",
      "training loss 0.0005325109045563328\n",
      "epochs 6244\n",
      "training loss 0.0004927823601338706\n",
      "epochs 6245\n",
      "training loss 0.0005188452165345959\n",
      "epochs 6246\n",
      "training loss 0.00049861524721868\n",
      "epochs 6247\n",
      "training loss 0.0004859041455513189\n",
      "epochs 6248\n",
      "training loss 0.0005076965989437418\n",
      "epochs 6249\n",
      "training loss 0.0005219603795275137\n",
      "testing loss 0.002609279488893688\n",
      "epochs 6250\n",
      "training loss 0.00047423051113593974\n",
      "epochs 6251\n",
      "training loss 0.0005132502013368753\n",
      "epochs 6252\n",
      "training loss 0.0005020350730011245\n",
      "epochs 6253\n",
      "training loss 0.000532943816868996\n",
      "epochs 6254\n",
      "training loss 0.0006375042434129298\n",
      "epochs 6255\n",
      "training loss 0.0006472963570315662\n",
      "epochs 6256\n",
      "training loss 0.0005918063319254225\n",
      "epochs 6257\n",
      "training loss 0.0005932344105321133\n",
      "epochs 6258\n",
      "training loss 0.0006013762860100343\n",
      "epochs 6259\n",
      "training loss 0.0005972504122699342\n",
      "testing loss 0.0026347704383656912\n",
      "epochs 6260\n",
      "training loss 0.0005690537977027409\n",
      "epochs 6261\n",
      "training loss 0.0005889677326371865\n",
      "epochs 6262\n",
      "training loss 0.0006023943864763078\n",
      "epochs 6263\n",
      "training loss 0.0005656870052474621\n",
      "epochs 6264\n",
      "training loss 0.0005761009997845341\n",
      "epochs 6265\n",
      "training loss 0.0006604543918924899\n",
      "epochs 6266\n",
      "training loss 0.0012056306657370034\n",
      "epochs 6267\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss 0.0013879102879093457\n",
      "epochs 6268\n",
      "training loss 0.0010386087214623756\n",
      "epochs 6269\n",
      "training loss 0.0010032483944839212\n",
      "testing loss 0.0027851026463124188\n",
      "epochs 6270\n",
      "training loss 0.0009586808019060087\n",
      "epochs 6271\n",
      "training loss 0.0007119997231838913\n",
      "epochs 6272\n",
      "training loss 0.0006953981334975522\n",
      "epochs 6273\n",
      "training loss 0.0006959200987102617\n",
      "epochs 6274\n",
      "training loss 0.0006537838574229261\n",
      "epochs 6275\n",
      "training loss 0.0006408303351343913\n",
      "epochs 6276\n",
      "training loss 0.0007797917257357491\n",
      "epochs 6277\n",
      "training loss 0.0006802278936353702\n",
      "epochs 6278\n",
      "training loss 0.0006926210959318822\n",
      "epochs 6279\n",
      "training loss 0.0008266415455135146\n",
      "testing loss 0.002718566236967974\n",
      "epochs 6280\n",
      "training loss 0.0006675876003490495\n",
      "epochs 6281\n",
      "training loss 0.0006859984928172359\n",
      "epochs 6282\n",
      "training loss 0.0006851078275418458\n",
      "epochs 6283\n",
      "training loss 0.0006468161639097886\n",
      "epochs 6284\n",
      "training loss 0.0006694813896930213\n",
      "epochs 6285\n",
      "training loss 0.000702125061990546\n",
      "epochs 6286\n",
      "training loss 0.0009203247900586575\n",
      "epochs 6287\n",
      "training loss 0.0008349494018172987\n",
      "epochs 6288\n",
      "training loss 0.0008072754674085832\n",
      "epochs 6289\n",
      "training loss 0.0006695625915030714\n",
      "testing loss 0.0026164657385947167\n",
      "epochs 6290\n",
      "training loss 0.0006484504928706231\n",
      "epochs 6291\n",
      "training loss 0.0006048852090559629\n",
      "epochs 6292\n",
      "training loss 0.0006211935186024053\n",
      "epochs 6293\n",
      "training loss 0.0005795515904388472\n",
      "epochs 6294\n",
      "training loss 0.0006252884768207181\n",
      "epochs 6295\n",
      "training loss 0.0006517304123823721\n",
      "epochs 6296\n",
      "training loss 0.0006567133186486943\n",
      "epochs 6297\n",
      "training loss 0.0006418441547722043\n",
      "epochs 6298\n",
      "training loss 0.0006330932661612153\n",
      "epochs 6299\n",
      "training loss 0.0006799234830495536\n",
      "testing loss 0.002542106248108102\n",
      "epochs 6300\n",
      "training loss 0.0006121290322374779\n",
      "epochs 6301\n",
      "training loss 0.0006401394738916218\n",
      "epochs 6302\n",
      "training loss 0.0005863513775406219\n",
      "epochs 6303\n",
      "training loss 0.0006052551283833704\n",
      "epochs 6304\n",
      "training loss 0.0006055712660436312\n",
      "epochs 6305\n",
      "training loss 0.000637124691425333\n",
      "epochs 6306\n",
      "training loss 0.0006542168947759065\n",
      "epochs 6307\n",
      "training loss 0.000704585190821371\n",
      "epochs 6308\n",
      "training loss 0.0006747263221680201\n",
      "epochs 6309\n",
      "training loss 0.0005646355772683946\n",
      "testing loss 0.0028636880996736123\n",
      "epochs 6310\n",
      "training loss 0.000779022664977464\n",
      "epochs 6311\n",
      "training loss 0.0006140598171499577\n",
      "epochs 6312\n",
      "training loss 0.0006379075243992669\n",
      "epochs 6313\n",
      "training loss 0.000588767814975781\n",
      "epochs 6314\n",
      "training loss 0.0006265164159045847\n",
      "epochs 6315\n",
      "training loss 0.0005941777834194601\n",
      "epochs 6316\n",
      "training loss 0.0006001309122278788\n",
      "epochs 6317\n",
      "training loss 0.000684179253465748\n",
      "epochs 6318\n",
      "training loss 0.0006094065167174015\n",
      "epochs 6319\n",
      "training loss 0.0006049024471928193\n",
      "testing loss 0.002689883238817598\n",
      "epochs 6320\n",
      "training loss 0.0009706762730247288\n",
      "epochs 6321\n",
      "training loss 0.0011391649043044545\n",
      "epochs 6322\n",
      "training loss 0.0009022847173231623\n",
      "epochs 6323\n",
      "training loss 0.0007004542589416914\n",
      "epochs 6324\n",
      "training loss 0.0006807151477533395\n",
      "epochs 6325\n",
      "training loss 0.0005712411996248917\n",
      "epochs 6326\n",
      "training loss 0.0006360474065948266\n",
      "epochs 6327\n",
      "training loss 0.0005972128171094419\n",
      "epochs 6328\n",
      "training loss 0.0006036689601580989\n",
      "epochs 6329\n",
      "training loss 0.000643517176081401\n",
      "testing loss 0.0026351836822094753\n",
      "epochs 6330\n",
      "training loss 0.0005991967606547891\n",
      "epochs 6331\n",
      "training loss 0.0006171043698271131\n",
      "epochs 6332\n",
      "training loss 0.0006242886141061465\n",
      "epochs 6333\n",
      "training loss 0.0006086858149368803\n",
      "epochs 6334\n",
      "training loss 0.0006437610626421688\n",
      "epochs 6335\n",
      "training loss 0.0005826511658978646\n",
      "epochs 6336\n",
      "training loss 0.0006231224869581726\n",
      "epochs 6337\n",
      "training loss 0.0005998208842489381\n",
      "epochs 6338\n",
      "training loss 0.0007431364391249602\n",
      "epochs 6339\n",
      "training loss 0.0005421222748955299\n",
      "testing loss 0.002649804334905897\n",
      "epochs 6340\n",
      "training loss 0.0008577884849490695\n",
      "epochs 6341\n",
      "training loss 0.0006091058948487723\n",
      "epochs 6342\n",
      "training loss 0.0006854164368638593\n",
      "epochs 6343\n",
      "training loss 0.000979430239034058\n",
      "epochs 6344\n",
      "training loss 0.0007100423284357634\n",
      "epochs 6345\n",
      "training loss 0.0006130671415776637\n",
      "epochs 6346\n",
      "training loss 0.0005777789990871997\n",
      "epochs 6347\n",
      "training loss 0.0005872883810237118\n",
      "epochs 6348\n",
      "training loss 0.0005369724287038618\n",
      "epochs 6349\n",
      "training loss 0.0005735993147530454\n",
      "testing loss 0.0026360586498606394\n",
      "epochs 6350\n",
      "training loss 0.0006751529525648406\n",
      "epochs 6351\n",
      "training loss 0.0006652450113625218\n",
      "epochs 6352\n",
      "training loss 0.0007207397523507373\n",
      "epochs 6353\n",
      "training loss 0.0006792818193994802\n",
      "epochs 6354\n",
      "training loss 0.0004981718829155002\n",
      "epochs 6355\n",
      "training loss 0.0005886984638208778\n",
      "epochs 6356\n",
      "training loss 0.0006841131368167925\n",
      "epochs 6357\n",
      "training loss 0.0005520866754500898\n",
      "epochs 6358\n",
      "training loss 0.0005411204190551102\n",
      "epochs 6359\n",
      "training loss 0.00060706074568259\n",
      "testing loss 0.002632265249580964\n",
      "epochs 6360\n",
      "training loss 0.0009734143078748963\n",
      "epochs 6361\n",
      "training loss 0.0007439644517706804\n",
      "epochs 6362\n",
      "training loss 0.0007401142782626509\n",
      "epochs 6363\n",
      "training loss 0.0006258594050262503\n",
      "epochs 6364\n",
      "training loss 0.000631366045558174\n",
      "epochs 6365\n",
      "training loss 0.0006093900629685835\n",
      "epochs 6366\n",
      "training loss 0.0007636140505457721\n",
      "epochs 6367\n",
      "training loss 0.0006626624818169441\n",
      "epochs 6368\n",
      "training loss 0.0006170143387641328\n",
      "epochs 6369\n",
      "training loss 0.000567542095962306\n",
      "testing loss 0.0026456782489466804\n",
      "epochs 6370\n",
      "training loss 0.00065971676397879\n",
      "epochs 6371\n",
      "training loss 0.0005979198105435105\n",
      "epochs 6372\n",
      "training loss 0.0006334204929116491\n",
      "epochs 6373\n",
      "training loss 0.0005578747453340711\n",
      "epochs 6374\n",
      "training loss 0.0005873018651202853\n",
      "epochs 6375\n",
      "training loss 0.0007045888939962968\n",
      "epochs 6376\n",
      "training loss 0.0009854007960830766\n",
      "epochs 6377\n",
      "training loss 0.001355849075701518\n",
      "epochs 6378\n",
      "training loss 0.0011834709342119021\n",
      "epochs 6379\n",
      "training loss 0.0007705000352318254\n",
      "testing loss 0.002735527824686431\n",
      "epochs 6380\n",
      "training loss 0.0006248891233476473\n",
      "epochs 6381\n",
      "training loss 0.0006260954063508863\n",
      "epochs 6382\n",
      "training loss 0.0006024643883539369\n",
      "epochs 6383\n",
      "training loss 0.0007150512748457333\n",
      "epochs 6384\n",
      "training loss 0.0005543718825194895\n",
      "epochs 6385\n",
      "training loss 0.000585376445839527\n",
      "epochs 6386\n",
      "training loss 0.0006030683713897179\n",
      "epochs 6387\n",
      "training loss 0.0005603752196815975\n",
      "epochs 6388\n",
      "training loss 0.000718694546923047\n",
      "epochs 6389\n",
      "training loss 0.0006567040624806097\n",
      "testing loss 0.002618808743497687\n",
      "epochs 6390\n",
      "training loss 0.0005922143394976718\n",
      "epochs 6391\n",
      "training loss 0.0007173983239721632\n",
      "epochs 6392\n",
      "training loss 0.0006267174107615629\n",
      "epochs 6393\n",
      "training loss 0.000715184169658672\n",
      "epochs 6394\n",
      "training loss 0.0005683741245827833\n",
      "epochs 6395\n",
      "training loss 0.0006811632328039732\n",
      "epochs 6396\n",
      "training loss 0.0005601325130201932\n",
      "epochs 6397\n",
      "training loss 0.0006294557197538904\n",
      "epochs 6398\n",
      "training loss 0.0005673772276281507\n",
      "epochs 6399\n",
      "training loss 0.0006438227739973464\n",
      "testing loss 0.00265299625643562\n",
      "epochs 6400\n",
      "training loss 0.0006063834002056077\n",
      "epochs 6401\n",
      "training loss 0.0005591980915510954\n",
      "epochs 6402\n",
      "training loss 0.0006857333768698412\n",
      "epochs 6403\n",
      "training loss 0.0005990805364982437\n",
      "epochs 6404\n",
      "training loss 0.0005901134728615407\n",
      "epochs 6405\n",
      "training loss 0.0005756799622770048\n",
      "epochs 6406\n",
      "training loss 0.0006799945236420072\n",
      "epochs 6407\n",
      "training loss 0.0005776653786177116\n",
      "epochs 6408\n",
      "training loss 0.0005819681444662512\n",
      "epochs 6409\n",
      "training loss 0.0005822758071176215\n",
      "testing loss 0.0026154962194099335\n",
      "epochs 6410\n",
      "training loss 0.0005886071021201536\n",
      "epochs 6411\n",
      "training loss 0.0006242919844889442\n",
      "epochs 6412\n",
      "training loss 0.0005725729831219807\n",
      "epochs 6413\n",
      "training loss 0.0006164630640922312\n",
      "epochs 6414\n",
      "training loss 0.0006567091940432266\n",
      "epochs 6415\n",
      "training loss 0.0006072308466023847\n",
      "epochs 6416\n",
      "training loss 0.0005941854359576405\n",
      "epochs 6417\n",
      "training loss 0.0006703282453439631\n",
      "epochs 6418\n",
      "training loss 0.0006945568111570875\n",
      "epochs 6419\n",
      "training loss 0.0007197904311358295\n",
      "testing loss 0.0025820497663671823\n",
      "epochs 6420\n",
      "training loss 0.000821355824152823\n",
      "epochs 6421\n",
      "training loss 0.0020345908956422463\n",
      "epochs 6422\n",
      "training loss 0.0007757157048226071\n",
      "epochs 6423\n",
      "training loss 0.0008186071354430169\n",
      "epochs 6424\n",
      "training loss 0.0006106269352476319\n",
      "epochs 6425\n",
      "training loss 0.0007880437631042544\n",
      "epochs 6426\n",
      "training loss 0.0009737041011724429\n",
      "epochs 6427\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss 0.0007279784361850244\n",
      "epochs 6428\n",
      "training loss 0.0006520942059284682\n",
      "epochs 6429\n",
      "training loss 0.0006043880208010437\n",
      "testing loss 0.0025583583921861192\n",
      "epochs 6430\n",
      "training loss 0.0006067450851393796\n",
      "epochs 6431\n",
      "training loss 0.0005626813796954654\n",
      "epochs 6432\n",
      "training loss 0.0005876571952901769\n",
      "epochs 6433\n",
      "training loss 0.0005515397853277465\n",
      "epochs 6434\n",
      "training loss 0.000554662292482088\n",
      "epochs 6435\n",
      "training loss 0.0005772324761242739\n",
      "epochs 6436\n",
      "training loss 0.0005752994844514458\n",
      "epochs 6437\n",
      "training loss 0.0006482156631742013\n",
      "epochs 6438\n",
      "training loss 0.0006258604338776184\n",
      "epochs 6439\n",
      "training loss 0.0006022419555623673\n",
      "testing loss 0.002625212685538601\n",
      "epochs 6440\n",
      "training loss 0.0006090895537998935\n",
      "epochs 6441\n",
      "training loss 0.0005675789494616599\n",
      "epochs 6442\n",
      "training loss 0.0005519482692651236\n",
      "epochs 6443\n",
      "training loss 0.0006121665258441789\n",
      "epochs 6444\n",
      "training loss 0.0005847413708897461\n",
      "epochs 6445\n",
      "training loss 0.0006565097577892539\n",
      "epochs 6446\n",
      "training loss 0.0006283983800703189\n",
      "epochs 6447\n",
      "training loss 0.0005984518700526988\n",
      "epochs 6448\n",
      "training loss 0.0006020071985812908\n",
      "epochs 6449\n",
      "training loss 0.0006277872847306816\n",
      "testing loss 0.002681640336778781\n",
      "epochs 6450\n",
      "training loss 0.0006021989762817019\n",
      "epochs 6451\n",
      "training loss 0.0006577129065134141\n",
      "epochs 6452\n",
      "training loss 0.0007107528959794428\n",
      "epochs 6453\n",
      "training loss 0.0007610597795368764\n",
      "epochs 6454\n",
      "training loss 0.0006844336948092846\n",
      "epochs 6455\n",
      "training loss 0.0007553547652619452\n",
      "epochs 6456\n",
      "training loss 0.0007270216176818524\n",
      "epochs 6457\n",
      "training loss 0.0006601408014808552\n",
      "epochs 6458\n",
      "training loss 0.0007414434985880454\n",
      "epochs 6459\n",
      "training loss 0.000725659231551269\n",
      "testing loss 0.002653395333525507\n",
      "epochs 6460\n",
      "training loss 0.0007015936415271669\n",
      "epochs 6461\n",
      "training loss 0.0006875233648813366\n",
      "epochs 6462\n",
      "training loss 0.0007207075733334777\n",
      "epochs 6463\n",
      "training loss 0.0007130373043742733\n",
      "epochs 6464\n",
      "training loss 0.0007731905097345677\n",
      "epochs 6465\n",
      "training loss 0.0006184843248520669\n",
      "epochs 6466\n",
      "training loss 0.0005607958798124073\n",
      "epochs 6467\n",
      "training loss 0.0006618420885363452\n",
      "epochs 6468\n",
      "training loss 0.000780600136199734\n",
      "epochs 6469\n",
      "training loss 0.0007288514534372406\n",
      "testing loss 0.0026148320881630035\n",
      "epochs 6470\n",
      "training loss 0.0009528643465431062\n",
      "epochs 6471\n",
      "training loss 0.001169428564777943\n",
      "epochs 6472\n",
      "training loss 0.0010433229599197574\n",
      "epochs 6473\n",
      "training loss 0.0008367972245360625\n",
      "epochs 6474\n",
      "training loss 0.0007351971099416422\n",
      "epochs 6475\n",
      "training loss 0.0010370073291030076\n",
      "epochs 6476\n",
      "training loss 0.0008179821620877877\n",
      "epochs 6477\n",
      "training loss 0.0007821163222742887\n",
      "epochs 6478\n",
      "training loss 0.0007528450535886318\n",
      "epochs 6479\n",
      "training loss 0.0006757317009873088\n",
      "testing loss 0.002796877794387149\n",
      "epochs 6480\n",
      "training loss 0.000648816483357842\n",
      "epochs 6481\n",
      "training loss 0.0006767758707895218\n",
      "epochs 6482\n",
      "training loss 0.0006160340423159313\n",
      "epochs 6483\n",
      "training loss 0.0005921805329659053\n",
      "epochs 6484\n",
      "training loss 0.0005858548144430579\n",
      "epochs 6485\n",
      "training loss 0.0005661937656549109\n",
      "epochs 6486\n",
      "training loss 0.0006529636819787482\n",
      "epochs 6487\n",
      "training loss 0.0005821153671214623\n",
      "epochs 6488\n",
      "training loss 0.0006357736166886487\n",
      "epochs 6489\n",
      "training loss 0.0006349553268453769\n",
      "testing loss 0.002682898974240962\n",
      "epochs 6490\n",
      "training loss 0.0006094168992656478\n",
      "epochs 6491\n",
      "training loss 0.0006318056636056821\n",
      "epochs 6492\n",
      "training loss 0.0006146151611388953\n",
      "epochs 6493\n",
      "training loss 0.0006104042886446392\n",
      "epochs 6494\n",
      "training loss 0.0007717058230276392\n",
      "epochs 6495\n",
      "training loss 0.001464763067370439\n",
      "epochs 6496\n",
      "training loss 0.0012345750249835937\n",
      "epochs 6497\n",
      "training loss 0.001438767168445139\n",
      "epochs 6498\n",
      "training loss 0.002394876471688082\n",
      "epochs 6499\n",
      "training loss 0.0020136814534389568\n",
      "testing loss 0.002886386860264399\n",
      "epochs 6500\n",
      "training loss 0.0015465452192998052\n",
      "epochs 6501\n",
      "training loss 0.001299627155340121\n",
      "epochs 6502\n",
      "training loss 0.0012885641598030869\n",
      "epochs 6503\n",
      "training loss 0.0011709591631754938\n",
      "epochs 6504\n",
      "training loss 0.0011835442369415971\n",
      "epochs 6505\n",
      "training loss 0.0012463659489857129\n",
      "epochs 6506\n",
      "training loss 0.0009441523222496173\n",
      "epochs 6507\n",
      "training loss 0.0009834494650162937\n",
      "epochs 6508\n",
      "training loss 0.0007328050317933449\n",
      "epochs 6509\n",
      "training loss 0.0007198584851798939\n",
      "testing loss 0.00279377272033879\n",
      "epochs 6510\n",
      "training loss 0.0008147009782844129\n",
      "epochs 6511\n",
      "training loss 0.000743696150457696\n",
      "epochs 6512\n",
      "training loss 0.0007307869498087178\n",
      "epochs 6513\n",
      "training loss 0.0007523093289429588\n",
      "epochs 6514\n",
      "training loss 0.0008776318366811993\n",
      "epochs 6515\n",
      "training loss 0.0007459146220457816\n",
      "epochs 6516\n",
      "training loss 0.0007398104025150075\n",
      "epochs 6517\n",
      "training loss 0.0007257665372857015\n",
      "epochs 6518\n",
      "training loss 0.0007598072477605046\n",
      "epochs 6519\n",
      "training loss 0.0007347978883646542\n",
      "testing loss 0.0027246537056077828\n",
      "epochs 6520\n",
      "training loss 0.0007127460964890281\n",
      "epochs 6521\n",
      "training loss 0.0007136940772469668\n",
      "epochs 6522\n",
      "training loss 0.0007826670390195681\n",
      "epochs 6523\n",
      "training loss 0.0007201702927386439\n",
      "epochs 6524\n",
      "training loss 0.0007470228446019094\n",
      "epochs 6525\n",
      "training loss 0.0007318416534283263\n",
      "epochs 6526\n",
      "training loss 0.0007134654282664422\n",
      "epochs 6527\n",
      "training loss 0.0007726824391239796\n",
      "epochs 6528\n",
      "training loss 0.000840450200927373\n",
      "epochs 6529\n",
      "training loss 0.0007171932781981389\n",
      "testing loss 0.002775779286653781\n",
      "epochs 6530\n",
      "training loss 0.0007180013720584484\n",
      "epochs 6531\n",
      "training loss 0.0006710477892520319\n",
      "epochs 6532\n",
      "training loss 0.0007082544774769616\n",
      "epochs 6533\n",
      "training loss 0.0006880212091666711\n",
      "epochs 6534\n",
      "training loss 0.0007655279314404462\n",
      "epochs 6535\n",
      "training loss 0.0006925908359097414\n",
      "epochs 6536\n",
      "training loss 0.0007523726194242077\n",
      "epochs 6537\n",
      "training loss 0.0007479922679828984\n",
      "epochs 6538\n",
      "training loss 0.0007014914913284154\n",
      "epochs 6539\n",
      "training loss 0.0006688190201271925\n",
      "testing loss 0.0027182852529015734\n",
      "epochs 6540\n",
      "training loss 0.0007388865782017324\n",
      "epochs 6541\n",
      "training loss 0.000761223997811767\n",
      "epochs 6542\n",
      "training loss 0.0007713226826881316\n",
      "epochs 6543\n",
      "training loss 0.0006679183990860182\n",
      "epochs 6544\n",
      "training loss 0.0006707463081569431\n",
      "epochs 6545\n",
      "training loss 0.0008331022217712652\n",
      "epochs 6546\n",
      "training loss 0.00118561086376158\n",
      "epochs 6547\n",
      "training loss 0.0009331959871204406\n",
      "epochs 6548\n",
      "training loss 0.0009000317875075078\n",
      "epochs 6549\n",
      "training loss 0.0006904637317723767\n",
      "testing loss 0.002834298442355654\n",
      "epochs 6550\n",
      "training loss 0.0006327045385939519\n",
      "epochs 6551\n",
      "training loss 0.0006364692846634411\n",
      "epochs 6552\n",
      "training loss 0.000610401048831002\n",
      "epochs 6553\n",
      "training loss 0.0005607865281943742\n",
      "epochs 6554\n",
      "training loss 0.0006309817530962109\n",
      "epochs 6555\n",
      "training loss 0.0006211438038638343\n",
      "epochs 6556\n",
      "training loss 0.0006361721198698704\n",
      "epochs 6557\n",
      "training loss 0.0006824940009400712\n",
      "epochs 6558\n",
      "training loss 0.0005683545017895207\n",
      "epochs 6559\n",
      "training loss 0.0005433362673176877\n",
      "testing loss 0.0027216936156966107\n",
      "epochs 6560\n",
      "training loss 0.0005418378459027824\n",
      "epochs 6561\n",
      "training loss 0.0005412004339773389\n",
      "epochs 6562\n",
      "training loss 0.0005707486210982556\n",
      "epochs 6563\n",
      "training loss 0.0005453995198625675\n",
      "epochs 6564\n",
      "training loss 0.0005926380833960492\n",
      "epochs 6565\n",
      "training loss 0.0006808691784048787\n",
      "epochs 6566\n",
      "training loss 0.0007181865138201309\n",
      "epochs 6567\n",
      "training loss 0.0007654450176351656\n",
      "epochs 6568\n",
      "training loss 0.0006983247277748666\n",
      "epochs 6569\n",
      "training loss 0.000591159586958859\n",
      "testing loss 0.002839285351917253\n",
      "epochs 6570\n",
      "training loss 0.0007231852747740558\n",
      "epochs 6571\n",
      "training loss 0.000639140383357403\n",
      "epochs 6572\n",
      "training loss 0.0007527567793708578\n",
      "epochs 6573\n",
      "training loss 0.0007000717882556688\n",
      "epochs 6574\n",
      "training loss 0.0008249989600879024\n",
      "epochs 6575\n",
      "training loss 0.0007198964127786684\n",
      "epochs 6576\n",
      "training loss 0.0007431744868544391\n",
      "epochs 6577\n",
      "training loss 0.0007094165461886629\n",
      "epochs 6578\n",
      "training loss 0.0006935858402307793\n",
      "epochs 6579\n",
      "training loss 0.0007128859496828294\n",
      "testing loss 0.002726849146659572\n",
      "epochs 6580\n",
      "training loss 0.0007381096366746209\n",
      "epochs 6581\n",
      "training loss 0.0006899835050352325\n",
      "epochs 6582\n",
      "training loss 0.0006647102458605622\n",
      "epochs 6583\n",
      "training loss 0.0006886075114042959\n",
      "epochs 6584\n",
      "training loss 0.0007041551044994915\n",
      "epochs 6585\n",
      "training loss 0.0006741869464512393\n",
      "epochs 6586\n",
      "training loss 0.0006638259655586514\n",
      "epochs 6587\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss 0.0006874670403886383\n",
      "epochs 6588\n",
      "training loss 0.0007203739946941622\n",
      "epochs 6589\n",
      "training loss 0.0007356417671979708\n",
      "testing loss 0.002598742626653654\n",
      "epochs 6590\n",
      "training loss 0.0007034336025847864\n",
      "epochs 6591\n",
      "training loss 0.0006989782475646993\n",
      "epochs 6592\n",
      "training loss 0.0007067217814805422\n",
      "epochs 6593\n",
      "training loss 0.0006949020938708597\n",
      "epochs 6594\n",
      "training loss 0.0006364807795264722\n",
      "epochs 6595\n",
      "training loss 0.0006583532654449604\n",
      "epochs 6596\n",
      "training loss 0.0006710203735764339\n",
      "epochs 6597\n",
      "training loss 0.0006694970602922618\n",
      "epochs 6598\n",
      "training loss 0.0006871916788756156\n",
      "epochs 6599\n",
      "training loss 0.0006794220830545984\n",
      "testing loss 0.0028681018371597357\n",
      "epochs 6600\n",
      "training loss 0.0007049593424118807\n",
      "epochs 6601\n",
      "training loss 0.000711791039961829\n",
      "epochs 6602\n",
      "training loss 0.0006972903632654421\n",
      "epochs 6603\n",
      "training loss 0.0006973007547040682\n",
      "epochs 6604\n",
      "training loss 0.0006553612005971882\n",
      "epochs 6605\n",
      "training loss 0.0006510879639904142\n",
      "epochs 6606\n",
      "training loss 0.000664114572056838\n",
      "epochs 6607\n",
      "training loss 0.0006674214188040639\n",
      "epochs 6608\n",
      "training loss 0.0006617089196697081\n",
      "epochs 6609\n",
      "training loss 0.0006763304721374393\n",
      "testing loss 0.0027410427669016975\n",
      "epochs 6610\n",
      "training loss 0.0006605136586143706\n",
      "epochs 6611\n",
      "training loss 0.0007423307417306658\n",
      "epochs 6612\n",
      "training loss 0.00063242769835865\n",
      "epochs 6613\n",
      "training loss 0.0007302353599927555\n",
      "epochs 6614\n",
      "training loss 0.0008071378074405222\n",
      "epochs 6615\n",
      "training loss 0.0011933063663610208\n",
      "epochs 6616\n",
      "training loss 0.0012599676843034811\n",
      "epochs 6617\n",
      "training loss 0.001049461249686002\n",
      "epochs 6618\n",
      "training loss 0.0010584112084088535\n",
      "epochs 6619\n",
      "training loss 0.0010836908978050558\n",
      "testing loss 0.0027821479585675643\n",
      "epochs 6620\n",
      "training loss 0.0007740154431242563\n",
      "epochs 6621\n",
      "training loss 0.0006673465400444497\n",
      "epochs 6622\n",
      "training loss 0.000736442456919966\n",
      "epochs 6623\n",
      "training loss 0.0007869918591139051\n",
      "epochs 6624\n",
      "training loss 0.0006125436023254185\n",
      "epochs 6625\n",
      "training loss 0.0005405399667758687\n",
      "epochs 6626\n",
      "training loss 0.0005111926986119713\n",
      "epochs 6627\n",
      "training loss 0.0005324861597542943\n",
      "epochs 6628\n",
      "training loss 0.0005271515644815012\n",
      "epochs 6629\n",
      "training loss 0.0005124663201827375\n",
      "testing loss 0.002883406251946345\n",
      "epochs 6630\n",
      "training loss 0.0007915691336182351\n",
      "epochs 6631\n",
      "training loss 0.0008456632490503378\n",
      "epochs 6632\n",
      "training loss 0.0007223152920163568\n",
      "epochs 6633\n",
      "training loss 0.0006464316919594607\n",
      "epochs 6634\n",
      "training loss 0.000625532950854246\n",
      "epochs 6635\n",
      "training loss 0.0006657728415278372\n",
      "epochs 6636\n",
      "training loss 0.0006555543259199494\n",
      "epochs 6637\n",
      "training loss 0.0007710292184156419\n",
      "epochs 6638\n",
      "training loss 0.0007997852389022742\n",
      "epochs 6639\n",
      "training loss 0.0007281085645417629\n",
      "testing loss 0.0029631573694480703\n",
      "epochs 6640\n",
      "training loss 0.0009555626988954457\n",
      "epochs 6641\n",
      "training loss 0.0008412721265821455\n",
      "epochs 6642\n",
      "training loss 0.0006878048174103048\n",
      "epochs 6643\n",
      "training loss 0.0007548919953384626\n",
      "epochs 6644\n",
      "training loss 0.0008057046517634929\n",
      "epochs 6645\n",
      "training loss 0.0008346905946338091\n",
      "epochs 6646\n",
      "training loss 0.0007466799018714906\n",
      "epochs 6647\n",
      "training loss 0.0008245554817578611\n",
      "epochs 6648\n",
      "training loss 0.0008942972005119882\n",
      "epochs 6649\n",
      "training loss 0.0010322365763145683\n",
      "testing loss 0.002737601338852699\n",
      "epochs 6650\n",
      "training loss 0.0007768516922560676\n",
      "epochs 6651\n",
      "training loss 0.0007557934513676482\n",
      "epochs 6652\n",
      "training loss 0.0007316734129421435\n",
      "epochs 6653\n",
      "training loss 0.0007554129089652009\n",
      "epochs 6654\n",
      "training loss 0.0006820467362813029\n",
      "epochs 6655\n",
      "training loss 0.0006430119325231342\n",
      "epochs 6656\n",
      "training loss 0.0006354466355957748\n",
      "epochs 6657\n",
      "training loss 0.0017633083354119824\n",
      "epochs 6658\n",
      "training loss 0.0009570470673179305\n",
      "epochs 6659\n",
      "training loss 0.0007296991343454296\n",
      "testing loss 0.0027479502085120755\n",
      "epochs 6660\n",
      "training loss 0.0007159156411833846\n",
      "epochs 6661\n",
      "training loss 0.0006958402324917989\n",
      "epochs 6662\n",
      "training loss 0.0006725753588166009\n",
      "epochs 6663\n",
      "training loss 0.0006425825310701159\n",
      "epochs 6664\n",
      "training loss 0.0006292494242843863\n",
      "epochs 6665\n",
      "training loss 0.0006578366985504931\n",
      "epochs 6666\n",
      "training loss 0.0006452772744590173\n",
      "epochs 6667\n",
      "training loss 0.0007169847973759674\n",
      "epochs 6668\n",
      "training loss 0.0007104112180714187\n",
      "epochs 6669\n",
      "training loss 0.0006903921918148078\n",
      "testing loss 0.0026274866627608523\n",
      "epochs 6670\n",
      "training loss 0.0006629757512902903\n",
      "epochs 6671\n",
      "training loss 0.0006485656759238838\n",
      "epochs 6672\n",
      "training loss 0.0006562418596837443\n",
      "epochs 6673\n",
      "training loss 0.0008234697320473049\n",
      "epochs 6674\n",
      "training loss 0.0007375124744620843\n",
      "epochs 6675\n",
      "training loss 0.0006502505420497689\n",
      "epochs 6676\n",
      "training loss 0.0006177348001947836\n",
      "epochs 6677\n",
      "training loss 0.0007930827882787706\n",
      "epochs 6678\n",
      "training loss 0.000714227615036127\n",
      "epochs 6679\n",
      "training loss 0.0005985452582734838\n",
      "testing loss 0.002602540975822968\n",
      "epochs 6680\n",
      "training loss 0.0005850198714587679\n",
      "epochs 6681\n",
      "training loss 0.0005918573788940443\n",
      "epochs 6682\n",
      "training loss 0.0005413705918663337\n",
      "epochs 6683\n",
      "training loss 0.0006080410385038704\n",
      "epochs 6684\n",
      "training loss 0.000659144880698773\n",
      "epochs 6685\n",
      "training loss 0.0005318727876812696\n",
      "epochs 6686\n",
      "training loss 0.0005503613041787434\n",
      "epochs 6687\n",
      "training loss 0.0008689298536515254\n",
      "epochs 6688\n",
      "training loss 0.0008994436618131741\n",
      "epochs 6689\n",
      "training loss 0.0006199349956388803\n",
      "testing loss 0.00270125691668322\n",
      "epochs 6690\n",
      "training loss 0.0005279316388723075\n",
      "epochs 6691\n",
      "training loss 0.0005922595228848407\n",
      "epochs 6692\n",
      "training loss 0.0005254031168360626\n",
      "epochs 6693\n",
      "training loss 0.0005488935020280929\n",
      "epochs 6694\n",
      "training loss 0.0005577308759885899\n",
      "epochs 6695\n",
      "training loss 0.000579520167501949\n",
      "epochs 6696\n",
      "training loss 0.0005686699542270741\n",
      "epochs 6697\n",
      "training loss 0.0005496377312036169\n",
      "epochs 6698\n",
      "training loss 0.0005584508617618051\n",
      "epochs 6699\n",
      "training loss 0.0004908497761800534\n",
      "testing loss 0.0027243220598225527\n",
      "epochs 6700\n",
      "training loss 0.0005034059294079088\n",
      "epochs 6701\n",
      "training loss 0.000533597567277935\n",
      "epochs 6702\n",
      "training loss 0.0010994142136362447\n",
      "epochs 6703\n",
      "training loss 0.0010043114517874858\n",
      "epochs 6704\n",
      "training loss 0.0009231175220639397\n",
      "epochs 6705\n",
      "training loss 0.000695727963094659\n",
      "epochs 6706\n",
      "training loss 0.000688344657196066\n",
      "epochs 6707\n",
      "training loss 0.0005912394649426999\n",
      "epochs 6708\n",
      "training loss 0.000548177286395152\n",
      "epochs 6709\n",
      "training loss 0.0005868023992473639\n",
      "testing loss 0.002724210736226185\n",
      "epochs 6710\n",
      "training loss 0.000658656844315841\n",
      "epochs 6711\n",
      "training loss 0.000698619932836802\n",
      "epochs 6712\n",
      "training loss 0.0005676773496008957\n",
      "epochs 6713\n",
      "training loss 0.0005665651806007426\n",
      "epochs 6714\n",
      "training loss 0.00043649500525007334\n",
      "epochs 6715\n",
      "training loss 0.0007121548945905844\n",
      "epochs 6716\n",
      "training loss 0.0007192984355704174\n",
      "epochs 6717\n",
      "training loss 0.0006430835701421888\n",
      "epochs 6718\n",
      "training loss 0.0006409014276537399\n",
      "epochs 6719\n",
      "training loss 0.000752298807864018\n",
      "testing loss 0.00265114721330213\n",
      "epochs 6720\n",
      "training loss 0.0007015412947938616\n",
      "epochs 6721\n",
      "training loss 0.0007235224206229859\n",
      "epochs 6722\n",
      "training loss 0.0007568051535027572\n",
      "epochs 6723\n",
      "training loss 0.0006621230354194323\n",
      "epochs 6724\n",
      "training loss 0.00061936877619427\n",
      "epochs 6725\n",
      "training loss 0.0008405830494749521\n",
      "epochs 6726\n",
      "training loss 0.0007231613006485247\n",
      "epochs 6727\n",
      "training loss 0.00047908585115568003\n",
      "epochs 6728\n",
      "training loss 0.0005257856832374182\n",
      "epochs 6729\n",
      "training loss 0.0023043506375746096\n",
      "testing loss 0.005185382742045038\n",
      "epochs 6730\n",
      "training loss 0.002971267743435289\n",
      "epochs 6731\n",
      "training loss 0.002053097703587547\n",
      "epochs 6732\n",
      "training loss 0.001496111763758715\n",
      "epochs 6733\n",
      "training loss 0.001271658669909502\n",
      "epochs 6734\n",
      "training loss 0.001040855378296798\n",
      "epochs 6735\n",
      "training loss 0.0016414410950216865\n",
      "epochs 6736\n",
      "training loss 0.0016592349292707592\n",
      "epochs 6737\n",
      "training loss 0.0014619795248332775\n",
      "epochs 6738\n",
      "training loss 0.001337104187188472\n",
      "epochs 6739\n",
      "training loss 0.001216559026335114\n",
      "testing loss 0.0029839650002896046\n",
      "epochs 6740\n",
      "training loss 0.0011060323465706095\n",
      "epochs 6741\n",
      "training loss 0.0013272969342703084\n",
      "epochs 6742\n",
      "training loss 0.0010489826007480068\n",
      "epochs 6743\n",
      "training loss 0.001225304364606789\n",
      "epochs 6744\n",
      "training loss 0.0011693879884652125\n",
      "epochs 6745\n",
      "training loss 0.0010956355119704363\n",
      "epochs 6746\n",
      "training loss 0.0009216942797354097\n",
      "epochs 6747\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss 0.0010182213733159573\n",
      "epochs 6748\n",
      "training loss 0.0008322982521183466\n",
      "epochs 6749\n",
      "training loss 0.0008965252794602767\n",
      "testing loss 0.002983309049489545\n",
      "epochs 6750\n",
      "training loss 0.0010626612900435008\n",
      "epochs 6751\n",
      "training loss 0.0012786930506924411\n",
      "epochs 6752\n",
      "training loss 0.001267925342796144\n",
      "epochs 6753\n",
      "training loss 0.001673197226901751\n",
      "epochs 6754\n",
      "training loss 0.0012523515448420051\n",
      "epochs 6755\n",
      "training loss 0.0016556503948271502\n",
      "epochs 6756\n",
      "training loss 0.001225670054590324\n",
      "epochs 6757\n",
      "training loss 0.0010014759847437142\n",
      "epochs 6758\n",
      "training loss 0.0010220168120727384\n",
      "epochs 6759\n",
      "training loss 0.0009885295332263658\n",
      "testing loss 0.00741584280485961\n",
      "epochs 6760\n",
      "training loss 0.0017346485426272958\n",
      "epochs 6761\n",
      "training loss 0.000963636274406358\n",
      "epochs 6762\n",
      "training loss 0.0010917283508623738\n",
      "epochs 6763\n",
      "training loss 0.0008325002641497763\n",
      "epochs 6764\n",
      "training loss 0.0007216329535959135\n",
      "epochs 6765\n",
      "training loss 0.0007247126098272128\n",
      "epochs 6766\n",
      "training loss 0.0008554117597347992\n",
      "epochs 6767\n",
      "training loss 0.0006787787787977176\n",
      "epochs 6768\n",
      "training loss 0.0008323974825129038\n",
      "epochs 6769\n",
      "training loss 0.0008198493476999544\n",
      "testing loss 0.0023896456386477863\n",
      "epochs 6770\n",
      "training loss 0.0007112588137027306\n",
      "epochs 6771\n",
      "training loss 0.0008178729981312805\n",
      "epochs 6772\n",
      "training loss 0.0009862458505696054\n",
      "epochs 6773\n",
      "training loss 0.0007385856353063533\n",
      "epochs 6774\n",
      "training loss 0.0006777535136583853\n",
      "epochs 6775\n",
      "training loss 0.0007349321015191895\n",
      "epochs 6776\n",
      "training loss 0.0006134212492097532\n",
      "epochs 6777\n",
      "training loss 0.0005884714380202469\n",
      "epochs 6778\n",
      "training loss 0.0006151411962436404\n",
      "epochs 6779\n",
      "training loss 0.0007729447852094066\n",
      "testing loss 0.002718657783995521\n",
      "epochs 6780\n",
      "training loss 0.0006166962294741661\n",
      "epochs 6781\n",
      "training loss 0.0006681530496479213\n",
      "epochs 6782\n",
      "training loss 0.0006838914187056066\n",
      "epochs 6783\n",
      "training loss 0.0008491866119307859\n",
      "epochs 6784\n",
      "training loss 0.0006881932462431139\n",
      "epochs 6785\n",
      "training loss 0.0006025006058151723\n",
      "epochs 6786\n",
      "training loss 0.000746651073333193\n",
      "epochs 6787\n",
      "training loss 0.0006820563068415256\n",
      "epochs 6788\n",
      "training loss 0.0008011504795082412\n",
      "epochs 6789\n",
      "training loss 0.000642945607901214\n",
      "testing loss 0.002812046300890651\n",
      "epochs 6790\n",
      "training loss 0.0006830830001031646\n",
      "epochs 6791\n",
      "training loss 0.0006295148732450629\n",
      "epochs 6792\n",
      "training loss 0.0007325656741070575\n",
      "epochs 6793\n",
      "training loss 0.0007993729370554179\n",
      "epochs 6794\n",
      "training loss 0.0006177140369559822\n",
      "epochs 6795\n",
      "training loss 0.0006690350999683425\n",
      "epochs 6796\n",
      "training loss 0.0007152853734963956\n",
      "epochs 6797\n",
      "training loss 0.0006194589755994672\n",
      "epochs 6798\n",
      "training loss 0.0005951127001844449\n",
      "epochs 6799\n",
      "training loss 0.0015492808550743437\n",
      "testing loss 0.0038363956367425253\n",
      "epochs 6800\n",
      "training loss 0.0013384668637381294\n",
      "epochs 6801\n",
      "training loss 0.0015175578836033171\n",
      "epochs 6802\n",
      "training loss 0.0008352037783185626\n",
      "epochs 6803\n",
      "training loss 0.0006695090175435049\n",
      "epochs 6804\n",
      "training loss 0.0006530441035584499\n",
      "epochs 6805\n",
      "training loss 0.0006073590521601603\n",
      "epochs 6806\n",
      "training loss 0.0006631653466457247\n",
      "epochs 6807\n",
      "training loss 0.0007159240851865226\n",
      "epochs 6808\n",
      "training loss 0.000638408729513558\n",
      "epochs 6809\n",
      "training loss 0.0006706173014919073\n",
      "testing loss 0.002579757087560146\n",
      "epochs 6810\n",
      "training loss 0.0006981207037310606\n",
      "epochs 6811\n",
      "training loss 0.0005912155358440675\n",
      "epochs 6812\n",
      "training loss 0.0015880432102679187\n",
      "epochs 6813\n",
      "training loss 0.0014973996140948838\n",
      "epochs 6814\n",
      "training loss 0.0012894826671384604\n",
      "epochs 6815\n",
      "training loss 0.001247213262690254\n",
      "epochs 6816\n",
      "training loss 0.0011750192049357158\n",
      "epochs 6817\n",
      "training loss 0.0010623654549145975\n",
      "epochs 6818\n",
      "training loss 0.0009795380147643907\n",
      "epochs 6819\n",
      "training loss 0.0007531481196482504\n",
      "testing loss 0.002650091334176745\n",
      "epochs 6820\n",
      "training loss 0.000738184976141679\n",
      "epochs 6821\n",
      "training loss 0.0006300277859722702\n",
      "epochs 6822\n",
      "training loss 0.0007734130484145418\n",
      "epochs 6823\n",
      "training loss 0.0006363115525177445\n",
      "epochs 6824\n",
      "training loss 0.0006109155918150223\n",
      "epochs 6825\n",
      "training loss 0.0006434013514169478\n",
      "epochs 6826\n",
      "training loss 0.0006573898358607388\n",
      "epochs 6827\n",
      "training loss 0.0005945526135980653\n",
      "epochs 6828\n",
      "training loss 0.0006810466218937902\n",
      "epochs 6829\n",
      "training loss 0.0006454847951201683\n",
      "testing loss 0.0025695135477593447\n",
      "epochs 6830\n",
      "training loss 0.0008579795254114166\n",
      "epochs 6831\n",
      "training loss 0.0008787531510956507\n",
      "epochs 6832\n",
      "training loss 0.0006753045438023109\n",
      "epochs 6833\n",
      "training loss 0.000596581423396137\n",
      "epochs 6834\n",
      "training loss 0.000607213955411495\n",
      "epochs 6835\n",
      "training loss 0.0006012610893337039\n",
      "epochs 6836\n",
      "training loss 0.0006488466840223225\n",
      "epochs 6837\n",
      "training loss 0.0005250323529668027\n",
      "epochs 6838\n",
      "training loss 0.0005796840523212503\n",
      "epochs 6839\n",
      "training loss 0.0006035876072558226\n",
      "testing loss 0.002655232878788275\n",
      "epochs 6840\n",
      "training loss 0.0006137971966569864\n",
      "epochs 6841\n",
      "training loss 0.0005788718326170122\n",
      "epochs 6842\n",
      "training loss 0.0005855495479038568\n",
      "epochs 6843\n",
      "training loss 0.0005957832172304947\n",
      "epochs 6844\n",
      "training loss 0.0006622083684695619\n",
      "epochs 6845\n",
      "training loss 0.0007109512196532465\n",
      "epochs 6846\n",
      "training loss 0.0005702027623926638\n",
      "epochs 6847\n",
      "training loss 0.0005583112204332742\n",
      "epochs 6848\n",
      "training loss 0.0005378259714242739\n",
      "epochs 6849\n",
      "training loss 0.0006147261865020908\n",
      "testing loss 0.002740773586605854\n",
      "epochs 6850\n",
      "training loss 0.0005920603191961272\n",
      "epochs 6851\n",
      "training loss 0.0005552935255493255\n",
      "epochs 6852\n",
      "training loss 0.0005570987704256691\n",
      "epochs 6853\n",
      "training loss 0.0005199681996866087\n",
      "epochs 6854\n",
      "training loss 0.0005889518008996254\n",
      "epochs 6855\n",
      "training loss 0.0006101606522087365\n",
      "epochs 6856\n",
      "training loss 0.0005757776602089269\n",
      "epochs 6857\n",
      "training loss 0.0006576614307719467\n",
      "epochs 6858\n",
      "training loss 0.0005569215790520063\n",
      "epochs 6859\n",
      "training loss 0.0006080133527995718\n",
      "testing loss 0.0026956034051452546\n",
      "epochs 6860\n",
      "training loss 0.0007339976084847456\n",
      "epochs 6861\n",
      "training loss 0.0005877349754097648\n",
      "epochs 6862\n",
      "training loss 0.0005561868491367434\n",
      "epochs 6863\n",
      "training loss 0.0005308799303206119\n",
      "epochs 6864\n",
      "training loss 0.0006029108677400519\n",
      "epochs 6865\n",
      "training loss 0.0005490927852436866\n",
      "epochs 6866\n",
      "training loss 0.0005230972697104874\n",
      "epochs 6867\n",
      "training loss 0.0006331473583281946\n",
      "epochs 6868\n",
      "training loss 0.000608705919579883\n",
      "epochs 6869\n",
      "training loss 0.00047804351365632493\n",
      "testing loss 0.0027177109612574707\n",
      "epochs 6870\n",
      "training loss 0.0005335901231992577\n",
      "epochs 6871\n",
      "training loss 0.000483466608635232\n",
      "epochs 6872\n",
      "training loss 0.0006229971585219222\n",
      "epochs 6873\n",
      "training loss 0.0006610303801395237\n",
      "epochs 6874\n",
      "training loss 0.0005417235211029049\n",
      "epochs 6875\n",
      "training loss 0.000588336303273901\n",
      "epochs 6876\n",
      "training loss 0.0005252643885185778\n",
      "epochs 6877\n",
      "training loss 0.0005382761055084177\n",
      "epochs 6878\n",
      "training loss 0.0005079060914115216\n",
      "epochs 6879\n",
      "training loss 0.0004999491422915531\n",
      "testing loss 0.002633575597738332\n",
      "epochs 6880\n",
      "training loss 0.0005366797696078609\n",
      "epochs 6881\n",
      "training loss 0.0005766669469446759\n",
      "epochs 6882\n",
      "training loss 0.0005807231784031066\n",
      "epochs 6883\n",
      "training loss 0.0005152603876911455\n",
      "epochs 6884\n",
      "training loss 0.0004948534165745414\n",
      "epochs 6885\n",
      "training loss 0.000613775874253102\n",
      "epochs 6886\n",
      "training loss 0.0005998811836702619\n",
      "epochs 6887\n",
      "training loss 0.001540169822130675\n",
      "epochs 6888\n",
      "training loss 0.0007299902308576579\n",
      "epochs 6889\n",
      "training loss 0.0005675922553967911\n",
      "testing loss 0.00269442689539006\n",
      "epochs 6890\n",
      "training loss 0.0005653810235855699\n",
      "epochs 6891\n",
      "training loss 0.0006065299284381164\n",
      "epochs 6892\n",
      "training loss 0.0005109960753449428\n",
      "epochs 6893\n",
      "training loss 0.0006423380216519917\n",
      "epochs 6894\n",
      "training loss 0.0005391980941130674\n",
      "epochs 6895\n",
      "training loss 0.0005615469499803955\n",
      "epochs 6896\n",
      "training loss 0.0005084982114960086\n",
      "epochs 6897\n",
      "training loss 0.000614490466529226\n",
      "epochs 6898\n",
      "training loss 0.0005406358238241683\n",
      "epochs 6899\n",
      "training loss 0.0004989359900956877\n",
      "testing loss 0.002686657539506093\n",
      "epochs 6900\n",
      "training loss 0.0004495336065715671\n",
      "epochs 6901\n",
      "training loss 0.0005441785083749646\n",
      "epochs 6902\n",
      "training loss 0.0005447907423466801\n",
      "epochs 6903\n",
      "training loss 0.0004669352437937094\n",
      "epochs 6904\n",
      "training loss 0.0005002563442797102\n",
      "epochs 6905\n",
      "training loss 0.0004939346686239131\n",
      "epochs 6906\n",
      "training loss 0.0004986489759485653\n",
      "epochs 6907\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss 0.0005315763459719241\n",
      "epochs 6908\n",
      "training loss 0.0005498908841940022\n",
      "epochs 6909\n",
      "training loss 0.0006075506883221862\n",
      "testing loss 0.0026670940272371345\n",
      "epochs 6910\n",
      "training loss 0.0008206093837938762\n",
      "epochs 6911\n",
      "training loss 0.0005652428790254626\n",
      "epochs 6912\n",
      "training loss 0.0005213179556393888\n",
      "epochs 6913\n",
      "training loss 0.0005346104960200748\n",
      "epochs 6914\n",
      "training loss 0.0005043398103772983\n",
      "epochs 6915\n",
      "training loss 0.0005191233061999932\n",
      "epochs 6916\n",
      "training loss 0.0007712552455745038\n",
      "epochs 6917\n",
      "training loss 0.0006658579875703754\n",
      "epochs 6918\n",
      "training loss 0.0005602305030519578\n",
      "epochs 6919\n",
      "training loss 0.0004935422162971202\n",
      "testing loss 0.0026449399483423177\n",
      "epochs 6920\n",
      "training loss 0.0004928619295640319\n",
      "epochs 6921\n",
      "training loss 0.00048011470880461317\n",
      "epochs 6922\n",
      "training loss 0.0005604514078481978\n",
      "epochs 6923\n",
      "training loss 0.0005303429117487138\n",
      "epochs 6924\n",
      "training loss 0.00047238062461059664\n",
      "epochs 6925\n",
      "training loss 0.0004939595471797257\n",
      "epochs 6926\n",
      "training loss 0.0005297046973890876\n",
      "epochs 6927\n",
      "training loss 0.0008370932119071914\n",
      "epochs 6928\n",
      "training loss 0.0007421662977020508\n",
      "epochs 6929\n",
      "training loss 0.0005777938736214849\n",
      "testing loss 0.0026416159961504715\n",
      "epochs 6930\n",
      "training loss 0.0005111888566409665\n",
      "epochs 6931\n",
      "training loss 0.0005170719907371367\n",
      "epochs 6932\n",
      "training loss 0.000515735409000328\n",
      "epochs 6933\n",
      "training loss 0.0004571972093382131\n",
      "epochs 6934\n",
      "training loss 0.0004784862840290558\n",
      "epochs 6935\n",
      "training loss 0.0005382974987257255\n",
      "epochs 6936\n",
      "training loss 0.0006044598786007488\n",
      "epochs 6937\n",
      "training loss 0.0005038132768805142\n",
      "epochs 6938\n",
      "training loss 0.0005194785768353015\n",
      "epochs 6939\n",
      "training loss 0.0005151898029407537\n",
      "testing loss 0.002630636408092811\n",
      "epochs 6940\n",
      "training loss 0.00047368351888480543\n",
      "epochs 6941\n",
      "training loss 0.0004767833556590664\n",
      "epochs 6942\n",
      "training loss 0.0005535852732129769\n",
      "epochs 6943\n",
      "training loss 0.0004958517842899193\n",
      "epochs 6944\n",
      "training loss 0.0005067375403302396\n",
      "epochs 6945\n",
      "training loss 0.00047372428229358897\n",
      "epochs 6946\n",
      "training loss 0.0005171207743300561\n",
      "epochs 6947\n",
      "training loss 0.0004941271085470439\n",
      "epochs 6948\n",
      "training loss 0.0005128807739438177\n",
      "epochs 6949\n",
      "training loss 0.000542342776484295\n",
      "testing loss 0.0026361467746079813\n",
      "epochs 6950\n",
      "training loss 0.000504636310559689\n",
      "epochs 6951\n",
      "training loss 0.0005079560822384053\n",
      "epochs 6952\n",
      "training loss 0.00047804015150044603\n",
      "epochs 6953\n",
      "training loss 0.0005303274974666428\n",
      "epochs 6954\n",
      "training loss 0.000753171754789349\n",
      "epochs 6955\n",
      "training loss 0.001118822418872301\n",
      "epochs 6956\n",
      "training loss 0.0010016825598399906\n",
      "epochs 6957\n",
      "training loss 0.000629657677425734\n",
      "epochs 6958\n",
      "training loss 0.0006735593951512468\n",
      "epochs 6959\n",
      "training loss 0.0005901355183496505\n",
      "testing loss 0.0027769161185996066\n",
      "epochs 6960\n",
      "training loss 0.0005017016967616998\n",
      "epochs 6961\n",
      "training loss 0.0005072505816804546\n",
      "epochs 6962\n",
      "training loss 0.0005220881067740089\n",
      "epochs 6963\n",
      "training loss 0.000514329304316401\n",
      "epochs 6964\n",
      "training loss 0.0005462807207757545\n",
      "epochs 6965\n",
      "training loss 0.0005581244606224644\n",
      "epochs 6966\n",
      "training loss 0.00047182091203939997\n",
      "epochs 6967\n",
      "training loss 0.0004770738090562569\n",
      "epochs 6968\n",
      "training loss 0.0006355474002221967\n",
      "epochs 6969\n",
      "training loss 0.0005576244678729041\n",
      "testing loss 0.0026480201029066815\n",
      "epochs 6970\n",
      "training loss 0.0009534036587445366\n",
      "epochs 6971\n",
      "training loss 0.0019869039958274972\n",
      "epochs 6972\n",
      "training loss 0.001277048278941085\n",
      "epochs 6973\n",
      "training loss 0.0016024600291422266\n",
      "epochs 6974\n",
      "training loss 0.0009720554234924242\n",
      "epochs 6975\n",
      "training loss 0.0008325890833787949\n",
      "epochs 6976\n",
      "training loss 0.0007477533236771573\n",
      "epochs 6977\n",
      "training loss 0.0006771964057473223\n",
      "epochs 6978\n",
      "training loss 0.0006790031867574527\n",
      "epochs 6979\n",
      "training loss 0.0007325149074729\n",
      "testing loss 0.0026436271897272755\n",
      "epochs 6980\n",
      "training loss 0.0006668146197736478\n",
      "epochs 6981\n",
      "training loss 0.0006190717639967709\n",
      "epochs 6982\n",
      "training loss 0.0006308281521021324\n",
      "epochs 6983\n",
      "training loss 0.0005951220982447606\n",
      "epochs 6984\n",
      "training loss 0.0005902614618586461\n",
      "epochs 6985\n",
      "training loss 0.0006206699351194148\n",
      "epochs 6986\n",
      "training loss 0.0008769961616971267\n",
      "epochs 6987\n",
      "training loss 0.0013157018585240971\n",
      "epochs 6988\n",
      "training loss 0.0009555709838448234\n",
      "epochs 6989\n",
      "training loss 0.0007675717796919454\n",
      "testing loss 0.0026599204767138716\n",
      "epochs 6990\n",
      "training loss 0.0006527702185561694\n",
      "epochs 6991\n",
      "training loss 0.0006838373017694099\n",
      "epochs 6992\n",
      "training loss 0.0006977176954714994\n",
      "epochs 6993\n",
      "training loss 0.0005733603280742502\n",
      "epochs 6994\n",
      "training loss 0.0006090774712871794\n",
      "epochs 6995\n",
      "training loss 0.0005582078780390118\n",
      "epochs 6996\n",
      "training loss 0.0005481367691746972\n",
      "epochs 6997\n",
      "training loss 0.0005081806406711362\n",
      "epochs 6998\n",
      "training loss 0.0007108193946051154\n",
      "epochs 6999\n",
      "training loss 0.0005425342372271846\n",
      "testing loss 0.0025853119903666805\n",
      "epochs 7000\n",
      "training loss 0.0005091261799803915\n",
      "epochs 7001\n",
      "training loss 0.0005536559159056451\n",
      "epochs 7002\n",
      "training loss 0.0008075971651389221\n",
      "epochs 7003\n",
      "training loss 0.000510679860900108\n",
      "epochs 7004\n",
      "training loss 0.0005134610887539027\n",
      "epochs 7005\n",
      "training loss 0.0004949109659050407\n",
      "epochs 7006\n",
      "training loss 0.0005267460818655823\n",
      "epochs 7007\n",
      "training loss 0.0005036746418899022\n",
      "epochs 7008\n",
      "training loss 0.00047654221750835474\n",
      "epochs 7009\n",
      "training loss 0.00048598850888658686\n",
      "testing loss 0.002583210527853948\n",
      "epochs 7010\n",
      "training loss 0.00048788102005047887\n",
      "epochs 7011\n",
      "training loss 0.00045740867184339187\n",
      "epochs 7012\n",
      "training loss 0.0004998987456918114\n",
      "epochs 7013\n",
      "training loss 0.000464579181856756\n",
      "epochs 7014\n",
      "training loss 0.0004897147714652936\n",
      "epochs 7015\n",
      "training loss 0.00045399217468992123\n",
      "epochs 7016\n",
      "training loss 0.0005137508337514752\n",
      "epochs 7017\n",
      "training loss 0.0005415781112005622\n",
      "epochs 7018\n",
      "training loss 0.0008362138422353244\n",
      "epochs 7019\n",
      "training loss 0.0011639850672177324\n",
      "testing loss 0.002854589091742689\n",
      "epochs 7020\n",
      "training loss 0.0008093284126859453\n",
      "epochs 7021\n",
      "training loss 0.0009384345144527401\n",
      "epochs 7022\n",
      "training loss 0.0015482008753529833\n",
      "epochs 7023\n",
      "training loss 0.0009499357716572446\n",
      "epochs 7024\n",
      "training loss 0.0006634366097378807\n",
      "epochs 7025\n",
      "training loss 0.0006061678592718594\n",
      "epochs 7026\n",
      "training loss 0.000627364108047383\n",
      "epochs 7027\n",
      "training loss 0.0005343837215385391\n",
      "epochs 7028\n",
      "training loss 0.0005325923161085774\n",
      "epochs 7029\n",
      "training loss 0.0005154858116311018\n",
      "testing loss 0.002625086430645158\n",
      "epochs 7030\n",
      "training loss 0.0005189551655868334\n",
      "epochs 7031\n",
      "training loss 0.0005268576104861987\n",
      "epochs 7032\n",
      "training loss 0.001396160264213578\n",
      "epochs 7033\n",
      "training loss 0.0014464463224764744\n",
      "epochs 7034\n",
      "training loss 0.001129030261247484\n",
      "epochs 7035\n",
      "training loss 0.0009982226679022324\n",
      "epochs 7036\n",
      "training loss 0.0008174477033260474\n",
      "epochs 7037\n",
      "training loss 0.0007896774139193009\n",
      "epochs 7038\n",
      "training loss 0.0007318683860485235\n",
      "epochs 7039\n",
      "training loss 0.0008131248756498664\n",
      "testing loss 0.002824472498350136\n",
      "epochs 7040\n",
      "training loss 0.0008234803967877068\n",
      "epochs 7041\n",
      "training loss 0.0007284301132144899\n",
      "epochs 7042\n",
      "training loss 0.0006723568453556097\n",
      "epochs 7043\n",
      "training loss 0.0005921002203707603\n",
      "epochs 7044\n",
      "training loss 0.0006166074545643544\n",
      "epochs 7045\n",
      "training loss 0.0005679048484051176\n",
      "epochs 7046\n",
      "training loss 0.0005917485577258137\n",
      "epochs 7047\n",
      "training loss 0.0005960014838396959\n",
      "epochs 7048\n",
      "training loss 0.0005482790079095194\n",
      "epochs 7049\n",
      "training loss 0.0005418637888272516\n",
      "testing loss 0.002665710205737343\n",
      "epochs 7050\n",
      "training loss 0.0005198611685366435\n",
      "epochs 7051\n",
      "training loss 0.0005589779199236907\n",
      "epochs 7052\n",
      "training loss 0.0005328054671666916\n",
      "epochs 7053\n",
      "training loss 0.0005048176734234096\n",
      "epochs 7054\n",
      "training loss 0.0005215672850145287\n",
      "epochs 7055\n",
      "training loss 0.0005145831289948856\n",
      "epochs 7056\n",
      "training loss 0.0005375451342334354\n",
      "epochs 7057\n",
      "training loss 0.0005287770657817122\n",
      "epochs 7058\n",
      "training loss 0.0005456181462446517\n",
      "epochs 7059\n",
      "training loss 0.0004966111345419032\n",
      "testing loss 0.002584149032056741\n",
      "epochs 7060\n",
      "training loss 0.0005467416123079425\n",
      "epochs 7061\n",
      "training loss 0.0005521088595131248\n",
      "epochs 7062\n",
      "training loss 0.0005378250220555552\n",
      "epochs 7063\n",
      "training loss 0.0005506461353174277\n",
      "epochs 7064\n",
      "training loss 0.000520225925074528\n",
      "epochs 7065\n",
      "training loss 0.0005571102734271573\n",
      "epochs 7066\n",
      "training loss 0.0005605365574291955\n",
      "epochs 7067\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss 0.000893091515596888\n",
      "epochs 7068\n",
      "training loss 0.0022211182118736005\n",
      "epochs 7069\n",
      "training loss 0.0014778116712980765\n",
      "testing loss 0.002733999053726356\n",
      "epochs 7070\n",
      "training loss 0.0008750503191350758\n",
      "epochs 7071\n",
      "training loss 0.0007549917413750493\n",
      "epochs 7072\n",
      "training loss 0.0007281222724459081\n",
      "epochs 7073\n",
      "training loss 0.0006935998208617005\n",
      "epochs 7074\n",
      "training loss 0.0014442085222295827\n",
      "epochs 7075\n",
      "training loss 0.0007490135720378287\n",
      "epochs 7076\n",
      "training loss 0.000590754219165955\n",
      "epochs 7077\n",
      "training loss 0.0005499508924000984\n",
      "epochs 7078\n",
      "training loss 0.0005291465142286046\n",
      "epochs 7079\n",
      "training loss 0.0005235877917728481\n",
      "testing loss 0.0025363015758157674\n",
      "epochs 7080\n",
      "training loss 0.0005303842589148747\n",
      "epochs 7081\n",
      "training loss 0.000550997145912726\n",
      "epochs 7082\n",
      "training loss 0.0005630488302395891\n",
      "epochs 7083\n",
      "training loss 0.00047501820418417544\n",
      "epochs 7084\n",
      "training loss 0.0005208400613663712\n",
      "epochs 7085\n",
      "training loss 0.0004804949483149161\n",
      "epochs 7086\n",
      "training loss 0.0005382341469848942\n",
      "epochs 7087\n",
      "training loss 0.0005010752453918832\n",
      "epochs 7088\n",
      "training loss 0.0005263253775040271\n",
      "epochs 7089\n",
      "training loss 0.0005125753064201097\n",
      "testing loss 0.002612162993623089\n",
      "epochs 7090\n",
      "training loss 0.0005391681172119278\n",
      "epochs 7091\n",
      "training loss 0.0004953132738149795\n",
      "epochs 7092\n",
      "training loss 0.0005248614617320497\n",
      "epochs 7093\n",
      "training loss 0.0006538983981130718\n",
      "epochs 7094\n",
      "training loss 0.0007563984776297896\n",
      "epochs 7095\n",
      "training loss 0.0006282702512971173\n",
      "epochs 7096\n",
      "training loss 0.0005131520898474838\n",
      "epochs 7097\n",
      "training loss 0.0004855970193746593\n",
      "epochs 7098\n",
      "training loss 0.0004983395696327509\n",
      "epochs 7099\n",
      "training loss 0.0005381421309345229\n",
      "testing loss 0.002664526716842323\n",
      "epochs 7100\n",
      "training loss 0.0005017696734461905\n",
      "epochs 7101\n",
      "training loss 0.00048115821532256856\n",
      "epochs 7102\n",
      "training loss 0.000515001679672987\n",
      "epochs 7103\n",
      "training loss 0.0004964762170569784\n",
      "epochs 7104\n",
      "training loss 0.0005214331678849416\n",
      "epochs 7105\n",
      "training loss 0.0005128081459099126\n",
      "epochs 7106\n",
      "training loss 0.0005255936520063745\n",
      "epochs 7107\n",
      "training loss 0.0005413921664739282\n",
      "epochs 7108\n",
      "training loss 0.0005099399594376345\n",
      "epochs 7109\n",
      "training loss 0.000492978405835826\n",
      "testing loss 0.002671562502216812\n",
      "epochs 7110\n",
      "training loss 0.0005339069878802802\n",
      "epochs 7111\n",
      "training loss 0.0006942310369443318\n",
      "epochs 7112\n",
      "training loss 0.0009212531704925522\n",
      "epochs 7113\n",
      "training loss 0.0009561908435951182\n",
      "epochs 7114\n",
      "training loss 0.0006782015244898281\n",
      "epochs 7115\n",
      "training loss 0.0006740694240338557\n",
      "epochs 7116\n",
      "training loss 0.0006308955541850099\n",
      "epochs 7117\n",
      "training loss 0.0006558128271151424\n",
      "epochs 7118\n",
      "training loss 0.0006520683499616443\n",
      "epochs 7119\n",
      "training loss 0.0005980389382715668\n",
      "testing loss 0.002752532297827911\n",
      "epochs 7120\n",
      "training loss 0.0005390274596377912\n",
      "epochs 7121\n",
      "training loss 0.0005306399877269478\n",
      "epochs 7122\n",
      "training loss 0.00048721330917983864\n",
      "epochs 7123\n",
      "training loss 0.0005039036318894736\n",
      "epochs 7124\n",
      "training loss 0.0005000758931885748\n",
      "epochs 7125\n",
      "training loss 0.0005167342690039019\n",
      "epochs 7126\n",
      "training loss 0.0005766826766361921\n",
      "epochs 7127\n",
      "training loss 0.0004791057089026621\n",
      "epochs 7128\n",
      "training loss 0.0004856737751986458\n",
      "epochs 7129\n",
      "training loss 0.00047102355510406877\n",
      "testing loss 0.0026246789728905607\n",
      "epochs 7130\n",
      "training loss 0.0005423059526195404\n",
      "epochs 7131\n",
      "training loss 0.00046779819766673797\n",
      "epochs 7132\n",
      "training loss 0.0005393789686251284\n",
      "epochs 7133\n",
      "training loss 0.0005841297094850294\n",
      "epochs 7134\n",
      "training loss 0.0005213405674579624\n",
      "epochs 7135\n",
      "training loss 0.00047833071520911547\n",
      "epochs 7136\n",
      "training loss 0.00048438229714520276\n",
      "epochs 7137\n",
      "training loss 0.000489580388464696\n",
      "epochs 7138\n",
      "training loss 0.0005048419493795472\n",
      "epochs 7139\n",
      "training loss 0.00047604760472127734\n",
      "testing loss 0.002637484403994225\n",
      "epochs 7140\n",
      "training loss 0.0004846593851611403\n",
      "epochs 7141\n",
      "training loss 0.0005208433053376985\n",
      "epochs 7142\n",
      "training loss 0.0004664660383852363\n",
      "epochs 7143\n",
      "training loss 0.00046611708823498057\n",
      "epochs 7144\n",
      "training loss 0.0005621699118982479\n",
      "epochs 7145\n",
      "training loss 0.0005638420624809911\n",
      "epochs 7146\n",
      "training loss 0.0005083043974120804\n",
      "epochs 7147\n",
      "training loss 0.0004874817270850678\n",
      "epochs 7148\n",
      "training loss 0.0004886128524096122\n",
      "epochs 7149\n",
      "training loss 0.00048148560683252886\n",
      "testing loss 0.002797959613901107\n",
      "epochs 7150\n",
      "training loss 0.001456346829109726\n",
      "epochs 7151\n",
      "training loss 0.0008970423561583151\n",
      "epochs 7152\n",
      "training loss 0.0006950700298725914\n",
      "epochs 7153\n",
      "training loss 0.0007378965162241826\n",
      "epochs 7154\n",
      "training loss 0.0006722406857317217\n",
      "epochs 7155\n",
      "training loss 0.0005589114737556823\n",
      "epochs 7156\n",
      "training loss 0.000593921014477179\n",
      "epochs 7157\n",
      "training loss 0.0005937333353745573\n",
      "epochs 7158\n",
      "training loss 0.0006147120671635522\n",
      "epochs 7159\n",
      "training loss 0.0006644535440163216\n",
      "testing loss 0.002622983402305065\n",
      "epochs 7160\n",
      "training loss 0.0005822455475820189\n",
      "epochs 7161\n",
      "training loss 0.0006867475551305378\n",
      "epochs 7162\n",
      "training loss 0.0005943093076985227\n",
      "epochs 7163\n",
      "training loss 0.0006209006133180757\n",
      "epochs 7164\n",
      "training loss 0.0005700900991207362\n",
      "epochs 7165\n",
      "training loss 0.000640807159904583\n",
      "epochs 7166\n",
      "training loss 0.0007253160122017685\n",
      "epochs 7167\n",
      "training loss 0.0005962373859547701\n",
      "epochs 7168\n",
      "training loss 0.0006773462737549526\n",
      "epochs 7169\n",
      "training loss 0.0006250586344504525\n",
      "testing loss 0.002570852814803679\n",
      "epochs 7170\n",
      "training loss 0.0006452042614407045\n",
      "epochs 7171\n",
      "training loss 0.0006332770400428663\n",
      "epochs 7172\n",
      "training loss 0.0007239704020852139\n",
      "epochs 7173\n",
      "training loss 0.0007234507252385778\n",
      "epochs 7174\n",
      "training loss 0.0006378013618526793\n",
      "epochs 7175\n",
      "training loss 0.0006349444720454622\n",
      "epochs 7176\n",
      "training loss 0.0006321226038770485\n",
      "epochs 7177\n",
      "training loss 0.000518932766695068\n",
      "epochs 7178\n",
      "training loss 0.0005506579220149168\n",
      "epochs 7179\n",
      "training loss 0.0005218042137694339\n",
      "testing loss 0.002584026513393334\n",
      "epochs 7180\n",
      "training loss 0.000491941723237267\n",
      "epochs 7181\n",
      "training loss 0.0004782784451719226\n",
      "epochs 7182\n",
      "training loss 0.0005727692463507418\n",
      "epochs 7183\n",
      "training loss 0.0004898458570638236\n",
      "epochs 7184\n",
      "training loss 0.0005443348836098546\n",
      "epochs 7185\n",
      "training loss 0.0005014789044626317\n",
      "epochs 7186\n",
      "training loss 0.0005272740464923638\n",
      "epochs 7187\n",
      "training loss 0.0004615131766488634\n",
      "epochs 7188\n",
      "training loss 0.00047547556641249774\n",
      "epochs 7189\n",
      "training loss 0.000481114831684429\n",
      "testing loss 0.0025808046434028405\n",
      "epochs 7190\n",
      "training loss 0.0005205737272600182\n",
      "epochs 7191\n",
      "training loss 0.0005364664299498485\n",
      "epochs 7192\n",
      "training loss 0.0005128035410470117\n",
      "epochs 7193\n",
      "training loss 0.0005416386136410073\n",
      "epochs 7194\n",
      "training loss 0.0005829179207270676\n",
      "epochs 7195\n",
      "training loss 0.0005016137825821931\n",
      "epochs 7196\n",
      "training loss 0.0004957875159553515\n",
      "epochs 7197\n",
      "training loss 0.00048716988653018165\n",
      "epochs 7198\n",
      "training loss 0.00048769784664542704\n",
      "epochs 7199\n",
      "training loss 0.00044295800565657034\n",
      "testing loss 0.0025231463536174296\n",
      "epochs 7200\n",
      "training loss 0.00047448465781425067\n",
      "epochs 7201\n",
      "training loss 0.0005050528110542808\n",
      "epochs 7202\n",
      "training loss 0.0005426030626554483\n",
      "epochs 7203\n",
      "training loss 0.0005225821296114045\n",
      "epochs 7204\n",
      "training loss 0.00048493666257312955\n",
      "epochs 7205\n",
      "training loss 0.000475777280205538\n",
      "epochs 7206\n",
      "training loss 0.0005507398805245587\n",
      "epochs 7207\n",
      "training loss 0.000452824348550556\n",
      "epochs 7208\n",
      "training loss 0.0005310990600485785\n",
      "epochs 7209\n",
      "training loss 0.0005088249876236085\n",
      "testing loss 0.002766048902701851\n",
      "epochs 7210\n",
      "training loss 0.0005174048381537698\n",
      "epochs 7211\n",
      "training loss 0.00048101029815619367\n",
      "epochs 7212\n",
      "training loss 0.0004726588260913183\n",
      "epochs 7213\n",
      "training loss 0.0005600122743042746\n",
      "epochs 7214\n",
      "training loss 0.0005197019409494458\n",
      "epochs 7215\n",
      "training loss 0.0005091037560540243\n",
      "epochs 7216\n",
      "training loss 0.00045315753185546937\n",
      "epochs 7217\n",
      "training loss 0.0004829677019273936\n",
      "epochs 7218\n",
      "training loss 0.0005372252959636321\n",
      "epochs 7219\n",
      "training loss 0.00047625426553673817\n",
      "testing loss 0.0026482923578880465\n",
      "epochs 7220\n",
      "training loss 0.0005641704554192574\n",
      "epochs 7221\n",
      "training loss 0.0005207115934318141\n",
      "epochs 7222\n",
      "training loss 0.0005433011030789612\n",
      "epochs 7223\n",
      "training loss 0.0005105185174025131\n",
      "epochs 7224\n",
      "training loss 0.0004815642315381996\n",
      "epochs 7225\n",
      "training loss 0.0004960478563091681\n",
      "epochs 7226\n",
      "training loss 0.0006021762760900992\n",
      "epochs 7227\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss 0.0005674728905034781\n",
      "epochs 7228\n",
      "training loss 0.0005498651938270891\n",
      "epochs 7229\n",
      "training loss 0.0005011879008349688\n",
      "testing loss 0.002654718642588705\n",
      "epochs 7230\n",
      "training loss 0.0004890938140848216\n",
      "epochs 7231\n",
      "training loss 0.0005237122349749606\n",
      "epochs 7232\n",
      "training loss 0.0005521101200009065\n",
      "epochs 7233\n",
      "training loss 0.0004724477675897678\n",
      "epochs 7234\n",
      "training loss 0.0004756364285468908\n",
      "epochs 7235\n",
      "training loss 0.00048792622537609747\n",
      "epochs 7236\n",
      "training loss 0.000509353082156089\n",
      "epochs 7237\n",
      "training loss 0.000484613269036013\n",
      "epochs 7238\n",
      "training loss 0.0006376342825120242\n",
      "epochs 7239\n",
      "training loss 0.0005525471378998168\n",
      "testing loss 0.002618471774807636\n",
      "epochs 7240\n",
      "training loss 0.0005767600036560243\n",
      "epochs 7241\n",
      "training loss 0.0005667777456014805\n",
      "epochs 7242\n",
      "training loss 0.0005405204738440745\n",
      "epochs 7243\n",
      "training loss 0.0006114801323489997\n",
      "epochs 7244\n",
      "training loss 0.0007526329199261227\n",
      "epochs 7245\n",
      "training loss 0.0005103240784266143\n",
      "epochs 7246\n",
      "training loss 0.0005471729078099392\n",
      "epochs 7247\n",
      "training loss 0.0005391349676836531\n",
      "epochs 7248\n",
      "training loss 0.0004969283294939015\n",
      "epochs 7249\n",
      "training loss 0.0005690563232340711\n",
      "testing loss 0.002604733395030233\n",
      "epochs 7250\n",
      "training loss 0.00048566939653177664\n",
      "epochs 7251\n",
      "training loss 0.0004802382519110573\n",
      "epochs 7252\n",
      "training loss 0.0004668791057336028\n",
      "epochs 7253\n",
      "training loss 0.0004974123026636404\n",
      "epochs 7254\n",
      "training loss 0.0004562142315337655\n",
      "epochs 7255\n",
      "training loss 0.0005194384861761551\n",
      "epochs 7256\n",
      "training loss 0.0004845628571766641\n",
      "epochs 7257\n",
      "training loss 0.00048643181852056535\n",
      "epochs 7258\n",
      "training loss 0.00048126209295308077\n",
      "epochs 7259\n",
      "training loss 0.0004826914761898371\n",
      "testing loss 0.002642468628572657\n",
      "epochs 7260\n",
      "training loss 0.0008327467881014294\n",
      "epochs 7261\n",
      "training loss 0.0006116048258086695\n",
      "epochs 7262\n",
      "training loss 0.0005950977981828669\n",
      "epochs 7263\n",
      "training loss 0.0004876538225460945\n",
      "epochs 7264\n",
      "training loss 0.0005215898751158064\n",
      "epochs 7265\n",
      "training loss 0.0005029391367865958\n",
      "epochs 7266\n",
      "training loss 0.0004743122904226014\n",
      "epochs 7267\n",
      "training loss 0.0005216459175932722\n",
      "epochs 7268\n",
      "training loss 0.000604378391856237\n",
      "epochs 7269\n",
      "training loss 0.0006652381130470116\n",
      "testing loss 0.003185732910204811\n",
      "epochs 7270\n",
      "training loss 0.0010748156271188443\n",
      "epochs 7271\n",
      "training loss 0.000867829884994792\n",
      "epochs 7272\n",
      "training loss 0.0007727134037418942\n",
      "epochs 7273\n",
      "training loss 0.0007978697462392388\n",
      "epochs 7274\n",
      "training loss 0.0008259958310348568\n",
      "epochs 7275\n",
      "training loss 0.0014368213008484863\n",
      "epochs 7276\n",
      "training loss 0.001107521952532577\n",
      "epochs 7277\n",
      "training loss 0.0009039488322410088\n",
      "epochs 7278\n",
      "training loss 0.0006727316684130647\n",
      "epochs 7279\n",
      "training loss 0.000564687015148344\n",
      "testing loss 0.0026361223641314037\n",
      "epochs 7280\n",
      "training loss 0.0005384777513535065\n",
      "epochs 7281\n",
      "training loss 0.0006173152849325871\n",
      "epochs 7282\n",
      "training loss 0.0007613270820753994\n",
      "epochs 7283\n",
      "training loss 0.0007743016718660331\n",
      "epochs 7284\n",
      "training loss 0.0006827345655949385\n",
      "epochs 7285\n",
      "training loss 0.0008474446017164907\n",
      "epochs 7286\n",
      "training loss 0.0006651009648286746\n",
      "epochs 7287\n",
      "training loss 0.0007438500674362195\n",
      "epochs 7288\n",
      "training loss 0.0007119114254353607\n",
      "epochs 7289\n",
      "training loss 0.0006372610172171904\n",
      "testing loss 0.002794291007543868\n",
      "epochs 7290\n",
      "training loss 0.0005920994103288895\n",
      "epochs 7291\n",
      "training loss 0.0005581425095088836\n",
      "epochs 7292\n",
      "training loss 0.0005185206528288797\n",
      "epochs 7293\n",
      "training loss 0.00047930703398638537\n",
      "epochs 7294\n",
      "training loss 0.0005305855164140192\n",
      "epochs 7295\n",
      "training loss 0.0005129459437894378\n",
      "epochs 7296\n",
      "training loss 0.0006230363520046294\n",
      "epochs 7297\n",
      "training loss 0.0005681758259435815\n",
      "epochs 7298\n",
      "training loss 0.0005106095011072873\n",
      "epochs 7299\n",
      "training loss 0.0005549701623545003\n",
      "testing loss 0.0025502412996076525\n",
      "epochs 7300\n",
      "training loss 0.0007953030241428277\n",
      "epochs 7301\n",
      "training loss 0.0010703651347384424\n",
      "epochs 7302\n",
      "training loss 0.0007932826881594164\n",
      "epochs 7303\n",
      "training loss 0.000698095921244427\n",
      "epochs 7304\n",
      "training loss 0.0008637661735865494\n",
      "epochs 7305\n",
      "training loss 0.0006426666045170787\n",
      "epochs 7306\n",
      "training loss 0.0006354733702505863\n",
      "epochs 7307\n",
      "training loss 0.0006338349136765933\n",
      "epochs 7308\n",
      "training loss 0.0007276824352792874\n",
      "epochs 7309\n",
      "training loss 0.0008414373804757082\n",
      "testing loss 0.0026879499167705894\n",
      "epochs 7310\n",
      "training loss 0.0007756658135149006\n",
      "epochs 7311\n",
      "training loss 0.0007332117348239902\n",
      "epochs 7312\n",
      "training loss 0.0006142340030444724\n",
      "epochs 7313\n",
      "training loss 0.0006281777279200966\n",
      "epochs 7314\n",
      "training loss 0.0005749000998399302\n",
      "epochs 7315\n",
      "training loss 0.0005760433112156483\n",
      "epochs 7316\n",
      "training loss 0.0006545830784630212\n",
      "epochs 7317\n",
      "training loss 0.0006042342789762718\n",
      "epochs 7318\n",
      "training loss 0.0006168412915901579\n",
      "epochs 7319\n",
      "training loss 0.0007237739061142706\n",
      "testing loss 0.0026426082633845245\n",
      "epochs 7320\n",
      "training loss 0.0006252362809142545\n",
      "epochs 7321\n",
      "training loss 0.0005375478975050219\n",
      "epochs 7322\n",
      "training loss 0.0005778715020296161\n",
      "epochs 7323\n",
      "training loss 0.0005437850973025349\n",
      "epochs 7324\n",
      "training loss 0.0005473310957092362\n",
      "epochs 7325\n",
      "training loss 0.0004999918175300748\n",
      "epochs 7326\n",
      "training loss 0.0005184420627558824\n",
      "epochs 7327\n",
      "training loss 0.0005258402931695029\n",
      "epochs 7328\n",
      "training loss 0.0005258346495917775\n",
      "epochs 7329\n",
      "training loss 0.0005777091424633384\n",
      "testing loss 0.0026686440382139584\n",
      "epochs 7330\n",
      "training loss 0.0005242981567397136\n",
      "epochs 7331\n",
      "training loss 0.0005097757840223362\n",
      "epochs 7332\n",
      "training loss 0.0005117829783436047\n",
      "epochs 7333\n",
      "training loss 0.0004997326066968028\n",
      "epochs 7334\n",
      "training loss 0.0005198238340721644\n",
      "epochs 7335\n",
      "training loss 0.0006061919489280975\n",
      "epochs 7336\n",
      "training loss 0.0006334042566011754\n",
      "epochs 7337\n",
      "training loss 0.0005511082895489348\n",
      "epochs 7338\n",
      "training loss 0.0005047495852332098\n",
      "epochs 7339\n",
      "training loss 0.0005668611114449788\n",
      "testing loss 0.002653959221272657\n",
      "epochs 7340\n",
      "training loss 0.0005298367631409351\n",
      "epochs 7341\n",
      "training loss 0.0005199999578040954\n",
      "epochs 7342\n",
      "training loss 0.0005274110744030733\n",
      "epochs 7343\n",
      "training loss 0.000483760432945989\n",
      "epochs 7344\n",
      "training loss 0.0004989538431283664\n",
      "epochs 7345\n",
      "training loss 0.0005117726039338155\n",
      "epochs 7346\n",
      "training loss 0.0005824490792491674\n",
      "epochs 7347\n",
      "training loss 0.0005552811225406304\n",
      "epochs 7348\n",
      "training loss 0.0005202133360313178\n",
      "epochs 7349\n",
      "training loss 0.0005292998431151376\n",
      "testing loss 0.002498961555778135\n",
      "epochs 7350\n",
      "training loss 0.0005094035175461944\n",
      "epochs 7351\n",
      "training loss 0.0005295405949545192\n",
      "epochs 7352\n",
      "training loss 0.0005226081387050687\n",
      "epochs 7353\n",
      "training loss 0.0004778757633352624\n",
      "epochs 7354\n",
      "training loss 0.000525426001735258\n",
      "epochs 7355\n",
      "training loss 0.0004846791542697086\n",
      "epochs 7356\n",
      "training loss 0.0004996591933902443\n",
      "epochs 7357\n",
      "training loss 0.0005320984567480167\n",
      "epochs 7358\n",
      "training loss 0.0007503955055482538\n",
      "epochs 7359\n",
      "training loss 0.0005665566800707119\n",
      "testing loss 0.0025994470215019447\n",
      "epochs 7360\n",
      "training loss 0.0005181730035933069\n",
      "epochs 7361\n",
      "training loss 0.0005308026462046028\n",
      "epochs 7362\n",
      "training loss 0.000507941285019463\n",
      "epochs 7363\n",
      "training loss 0.000497189819625944\n",
      "epochs 7364\n",
      "training loss 0.0005029985760526143\n",
      "epochs 7365\n",
      "training loss 0.0005178471314536809\n",
      "epochs 7366\n",
      "training loss 0.0005211935359680328\n",
      "epochs 7367\n",
      "training loss 0.0023544755264321244\n",
      "epochs 7368\n",
      "training loss 0.001704026847804605\n",
      "epochs 7369\n",
      "training loss 0.001217617046199088\n",
      "testing loss 0.0027072641879637193\n",
      "epochs 7370\n",
      "training loss 0.0010444709552928952\n",
      "epochs 7371\n",
      "training loss 0.0007635765748967539\n",
      "epochs 7372\n",
      "training loss 0.0009833519718727226\n",
      "epochs 7373\n",
      "training loss 0.0007274648955581557\n",
      "epochs 7374\n",
      "training loss 0.0006203430140034315\n",
      "epochs 7375\n",
      "training loss 0.0007694792753477556\n",
      "epochs 7376\n",
      "training loss 0.0007344519920819821\n",
      "epochs 7377\n",
      "training loss 0.000593802590725666\n",
      "epochs 7378\n",
      "training loss 0.0005603067751685129\n",
      "epochs 7379\n",
      "training loss 0.0005316736556463635\n",
      "testing loss 0.002587131010318928\n",
      "epochs 7380\n",
      "training loss 0.000539277113356987\n",
      "epochs 7381\n",
      "training loss 0.0005785211771945993\n",
      "epochs 7382\n",
      "training loss 0.0009683187736770121\n",
      "epochs 7383\n",
      "training loss 0.000849303408167792\n",
      "epochs 7384\n",
      "training loss 0.0006168208859569328\n",
      "epochs 7385\n",
      "training loss 0.0005896782558616591\n",
      "epochs 7386\n",
      "training loss 0.0005309616033650232\n",
      "epochs 7387\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss 0.0005184088162738139\n",
      "epochs 7388\n",
      "training loss 0.0004960932619558324\n",
      "epochs 7389\n",
      "training loss 0.0005014288904588375\n",
      "testing loss 0.002609383412686355\n",
      "epochs 7390\n",
      "training loss 0.0005102998744781302\n",
      "epochs 7391\n",
      "training loss 0.000524581347536975\n",
      "epochs 7392\n",
      "training loss 0.0004917612457846074\n",
      "epochs 7393\n",
      "training loss 0.0006319091464767918\n",
      "epochs 7394\n",
      "training loss 0.0004998672256241963\n",
      "epochs 7395\n",
      "training loss 0.0005192355928471239\n",
      "epochs 7396\n",
      "training loss 0.0005223514432742863\n",
      "epochs 7397\n",
      "training loss 0.0005032556178543638\n",
      "epochs 7398\n",
      "training loss 0.0004991709546074215\n",
      "epochs 7399\n",
      "training loss 0.0005013893255263307\n",
      "testing loss 0.002621604339797578\n",
      "epochs 7400\n",
      "training loss 0.0004793769238717673\n",
      "epochs 7401\n",
      "training loss 0.0005095432110670048\n",
      "epochs 7402\n",
      "training loss 0.000644716167115496\n",
      "epochs 7403\n",
      "training loss 0.0005970173503879435\n",
      "epochs 7404\n",
      "training loss 0.0006436513626090276\n",
      "epochs 7405\n",
      "training loss 0.0006495057635726181\n",
      "epochs 7406\n",
      "training loss 0.0005842812054494741\n",
      "epochs 7407\n",
      "training loss 0.0004891789742811982\n",
      "epochs 7408\n",
      "training loss 0.0006908890905352677\n",
      "epochs 7409\n",
      "training loss 0.0006209523220671098\n",
      "testing loss 0.002607720388026895\n",
      "epochs 7410\n",
      "training loss 0.0005730388268168823\n",
      "epochs 7411\n",
      "training loss 0.0004881340498140076\n",
      "epochs 7412\n",
      "training loss 0.0005174693650612749\n",
      "epochs 7413\n",
      "training loss 0.0004881140913978491\n",
      "epochs 7414\n",
      "training loss 0.0005280053754171532\n",
      "epochs 7415\n",
      "training loss 0.0005048850384409225\n",
      "epochs 7416\n",
      "training loss 0.0005227658493546231\n",
      "epochs 7417\n",
      "training loss 0.0006089680065616037\n",
      "epochs 7418\n",
      "training loss 0.0005085793744714641\n",
      "epochs 7419\n",
      "training loss 0.0005378449818870976\n",
      "testing loss 0.0026397273199986137\n",
      "epochs 7420\n",
      "training loss 0.0005074953994753355\n",
      "epochs 7421\n",
      "training loss 0.0005272456587134439\n",
      "epochs 7422\n",
      "training loss 0.0005295432414569379\n",
      "epochs 7423\n",
      "training loss 0.0005246018348643868\n",
      "epochs 7424\n",
      "training loss 0.0005285177035908296\n",
      "epochs 7425\n",
      "training loss 0.0004892945998188357\n",
      "epochs 7426\n",
      "training loss 0.0005768409347739127\n",
      "epochs 7427\n",
      "training loss 0.0005306695584129219\n",
      "epochs 7428\n",
      "training loss 0.0004454394751143469\n",
      "epochs 7429\n",
      "training loss 0.00047423259847327544\n",
      "testing loss 0.00257381206379992\n",
      "epochs 7430\n",
      "training loss 0.0006304704282527625\n",
      "epochs 7431\n",
      "training loss 0.000537883241128001\n",
      "epochs 7432\n",
      "training loss 0.00047846596760924416\n",
      "epochs 7433\n",
      "training loss 0.0005065739386761703\n",
      "epochs 7434\n",
      "training loss 0.0005567830007652098\n",
      "epochs 7435\n",
      "training loss 0.0004562396327200654\n",
      "epochs 7436\n",
      "training loss 0.0005160876861872508\n",
      "epochs 7437\n",
      "training loss 0.0005324037334602892\n",
      "epochs 7438\n",
      "training loss 0.0004677987256933762\n",
      "epochs 7439\n",
      "training loss 0.0004927443931697327\n",
      "testing loss 0.002679192023483891\n",
      "epochs 7440\n",
      "training loss 0.0005044394646350883\n",
      "epochs 7441\n",
      "training loss 0.0005007519623431686\n",
      "epochs 7442\n",
      "training loss 0.0004928446826694879\n",
      "epochs 7443\n",
      "training loss 0.0004902905811085776\n",
      "epochs 7444\n",
      "training loss 0.0004871094602550802\n",
      "epochs 7445\n",
      "training loss 0.0004799644062741402\n",
      "epochs 7446\n",
      "training loss 0.0004802990982013169\n",
      "epochs 7447\n",
      "training loss 0.0004905503523453934\n",
      "epochs 7448\n",
      "training loss 0.0004959595853202385\n",
      "epochs 7449\n",
      "training loss 0.0005282844570012463\n",
      "testing loss 0.0028168306391230446\n",
      "epochs 7450\n",
      "training loss 0.0004850029522527609\n",
      "epochs 7451\n",
      "training loss 0.0005637377134834255\n",
      "epochs 7452\n",
      "training loss 0.0005176931648482611\n",
      "epochs 7453\n",
      "training loss 0.000477218008982329\n",
      "epochs 7454\n",
      "training loss 0.00045070423402096\n",
      "epochs 7455\n",
      "training loss 0.0005089978426149947\n",
      "epochs 7456\n",
      "training loss 0.001143423600672917\n",
      "epochs 7457\n",
      "training loss 0.0012125053781291363\n",
      "epochs 7458\n",
      "training loss 0.0008424267866882272\n",
      "epochs 7459\n",
      "training loss 0.00133417136411644\n",
      "testing loss 0.0027961403020849147\n",
      "epochs 7460\n",
      "training loss 0.0014354745758517636\n",
      "epochs 7461\n",
      "training loss 0.0011276221912146168\n",
      "epochs 7462\n",
      "training loss 0.0010224063627741733\n",
      "epochs 7463\n",
      "training loss 0.001055866219000721\n",
      "epochs 7464\n",
      "training loss 0.0010072599773048947\n",
      "epochs 7465\n",
      "training loss 0.0009396566367512823\n",
      "epochs 7466\n",
      "training loss 0.0017482762661618165\n",
      "epochs 7467\n",
      "training loss 0.0009037357661943871\n",
      "epochs 7468\n",
      "training loss 0.001115248081827038\n",
      "epochs 7469\n",
      "training loss 0.0010430357971130998\n",
      "testing loss 0.002603300893349005\n",
      "epochs 7470\n",
      "training loss 0.0007706346589361393\n",
      "epochs 7471\n",
      "training loss 0.0006460609360517351\n",
      "epochs 7472\n",
      "training loss 0.0006047736916699558\n",
      "epochs 7473\n",
      "training loss 0.0005266972505034578\n",
      "epochs 7474\n",
      "training loss 0.0005399705386560659\n",
      "epochs 7475\n",
      "training loss 0.0004964726513512093\n",
      "epochs 7476\n",
      "training loss 0.000557218543391839\n",
      "epochs 7477\n",
      "training loss 0.0004988985067505197\n",
      "epochs 7478\n",
      "training loss 0.0004951962857934615\n",
      "epochs 7479\n",
      "training loss 0.0004959207482488775\n",
      "testing loss 0.0025538550590739604\n",
      "epochs 7480\n",
      "training loss 0.0004700434392057699\n",
      "epochs 7481\n",
      "training loss 0.0004737355965182559\n",
      "epochs 7482\n",
      "training loss 0.0004913836447267275\n",
      "epochs 7483\n",
      "training loss 0.0004944034485326157\n",
      "epochs 7484\n",
      "training loss 0.0004901460174288556\n",
      "epochs 7485\n",
      "training loss 0.00049332315459604\n",
      "epochs 7486\n",
      "training loss 0.0004634788460406053\n",
      "epochs 7487\n",
      "training loss 0.00046515290181847475\n",
      "epochs 7488\n",
      "training loss 0.0006147110043872023\n",
      "epochs 7489\n",
      "training loss 0.0005023310115857412\n",
      "testing loss 0.0025908047657836465\n",
      "epochs 7490\n",
      "training loss 0.000525869825109344\n",
      "epochs 7491\n",
      "training loss 0.0004667667016538432\n",
      "epochs 7492\n",
      "training loss 0.0004962038098039009\n",
      "epochs 7493\n",
      "training loss 0.00048434193429004935\n",
      "epochs 7494\n",
      "training loss 0.0005270949176351305\n",
      "epochs 7495\n",
      "training loss 0.0005291247754364832\n",
      "epochs 7496\n",
      "training loss 0.0005036589437791381\n",
      "epochs 7497\n",
      "training loss 0.0004941061335314336\n",
      "epochs 7498\n",
      "training loss 0.0005331482473048905\n",
      "epochs 7499\n",
      "training loss 0.00048610742934937035\n",
      "testing loss 0.0024132438343355154\n",
      "epochs 7500\n",
      "training loss 0.0005213792704217034\n",
      "epochs 7501\n",
      "training loss 0.0005238153026078326\n",
      "epochs 7502\n",
      "training loss 0.0005705556695138623\n",
      "epochs 7503\n",
      "training loss 0.0005258705143570493\n",
      "epochs 7504\n",
      "training loss 0.0005197184757289893\n",
      "epochs 7505\n",
      "training loss 0.0005228087356622617\n",
      "epochs 7506\n",
      "training loss 0.0006816143801260321\n",
      "epochs 7507\n",
      "training loss 0.0005102398997989389\n",
      "epochs 7508\n",
      "training loss 0.0005162026199560306\n",
      "epochs 7509\n",
      "training loss 0.0004963887478387702\n",
      "testing loss 0.0025777894993649518\n",
      "epochs 7510\n",
      "training loss 0.0004912262533346933\n",
      "epochs 7511\n",
      "training loss 0.0005087485532686794\n",
      "epochs 7512\n",
      "training loss 0.0004699058778722711\n",
      "epochs 7513\n",
      "training loss 0.0005118245756788615\n",
      "epochs 7514\n",
      "training loss 0.00047099613885347104\n",
      "epochs 7515\n",
      "training loss 0.0005128252862968219\n",
      "epochs 7516\n",
      "training loss 0.000485588965044388\n",
      "epochs 7517\n",
      "training loss 0.0004926427835591511\n",
      "epochs 7518\n",
      "training loss 0.0005050237144776662\n",
      "epochs 7519\n",
      "training loss 0.0004752465745110042\n",
      "testing loss 0.0026367543643366887\n",
      "epochs 7520\n",
      "training loss 0.00046777816715446444\n",
      "epochs 7521\n",
      "training loss 0.00047989937991305825\n",
      "epochs 7522\n",
      "training loss 0.00044737303727532886\n",
      "epochs 7523\n",
      "training loss 0.000527219240971923\n",
      "epochs 7524\n",
      "training loss 0.0005790930702053803\n",
      "epochs 7525\n",
      "training loss 0.0005318069380090932\n",
      "epochs 7526\n",
      "training loss 0.001056904551140698\n",
      "epochs 7527\n",
      "training loss 0.0008343821381732515\n",
      "epochs 7528\n",
      "training loss 0.0008317130748897304\n",
      "epochs 7529\n",
      "training loss 0.001049370092596706\n",
      "testing loss 0.0025824022054976078\n",
      "epochs 7530\n",
      "training loss 0.0010181175796796305\n",
      "epochs 7531\n",
      "training loss 0.0005152338913515901\n",
      "epochs 7532\n",
      "training loss 0.0005304461446276506\n",
      "epochs 7533\n",
      "training loss 0.0008015098831528588\n",
      "epochs 7534\n",
      "training loss 0.0006269918860673712\n",
      "epochs 7535\n",
      "training loss 0.0007280412658703681\n",
      "epochs 7536\n",
      "training loss 0.0005657260735571599\n",
      "epochs 7537\n",
      "training loss 0.000582458058002017\n",
      "epochs 7538\n",
      "training loss 0.0004837864471704198\n",
      "epochs 7539\n",
      "training loss 0.0004974505285545617\n",
      "testing loss 0.0026108458413616987\n",
      "epochs 7540\n",
      "training loss 0.0004832006011287028\n",
      "epochs 7541\n",
      "training loss 0.0005362621649369416\n",
      "epochs 7542\n",
      "training loss 0.0004978057651321961\n",
      "epochs 7543\n",
      "training loss 0.0005009601963577809\n",
      "epochs 7544\n",
      "training loss 0.0004967076000283361\n",
      "epochs 7545\n",
      "training loss 0.0004846903937886466\n",
      "epochs 7546\n",
      "training loss 0.0005201915576084486\n",
      "epochs 7547\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss 0.0004866269237884125\n",
      "epochs 7548\n",
      "training loss 0.0005011124560987368\n",
      "epochs 7549\n",
      "training loss 0.0005115749027192916\n",
      "testing loss 0.002588934599461549\n",
      "epochs 7550\n",
      "training loss 0.0004905125063081133\n",
      "epochs 7551\n",
      "training loss 0.0005023460945795293\n",
      "epochs 7552\n",
      "training loss 0.0004987918749157237\n",
      "epochs 7553\n",
      "training loss 0.0005008916576332087\n",
      "epochs 7554\n",
      "training loss 0.0004868413622708323\n",
      "epochs 7555\n",
      "training loss 0.0013383699530250136\n",
      "epochs 7556\n",
      "training loss 0.0014823049088900394\n",
      "epochs 7557\n",
      "training loss 0.001083251448011303\n",
      "epochs 7558\n",
      "training loss 0.0007782232389278642\n",
      "epochs 7559\n",
      "training loss 0.0006940184019705546\n",
      "testing loss 0.0027255489134249537\n",
      "epochs 7560\n",
      "training loss 0.0009000554271601424\n",
      "epochs 7561\n",
      "training loss 0.0008537419019854347\n",
      "epochs 7562\n",
      "training loss 0.0011628023812286896\n",
      "epochs 7563\n",
      "training loss 0.0010346786790820387\n",
      "epochs 7564\n",
      "training loss 0.000913763471472496\n",
      "epochs 7565\n",
      "training loss 0.0007431404567804856\n",
      "epochs 7566\n",
      "training loss 0.0007140376192155241\n",
      "epochs 7567\n",
      "training loss 0.0006960926144518309\n",
      "epochs 7568\n",
      "training loss 0.000654735821469101\n",
      "epochs 7569\n",
      "training loss 0.0008065682920976896\n",
      "testing loss 0.0027620497461844314\n",
      "epochs 7570\n",
      "training loss 0.0007712478254246596\n",
      "epochs 7571\n",
      "training loss 0.0006652460973157821\n",
      "epochs 7572\n",
      "training loss 0.0005830415944026721\n",
      "epochs 7573\n",
      "training loss 0.0005349087380976798\n",
      "epochs 7574\n",
      "training loss 0.0005318504788433018\n",
      "epochs 7575\n",
      "training loss 0.0005388171696012109\n",
      "epochs 7576\n",
      "training loss 0.0005031016160412706\n",
      "epochs 7577\n",
      "training loss 0.0007111725012069755\n",
      "epochs 7578\n",
      "training loss 0.0010270920664738684\n",
      "epochs 7579\n",
      "training loss 0.0006741544621533751\n",
      "testing loss 0.0025969735513513923\n",
      "epochs 7580\n",
      "training loss 0.0005809045879302636\n",
      "epochs 7581\n",
      "training loss 0.0005622109413107342\n",
      "epochs 7582\n",
      "training loss 0.0005299665274786392\n",
      "epochs 7583\n",
      "training loss 0.0005008082050974495\n",
      "epochs 7584\n",
      "training loss 0.0005122603107976945\n",
      "epochs 7585\n",
      "training loss 0.0004878562527792217\n",
      "epochs 7586\n",
      "training loss 0.0004824529473434873\n",
      "epochs 7587\n",
      "training loss 0.0005074921497540113\n",
      "epochs 7588\n",
      "training loss 0.0004993588808714483\n",
      "epochs 7589\n",
      "training loss 0.0005136266383299983\n",
      "testing loss 0.0025646709490250398\n",
      "epochs 7590\n",
      "training loss 0.0004959154133132933\n",
      "epochs 7591\n",
      "training loss 0.0005828144211809669\n",
      "epochs 7592\n",
      "training loss 0.000502192337008612\n",
      "epochs 7593\n",
      "training loss 0.0005072162950681777\n",
      "epochs 7594\n",
      "training loss 0.000492488021065699\n",
      "epochs 7595\n",
      "training loss 0.000469557868067662\n",
      "epochs 7596\n",
      "training loss 0.0004982102007179105\n",
      "epochs 7597\n",
      "training loss 0.0005752010956352808\n",
      "epochs 7598\n",
      "training loss 0.0005125071052645863\n",
      "epochs 7599\n",
      "training loss 0.0004914190616114716\n",
      "testing loss 0.0025545057460025005\n",
      "epochs 7600\n",
      "training loss 0.00048708659711741136\n",
      "epochs 7601\n",
      "training loss 0.0005123503392068301\n",
      "epochs 7602\n",
      "training loss 0.0005043208758144336\n",
      "epochs 7603\n",
      "training loss 0.0005045668781971372\n",
      "epochs 7604\n",
      "training loss 0.000511409851491004\n",
      "epochs 7605\n",
      "training loss 0.0005118799844182077\n",
      "epochs 7606\n",
      "training loss 0.000500794018174332\n",
      "epochs 7607\n",
      "training loss 0.000487476895495366\n",
      "epochs 7608\n",
      "training loss 0.0005505698708527917\n",
      "epochs 7609\n",
      "training loss 0.0005177902285997561\n",
      "testing loss 0.0026176194759442452\n",
      "epochs 7610\n",
      "training loss 0.00047298635706081874\n",
      "epochs 7611\n",
      "training loss 0.0005212434577064923\n",
      "epochs 7612\n",
      "training loss 0.0004736158710559066\n",
      "epochs 7613\n",
      "training loss 0.0005038629661421759\n",
      "epochs 7614\n",
      "training loss 0.0004951236835018503\n",
      "epochs 7615\n",
      "training loss 0.00050172207837763\n",
      "epochs 7616\n",
      "training loss 0.0004872095718587774\n",
      "epochs 7617\n",
      "training loss 0.0004897477485821228\n",
      "epochs 7618\n",
      "training loss 0.0005039936787870607\n",
      "epochs 7619\n",
      "training loss 0.0004986918345235266\n",
      "testing loss 0.0026146199856389393\n",
      "epochs 7620\n",
      "training loss 0.0004908571618299161\n",
      "epochs 7621\n",
      "training loss 0.00077580410952108\n",
      "epochs 7622\n",
      "training loss 0.0005918488895101615\n",
      "epochs 7623\n",
      "training loss 0.0005009681032227472\n",
      "epochs 7624\n",
      "training loss 0.0004994174163706464\n",
      "epochs 7625\n",
      "training loss 0.0004452012510620635\n",
      "epochs 7626\n",
      "training loss 0.0005111983979204358\n",
      "epochs 7627\n",
      "training loss 0.000475306361651835\n",
      "epochs 7628\n",
      "training loss 0.0005651462574044984\n",
      "epochs 7629\n",
      "training loss 0.0005336401002703795\n",
      "testing loss 0.002602506500787716\n",
      "epochs 7630\n",
      "training loss 0.0005018099162148702\n",
      "epochs 7631\n",
      "training loss 0.0004891018507670254\n",
      "epochs 7632\n",
      "training loss 0.000537626498193398\n",
      "epochs 7633\n",
      "training loss 0.0005132448906397396\n",
      "epochs 7634\n",
      "training loss 0.0005181100495311072\n",
      "epochs 7635\n",
      "training loss 0.0004671469555833691\n",
      "epochs 7636\n",
      "training loss 0.00048442373064977874\n",
      "epochs 7637\n",
      "training loss 0.0005283106861870996\n",
      "epochs 7638\n",
      "training loss 0.0005001482126688002\n",
      "epochs 7639\n",
      "training loss 0.0004783851161066975\n",
      "testing loss 0.0025910472902733544\n",
      "epochs 7640\n",
      "training loss 0.0006623364266504938\n",
      "epochs 7641\n",
      "training loss 0.0006683069394687672\n",
      "epochs 7642\n",
      "training loss 0.0006427057951690182\n",
      "epochs 7643\n",
      "training loss 0.0005200890626752676\n",
      "epochs 7644\n",
      "training loss 0.0005231434166202135\n",
      "epochs 7645\n",
      "training loss 0.000529128706355517\n",
      "epochs 7646\n",
      "training loss 0.0004624258314604704\n",
      "epochs 7647\n",
      "training loss 0.00046951878126951267\n",
      "epochs 7648\n",
      "training loss 0.0004829523881818069\n",
      "epochs 7649\n",
      "training loss 0.0005197176809024949\n",
      "testing loss 0.0026195775106522845\n",
      "epochs 7650\n",
      "training loss 0.0004878817125270285\n",
      "epochs 7651\n",
      "training loss 0.0005260582063750486\n",
      "epochs 7652\n",
      "training loss 0.0005019291247967291\n",
      "epochs 7653\n",
      "training loss 0.00046471326293828574\n",
      "epochs 7654\n",
      "training loss 0.0004981987399125534\n",
      "epochs 7655\n",
      "training loss 0.0005037843796076384\n",
      "epochs 7656\n",
      "training loss 0.0005250871606987807\n",
      "epochs 7657\n",
      "training loss 0.00047354491901340526\n",
      "epochs 7658\n",
      "training loss 0.000473761533560036\n",
      "epochs 7659\n",
      "training loss 0.0004712635077823429\n",
      "testing loss 0.002699248336258853\n",
      "epochs 7660\n",
      "training loss 0.0005166530372938679\n",
      "epochs 7661\n",
      "training loss 0.0004897808225642845\n",
      "epochs 7662\n",
      "training loss 0.0005107598284069777\n",
      "epochs 7663\n",
      "training loss 0.0004746974181379602\n",
      "epochs 7664\n",
      "training loss 0.0005312217078362747\n",
      "epochs 7665\n",
      "training loss 0.00048458257971025756\n",
      "epochs 7666\n",
      "training loss 0.0005209133197768594\n",
      "epochs 7667\n",
      "training loss 0.0004580407502486351\n",
      "epochs 7668\n",
      "training loss 0.0004499157990462014\n",
      "epochs 7669\n",
      "training loss 0.00047894612056950507\n",
      "testing loss 0.002594004706760327\n",
      "epochs 7670\n",
      "training loss 0.0005981757651977693\n",
      "epochs 7671\n",
      "training loss 0.0005287388639965471\n",
      "epochs 7672\n",
      "training loss 0.000488615692952311\n",
      "epochs 7673\n",
      "training loss 0.0005254997941877659\n",
      "epochs 7674\n",
      "training loss 0.0005627352994509992\n",
      "epochs 7675\n",
      "training loss 0.000539769784679727\n",
      "epochs 7676\n",
      "training loss 0.000506495516768467\n",
      "epochs 7677\n",
      "training loss 0.0004427153758239709\n",
      "epochs 7678\n",
      "training loss 0.0004939979559647792\n",
      "epochs 7679\n",
      "training loss 0.0004903036305053856\n",
      "testing loss 0.0026270269758087842\n",
      "epochs 7680\n",
      "training loss 0.00049790139456908\n",
      "epochs 7681\n",
      "training loss 0.00049550141450966\n",
      "epochs 7682\n",
      "training loss 0.0005473382783399776\n",
      "epochs 7683\n",
      "training loss 0.0009535511129919303\n",
      "epochs 7684\n",
      "training loss 0.0010249452739932764\n",
      "epochs 7685\n",
      "training loss 0.00116840979616203\n",
      "epochs 7686\n",
      "training loss 0.0012307792556462214\n",
      "epochs 7687\n",
      "training loss 0.001309212623889442\n",
      "epochs 7688\n",
      "training loss 0.0017971622228260097\n",
      "epochs 7689\n",
      "training loss 0.0009301253183996787\n",
      "testing loss 0.0027223346657482975\n",
      "epochs 7690\n",
      "training loss 0.0013575024822674476\n",
      "epochs 7691\n",
      "training loss 0.0006864769230341952\n",
      "epochs 7692\n",
      "training loss 0.0006800722927923702\n",
      "epochs 7693\n",
      "training loss 0.0005656383486852435\n",
      "epochs 7694\n",
      "training loss 0.0005443436948166407\n",
      "epochs 7695\n",
      "training loss 0.0005186321126264562\n",
      "epochs 7696\n",
      "training loss 0.0005093314949427321\n",
      "epochs 7697\n",
      "training loss 0.0007845388687715376\n",
      "epochs 7698\n",
      "training loss 0.0005454734948111307\n",
      "epochs 7699\n",
      "training loss 0.00047663908867918433\n",
      "testing loss 0.0026861533819010864\n",
      "epochs 7700\n",
      "training loss 0.0006079680885586004\n",
      "epochs 7701\n",
      "training loss 0.001200917588955918\n",
      "epochs 7702\n",
      "training loss 0.0008200654709756963\n",
      "epochs 7703\n",
      "training loss 0.0005989469273587672\n",
      "epochs 7704\n",
      "training loss 0.0005578245875803544\n",
      "epochs 7705\n",
      "training loss 0.0005257406856193799\n",
      "epochs 7706\n",
      "training loss 0.000503109410117836\n",
      "epochs 7707\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss 0.0005136623688107272\n",
      "epochs 7708\n",
      "training loss 0.00045345656159418807\n",
      "epochs 7709\n",
      "training loss 0.0005195574584331414\n",
      "testing loss 0.0025993866407550237\n",
      "epochs 7710\n",
      "training loss 0.00046765713255051355\n",
      "epochs 7711\n",
      "training loss 0.0004970204235673076\n",
      "epochs 7712\n",
      "training loss 0.000634128444472124\n",
      "epochs 7713\n",
      "training loss 0.000630587364258924\n",
      "epochs 7714\n",
      "training loss 0.0005597115563664664\n",
      "epochs 7715\n",
      "training loss 0.0008339983765686944\n",
      "epochs 7716\n",
      "training loss 0.0008348143150170807\n",
      "epochs 7717\n",
      "training loss 0.0007879737476035556\n",
      "epochs 7718\n",
      "training loss 0.0006670180898715988\n",
      "epochs 7719\n",
      "training loss 0.0007907052185226481\n",
      "testing loss 0.002626070292858103\n",
      "epochs 7720\n",
      "training loss 0.0006250158514216044\n",
      "epochs 7721\n",
      "training loss 0.0006742686384264096\n",
      "epochs 7722\n",
      "training loss 0.0006629652582536421\n",
      "epochs 7723\n",
      "training loss 0.000659382653862838\n",
      "epochs 7724\n",
      "training loss 0.0006693551018034423\n",
      "epochs 7725\n",
      "training loss 0.0008406177888331386\n",
      "epochs 7726\n",
      "training loss 0.000797826699462456\n",
      "epochs 7727\n",
      "training loss 0.0006886583569461033\n",
      "epochs 7728\n",
      "training loss 0.0006855929152379067\n",
      "epochs 7729\n",
      "training loss 0.0006966120924370358\n",
      "testing loss 0.0026273178110057687\n",
      "epochs 7730\n",
      "training loss 0.0006987437226181131\n",
      "epochs 7731\n",
      "training loss 0.0006490076374932048\n",
      "epochs 7732\n",
      "training loss 0.0006518071176948473\n",
      "epochs 7733\n",
      "training loss 0.0008513074745792092\n",
      "epochs 7734\n",
      "training loss 0.0005460888261292526\n",
      "epochs 7735\n",
      "training loss 0.0007587708585887105\n",
      "epochs 7736\n",
      "training loss 0.0006652869610398963\n",
      "epochs 7737\n",
      "training loss 0.0006536421690070379\n",
      "epochs 7738\n",
      "training loss 0.0006415811834409607\n",
      "epochs 7739\n",
      "training loss 0.0006237792238270393\n",
      "testing loss 0.0024576496802673326\n",
      "epochs 7740\n",
      "training loss 0.0006712278546952985\n",
      "epochs 7741\n",
      "training loss 0.0006387844068878599\n",
      "epochs 7742\n",
      "training loss 0.00103196105008625\n",
      "epochs 7743\n",
      "training loss 0.0008348112338148963\n",
      "epochs 7744\n",
      "training loss 0.0007656845165059921\n",
      "epochs 7745\n",
      "training loss 0.0007116912017041382\n",
      "epochs 7746\n",
      "training loss 0.0007343941364093403\n",
      "epochs 7747\n",
      "training loss 0.0006575983095175295\n",
      "epochs 7748\n",
      "training loss 0.0007035271944881539\n",
      "epochs 7749\n",
      "training loss 0.0008348002273477558\n",
      "testing loss 0.00262530796239747\n",
      "epochs 7750\n",
      "training loss 0.0006814464506704508\n",
      "epochs 7751\n",
      "training loss 0.0006851500867459764\n",
      "epochs 7752\n",
      "training loss 0.0006620033924916539\n",
      "epochs 7753\n",
      "training loss 0.0006958476068185908\n",
      "epochs 7754\n",
      "training loss 0.0006682999474725383\n",
      "epochs 7755\n",
      "training loss 0.0006509288529069997\n",
      "epochs 7756\n",
      "training loss 0.0006121826253931879\n",
      "epochs 7757\n",
      "training loss 0.000627014237809162\n",
      "epochs 7758\n",
      "training loss 0.0007832171588267078\n",
      "epochs 7759\n",
      "training loss 0.0006992582236271561\n",
      "testing loss 0.0026335887683568695\n",
      "epochs 7760\n",
      "training loss 0.0006483264907817342\n",
      "epochs 7761\n",
      "training loss 0.0006671851686814851\n",
      "epochs 7762\n",
      "training loss 0.0005866540889138933\n",
      "epochs 7763\n",
      "training loss 0.0006362279909089671\n",
      "epochs 7764\n",
      "training loss 0.0009564718147166537\n",
      "epochs 7765\n",
      "training loss 0.0008482570862744321\n",
      "epochs 7766\n",
      "training loss 0.0007648234040473551\n",
      "epochs 7767\n",
      "training loss 0.000717321726671168\n",
      "epochs 7768\n",
      "training loss 0.0006132474099073593\n",
      "epochs 7769\n",
      "training loss 0.0006527234349006329\n",
      "testing loss 0.0026138457118744917\n",
      "epochs 7770\n",
      "training loss 0.0006540723474615602\n",
      "epochs 7771\n",
      "training loss 0.0006629089651647729\n",
      "epochs 7772\n",
      "training loss 0.0006142314669419941\n",
      "epochs 7773\n",
      "training loss 0.0006342633524032078\n",
      "epochs 7774\n",
      "training loss 0.0006600864696716974\n",
      "epochs 7775\n",
      "training loss 0.0005703969954302121\n",
      "epochs 7776\n",
      "training loss 0.0006387402663732056\n",
      "epochs 7777\n",
      "training loss 0.000612508543178943\n",
      "epochs 7778\n",
      "training loss 0.0005580873984424539\n",
      "epochs 7779\n",
      "training loss 0.0012424119865298159\n",
      "testing loss 0.002849122898649847\n",
      "epochs 7780\n",
      "training loss 0.0008346996251366308\n",
      "epochs 7781\n",
      "training loss 0.0007631283276077462\n",
      "epochs 7782\n",
      "training loss 0.0007630007436688661\n",
      "epochs 7783\n",
      "training loss 0.0007857441550791603\n",
      "epochs 7784\n",
      "training loss 0.0007944654488984189\n",
      "epochs 7785\n",
      "training loss 0.0007508995669956197\n",
      "epochs 7786\n",
      "training loss 0.0008307266836217392\n",
      "epochs 7787\n",
      "training loss 0.0007599426683259273\n",
      "epochs 7788\n",
      "training loss 0.0007229760496369011\n",
      "epochs 7789\n",
      "training loss 0.0006370137873428413\n",
      "testing loss 0.0026639575078416327\n",
      "epochs 7790\n",
      "training loss 0.0007160729191677877\n",
      "epochs 7791\n",
      "training loss 0.0005797889069646971\n",
      "epochs 7792\n",
      "training loss 0.0005990658581715451\n",
      "epochs 7793\n",
      "training loss 0.0006119022282098043\n",
      "epochs 7794\n",
      "training loss 0.0006519845046568662\n",
      "epochs 7795\n",
      "training loss 0.0006000793698749089\n",
      "epochs 7796\n",
      "training loss 0.0008644077982251054\n",
      "epochs 7797\n",
      "training loss 0.0006268085978393044\n",
      "epochs 7798\n",
      "training loss 0.0005224580957206097\n",
      "epochs 7799\n",
      "training loss 0.0005749312420885184\n",
      "testing loss 0.002677230369580368\n",
      "epochs 7800\n",
      "training loss 0.0004930103941301116\n",
      "epochs 7801\n",
      "training loss 0.0005220763187495975\n",
      "epochs 7802\n",
      "training loss 0.001077660469753713\n",
      "epochs 7803\n",
      "training loss 0.0008092744535650481\n",
      "epochs 7804\n",
      "training loss 0.0006763420830619462\n",
      "epochs 7805\n",
      "training loss 0.0006167345480727297\n",
      "epochs 7806\n",
      "training loss 0.0005566391772427808\n",
      "epochs 7807\n",
      "training loss 0.0006212009051368829\n",
      "epochs 7808\n",
      "training loss 0.0005745680190305761\n",
      "epochs 7809\n",
      "training loss 0.0005932688013520262\n",
      "testing loss 0.002607164409090864\n",
      "epochs 7810\n",
      "training loss 0.0005993972549966528\n",
      "epochs 7811\n",
      "training loss 0.0005456558237627918\n",
      "epochs 7812\n",
      "training loss 0.0006260272062569007\n",
      "epochs 7813\n",
      "training loss 0.0005522640027006023\n",
      "epochs 7814\n",
      "training loss 0.0005162585246989554\n",
      "epochs 7815\n",
      "training loss 0.0005672404289211637\n",
      "epochs 7816\n",
      "training loss 0.0006387273963763008\n",
      "epochs 7817\n",
      "training loss 0.0006676867202994355\n",
      "epochs 7818\n",
      "training loss 0.0005274602813284567\n",
      "epochs 7819\n",
      "training loss 0.0005720499855194433\n",
      "testing loss 0.00282299056102634\n",
      "epochs 7820\n",
      "training loss 0.0007220635088521557\n",
      "epochs 7821\n",
      "training loss 0.0006757736088223982\n",
      "epochs 7822\n",
      "training loss 0.0007911604134886777\n",
      "epochs 7823\n",
      "training loss 0.0007256885079700941\n",
      "epochs 7824\n",
      "training loss 0.0006015655632579479\n",
      "epochs 7825\n",
      "training loss 0.0006013567261128915\n",
      "epochs 7826\n",
      "training loss 0.0005202407593588348\n",
      "epochs 7827\n",
      "training loss 0.0005468798489564617\n",
      "epochs 7828\n",
      "training loss 0.00051120506623607\n",
      "epochs 7829\n",
      "training loss 0.0005253107642781804\n",
      "testing loss 0.0026411538297997405\n",
      "epochs 7830\n",
      "training loss 0.0006561080672520589\n",
      "epochs 7831\n",
      "training loss 0.0004452860598893989\n",
      "epochs 7832\n",
      "training loss 0.0008577394082832312\n",
      "epochs 7833\n",
      "training loss 0.0010536323559093982\n",
      "epochs 7834\n",
      "training loss 0.0006458244446062095\n",
      "epochs 7835\n",
      "training loss 0.0005391086720632202\n",
      "epochs 7836\n",
      "training loss 0.0005365959534953747\n",
      "epochs 7837\n",
      "training loss 0.000581761530623842\n",
      "epochs 7838\n",
      "training loss 0.0005308675098850032\n",
      "epochs 7839\n",
      "training loss 0.0005999077529020856\n",
      "testing loss 0.002616736144554002\n",
      "epochs 7840\n",
      "training loss 0.0006621501745201795\n",
      "epochs 7841\n",
      "training loss 0.0005891368548190476\n",
      "epochs 7842\n",
      "training loss 0.00048700079999830135\n",
      "epochs 7843\n",
      "training loss 0.0005516752819258204\n",
      "epochs 7844\n",
      "training loss 0.0005801516803728818\n",
      "epochs 7845\n",
      "training loss 0.0005143508219547955\n",
      "epochs 7846\n",
      "training loss 0.001076583640322961\n",
      "epochs 7847\n",
      "training loss 0.001987548868506609\n",
      "epochs 7848\n",
      "training loss 0.001295476880647797\n",
      "epochs 7849\n",
      "training loss 0.0037294808992094112\n",
      "testing loss 0.0028926178293652727\n",
      "epochs 7850\n",
      "training loss 0.0015501130565485739\n",
      "epochs 7851\n",
      "training loss 0.001233437380401027\n",
      "epochs 7852\n",
      "training loss 0.001002749351899233\n",
      "epochs 7853\n",
      "training loss 0.0009663582721613291\n",
      "epochs 7854\n",
      "training loss 0.0010372562147995406\n",
      "epochs 7855\n",
      "training loss 0.0012733757342487902\n",
      "epochs 7856\n",
      "training loss 0.0010222143239354414\n",
      "epochs 7857\n",
      "training loss 0.0010685449851624452\n",
      "epochs 7858\n",
      "training loss 0.0009445973533442057\n",
      "epochs 7859\n",
      "training loss 0.0009695276384288587\n",
      "testing loss 0.0027585882315385745\n",
      "epochs 7860\n",
      "training loss 0.0007903416896533323\n",
      "epochs 7861\n",
      "training loss 0.0011461923054757735\n",
      "epochs 7862\n",
      "training loss 0.0013077976304180015\n",
      "epochs 7863\n",
      "training loss 0.0013977850710910867\n",
      "epochs 7864\n",
      "training loss 0.0012038527882805145\n",
      "epochs 7865\n",
      "training loss 0.0011127308565000848\n",
      "epochs 7866\n",
      "training loss 0.001079340755166684\n",
      "epochs 7867\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss 0.0008374403789391781\n",
      "epochs 7868\n",
      "training loss 0.0006606914435646363\n",
      "epochs 7869\n",
      "training loss 0.0006773931765681172\n",
      "testing loss 0.0027702415101098043\n",
      "epochs 7870\n",
      "training loss 0.0007835699651902683\n",
      "epochs 7871\n",
      "training loss 0.0005612835741147546\n",
      "epochs 7872\n",
      "training loss 0.0007347715026019623\n",
      "epochs 7873\n",
      "training loss 0.0005939131018622159\n",
      "epochs 7874\n",
      "training loss 0.0006109198921934721\n",
      "epochs 7875\n",
      "training loss 0.0006021582161459936\n",
      "epochs 7876\n",
      "training loss 0.0006996391239005642\n",
      "epochs 7877\n",
      "training loss 0.0007650058530412592\n",
      "epochs 7878\n",
      "training loss 0.001535913240964918\n",
      "epochs 7879\n",
      "training loss 0.001041159163636798\n",
      "testing loss 0.00275493040185501\n",
      "epochs 7880\n",
      "training loss 0.0010192591267408615\n",
      "epochs 7881\n",
      "training loss 0.0008630795270030451\n",
      "epochs 7882\n",
      "training loss 0.0008885115737132276\n",
      "epochs 7883\n",
      "training loss 0.0006853555245813277\n",
      "epochs 7884\n",
      "training loss 0.0006983045329011433\n",
      "epochs 7885\n",
      "training loss 0.0007144044874176542\n",
      "epochs 7886\n",
      "training loss 0.0006065518157570807\n",
      "epochs 7887\n",
      "training loss 0.0006121068132763848\n",
      "epochs 7888\n",
      "training loss 0.0005679106977442704\n",
      "epochs 7889\n",
      "training loss 0.0006268084109201744\n",
      "testing loss 0.002695483628847035\n",
      "epochs 7890\n",
      "training loss 0.0006257000852179485\n",
      "epochs 7891\n",
      "training loss 0.0009297327935344634\n",
      "epochs 7892\n",
      "training loss 0.0008208269399688451\n",
      "epochs 7893\n",
      "training loss 0.0008047166819001992\n",
      "epochs 7894\n",
      "training loss 0.0008465984722459264\n",
      "epochs 7895\n",
      "training loss 0.0007875673975342584\n",
      "epochs 7896\n",
      "training loss 0.0006992232835056163\n",
      "epochs 7897\n",
      "training loss 0.0005979794143921325\n",
      "epochs 7898\n",
      "training loss 0.0006928721929002994\n",
      "epochs 7899\n",
      "training loss 0.0006163408008466353\n",
      "testing loss 0.0026695787042201042\n",
      "epochs 7900\n",
      "training loss 0.0006769191207276448\n",
      "epochs 7901\n",
      "training loss 0.0006625857973813807\n",
      "epochs 7902\n",
      "training loss 0.000653055067210229\n",
      "epochs 7903\n",
      "training loss 0.0007028201410771945\n",
      "epochs 7904\n",
      "training loss 0.0007981058255426789\n",
      "epochs 7905\n",
      "training loss 0.0005791642244708495\n",
      "epochs 7906\n",
      "training loss 0.0016618310202282534\n",
      "epochs 7907\n",
      "training loss 0.0007253555484727524\n",
      "epochs 7908\n",
      "training loss 0.0006645743089896488\n",
      "epochs 7909\n",
      "training loss 0.0006812244785863249\n",
      "testing loss 0.002649858366476755\n",
      "epochs 7910\n",
      "training loss 0.0011358928079731015\n",
      "epochs 7911\n",
      "training loss 0.0009917620994790391\n",
      "epochs 7912\n",
      "training loss 0.000794114316137802\n",
      "epochs 7913\n",
      "training loss 0.0007725766212233599\n",
      "epochs 7914\n",
      "training loss 0.0005765236031489113\n",
      "epochs 7915\n",
      "training loss 0.0015502595647887856\n",
      "epochs 7916\n",
      "training loss 0.0015844910980222073\n",
      "epochs 7917\n",
      "training loss 0.0010007120974787928\n",
      "epochs 7918\n",
      "training loss 0.0006611071411827381\n",
      "epochs 7919\n",
      "training loss 0.0008159912813038744\n",
      "testing loss 0.0027030993055664533\n",
      "epochs 7920\n",
      "training loss 0.0009242360623260411\n",
      "epochs 7921\n",
      "training loss 0.0007146966752792938\n",
      "epochs 7922\n",
      "training loss 0.0007237315390755827\n",
      "epochs 7923\n",
      "training loss 0.0006801676312794111\n",
      "epochs 7924\n",
      "training loss 0.0006618166509039111\n",
      "epochs 7925\n",
      "training loss 0.0006531239308538566\n",
      "epochs 7926\n",
      "training loss 0.0007679598995287674\n",
      "epochs 7927\n",
      "training loss 0.0006796375749806809\n",
      "epochs 7928\n",
      "training loss 0.0006497145752849958\n",
      "epochs 7929\n",
      "training loss 0.0007193616845632272\n",
      "testing loss 0.0027231723928810856\n",
      "epochs 7930\n",
      "training loss 0.0009846333781431363\n",
      "epochs 7931\n",
      "training loss 0.0012224380785527166\n",
      "epochs 7932\n",
      "training loss 0.0009477989116328341\n",
      "epochs 7933\n",
      "training loss 0.0009087278510480667\n",
      "epochs 7934\n",
      "training loss 0.0007290520495098187\n",
      "epochs 7935\n",
      "training loss 0.0006464198053889486\n",
      "epochs 7936\n",
      "training loss 0.0009682829639347876\n",
      "epochs 7937\n",
      "training loss 0.0012181365824804151\n",
      "epochs 7938\n",
      "training loss 0.0009755273791890603\n",
      "epochs 7939\n",
      "training loss 0.0010388254350416452\n",
      "testing loss 0.0027031523199481165\n",
      "epochs 7940\n",
      "training loss 0.0008035042387041289\n",
      "epochs 7941\n",
      "training loss 0.0010229993677389523\n",
      "epochs 7942\n",
      "training loss 0.000923445312756377\n",
      "epochs 7943\n",
      "training loss 0.0008085941225127529\n",
      "epochs 7944\n",
      "training loss 0.0009653040115568662\n",
      "epochs 7945\n",
      "training loss 0.0011907850975477869\n",
      "epochs 7946\n",
      "training loss 0.0013121689918718519\n",
      "epochs 7947\n",
      "training loss 0.001717386907568105\n",
      "epochs 7948\n",
      "training loss 0.0015629729269126197\n",
      "epochs 7949\n",
      "training loss 0.0012763556431608111\n",
      "testing loss 0.00279598588954512\n",
      "epochs 7950\n",
      "training loss 0.0011068104722432362\n",
      "epochs 7951\n",
      "training loss 0.0010484622906940199\n",
      "epochs 7952\n",
      "training loss 0.0010028921539568282\n",
      "epochs 7953\n",
      "training loss 0.0011632064392607614\n",
      "epochs 7954\n",
      "training loss 0.0012347582965809003\n",
      "epochs 7955\n",
      "training loss 0.0010668862551609253\n",
      "epochs 7956\n",
      "training loss 0.0016309273918230075\n",
      "epochs 7957\n",
      "training loss 0.001712592329977131\n",
      "epochs 7958\n",
      "training loss 0.0015481981058890922\n",
      "epochs 7959\n",
      "training loss 0.0014225752743974463\n",
      "testing loss 0.0028162408819924116\n",
      "epochs 7960\n",
      "training loss 0.0014787884360097214\n",
      "epochs 7961\n",
      "training loss 0.0016603749516981973\n",
      "epochs 7962\n",
      "training loss 0.0015412245558271904\n",
      "epochs 7963\n",
      "training loss 0.001444523691059597\n",
      "epochs 7964\n",
      "training loss 0.001372286776543558\n",
      "epochs 7965\n",
      "training loss 0.0013467795257123985\n",
      "epochs 7966\n",
      "training loss 0.0012977084983211\n",
      "epochs 7967\n",
      "training loss 0.0013065479896073782\n",
      "epochs 7968\n",
      "training loss 0.0012341031768765458\n",
      "epochs 7969\n",
      "training loss 0.0012351263430900872\n",
      "testing loss 0.0024948160817139906\n",
      "epochs 7970\n",
      "training loss 0.0012343011973928208\n",
      "epochs 7971\n",
      "training loss 0.001336918413015592\n",
      "epochs 7972\n",
      "training loss 0.0011534770879198127\n",
      "epochs 7973\n",
      "training loss 0.0011054155158302195\n",
      "epochs 7974\n",
      "training loss 0.00103203595529585\n",
      "epochs 7975\n",
      "training loss 0.0010475904814719213\n",
      "epochs 7976\n",
      "training loss 0.0010074135595451372\n",
      "epochs 7977\n",
      "training loss 0.001139778774592595\n",
      "epochs 7978\n",
      "training loss 0.0009722313940975147\n",
      "epochs 7979\n",
      "training loss 0.0014110516275896332\n",
      "testing loss 0.0027147592264161516\n",
      "epochs 7980\n",
      "training loss 0.0011757537904818257\n",
      "epochs 7981\n",
      "training loss 0.0008487967550641316\n",
      "epochs 7982\n",
      "training loss 0.0008617276035668187\n",
      "epochs 7983\n",
      "training loss 0.0008944721726522326\n",
      "epochs 7984\n",
      "training loss 0.0009046635267786161\n",
      "epochs 7985\n",
      "training loss 0.0007242261983049428\n",
      "epochs 7986\n",
      "training loss 0.0007853279456228731\n",
      "epochs 7987\n",
      "training loss 0.0010386723194357665\n",
      "epochs 7988\n",
      "training loss 0.0007579695815708783\n",
      "epochs 7989\n",
      "training loss 0.0008597663503053872\n",
      "testing loss 0.0027448327259114343\n",
      "epochs 7990\n",
      "training loss 0.0008250666346321714\n",
      "epochs 7991\n",
      "training loss 0.0007259869310399093\n",
      "epochs 7992\n",
      "training loss 0.0007345680101232541\n",
      "epochs 7993\n",
      "training loss 0.0007156734728101516\n",
      "epochs 7994\n",
      "training loss 0.0007603038873772581\n",
      "epochs 7995\n",
      "training loss 0.0008840966865520834\n",
      "epochs 7996\n",
      "training loss 0.0008343456847852204\n",
      "epochs 7997\n",
      "training loss 0.0007110586945260493\n",
      "epochs 7998\n",
      "training loss 0.0006223157028586952\n",
      "epochs 7999\n",
      "training loss 0.0005981581847149438\n",
      "testing loss 0.0025749354522529963\n",
      "epochs 8000\n",
      "training loss 0.0006144399855372222\n",
      "epochs 8001\n",
      "training loss 0.0007441704105557506\n",
      "epochs 8002\n",
      "training loss 0.0008317793241424605\n",
      "epochs 8003\n",
      "training loss 0.0007800973566478305\n",
      "epochs 8004\n",
      "training loss 0.000812100759802222\n",
      "epochs 8005\n",
      "training loss 0.0007071515578333583\n",
      "epochs 8006\n",
      "training loss 0.0006884500649892145\n",
      "epochs 8007\n",
      "training loss 0.0006556148428680788\n",
      "epochs 8008\n",
      "training loss 0.0006610964278769779\n",
      "epochs 8009\n",
      "training loss 0.0007127978324842014\n",
      "testing loss 0.00287980874356358\n",
      "epochs 8010\n",
      "training loss 0.0010364860654341504\n",
      "epochs 8011\n",
      "training loss 0.0006774202100458444\n",
      "epochs 8012\n",
      "training loss 0.0006105043622983569\n",
      "epochs 8013\n",
      "training loss 0.0006367287990080878\n",
      "epochs 8014\n",
      "training loss 0.0006510423492650164\n",
      "epochs 8015\n",
      "training loss 0.0006381135432496893\n",
      "epochs 8016\n",
      "training loss 0.000589521569507706\n",
      "epochs 8017\n",
      "training loss 0.0005637801443913096\n",
      "epochs 8018\n",
      "training loss 0.0006404705418169069\n",
      "epochs 8019\n",
      "training loss 0.0006018742776722123\n",
      "testing loss 0.002543771379389503\n",
      "epochs 8020\n",
      "training loss 0.0006560657599248773\n",
      "epochs 8021\n",
      "training loss 0.0006607629025799412\n",
      "epochs 8022\n",
      "training loss 0.0006352146808978023\n",
      "epochs 8023\n",
      "training loss 0.0006506589460179583\n",
      "epochs 8024\n",
      "training loss 0.0005757092882342648\n",
      "epochs 8025\n",
      "training loss 0.0005732861118027402\n",
      "epochs 8026\n",
      "training loss 0.0006306238773584615\n",
      "epochs 8027\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss 0.0006424559593960745\n",
      "epochs 8028\n",
      "training loss 0.0005945770037579874\n",
      "epochs 8029\n",
      "training loss 0.0006255875613170996\n",
      "testing loss 0.002621981152250755\n",
      "epochs 8030\n",
      "training loss 0.0005917642076250653\n",
      "epochs 8031\n",
      "training loss 0.0007642908238538323\n",
      "epochs 8032\n",
      "training loss 0.000572624986093933\n",
      "epochs 8033\n",
      "training loss 0.0005994077353833079\n",
      "epochs 8034\n",
      "training loss 0.0006667114184754632\n",
      "epochs 8035\n",
      "training loss 0.0006812391131245857\n",
      "epochs 8036\n",
      "training loss 0.0005797788766701069\n",
      "epochs 8037\n",
      "training loss 0.0006221505760400638\n",
      "epochs 8038\n",
      "training loss 0.0005837739935345767\n",
      "epochs 8039\n",
      "training loss 0.0006776818441047325\n",
      "testing loss 0.0028110295344236577\n",
      "epochs 8040\n",
      "training loss 0.0007164691732156071\n",
      "epochs 8041\n",
      "training loss 0.000629598302869296\n",
      "epochs 8042\n",
      "training loss 0.0007389874712742389\n",
      "epochs 8043\n",
      "training loss 0.0006589824676132934\n",
      "epochs 8044\n",
      "training loss 0.0006356227633969343\n",
      "epochs 8045\n",
      "training loss 0.0006611913268873326\n",
      "epochs 8046\n",
      "training loss 0.0006441363519359109\n",
      "epochs 8047\n",
      "training loss 0.0006604984432379616\n",
      "epochs 8048\n",
      "training loss 0.0005932012272115491\n",
      "epochs 8049\n",
      "training loss 0.0006276966861872382\n",
      "testing loss 0.0026129180002389544\n",
      "epochs 8050\n",
      "training loss 0.0005768627712275199\n",
      "epochs 8051\n",
      "training loss 0.000557072362636066\n",
      "epochs 8052\n",
      "training loss 0.0005209610252011296\n",
      "epochs 8053\n",
      "training loss 0.0006208155218562774\n",
      "epochs 8054\n",
      "training loss 0.000573574536070256\n",
      "epochs 8055\n",
      "training loss 0.0005465155515337142\n",
      "epochs 8056\n",
      "training loss 0.0008092279872208789\n",
      "epochs 8057\n",
      "training loss 0.0007004234759352173\n",
      "epochs 8058\n",
      "training loss 0.0007139544203873203\n",
      "epochs 8059\n",
      "training loss 0.0005815929357609273\n",
      "testing loss 0.002822025873903053\n",
      "epochs 8060\n",
      "training loss 0.0007230793028619809\n",
      "epochs 8061\n",
      "training loss 0.0007638271342846919\n",
      "epochs 8062\n",
      "training loss 0.0008033111582313435\n",
      "epochs 8063\n",
      "training loss 0.0005834004433052812\n",
      "epochs 8064\n",
      "training loss 0.0005267704722908889\n",
      "epochs 8065\n",
      "training loss 0.0006023629500048014\n",
      "epochs 8066\n",
      "training loss 0.0005867283767065186\n",
      "epochs 8067\n",
      "training loss 0.0005310171233004633\n",
      "epochs 8068\n",
      "training loss 0.0005514623448118216\n",
      "epochs 8069\n",
      "training loss 0.0005157135023082972\n",
      "testing loss 0.0026190133483796414\n",
      "epochs 8070\n",
      "training loss 0.000550649667319369\n",
      "epochs 8071\n",
      "training loss 0.0005522556500339535\n",
      "epochs 8072\n",
      "training loss 0.0004982757550171693\n",
      "epochs 8073\n",
      "training loss 0.0005752312584382434\n",
      "epochs 8074\n",
      "training loss 0.0005774323246087935\n",
      "epochs 8075\n",
      "training loss 0.0005011229585123031\n",
      "epochs 8076\n",
      "training loss 0.0006276915832861443\n",
      "epochs 8077\n",
      "training loss 0.0006043458285622616\n",
      "epochs 8078\n",
      "training loss 0.0005398408840106104\n",
      "epochs 8079\n",
      "training loss 0.0005684914075349115\n",
      "testing loss 0.0025939067787695545\n",
      "epochs 8080\n",
      "training loss 0.0006366115430367143\n",
      "epochs 8081\n",
      "training loss 0.0005750683550107206\n",
      "epochs 8082\n",
      "training loss 0.0005604352257646179\n",
      "epochs 8083\n",
      "training loss 0.0005533468688761754\n",
      "epochs 8084\n",
      "training loss 0.0006563604739813083\n",
      "epochs 8085\n",
      "training loss 0.000618237575412074\n",
      "epochs 8086\n",
      "training loss 0.0006585478847053774\n",
      "epochs 8087\n",
      "training loss 0.0005796943875425991\n",
      "epochs 8088\n",
      "training loss 0.0004758685645909193\n",
      "epochs 8089\n",
      "training loss 0.0005739692659265897\n",
      "testing loss 0.002643370403947824\n",
      "epochs 8090\n",
      "training loss 0.0005345794110060712\n",
      "epochs 8091\n",
      "training loss 0.0004817946626639169\n",
      "epochs 8092\n",
      "training loss 0.0005226116139147328\n",
      "epochs 8093\n",
      "training loss 0.000521528528841201\n",
      "epochs 8094\n",
      "training loss 0.0005822622000153451\n",
      "epochs 8095\n",
      "training loss 0.0005359230962890487\n",
      "epochs 8096\n",
      "training loss 0.000487072485386561\n",
      "epochs 8097\n",
      "training loss 0.0005615574717670283\n",
      "epochs 8098\n",
      "training loss 0.0004960354134485714\n",
      "epochs 8099\n",
      "training loss 0.0005616849846713312\n",
      "testing loss 0.0025184391927575126\n",
      "epochs 8100\n",
      "training loss 0.0004919843637988844\n",
      "epochs 8101\n",
      "training loss 0.0005064458675798606\n",
      "epochs 8102\n",
      "training loss 0.0005627507646426581\n",
      "epochs 8103\n",
      "training loss 0.0005607453897973313\n",
      "epochs 8104\n",
      "training loss 0.0005795773038942096\n",
      "epochs 8105\n",
      "training loss 0.0004958457978354558\n",
      "epochs 8106\n",
      "training loss 0.0004820717370567849\n",
      "epochs 8107\n",
      "training loss 0.0004964138382598532\n",
      "epochs 8108\n",
      "training loss 0.0004719859291657828\n",
      "epochs 8109\n",
      "training loss 0.0005086136154376118\n",
      "testing loss 0.002614994880129048\n",
      "epochs 8110\n",
      "training loss 0.0008976207275579098\n",
      "epochs 8111\n",
      "training loss 0.0005287559831084678\n",
      "epochs 8112\n",
      "training loss 0.000506161158606495\n",
      "epochs 8113\n",
      "training loss 0.0005030247371673505\n",
      "epochs 8114\n",
      "training loss 0.0005049446862549053\n",
      "epochs 8115\n",
      "training loss 0.0005534122153793923\n",
      "epochs 8116\n",
      "training loss 0.0006511784458531514\n",
      "epochs 8117\n",
      "training loss 0.000488375367983853\n",
      "epochs 8118\n",
      "training loss 0.0004717097033839956\n",
      "epochs 8119\n",
      "training loss 0.0004753558120674717\n",
      "testing loss 0.002626831487650118\n",
      "epochs 8120\n",
      "training loss 0.0004836210535519323\n",
      "epochs 8121\n",
      "training loss 0.0005109560037492477\n",
      "epochs 8122\n",
      "training loss 0.00045802486769566284\n",
      "epochs 8123\n",
      "training loss 0.0004977102876721533\n",
      "epochs 8124\n",
      "training loss 0.0005401951369849291\n",
      "epochs 8125\n",
      "training loss 0.0005102726986658643\n",
      "epochs 8126\n",
      "training loss 0.0005175229795362042\n",
      "epochs 8127\n",
      "training loss 0.0004712318070763637\n",
      "epochs 8128\n",
      "training loss 0.0004809450171144798\n",
      "epochs 8129\n",
      "training loss 0.0004257140485647681\n",
      "testing loss 0.0025977747831064284\n",
      "epochs 8130\n",
      "training loss 0.0005561453862629525\n",
      "epochs 8131\n",
      "training loss 0.00047946297107151167\n",
      "epochs 8132\n",
      "training loss 0.0005459060223163091\n",
      "epochs 8133\n",
      "training loss 0.00044863367650309707\n",
      "epochs 8134\n",
      "training loss 0.0005051381466255628\n",
      "epochs 8135\n",
      "training loss 0.0005618178925765706\n",
      "epochs 8136\n",
      "training loss 0.000495423980451424\n",
      "epochs 8137\n",
      "training loss 0.0005095604218692606\n",
      "epochs 8138\n",
      "training loss 0.0006368709486621887\n",
      "epochs 8139\n",
      "training loss 0.0005200384983525394\n",
      "testing loss 0.0026353582494614766\n",
      "epochs 8140\n",
      "training loss 0.0009301419128022669\n",
      "epochs 8141\n",
      "training loss 0.0007835672213802097\n",
      "epochs 8142\n",
      "training loss 0.000802143740872527\n",
      "epochs 8143\n",
      "training loss 0.000736558302638254\n",
      "epochs 8144\n",
      "training loss 0.0005268338825489963\n",
      "epochs 8145\n",
      "training loss 0.0005422118450741434\n",
      "epochs 8146\n",
      "training loss 0.000449354347410558\n",
      "epochs 8147\n",
      "training loss 0.0004913709943797043\n",
      "epochs 8148\n",
      "training loss 0.0005528194645644763\n",
      "epochs 8149\n",
      "training loss 0.00047712685339687826\n",
      "testing loss 0.002615156465008564\n",
      "epochs 8150\n",
      "training loss 0.0005062960919260265\n",
      "epochs 8151\n",
      "training loss 0.00048109512414505823\n",
      "epochs 8152\n",
      "training loss 0.0005783066285333928\n",
      "epochs 8153\n",
      "training loss 0.000522522759654964\n",
      "epochs 8154\n",
      "training loss 0.0004755236755307809\n",
      "epochs 8155\n",
      "training loss 0.0004921315032118326\n",
      "epochs 8156\n",
      "training loss 0.0005080660521675546\n",
      "epochs 8157\n",
      "training loss 0.0004967885225654599\n",
      "epochs 8158\n",
      "training loss 0.0004690487852806967\n",
      "epochs 8159\n",
      "training loss 0.0004732666725057848\n",
      "testing loss 0.0025694201682225294\n",
      "epochs 8160\n",
      "training loss 0.0004729135186212579\n",
      "epochs 8161\n",
      "training loss 0.0004908242707861174\n",
      "epochs 8162\n",
      "training loss 0.0005182933775668448\n",
      "epochs 8163\n",
      "training loss 0.0005432559214610222\n",
      "epochs 8164\n",
      "training loss 0.0005067765365438224\n",
      "epochs 8165\n",
      "training loss 0.00048789447858168156\n",
      "epochs 8166\n",
      "training loss 0.0004715376441921801\n",
      "epochs 8167\n",
      "training loss 0.00047323566383404775\n",
      "epochs 8168\n",
      "training loss 0.0006037489830860924\n",
      "epochs 8169\n",
      "training loss 0.000733172813183444\n",
      "testing loss 0.002551995318528291\n",
      "epochs 8170\n",
      "training loss 0.0005035640613995436\n",
      "epochs 8171\n",
      "training loss 0.0004703559322526118\n",
      "epochs 8172\n",
      "training loss 0.0005426018300330363\n",
      "epochs 8173\n",
      "training loss 0.00047453070529326116\n",
      "epochs 8174\n",
      "training loss 0.00047847852056016605\n",
      "epochs 8175\n",
      "training loss 0.000443951951978179\n",
      "epochs 8176\n",
      "training loss 0.0005031704341272305\n",
      "epochs 8177\n",
      "training loss 0.00048322765362565054\n",
      "epochs 8178\n",
      "training loss 0.0004558805048983759\n",
      "epochs 8179\n",
      "training loss 0.0005138991369637958\n",
      "testing loss 0.0025713541264256053\n",
      "epochs 8180\n",
      "training loss 0.0006223348114695428\n",
      "epochs 8181\n",
      "training loss 0.0005320998299357376\n",
      "epochs 8182\n",
      "training loss 0.0005332491518773908\n",
      "epochs 8183\n",
      "training loss 0.0006247774277117363\n",
      "epochs 8184\n",
      "training loss 0.0005558253792086248\n",
      "epochs 8185\n",
      "training loss 0.000536128925301112\n",
      "epochs 8186\n",
      "training loss 0.00045005883649982354\n",
      "epochs 8187\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss 0.0004610431714600524\n",
      "epochs 8188\n",
      "training loss 0.0004930922132244442\n",
      "epochs 8189\n",
      "training loss 0.0005967376188772778\n",
      "testing loss 0.002531507998252459\n",
      "epochs 8190\n",
      "training loss 0.0005208300966217457\n",
      "epochs 8191\n",
      "training loss 0.0004663308853273617\n",
      "epochs 8192\n",
      "training loss 0.0005042120613692764\n",
      "epochs 8193\n",
      "training loss 0.00044832351910499546\n",
      "epochs 8194\n",
      "training loss 0.0004432677867394903\n",
      "epochs 8195\n",
      "training loss 0.0004990070687265824\n",
      "epochs 8196\n",
      "training loss 0.00047385844997891813\n",
      "epochs 8197\n",
      "training loss 0.000529329496114529\n",
      "epochs 8198\n",
      "training loss 0.00048332001803737235\n",
      "epochs 8199\n",
      "training loss 0.0005297946558251841\n",
      "testing loss 0.002620354957353482\n",
      "epochs 8200\n",
      "training loss 0.000508669891674567\n",
      "epochs 8201\n",
      "training loss 0.0005041903812271234\n",
      "epochs 8202\n",
      "training loss 0.0004739528856279844\n",
      "epochs 8203\n",
      "training loss 0.0004696456478299335\n",
      "epochs 8204\n",
      "training loss 0.00046026415931482695\n",
      "epochs 8205\n",
      "training loss 0.0005426516680869254\n",
      "epochs 8206\n",
      "training loss 0.0004541145304220058\n",
      "epochs 8207\n",
      "training loss 0.00048159732542419665\n",
      "epochs 8208\n",
      "training loss 0.0004800943349732941\n",
      "epochs 8209\n",
      "training loss 0.000475812573951887\n",
      "testing loss 0.0025855953324625783\n",
      "epochs 8210\n",
      "training loss 0.0004867287104988986\n",
      "epochs 8211\n",
      "training loss 0.0004954405453963358\n",
      "epochs 8212\n",
      "training loss 0.0004935696077342697\n",
      "epochs 8213\n",
      "training loss 0.0004434149947100939\n",
      "epochs 8214\n",
      "training loss 0.000499116074513944\n",
      "epochs 8215\n",
      "training loss 0.0005017123011713649\n",
      "epochs 8216\n",
      "training loss 0.00045209734388881883\n",
      "epochs 8217\n",
      "training loss 0.0005086566110836529\n",
      "epochs 8218\n",
      "training loss 0.00048525285437182273\n",
      "epochs 8219\n",
      "training loss 0.00047395760248313267\n",
      "testing loss 0.00260866257974693\n",
      "epochs 8220\n",
      "training loss 0.00044238621534958004\n",
      "epochs 8221\n",
      "training loss 0.0005105326086102976\n",
      "epochs 8222\n",
      "training loss 0.0004452285708896363\n",
      "epochs 8223\n",
      "training loss 0.0004771830149435107\n",
      "epochs 8224\n",
      "training loss 0.0005077827167357558\n",
      "epochs 8225\n",
      "training loss 0.0004456902688810047\n",
      "epochs 8226\n",
      "training loss 0.0005040268281826432\n",
      "epochs 8227\n",
      "training loss 0.0004537836115101018\n",
      "epochs 8228\n",
      "training loss 0.0005405195553484161\n",
      "epochs 8229\n",
      "training loss 0.0005693282498758694\n",
      "testing loss 0.002622703397861213\n",
      "epochs 8230\n",
      "training loss 0.0004306622466998101\n",
      "epochs 8231\n",
      "training loss 0.0004570164005530398\n",
      "epochs 8232\n",
      "training loss 0.0004810834891590259\n",
      "epochs 8233\n",
      "training loss 0.0004499882131802218\n",
      "epochs 8234\n",
      "training loss 0.0004941763750954721\n",
      "epochs 8235\n",
      "training loss 0.0004431232857789652\n",
      "epochs 8236\n",
      "training loss 0.0004644785163514344\n",
      "epochs 8237\n",
      "training loss 0.0012485408129511645\n",
      "epochs 8238\n",
      "training loss 0.00047570745312781453\n",
      "epochs 8239\n",
      "training loss 0.00046397752810048795\n",
      "testing loss 0.0026008596297862102\n",
      "epochs 8240\n",
      "training loss 0.0004591152280191169\n",
      "epochs 8241\n",
      "training loss 0.0005145189635410316\n",
      "epochs 8242\n",
      "training loss 0.00043573309890331425\n",
      "epochs 8243\n",
      "training loss 0.00042498964290162914\n",
      "epochs 8244\n",
      "training loss 0.0005656377801432425\n",
      "epochs 8245\n",
      "training loss 0.0004402756571379068\n",
      "epochs 8246\n",
      "training loss 0.0005133102030852826\n",
      "epochs 8247\n",
      "training loss 0.0004324689851599635\n",
      "epochs 8248\n",
      "training loss 0.0004692480818539756\n",
      "epochs 8249\n",
      "training loss 0.0004973757317987494\n",
      "testing loss 0.002623095101980717\n",
      "epochs 8250\n",
      "training loss 0.0004741829807769598\n",
      "epochs 8251\n",
      "training loss 0.0005195071435275864\n",
      "epochs 8252\n",
      "training loss 0.00045204900021489293\n",
      "epochs 8253\n",
      "training loss 0.0006358296216584425\n",
      "epochs 8254\n",
      "training loss 0.0005419548226896911\n",
      "epochs 8255\n",
      "training loss 0.0004674335601980201\n",
      "epochs 8256\n",
      "training loss 0.0004975830554561605\n",
      "epochs 8257\n",
      "training loss 0.00042180983738203767\n",
      "epochs 8258\n",
      "training loss 0.0004492953185616259\n",
      "epochs 8259\n",
      "training loss 0.00042723644083212937\n",
      "testing loss 0.0025125558868691273\n",
      "epochs 8260\n",
      "training loss 0.0004670305345115453\n",
      "epochs 8261\n",
      "training loss 0.000468145248946864\n",
      "epochs 8262\n",
      "training loss 0.0004695592084804006\n",
      "epochs 8263\n",
      "training loss 0.000478920917448483\n",
      "epochs 8264\n",
      "training loss 0.000453061600587979\n",
      "epochs 8265\n",
      "training loss 0.00044211609845295954\n",
      "epochs 8266\n",
      "training loss 0.0004636520326741204\n",
      "epochs 8267\n",
      "training loss 0.0004957464058659857\n",
      "epochs 8268\n",
      "training loss 0.00043783024962606494\n",
      "epochs 8269\n",
      "training loss 0.0004886963332972793\n",
      "testing loss 0.002778448782867838\n",
      "epochs 8270\n",
      "training loss 0.0004416906819247151\n",
      "epochs 8271\n",
      "training loss 0.00042172116084140374\n",
      "epochs 8272\n",
      "training loss 0.0004940412397741264\n",
      "epochs 8273\n",
      "training loss 0.0004858123422508329\n",
      "epochs 8274\n",
      "training loss 0.0004618507037668186\n",
      "epochs 8275\n",
      "training loss 0.0004656960304697698\n",
      "epochs 8276\n",
      "training loss 0.0004773949858368768\n",
      "epochs 8277\n",
      "training loss 0.00046184494293338723\n",
      "epochs 8278\n",
      "training loss 0.00048651053456272536\n",
      "epochs 8279\n",
      "training loss 0.0004324758819716283\n",
      "testing loss 0.0025376138691823426\n",
      "epochs 8280\n",
      "training loss 0.0004644485080022348\n",
      "epochs 8281\n",
      "training loss 0.00047073798221578444\n",
      "epochs 8282\n",
      "training loss 0.00045031187404796346\n",
      "epochs 8283\n",
      "training loss 0.0005267401851995319\n",
      "epochs 8284\n",
      "training loss 0.0005025333177516276\n",
      "epochs 8285\n",
      "training loss 0.0004793750514073926\n",
      "epochs 8286\n",
      "training loss 0.0004855829555899369\n",
      "epochs 8287\n",
      "training loss 0.00046012694731575513\n",
      "epochs 8288\n",
      "training loss 0.00044228241897094713\n",
      "epochs 8289\n",
      "training loss 0.00047378882061262646\n",
      "testing loss 0.002586144807827758\n",
      "epochs 8290\n",
      "training loss 0.00044412738155279207\n",
      "epochs 8291\n",
      "training loss 0.0004283027277762597\n",
      "epochs 8292\n",
      "training loss 0.0005694529014047926\n",
      "epochs 8293\n",
      "training loss 0.0005175123100188818\n",
      "epochs 8294\n",
      "training loss 0.0005585698553822414\n",
      "epochs 8295\n",
      "training loss 0.0004665930686436458\n",
      "epochs 8296\n",
      "training loss 0.00045098019176443026\n",
      "epochs 8297\n",
      "training loss 0.0004800883100380821\n",
      "epochs 8298\n",
      "training loss 0.0004369935709388649\n",
      "epochs 8299\n",
      "training loss 0.0004565475656212899\n",
      "testing loss 0.0025985784608216836\n",
      "epochs 8300\n",
      "training loss 0.0004889177674913105\n",
      "epochs 8301\n",
      "training loss 0.0004712376772039669\n",
      "epochs 8302\n",
      "training loss 0.0005240644038850187\n",
      "epochs 8303\n",
      "training loss 0.0004920674643021411\n",
      "epochs 8304\n",
      "training loss 0.0004563103991703592\n",
      "epochs 8305\n",
      "training loss 0.000508980896179904\n",
      "epochs 8306\n",
      "training loss 0.0005478792735212695\n",
      "epochs 8307\n",
      "training loss 0.00047447801656783263\n",
      "epochs 8308\n",
      "training loss 0.0004972412068174591\n",
      "epochs 8309\n",
      "training loss 0.0005179732912510215\n",
      "testing loss 0.0025445407480232628\n",
      "epochs 8310\n",
      "training loss 0.0004649623447981745\n",
      "epochs 8311\n",
      "training loss 0.00048564940609255845\n",
      "epochs 8312\n",
      "training loss 0.00046935863837127014\n",
      "epochs 8313\n",
      "training loss 0.00046693877340719036\n",
      "epochs 8314\n",
      "training loss 0.0005107215328526324\n",
      "epochs 8315\n",
      "training loss 0.0005132499900908354\n",
      "epochs 8316\n",
      "training loss 0.0005152320170737549\n",
      "epochs 8317\n",
      "training loss 0.0005021727361095684\n",
      "epochs 8318\n",
      "training loss 0.00045436560487697374\n",
      "epochs 8319\n",
      "training loss 0.0004915116247077017\n",
      "testing loss 0.002647730128440002\n",
      "epochs 8320\n",
      "training loss 0.00044617443427756305\n",
      "epochs 8321\n",
      "training loss 0.0005080096968902575\n",
      "epochs 8322\n",
      "training loss 0.0004320849871863031\n",
      "epochs 8323\n",
      "training loss 0.0005050347928639989\n",
      "epochs 8324\n",
      "training loss 0.0004770241342138182\n",
      "epochs 8325\n",
      "training loss 0.0005121687797816771\n",
      "epochs 8326\n",
      "training loss 0.0004656446074513509\n",
      "epochs 8327\n",
      "training loss 0.0005148732735730119\n",
      "epochs 8328\n",
      "training loss 0.0004952760163119974\n",
      "epochs 8329\n",
      "training loss 0.0005549916486775271\n",
      "testing loss 0.0026034140296392672\n",
      "epochs 8330\n",
      "training loss 0.0005412933592349121\n",
      "epochs 8331\n",
      "training loss 0.000457272842055113\n",
      "epochs 8332\n",
      "training loss 0.00046438660172216234\n",
      "epochs 8333\n",
      "training loss 0.00044818254386564565\n",
      "epochs 8334\n",
      "training loss 0.0005131778953912581\n",
      "epochs 8335\n",
      "training loss 0.0004497359510855098\n",
      "epochs 8336\n",
      "training loss 0.0004879430513708685\n",
      "epochs 8337\n",
      "training loss 0.00043258628040823894\n",
      "epochs 8338\n",
      "training loss 0.00045630402503341245\n",
      "epochs 8339\n",
      "training loss 0.0005173190922538628\n",
      "testing loss 0.0025310690270353717\n",
      "epochs 8340\n",
      "training loss 0.00044526388223982194\n",
      "epochs 8341\n",
      "training loss 0.0005437558493683098\n",
      "epochs 8342\n",
      "training loss 0.0004510682203246445\n",
      "epochs 8343\n",
      "training loss 0.0005109911159283869\n",
      "epochs 8344\n",
      "training loss 0.000493482883981044\n",
      "epochs 8345\n",
      "training loss 0.00045134745238173337\n",
      "epochs 8346\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss 0.0006225987574252609\n",
      "epochs 8347\n",
      "training loss 0.000608085843762397\n",
      "epochs 8348\n",
      "training loss 0.0006658820876650693\n",
      "epochs 8349\n",
      "training loss 0.0005742458476774157\n",
      "testing loss 0.0026559861585768664\n",
      "epochs 8350\n",
      "training loss 0.0005532169375674074\n",
      "epochs 8351\n",
      "training loss 0.0005879994366978972\n",
      "epochs 8352\n",
      "training loss 0.0005853967765901\n",
      "epochs 8353\n",
      "training loss 0.0006329921922734217\n",
      "epochs 8354\n",
      "training loss 0.0006543187620748106\n",
      "epochs 8355\n",
      "training loss 0.0005916347294602838\n",
      "epochs 8356\n",
      "training loss 0.000614964292635207\n",
      "epochs 8357\n",
      "training loss 0.0005661350943673243\n",
      "epochs 8358\n",
      "training loss 0.0006495025130551405\n",
      "epochs 8359\n",
      "training loss 0.0005831154333859241\n",
      "testing loss 0.0025332522424142676\n",
      "epochs 8360\n",
      "training loss 0.0005832009547705675\n",
      "epochs 8361\n",
      "training loss 0.0005931204550589596\n",
      "epochs 8362\n",
      "training loss 0.0006608228963668144\n",
      "epochs 8363\n",
      "training loss 0.0007568451570273352\n",
      "epochs 8364\n",
      "training loss 0.0006320277096436141\n",
      "epochs 8365\n",
      "training loss 0.0005924125134946332\n",
      "epochs 8366\n",
      "training loss 0.0006022075490847706\n",
      "epochs 8367\n",
      "training loss 0.0005871743792851985\n",
      "epochs 8368\n",
      "training loss 0.0006406315496473752\n",
      "epochs 8369\n",
      "training loss 0.0006492858039431761\n",
      "testing loss 0.0026455726501356863\n",
      "epochs 8370\n",
      "training loss 0.0006080809221631284\n",
      "epochs 8371\n",
      "training loss 0.0006147857405468935\n",
      "epochs 8372\n",
      "training loss 0.0006126825345466395\n",
      "epochs 8373\n",
      "training loss 0.0006253859889835097\n",
      "epochs 8374\n",
      "training loss 0.0005954460136162111\n",
      "epochs 8375\n",
      "training loss 0.000574113249210471\n",
      "epochs 8376\n",
      "training loss 0.0006497413228551849\n",
      "epochs 8377\n",
      "training loss 0.0006743547088030647\n",
      "epochs 8378\n",
      "training loss 0.0005670782081509648\n",
      "epochs 8379\n",
      "training loss 0.0005957105324043125\n",
      "testing loss 0.002635381334784923\n",
      "epochs 8380\n",
      "training loss 0.0006196949513145017\n",
      "epochs 8381\n",
      "training loss 0.0005994941368713228\n",
      "epochs 8382\n",
      "training loss 0.0005807582390091968\n",
      "epochs 8383\n",
      "training loss 0.0005599708712746822\n",
      "epochs 8384\n",
      "training loss 0.0006303803109398287\n",
      "epochs 8385\n",
      "training loss 0.0006247320009227758\n",
      "epochs 8386\n",
      "training loss 0.0006546339409894347\n",
      "epochs 8387\n",
      "training loss 0.0005878163809466281\n",
      "epochs 8388\n",
      "training loss 0.00061564826171054\n",
      "epochs 8389\n",
      "training loss 0.0006075843030694408\n",
      "testing loss 0.002663043264468062\n",
      "epochs 8390\n",
      "training loss 0.0006242979019434448\n",
      "epochs 8391\n",
      "training loss 0.0006076676157475831\n",
      "epochs 8392\n",
      "training loss 0.0006247757270395767\n",
      "epochs 8393\n",
      "training loss 0.0008338803544323495\n",
      "epochs 8394\n",
      "training loss 0.0007402212881818584\n",
      "epochs 8395\n",
      "training loss 0.000601821941377363\n",
      "epochs 8396\n",
      "training loss 0.0005892213048465765\n",
      "epochs 8397\n",
      "training loss 0.0005794297855564656\n",
      "epochs 8398\n",
      "training loss 0.0006041015586093929\n",
      "epochs 8399\n",
      "training loss 0.0005921314897385106\n",
      "testing loss 0.0026788120236452538\n",
      "epochs 8400\n",
      "training loss 0.0006903891005280136\n",
      "epochs 8401\n",
      "training loss 0.0005990399989316461\n",
      "epochs 8402\n",
      "training loss 0.0006517457435548724\n",
      "epochs 8403\n",
      "training loss 0.0008377688967850693\n",
      "epochs 8404\n",
      "training loss 0.0006246474402741526\n",
      "epochs 8405\n",
      "training loss 0.0005818810091901707\n",
      "epochs 8406\n",
      "training loss 0.000615655662929625\n",
      "epochs 8407\n",
      "training loss 0.0005598275759115838\n",
      "epochs 8408\n",
      "training loss 0.0016010862314793364\n",
      "epochs 8409\n",
      "training loss 0.0017188353342638212\n",
      "testing loss 0.0028153145809638055\n",
      "epochs 8410\n",
      "training loss 0.001266435007469185\n",
      "epochs 8411\n",
      "training loss 0.0011056511837877277\n",
      "epochs 8412\n",
      "training loss 0.0012446247724325066\n",
      "epochs 8413\n",
      "training loss 0.001083706952681012\n",
      "epochs 8414\n",
      "training loss 0.001770592576117852\n",
      "epochs 8415\n",
      "training loss 0.0012488016413912562\n",
      "epochs 8416\n",
      "training loss 0.0010069018935941806\n",
      "epochs 8417\n",
      "training loss 0.0011135673845373661\n",
      "epochs 8418\n",
      "training loss 0.0008693877052045838\n",
      "epochs 8419\n",
      "training loss 0.001069590253037143\n",
      "testing loss 0.0028625487730547733\n",
      "epochs 8420\n",
      "training loss 0.0017269419533261423\n",
      "epochs 8421\n",
      "training loss 0.0013574770801080714\n",
      "epochs 8422\n",
      "training loss 0.0009100909639782581\n",
      "epochs 8423\n",
      "training loss 0.0008319088848418129\n",
      "epochs 8424\n",
      "training loss 0.0007566792708552672\n",
      "epochs 8425\n",
      "training loss 0.0006439767407796892\n",
      "epochs 8426\n",
      "training loss 0.0006472702223225851\n",
      "epochs 8427\n",
      "training loss 0.0005906034604395743\n",
      "epochs 8428\n",
      "training loss 0.0007829098411309207\n",
      "epochs 8429\n",
      "training loss 0.0006187644465663682\n",
      "testing loss 0.002606028306185671\n",
      "epochs 8430\n",
      "training loss 0.0005990565479534896\n",
      "epochs 8431\n",
      "training loss 0.0006192659908420149\n",
      "epochs 8432\n",
      "training loss 0.000817049345487055\n",
      "epochs 8433\n",
      "training loss 0.0005660750906727642\n",
      "epochs 8434\n",
      "training loss 0.0005569909330376772\n",
      "epochs 8435\n",
      "training loss 0.0005367092532034975\n",
      "epochs 8436\n",
      "training loss 0.0004743340204570352\n",
      "epochs 8437\n",
      "training loss 0.0004630053316729177\n",
      "epochs 8438\n",
      "training loss 0.0005438244941582094\n",
      "epochs 8439\n",
      "training loss 0.0005472705801764905\n",
      "testing loss 0.002602367393147359\n",
      "epochs 8440\n",
      "training loss 0.0004962053901684331\n",
      "epochs 8441\n",
      "training loss 0.0004814669582214331\n",
      "epochs 8442\n",
      "training loss 0.0004591899385692065\n",
      "epochs 8443\n",
      "training loss 0.0004540683696680564\n",
      "epochs 8444\n",
      "training loss 0.00043667629300998833\n",
      "epochs 8445\n",
      "training loss 0.0007132414811026124\n",
      "epochs 8446\n",
      "training loss 0.0005623986051095179\n",
      "epochs 8447\n",
      "training loss 0.0006730314352129243\n",
      "epochs 8448\n",
      "training loss 0.000777897995660976\n",
      "epochs 8449\n",
      "training loss 0.0006408544833521361\n",
      "testing loss 0.0025632972800146447\n",
      "epochs 8450\n",
      "training loss 0.000522769814640946\n",
      "epochs 8451\n",
      "training loss 0.000712281214016685\n",
      "epochs 8452\n",
      "training loss 0.0004460843254127016\n",
      "epochs 8453\n",
      "training loss 0.0005240002984965169\n",
      "epochs 8454\n",
      "training loss 0.0004892879951954749\n",
      "epochs 8455\n",
      "training loss 0.0004840271469944448\n",
      "epochs 8456\n",
      "training loss 0.0004775498052110675\n",
      "epochs 8457\n",
      "training loss 0.0004344460873590007\n",
      "epochs 8458\n",
      "training loss 0.0004592822389790398\n",
      "epochs 8459\n",
      "training loss 0.00045635966027840567\n",
      "testing loss 0.002628760083936855\n",
      "epochs 8460\n",
      "training loss 0.00047970692388993606\n",
      "epochs 8461\n",
      "training loss 0.0004662787143670385\n",
      "epochs 8462\n",
      "training loss 0.0004457806117265092\n",
      "epochs 8463\n",
      "training loss 0.0005499428720390396\n",
      "epochs 8464\n",
      "training loss 0.0004765995132639908\n",
      "epochs 8465\n",
      "training loss 0.0004927177699763996\n",
      "epochs 8466\n",
      "training loss 0.0005170710724184013\n",
      "epochs 8467\n",
      "training loss 0.0004949950894212073\n",
      "epochs 8468\n",
      "training loss 0.0004616808508045824\n",
      "epochs 8469\n",
      "training loss 0.0004799628406384462\n",
      "testing loss 0.0026043477308843946\n",
      "epochs 8470\n",
      "training loss 0.00048621606182924114\n",
      "epochs 8471\n",
      "training loss 0.00044655974165820953\n",
      "epochs 8472\n",
      "training loss 0.00046577990346299456\n",
      "epochs 8473\n",
      "training loss 0.00044139025440598104\n",
      "epochs 8474\n",
      "training loss 0.0004764777059489182\n",
      "epochs 8475\n",
      "training loss 0.00046624716041867247\n",
      "epochs 8476\n",
      "training loss 0.0007673005004997979\n",
      "epochs 8477\n",
      "training loss 0.0005339823158473445\n",
      "epochs 8478\n",
      "training loss 0.0004760944604729288\n",
      "epochs 8479\n",
      "training loss 0.0005066300930574219\n",
      "testing loss 0.002651605914852166\n",
      "epochs 8480\n",
      "training loss 0.00046743551316235136\n",
      "epochs 8481\n",
      "training loss 0.0005042872772556319\n",
      "epochs 8482\n",
      "training loss 0.0004271096096120741\n",
      "epochs 8483\n",
      "training loss 0.00044366177020199586\n",
      "epochs 8484\n",
      "training loss 0.00042908436307007036\n",
      "epochs 8485\n",
      "training loss 0.00045092373475641873\n",
      "epochs 8486\n",
      "training loss 0.0004890227995885078\n",
      "epochs 8487\n",
      "training loss 0.0004827329014232637\n",
      "epochs 8488\n",
      "training loss 0.0004960191712996393\n",
      "epochs 8489\n",
      "training loss 0.00042003916958127576\n",
      "testing loss 0.0026203010401338444\n",
      "epochs 8490\n",
      "training loss 0.0004990653813028238\n",
      "epochs 8491\n",
      "training loss 0.00043065640019142494\n",
      "epochs 8492\n",
      "training loss 0.0004447967463879249\n",
      "epochs 8493\n",
      "training loss 0.0004375466494290243\n",
      "epochs 8494\n",
      "training loss 0.00045597793541121153\n",
      "epochs 8495\n",
      "training loss 0.00046552112883333353\n",
      "epochs 8496\n",
      "training loss 0.00046088954304291166\n",
      "epochs 8497\n",
      "training loss 0.00042370460555240467\n",
      "epochs 8498\n",
      "training loss 0.000457299820509793\n",
      "epochs 8499\n",
      "training loss 0.0006228400113720639\n",
      "testing loss 0.0027012870083926313\n",
      "epochs 8500\n",
      "training loss 0.0004731122589929137\n",
      "epochs 8501\n",
      "training loss 0.0004363365802739812\n",
      "epochs 8502\n",
      "training loss 0.0004567435896944107\n",
      "epochs 8503\n",
      "training loss 0.000443635242502842\n",
      "epochs 8504\n",
      "training loss 0.0004624235982501364\n",
      "epochs 8505\n",
      "training loss 0.0004286321408524373\n",
      "epochs 8506\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss 0.0004892118844326789\n",
      "epochs 8507\n",
      "training loss 0.0004490709535057138\n",
      "epochs 8508\n",
      "training loss 0.0004674934951580019\n",
      "epochs 8509\n",
      "training loss 0.000493633599936294\n",
      "testing loss 0.002692848126526182\n",
      "epochs 8510\n",
      "training loss 0.0005135516704454321\n",
      "epochs 8511\n",
      "training loss 0.00046988766798593875\n",
      "epochs 8512\n",
      "training loss 0.0005850623327089434\n",
      "epochs 8513\n",
      "training loss 0.0005194805250227123\n",
      "epochs 8514\n",
      "training loss 0.0004715407372924349\n",
      "epochs 8515\n",
      "training loss 0.0004553297753261804\n",
      "epochs 8516\n",
      "training loss 0.0004890721798541822\n",
      "epochs 8517\n",
      "training loss 0.00045268081624335455\n",
      "epochs 8518\n",
      "training loss 0.00047767031523837823\n",
      "epochs 8519\n",
      "training loss 0.000465283747465211\n",
      "testing loss 0.0026073408377495534\n",
      "epochs 8520\n",
      "training loss 0.0004389324343316031\n",
      "epochs 8521\n",
      "training loss 0.0005142336910679699\n",
      "epochs 8522\n",
      "training loss 0.00046719527324961673\n",
      "epochs 8523\n",
      "training loss 0.00047706368884056137\n",
      "epochs 8524\n",
      "training loss 0.0005074043092629264\n",
      "epochs 8525\n",
      "training loss 0.0004354673173274324\n",
      "epochs 8526\n",
      "training loss 0.00046271023833784514\n",
      "epochs 8527\n",
      "training loss 0.0004037622310006057\n",
      "epochs 8528\n",
      "training loss 0.0004698490495029214\n",
      "epochs 8529\n",
      "training loss 0.000699219940015112\n",
      "testing loss 0.002678420755463976\n",
      "epochs 8530\n",
      "training loss 0.0005371475209748107\n",
      "epochs 8531\n",
      "training loss 0.0004033407312375564\n",
      "epochs 8532\n",
      "training loss 0.00044872529465368293\n",
      "epochs 8533\n",
      "training loss 0.000515684431031669\n",
      "epochs 8534\n",
      "training loss 0.00045408440464017716\n",
      "epochs 8535\n",
      "training loss 0.0004557578066433992\n",
      "epochs 8536\n",
      "training loss 0.0004605882550592571\n",
      "epochs 8537\n",
      "training loss 0.0004628627247171403\n",
      "epochs 8538\n",
      "training loss 0.0006267385966693671\n",
      "epochs 8539\n",
      "training loss 0.0006742069203481588\n",
      "testing loss 0.0026605408209382643\n",
      "epochs 8540\n",
      "training loss 0.00046641075986120456\n",
      "epochs 8541\n",
      "training loss 0.00046350417827117316\n",
      "epochs 8542\n",
      "training loss 0.000565289869061657\n",
      "epochs 8543\n",
      "training loss 0.0004074621024647003\n",
      "epochs 8544\n",
      "training loss 0.0005073666101601825\n",
      "epochs 8545\n",
      "training loss 0.0004653371090287382\n",
      "epochs 8546\n",
      "training loss 0.00043567653538766787\n",
      "epochs 8547\n",
      "training loss 0.0004590192763170222\n",
      "epochs 8548\n",
      "training loss 0.0004479040134851014\n",
      "epochs 8549\n",
      "training loss 0.00040776512690318754\n",
      "testing loss 0.0026092901784622816\n",
      "epochs 8550\n",
      "training loss 0.0004397545512843492\n",
      "epochs 8551\n",
      "training loss 0.000525586203106546\n",
      "epochs 8552\n",
      "training loss 0.0004448611390108871\n",
      "epochs 8553\n",
      "training loss 0.000467659810722146\n",
      "epochs 8554\n",
      "training loss 0.00043701208354041864\n",
      "epochs 8555\n",
      "training loss 0.0004526986825452568\n",
      "epochs 8556\n",
      "training loss 0.00046318104702237667\n",
      "epochs 8557\n",
      "training loss 0.00046957493883537804\n",
      "epochs 8558\n",
      "training loss 0.00042123908503794913\n",
      "epochs 8559\n",
      "training loss 0.00047107953035080164\n",
      "testing loss 0.002604402465488207\n",
      "epochs 8560\n",
      "training loss 0.000565876553099076\n",
      "epochs 8561\n",
      "training loss 0.00043241173270622713\n",
      "epochs 8562\n",
      "training loss 0.00045181396325319825\n",
      "epochs 8563\n",
      "training loss 0.0004394063483683058\n",
      "epochs 8564\n",
      "training loss 0.0005178381634931332\n",
      "epochs 8565\n",
      "training loss 0.0004838634473250437\n",
      "epochs 8566\n",
      "training loss 0.0004417863553269599\n",
      "epochs 8567\n",
      "training loss 0.0004705109289920914\n",
      "epochs 8568\n",
      "training loss 0.0004713858372855954\n",
      "epochs 8569\n",
      "training loss 0.0004748174345501526\n",
      "testing loss 0.002715916061981958\n",
      "epochs 8570\n",
      "training loss 0.0004069673334103995\n",
      "epochs 8571\n",
      "training loss 0.00044771745430495264\n",
      "epochs 8572\n",
      "training loss 0.00044187273730921607\n",
      "epochs 8573\n",
      "training loss 0.0004561359989778832\n",
      "epochs 8574\n",
      "training loss 0.00046252729625959163\n",
      "epochs 8575\n",
      "training loss 0.0004381121729470869\n",
      "epochs 8576\n",
      "training loss 0.00044572389689748285\n",
      "epochs 8577\n",
      "training loss 0.00047627970122301945\n",
      "epochs 8578\n",
      "training loss 0.0004570676145811868\n",
      "epochs 8579\n",
      "training loss 0.00042354533165561654\n",
      "testing loss 0.0026902591182969195\n",
      "epochs 8580\n",
      "training loss 0.0004531680438228767\n",
      "epochs 8581\n",
      "training loss 0.0004321444538311529\n",
      "epochs 8582\n",
      "training loss 0.0004065502095276824\n",
      "epochs 8583\n",
      "training loss 0.00048732814241213426\n",
      "epochs 8584\n",
      "training loss 0.0005353816040426403\n",
      "epochs 8585\n",
      "training loss 0.0006824283179293434\n",
      "epochs 8586\n",
      "training loss 0.0007538167998799064\n",
      "epochs 8587\n",
      "training loss 0.0006791785981089986\n",
      "epochs 8588\n",
      "training loss 0.0004751764812526551\n",
      "epochs 8589\n",
      "training loss 0.00045022216693096223\n",
      "testing loss 0.002740874546348837\n",
      "epochs 8590\n",
      "training loss 0.0004538687111103573\n",
      "epochs 8591\n",
      "training loss 0.00045097125255386697\n",
      "epochs 8592\n",
      "training loss 0.00046139932918718996\n",
      "epochs 8593\n",
      "training loss 0.0005772882097826755\n",
      "epochs 8594\n",
      "training loss 0.000481454650928071\n",
      "epochs 8595\n",
      "training loss 0.00045766937369509035\n",
      "epochs 8596\n",
      "training loss 0.000470791373767757\n",
      "epochs 8597\n",
      "training loss 0.0004421297667263568\n",
      "epochs 8598\n",
      "training loss 0.0006738077553865248\n",
      "epochs 8599\n",
      "training loss 0.0006648840171803004\n",
      "testing loss 0.0026758507002270547\n",
      "epochs 8600\n",
      "training loss 0.0004937309620683973\n",
      "epochs 8601\n",
      "training loss 0.00043026231897897214\n",
      "epochs 8602\n",
      "training loss 0.00045751680955814485\n",
      "epochs 8603\n",
      "training loss 0.0004268906163801878\n",
      "epochs 8604\n",
      "training loss 0.00061894808934809\n",
      "epochs 8605\n",
      "training loss 0.0005696448453243448\n",
      "epochs 8606\n",
      "training loss 0.0005121748693822387\n",
      "epochs 8607\n",
      "training loss 0.0004700676037888906\n",
      "epochs 8608\n",
      "training loss 0.0005751486712327866\n",
      "epochs 8609\n",
      "training loss 0.0005649661297728039\n",
      "testing loss 0.002611135813351456\n",
      "epochs 8610\n",
      "training loss 0.0004665872233294907\n",
      "epochs 8611\n",
      "training loss 0.0005017598545303325\n",
      "epochs 8612\n",
      "training loss 0.000891614365543587\n",
      "epochs 8613\n",
      "training loss 0.0005879396760070521\n",
      "epochs 8614\n",
      "training loss 0.0004579639252477628\n",
      "epochs 8615\n",
      "training loss 0.00047231909283224527\n",
      "epochs 8616\n",
      "training loss 0.0004600862908569139\n",
      "epochs 8617\n",
      "training loss 0.0005846531161334999\n",
      "epochs 8618\n",
      "training loss 0.0007290383965402593\n",
      "epochs 8619\n",
      "training loss 0.0005777061078803597\n",
      "testing loss 0.0025839197985226855\n",
      "epochs 8620\n",
      "training loss 0.000668273043590895\n",
      "epochs 8621\n",
      "training loss 0.0005365143800586021\n",
      "epochs 8622\n",
      "training loss 0.0004649769907921983\n",
      "epochs 8623\n",
      "training loss 0.0009664477309669257\n",
      "epochs 8624\n",
      "training loss 0.0008210369767401775\n",
      "epochs 8625\n",
      "training loss 0.0007286194217777711\n",
      "epochs 8626\n",
      "training loss 0.0005835216683668218\n",
      "epochs 8627\n",
      "training loss 0.0006346765022419144\n",
      "epochs 8628\n",
      "training loss 0.0005758979451902052\n",
      "epochs 8629\n",
      "training loss 0.0006033439674141525\n",
      "testing loss 0.0026808018343694876\n",
      "epochs 8630\n",
      "training loss 0.0005777963141855532\n",
      "epochs 8631\n",
      "training loss 0.0005598899037548904\n",
      "epochs 8632\n",
      "training loss 0.0006508615271663887\n",
      "epochs 8633\n",
      "training loss 0.0005738498861717462\n",
      "epochs 8634\n",
      "training loss 0.0004815936600223274\n",
      "epochs 8635\n",
      "training loss 0.0007193776727392194\n",
      "epochs 8636\n",
      "training loss 0.0004671657190617106\n",
      "epochs 8637\n",
      "training loss 0.0005410522907476244\n",
      "epochs 8638\n",
      "training loss 0.0005307439228131982\n",
      "epochs 8639\n",
      "training loss 0.0005641914215887186\n",
      "testing loss 0.0027241563174298946\n",
      "epochs 8640\n",
      "training loss 0.0007918325556607741\n",
      "epochs 8641\n",
      "training loss 0.0010370869961946545\n",
      "epochs 8642\n",
      "training loss 0.0008610742152307612\n",
      "epochs 8643\n",
      "training loss 0.0008597175882970716\n",
      "epochs 8644\n",
      "training loss 0.0005510969124281478\n",
      "epochs 8645\n",
      "training loss 0.00047009945886017113\n",
      "epochs 8646\n",
      "training loss 0.00045392046400167526\n",
      "epochs 8647\n",
      "training loss 0.00042498576227295294\n",
      "epochs 8648\n",
      "training loss 0.00044119575218011634\n",
      "epochs 8649\n",
      "training loss 0.00045565829060668846\n",
      "testing loss 0.002510498015289294\n",
      "epochs 8650\n",
      "training loss 0.000491426813668829\n",
      "epochs 8651\n",
      "training loss 0.0006400606203803051\n",
      "epochs 8652\n",
      "training loss 0.000523129945704402\n",
      "epochs 8653\n",
      "training loss 0.0005850126367242084\n",
      "epochs 8654\n",
      "training loss 0.0004398192160590877\n",
      "epochs 8655\n",
      "training loss 0.00046716160445239136\n",
      "epochs 8656\n",
      "training loss 0.0004706481631065359\n",
      "epochs 8657\n",
      "training loss 0.00045383374909459864\n",
      "epochs 8658\n",
      "training loss 0.0004707173841345863\n",
      "epochs 8659\n",
      "training loss 0.0005139501367824429\n",
      "testing loss 0.0025297468449715656\n",
      "epochs 8660\n",
      "training loss 0.000452407031821789\n",
      "epochs 8661\n",
      "training loss 0.0006904824389892101\n",
      "epochs 8662\n",
      "training loss 0.0021499670507835003\n",
      "epochs 8663\n",
      "training loss 0.0009770530345354308\n",
      "epochs 8664\n",
      "training loss 0.0006885630917051768\n",
      "epochs 8665\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss 0.0006229652160506888\n",
      "epochs 8666\n",
      "training loss 0.0006498325021483152\n",
      "epochs 8667\n",
      "training loss 0.0007379976607042459\n",
      "epochs 8668\n",
      "training loss 0.000655270986418922\n",
      "epochs 8669\n",
      "training loss 0.0006309480905797514\n",
      "testing loss 0.002567700926934415\n",
      "epochs 8670\n",
      "training loss 0.0006668500822160597\n",
      "epochs 8671\n",
      "training loss 0.0006248628438272058\n",
      "epochs 8672\n",
      "training loss 0.000571149016028457\n",
      "epochs 8673\n",
      "training loss 0.0005487087170758332\n",
      "epochs 8674\n",
      "training loss 0.0005671064899087881\n",
      "epochs 8675\n",
      "training loss 0.0006811709785805647\n",
      "epochs 8676\n",
      "training loss 0.001325941505547511\n",
      "epochs 8677\n",
      "training loss 0.000789676484896725\n",
      "epochs 8678\n",
      "training loss 0.0006611655922012127\n",
      "epochs 8679\n",
      "training loss 0.0005548209545349753\n",
      "testing loss 0.002572041167547358\n",
      "epochs 8680\n",
      "training loss 0.0005522780361872642\n",
      "epochs 8681\n",
      "training loss 0.0005292786060765918\n",
      "epochs 8682\n",
      "training loss 0.0006128187787770025\n",
      "epochs 8683\n",
      "training loss 0.0007431372121899278\n",
      "epochs 8684\n",
      "training loss 0.0005860783853801675\n",
      "epochs 8685\n",
      "training loss 0.0005971427076626399\n",
      "epochs 8686\n",
      "training loss 0.0005499259788135356\n",
      "epochs 8687\n",
      "training loss 0.0005414904184401669\n",
      "epochs 8688\n",
      "training loss 0.0005936638766504813\n",
      "epochs 8689\n",
      "training loss 0.0005517519694133053\n",
      "testing loss 0.0025845490992960937\n",
      "epochs 8690\n",
      "training loss 0.0005699893452423854\n",
      "epochs 8691\n",
      "training loss 0.0006207918794613365\n",
      "epochs 8692\n",
      "training loss 0.0005684493695729693\n",
      "epochs 8693\n",
      "training loss 0.0005835772559310714\n",
      "epochs 8694\n",
      "training loss 0.0005610448384454395\n",
      "epochs 8695\n",
      "training loss 0.0006207062239690732\n",
      "epochs 8696\n",
      "training loss 0.0006116347211483147\n",
      "epochs 8697\n",
      "training loss 0.0005966247475881548\n",
      "epochs 8698\n",
      "training loss 0.0005591998326501563\n",
      "epochs 8699\n",
      "training loss 0.0005367414638015093\n",
      "testing loss 0.002592484150511206\n",
      "epochs 8700\n",
      "training loss 0.0006546491752966026\n",
      "epochs 8701\n",
      "training loss 0.0006180227525644769\n",
      "epochs 8702\n",
      "training loss 0.000500867631846167\n",
      "epochs 8703\n",
      "training loss 0.0005630763179670713\n",
      "epochs 8704\n",
      "training loss 0.0005649424864490174\n",
      "epochs 8705\n",
      "training loss 0.0007544734558949705\n",
      "epochs 8706\n",
      "training loss 0.0006028788789149974\n",
      "epochs 8707\n",
      "training loss 0.0005934268536398578\n",
      "epochs 8708\n",
      "training loss 0.0006302074919522692\n",
      "epochs 8709\n",
      "training loss 0.0005115911485393755\n",
      "testing loss 0.0025705767767371756\n",
      "epochs 8710\n",
      "training loss 0.0005816387296208438\n",
      "epochs 8711\n",
      "training loss 0.0005201453010064739\n",
      "epochs 8712\n",
      "training loss 0.0005575915594021917\n",
      "epochs 8713\n",
      "training loss 0.0006640939046218312\n",
      "epochs 8714\n",
      "training loss 0.0006070148317804306\n",
      "epochs 8715\n",
      "training loss 0.0007102362296100293\n",
      "epochs 8716\n",
      "training loss 0.0008528604846069799\n",
      "epochs 8717\n",
      "training loss 0.0005713811411917221\n",
      "epochs 8718\n",
      "training loss 0.0005796614455449816\n",
      "epochs 8719\n",
      "training loss 0.0007116044574278466\n",
      "testing loss 0.002511586356951016\n",
      "epochs 8720\n",
      "training loss 0.0006867635814334325\n",
      "epochs 8721\n",
      "training loss 0.00064618807166778\n",
      "epochs 8722\n",
      "training loss 0.0005239718569772415\n",
      "epochs 8723\n",
      "training loss 0.0005487739894040902\n",
      "epochs 8724\n",
      "training loss 0.0004991934552299012\n",
      "epochs 8725\n",
      "training loss 0.0005552666701888099\n",
      "epochs 8726\n",
      "training loss 0.0004803323112449419\n",
      "epochs 8727\n",
      "training loss 0.0005138302628817121\n",
      "epochs 8728\n",
      "training loss 0.0004385616198623706\n",
      "epochs 8729\n",
      "training loss 0.0005135372609089731\n",
      "testing loss 0.0026968586298220967\n",
      "epochs 8730\n",
      "training loss 0.0005302716112564003\n",
      "epochs 8731\n",
      "training loss 0.0005370182759060572\n",
      "epochs 8732\n",
      "training loss 0.0005368363410503374\n",
      "epochs 8733\n",
      "training loss 0.0005318138608284362\n",
      "epochs 8734\n",
      "training loss 0.0005193422885511161\n",
      "epochs 8735\n",
      "training loss 0.00048388018786601475\n",
      "epochs 8736\n",
      "training loss 0.0005675815333333433\n",
      "epochs 8737\n",
      "training loss 0.0005569211005638028\n",
      "epochs 8738\n",
      "training loss 0.0006676144224038138\n",
      "epochs 8739\n",
      "training loss 0.0006873259708935701\n",
      "testing loss 0.0030507251995133488\n",
      "epochs 8740\n",
      "training loss 0.0007144645832890877\n",
      "epochs 8741\n",
      "training loss 0.000520548653558157\n",
      "epochs 8742\n",
      "training loss 0.0005488914153984491\n",
      "epochs 8743\n",
      "training loss 0.0011074577966325642\n",
      "epochs 8744\n",
      "training loss 0.0013266795360494551\n",
      "epochs 8745\n",
      "training loss 0.0010547049922654886\n",
      "epochs 8746\n",
      "training loss 0.0006603865276867847\n",
      "epochs 8747\n",
      "training loss 0.0007142255401718614\n",
      "epochs 8748\n",
      "training loss 0.0006706411256752116\n",
      "epochs 8749\n",
      "training loss 0.0006619604439955873\n",
      "testing loss 0.002754967029335255\n",
      "epochs 8750\n",
      "training loss 0.0006212348455993464\n",
      "epochs 8751\n",
      "training loss 0.0005166898859278398\n",
      "epochs 8752\n",
      "training loss 0.0005062492144128483\n",
      "epochs 8753\n",
      "training loss 0.00045471963793602645\n",
      "epochs 8754\n",
      "training loss 0.00048561305761985526\n",
      "epochs 8755\n",
      "training loss 0.000516654977785129\n",
      "epochs 8756\n",
      "training loss 0.0005044444428939417\n",
      "epochs 8757\n",
      "training loss 0.0004763207089624404\n",
      "epochs 8758\n",
      "training loss 0.0005564588418592752\n",
      "epochs 8759\n",
      "training loss 0.0004902538219976344\n",
      "testing loss 0.0025381799717103496\n",
      "epochs 8760\n",
      "training loss 0.0006452415864840348\n",
      "epochs 8761\n",
      "training loss 0.0004979855602813777\n",
      "epochs 8762\n",
      "training loss 0.0005718714409945873\n",
      "epochs 8763\n",
      "training loss 0.0004383163532138856\n",
      "epochs 8764\n",
      "training loss 0.0004647215009146118\n",
      "epochs 8765\n",
      "training loss 0.0004383324451552064\n",
      "epochs 8766\n",
      "training loss 0.00048735010655990326\n",
      "epochs 8767\n",
      "training loss 0.00043484832609205374\n",
      "epochs 8768\n",
      "training loss 0.0005338500223071583\n",
      "epochs 8769\n",
      "training loss 0.0004674256577561284\n",
      "testing loss 0.002604617570867062\n",
      "epochs 8770\n",
      "training loss 0.00048430427720651346\n",
      "epochs 8771\n",
      "training loss 0.00047108252963764554\n",
      "epochs 8772\n",
      "training loss 0.00045998177966520494\n",
      "epochs 8773\n",
      "training loss 0.00046550184984565473\n",
      "epochs 8774\n",
      "training loss 0.0004909045772774196\n",
      "epochs 8775\n",
      "training loss 0.0004624336075351225\n",
      "epochs 8776\n",
      "training loss 0.00043630539450233965\n",
      "epochs 8777\n",
      "training loss 0.000545457206219916\n",
      "epochs 8778\n",
      "training loss 0.0004425661850332829\n",
      "epochs 8779\n",
      "training loss 0.0004772631465464457\n",
      "testing loss 0.002560396458712532\n",
      "epochs 8780\n",
      "training loss 0.0005148916066862009\n",
      "epochs 8781\n",
      "training loss 0.0005405314830535214\n",
      "epochs 8782\n",
      "training loss 0.000481306710496324\n",
      "epochs 8783\n",
      "training loss 0.0005006442494204942\n",
      "epochs 8784\n",
      "training loss 0.0004420384135621665\n",
      "epochs 8785\n",
      "training loss 0.0004699872740764471\n",
      "epochs 8786\n",
      "training loss 0.00044397464571209304\n",
      "epochs 8787\n",
      "training loss 0.000495238298366956\n",
      "epochs 8788\n",
      "training loss 0.000557339016530708\n",
      "epochs 8789\n",
      "training loss 0.0005628696302593173\n",
      "testing loss 0.0025986433644277036\n",
      "epochs 8790\n",
      "training loss 0.0004461648583211894\n",
      "epochs 8791\n",
      "training loss 0.0004782454079012797\n",
      "epochs 8792\n",
      "training loss 0.00043126654050080815\n",
      "epochs 8793\n",
      "training loss 0.0005060570781780152\n",
      "epochs 8794\n",
      "training loss 0.0004595382389255819\n",
      "epochs 8795\n",
      "training loss 0.0005275985648173352\n",
      "epochs 8796\n",
      "training loss 0.0004938050598457405\n",
      "epochs 8797\n",
      "training loss 0.0004581956039016534\n",
      "epochs 8798\n",
      "training loss 0.0004239567994433073\n",
      "epochs 8799\n",
      "training loss 0.00042338839796333543\n",
      "testing loss 0.0026022564031097854\n",
      "epochs 8800\n",
      "training loss 0.00048009850770181276\n",
      "epochs 8801\n",
      "training loss 0.00046958663791176044\n",
      "epochs 8802\n",
      "training loss 0.00044780893410176697\n",
      "epochs 8803\n",
      "training loss 0.0004619320579075557\n",
      "epochs 8804\n",
      "training loss 0.0004588561504088501\n",
      "epochs 8805\n",
      "training loss 0.0004892544154789706\n",
      "epochs 8806\n",
      "training loss 0.00048285085075580174\n",
      "epochs 8807\n",
      "training loss 0.00046204678149183357\n",
      "epochs 8808\n",
      "training loss 0.00041521226081927805\n",
      "epochs 8809\n",
      "training loss 0.00044874620712701923\n",
      "testing loss 0.0025536761501909677\n",
      "epochs 8810\n",
      "training loss 0.000787295529807813\n",
      "epochs 8811\n",
      "training loss 0.0006554409038695849\n",
      "epochs 8812\n",
      "training loss 0.0005013713954436935\n",
      "epochs 8813\n",
      "training loss 0.00044296215688894674\n",
      "epochs 8814\n",
      "training loss 0.000516572523183447\n",
      "epochs 8815\n",
      "training loss 0.00046871883126250313\n",
      "epochs 8816\n",
      "training loss 0.0004285991104817907\n",
      "epochs 8817\n",
      "training loss 0.0004957244421162935\n",
      "epochs 8818\n",
      "training loss 0.0005758266745094142\n",
      "epochs 8819\n",
      "training loss 0.0005651703510415035\n",
      "testing loss 0.0026387224380085444\n",
      "epochs 8820\n",
      "training loss 0.0004939833132438305\n",
      "epochs 8821\n",
      "training loss 0.0005036985985442888\n",
      "epochs 8822\n",
      "training loss 0.0004588880909339307\n",
      "epochs 8823\n",
      "training loss 0.00043679114300573644\n",
      "epochs 8824\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss 0.0004846245171799463\n",
      "epochs 8825\n",
      "training loss 0.0005019592157689611\n",
      "epochs 8826\n",
      "training loss 0.0004859068056325765\n",
      "epochs 8827\n",
      "training loss 0.0007531466940028655\n",
      "epochs 8828\n",
      "training loss 0.0005264142254830301\n",
      "epochs 8829\n",
      "training loss 0.0005024066320507246\n",
      "testing loss 0.002585858153261852\n",
      "epochs 8830\n",
      "training loss 0.0004528649770555661\n",
      "epochs 8831\n",
      "training loss 0.000459566478310351\n",
      "epochs 8832\n",
      "training loss 0.0004752924862900879\n",
      "epochs 8833\n",
      "training loss 0.0004622627747291841\n",
      "epochs 8834\n",
      "training loss 0.0009238117436933583\n",
      "epochs 8835\n",
      "training loss 0.0008696302651968363\n",
      "epochs 8836\n",
      "training loss 0.0005302609437736923\n",
      "epochs 8837\n",
      "training loss 0.0006032154012873406\n",
      "epochs 8838\n",
      "training loss 0.0007773004267025048\n",
      "epochs 8839\n",
      "training loss 0.0005420541981168624\n",
      "testing loss 0.0026694678722927016\n",
      "epochs 8840\n",
      "training loss 0.0005814566475652033\n",
      "epochs 8841\n",
      "training loss 0.0006381880202172126\n",
      "epochs 8842\n",
      "training loss 0.0005808799618877765\n",
      "epochs 8843\n",
      "training loss 0.0007015187460041002\n",
      "epochs 8844\n",
      "training loss 0.0006869608487885751\n",
      "epochs 8845\n",
      "training loss 0.0005787243947349941\n",
      "epochs 8846\n",
      "training loss 0.0005707324587415881\n",
      "epochs 8847\n",
      "training loss 0.0005591488328315091\n",
      "epochs 8848\n",
      "training loss 0.0006304042375173085\n",
      "epochs 8849\n",
      "training loss 0.001152492410858589\n",
      "testing loss 0.002855614365197401\n",
      "epochs 8850\n",
      "training loss 0.0011532903406705345\n",
      "epochs 8851\n",
      "training loss 0.001232693399271523\n",
      "epochs 8852\n",
      "training loss 0.0007902603425010529\n",
      "epochs 8853\n",
      "training loss 0.0005861850811726213\n",
      "epochs 8854\n",
      "training loss 0.0005111409022860614\n",
      "epochs 8855\n",
      "training loss 0.0005343639926799491\n",
      "epochs 8856\n",
      "training loss 0.0006150611320483615\n",
      "epochs 8857\n",
      "training loss 0.0005638654932760461\n",
      "epochs 8858\n",
      "training loss 0.0006706476730639879\n",
      "epochs 8859\n",
      "training loss 0.000605731860714707\n",
      "testing loss 0.0025429690875119616\n",
      "epochs 8860\n",
      "training loss 0.000490259735648291\n",
      "epochs 8861\n",
      "training loss 0.0007289711572265247\n",
      "epochs 8862\n",
      "training loss 0.0006413510587458473\n",
      "epochs 8863\n",
      "training loss 0.0005268101140964313\n",
      "epochs 8864\n",
      "training loss 0.0005008098155831193\n",
      "epochs 8865\n",
      "training loss 0.0005299400059275589\n",
      "epochs 8866\n",
      "training loss 0.0005142516286698337\n",
      "epochs 8867\n",
      "training loss 0.0004973271721018631\n",
      "epochs 8868\n",
      "training loss 0.0005543331677903702\n",
      "epochs 8869\n",
      "training loss 0.0004615268545203324\n",
      "testing loss 0.0026733887692292533\n",
      "epochs 8870\n",
      "training loss 0.001304092562770171\n",
      "epochs 8871\n",
      "training loss 0.0009881183473212153\n",
      "epochs 8872\n",
      "training loss 0.0008688799452707511\n",
      "epochs 8873\n",
      "training loss 0.0008037001347292418\n",
      "epochs 8874\n",
      "training loss 0.0007344750588580026\n",
      "epochs 8875\n",
      "training loss 0.000701328467416342\n",
      "epochs 8876\n",
      "training loss 0.0005629499333006213\n",
      "epochs 8877\n",
      "training loss 0.0005139043437186799\n",
      "epochs 8878\n",
      "training loss 0.0005674433471078739\n",
      "epochs 8879\n",
      "training loss 0.0005404602930496098\n",
      "testing loss 0.0026780519517244283\n",
      "epochs 8880\n",
      "training loss 0.0005487676109767613\n",
      "epochs 8881\n",
      "training loss 0.0006490403830178512\n",
      "epochs 8882\n",
      "training loss 0.0005388985906188351\n",
      "epochs 8883\n",
      "training loss 0.0005301076186025418\n",
      "epochs 8884\n",
      "training loss 0.0004786599993084396\n",
      "epochs 8885\n",
      "training loss 0.0005864794939292148\n",
      "epochs 8886\n",
      "training loss 0.0007762137463770659\n",
      "epochs 8887\n",
      "training loss 0.0004967168334618177\n",
      "epochs 8888\n",
      "training loss 0.0006048872046587326\n",
      "epochs 8889\n",
      "training loss 0.0005828267869031436\n",
      "testing loss 0.002612814130112925\n",
      "epochs 8890\n",
      "training loss 0.0005076523469676091\n",
      "epochs 8891\n",
      "training loss 0.0004928251186588858\n",
      "epochs 8892\n",
      "training loss 0.0005050178098500817\n",
      "epochs 8893\n",
      "training loss 0.0004600362429723687\n",
      "epochs 8894\n",
      "training loss 0.0005595973339165337\n",
      "epochs 8895\n",
      "training loss 0.0004902218101725922\n",
      "epochs 8896\n",
      "training loss 0.0004555911260871443\n",
      "epochs 8897\n",
      "training loss 0.0004736379007094095\n",
      "epochs 8898\n",
      "training loss 0.0004918917226796194\n",
      "epochs 8899\n",
      "training loss 0.00045947484233477477\n",
      "testing loss 0.002577165285363159\n",
      "epochs 8900\n",
      "training loss 0.0004834567598636208\n",
      "epochs 8901\n",
      "training loss 0.00048372995380473557\n",
      "epochs 8902\n",
      "training loss 0.000509277444087269\n",
      "epochs 8903\n",
      "training loss 0.0004886531031840568\n",
      "epochs 8904\n",
      "training loss 0.0005895158177415776\n",
      "epochs 8905\n",
      "training loss 0.0005350574173597976\n",
      "epochs 8906\n",
      "training loss 0.0006092180247421413\n",
      "epochs 8907\n",
      "training loss 0.0005938599641947218\n",
      "epochs 8908\n",
      "training loss 0.0006548445722219849\n",
      "epochs 8909\n",
      "training loss 0.0005898596499522859\n",
      "testing loss 0.0027158806151677426\n",
      "epochs 8910\n",
      "training loss 0.0006210148695602979\n",
      "epochs 8911\n",
      "training loss 0.0005088392865389733\n",
      "epochs 8912\n",
      "training loss 0.000611900080010963\n",
      "epochs 8913\n",
      "training loss 0.0008160027775822893\n",
      "epochs 8914\n",
      "training loss 0.0006002161051550071\n",
      "epochs 8915\n",
      "training loss 0.0005185541962319419\n",
      "epochs 8916\n",
      "training loss 0.0005084863115678114\n",
      "epochs 8917\n",
      "training loss 0.0004986346360312995\n",
      "epochs 8918\n",
      "training loss 0.00049876754340577\n",
      "epochs 8919\n",
      "training loss 0.0005139043043533165\n",
      "testing loss 0.002604534657563063\n",
      "epochs 8920\n",
      "training loss 0.00046685323220717307\n",
      "epochs 8921\n",
      "training loss 0.0004906372230331552\n",
      "epochs 8922\n",
      "training loss 0.000474745098085321\n",
      "epochs 8923\n",
      "training loss 0.0004953802080250325\n",
      "epochs 8924\n",
      "training loss 0.0005099293678548856\n",
      "epochs 8925\n",
      "training loss 0.0005980113040960867\n",
      "epochs 8926\n",
      "training loss 0.0005438414449721439\n",
      "epochs 8927\n",
      "training loss 0.0004974630136555203\n",
      "epochs 8928\n",
      "training loss 0.0004864509382333301\n",
      "epochs 8929\n",
      "training loss 0.0005264279172871839\n",
      "testing loss 0.002598978822195493\n",
      "epochs 8930\n",
      "training loss 0.00048120221739498994\n",
      "epochs 8931\n",
      "training loss 0.0004647176241782412\n",
      "epochs 8932\n",
      "training loss 0.0005983540166054758\n",
      "epochs 8933\n",
      "training loss 0.0004743019195512718\n",
      "epochs 8934\n",
      "training loss 0.0005197617460037284\n",
      "epochs 8935\n",
      "training loss 0.0004937122845746248\n",
      "epochs 8936\n",
      "training loss 0.0005123175965129514\n",
      "epochs 8937\n",
      "training loss 0.00046331989971671743\n",
      "epochs 8938\n",
      "training loss 0.0005284566544583718\n",
      "epochs 8939\n",
      "training loss 0.000508990055880733\n",
      "testing loss 0.002642811028739266\n",
      "epochs 8940\n",
      "training loss 0.00046308975980622767\n",
      "epochs 8941\n",
      "training loss 0.0005008016953048067\n",
      "epochs 8942\n",
      "training loss 0.00045042382290489167\n",
      "epochs 8943\n",
      "training loss 0.0004704569583712004\n",
      "epochs 8944\n",
      "training loss 0.00047638181665640516\n",
      "epochs 8945\n",
      "training loss 0.00047852849121782985\n",
      "epochs 8946\n",
      "training loss 0.0005011687968683494\n",
      "epochs 8947\n",
      "training loss 0.0004131435558619544\n",
      "epochs 8948\n",
      "training loss 0.0005577243908767031\n",
      "epochs 8949\n",
      "training loss 0.0005021864213233412\n",
      "testing loss 0.0026546750950019356\n",
      "epochs 8950\n",
      "training loss 0.00048633783252125657\n",
      "epochs 8951\n",
      "training loss 0.0005616151980205091\n",
      "epochs 8952\n",
      "training loss 0.0004612372003284801\n",
      "epochs 8953\n",
      "training loss 0.0004964523111352566\n",
      "epochs 8954\n",
      "training loss 0.0004991268154639201\n",
      "epochs 8955\n",
      "training loss 0.00045257703242625327\n",
      "epochs 8956\n",
      "training loss 0.00048322324479341304\n",
      "epochs 8957\n",
      "training loss 0.0004576658693815958\n",
      "epochs 8958\n",
      "training loss 0.00046318494047796905\n",
      "epochs 8959\n",
      "training loss 0.0004727116187589985\n",
      "testing loss 0.0025968644037307736\n",
      "epochs 8960\n",
      "training loss 0.00044350991853389686\n",
      "epochs 8961\n",
      "training loss 0.00044357619304238253\n",
      "epochs 8962\n",
      "training loss 0.00044971338221499\n",
      "epochs 8963\n",
      "training loss 0.00043107711622989694\n",
      "epochs 8964\n",
      "training loss 0.0005034707121902759\n",
      "epochs 8965\n",
      "training loss 0.0004278173979610986\n",
      "epochs 8966\n",
      "training loss 0.000495079909483152\n",
      "epochs 8967\n",
      "training loss 0.0004961761723111149\n",
      "epochs 8968\n",
      "training loss 0.0005334444154028449\n",
      "epochs 8969\n",
      "training loss 0.0004976606121220227\n",
      "testing loss 0.002667891675299232\n",
      "epochs 8970\n",
      "training loss 0.0004731564179075582\n",
      "epochs 8971\n",
      "training loss 0.0004868131954244856\n",
      "epochs 8972\n",
      "training loss 0.0004636997051022545\n",
      "epochs 8973\n",
      "training loss 0.0004937949636915704\n",
      "epochs 8974\n",
      "training loss 0.00045271832152697227\n",
      "epochs 8975\n",
      "training loss 0.000464058916475822\n",
      "epochs 8976\n",
      "training loss 0.0005580567054013158\n",
      "epochs 8977\n",
      "training loss 0.0004995178196318787\n",
      "epochs 8978\n",
      "training loss 0.0009396282154896882\n",
      "epochs 8979\n",
      "training loss 0.0016293740956223142\n",
      "testing loss 0.0028497747154675214\n",
      "epochs 8980\n",
      "training loss 0.0013049823725787147\n",
      "epochs 8981\n",
      "training loss 0.0009201004798488697\n",
      "epochs 8982\n",
      "training loss 0.0007807874217371833\n",
      "epochs 8983\n",
      "training loss 0.0007345353076793537\n",
      "epochs 8984\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss 0.0006374916219485834\n",
      "epochs 8985\n",
      "training loss 0.0009156345557152523\n",
      "epochs 8986\n",
      "training loss 0.0008939653745601888\n",
      "epochs 8987\n",
      "training loss 0.0007478943521703245\n",
      "epochs 8988\n",
      "training loss 0.0006603192138884749\n",
      "epochs 8989\n",
      "training loss 0.0008196788408303786\n",
      "testing loss 0.002839736976901875\n",
      "epochs 8990\n",
      "training loss 0.0006266952921158003\n",
      "epochs 8991\n",
      "training loss 0.0006231155553811419\n",
      "epochs 8992\n",
      "training loss 0.000576778798892041\n",
      "epochs 8993\n",
      "training loss 0.0006573645593166793\n",
      "epochs 8994\n",
      "training loss 0.0007028692947929912\n",
      "epochs 8995\n",
      "training loss 0.000557861673025737\n",
      "epochs 8996\n",
      "training loss 0.0007640430377336292\n",
      "epochs 8997\n",
      "training loss 0.0009257388226886062\n",
      "epochs 8998\n",
      "training loss 0.001060387466508346\n",
      "epochs 8999\n",
      "training loss 0.0007986549030080733\n",
      "testing loss 0.0025836791585576026\n",
      "epochs 9000\n",
      "training loss 0.0008325297194377358\n",
      "epochs 9001\n",
      "training loss 0.0009298420859370551\n",
      "epochs 9002\n",
      "training loss 0.0007800442343726358\n",
      "epochs 9003\n",
      "training loss 0.0006881765749674902\n",
      "epochs 9004\n",
      "training loss 0.0006784652187283742\n",
      "epochs 9005\n",
      "training loss 0.0006717883873487452\n",
      "epochs 9006\n",
      "training loss 0.0006978120553975297\n",
      "epochs 9007\n",
      "training loss 0.0006799586576382746\n",
      "epochs 9008\n",
      "training loss 0.0006587623408358647\n",
      "epochs 9009\n",
      "training loss 0.0006543240481796519\n",
      "testing loss 0.0025806413300447696\n",
      "epochs 9010\n",
      "training loss 0.0006093078287687056\n",
      "epochs 9011\n",
      "training loss 0.0005999779562065293\n",
      "epochs 9012\n",
      "training loss 0.0006610887859541764\n",
      "epochs 9013\n",
      "training loss 0.0006258312206202976\n",
      "epochs 9014\n",
      "training loss 0.0005676914619509764\n",
      "epochs 9015\n",
      "training loss 0.000557969577644462\n",
      "epochs 9016\n",
      "training loss 0.0008064933222227398\n",
      "epochs 9017\n",
      "training loss 0.0009026147657297665\n",
      "epochs 9018\n",
      "training loss 0.0006996043024501144\n",
      "epochs 9019\n",
      "training loss 0.0005761656365612109\n",
      "testing loss 0.0025910940165763574\n",
      "epochs 9020\n",
      "training loss 0.0005296029055478352\n",
      "epochs 9021\n",
      "training loss 0.0007255429734255111\n",
      "epochs 9022\n",
      "training loss 0.0007294932639333887\n",
      "epochs 9023\n",
      "training loss 0.0011211753827993869\n",
      "epochs 9024\n",
      "training loss 0.0008086140668635344\n",
      "epochs 9025\n",
      "training loss 0.0006165780446571398\n",
      "epochs 9026\n",
      "training loss 0.0005464629620620783\n",
      "epochs 9027\n",
      "training loss 0.0005024702892048528\n",
      "epochs 9028\n",
      "training loss 0.00046818515746380093\n",
      "epochs 9029\n",
      "training loss 0.0005073116048936956\n",
      "testing loss 0.002583495254961919\n",
      "epochs 9030\n",
      "training loss 0.000517884968290966\n",
      "epochs 9031\n",
      "training loss 0.0005156828868036557\n",
      "epochs 9032\n",
      "training loss 0.00044427269777441594\n",
      "epochs 9033\n",
      "training loss 0.0004746940785397614\n",
      "epochs 9034\n",
      "training loss 0.00042939248687119187\n",
      "epochs 9035\n",
      "training loss 0.00046295741133145583\n",
      "epochs 9036\n",
      "training loss 0.00050553767078508\n",
      "epochs 9037\n",
      "training loss 0.0004951823664663535\n",
      "epochs 9038\n",
      "training loss 0.0004974692896002122\n",
      "epochs 9039\n",
      "training loss 0.0005313389630999564\n",
      "testing loss 0.0026241175769266822\n",
      "epochs 9040\n",
      "training loss 0.000554105126540287\n",
      "epochs 9041\n",
      "training loss 0.0004884268176291806\n",
      "epochs 9042\n",
      "training loss 0.00047377515950460994\n",
      "epochs 9043\n",
      "training loss 0.0008660510888657218\n",
      "epochs 9044\n",
      "training loss 0.0010488936765151986\n",
      "epochs 9045\n",
      "training loss 0.0008498540230054341\n",
      "epochs 9046\n",
      "training loss 0.0007996717483827159\n",
      "epochs 9047\n",
      "training loss 0.00077429449507375\n",
      "epochs 9048\n",
      "training loss 0.0004522497829412164\n",
      "epochs 9049\n",
      "training loss 0.00045759096709122504\n",
      "testing loss 0.0026219740538058656\n",
      "epochs 9050\n",
      "training loss 0.0004199688036403814\n",
      "epochs 9051\n",
      "training loss 0.0005275826372374641\n",
      "epochs 9052\n",
      "training loss 0.0004717771995898993\n",
      "epochs 9053\n",
      "training loss 0.0004763824625579799\n",
      "epochs 9054\n",
      "training loss 0.00046881906423536566\n",
      "epochs 9055\n",
      "training loss 0.00047593065809973693\n",
      "epochs 9056\n",
      "training loss 0.0004876072235981506\n",
      "epochs 9057\n",
      "training loss 0.0005373645042731656\n",
      "epochs 9058\n",
      "training loss 0.0005307239698816521\n",
      "epochs 9059\n",
      "training loss 0.0005330518736414849\n",
      "testing loss 0.00257813414609958\n",
      "epochs 9060\n",
      "training loss 0.0006166950823055541\n",
      "epochs 9061\n",
      "training loss 0.0005168039813470718\n",
      "epochs 9062\n",
      "training loss 0.000640778905746745\n",
      "epochs 9063\n",
      "training loss 0.0006069472070399808\n",
      "epochs 9064\n",
      "training loss 0.0005679657153069044\n",
      "epochs 9065\n",
      "training loss 0.0005589407941398684\n",
      "epochs 9066\n",
      "training loss 0.0005838837030330973\n",
      "epochs 9067\n",
      "training loss 0.0011081807812503156\n",
      "epochs 9068\n",
      "training loss 0.0011681135785256407\n",
      "epochs 9069\n",
      "training loss 0.000934080957112364\n",
      "testing loss 0.0026330027575703695\n",
      "epochs 9070\n",
      "training loss 0.0008477047630684807\n",
      "epochs 9071\n",
      "training loss 0.0008749604645527696\n",
      "epochs 9072\n",
      "training loss 0.0008458470643319666\n",
      "epochs 9073\n",
      "training loss 0.001042171373010095\n",
      "epochs 9074\n",
      "training loss 0.0006070810252139599\n",
      "epochs 9075\n",
      "training loss 0.0004986327601169267\n",
      "epochs 9076\n",
      "training loss 0.0004783162675015232\n",
      "epochs 9077\n",
      "training loss 0.0005625429465739753\n",
      "epochs 9078\n",
      "training loss 0.0004673521757149916\n",
      "epochs 9079\n",
      "training loss 0.0004909520779133387\n",
      "testing loss 0.0025245893485712034\n",
      "epochs 9080\n",
      "training loss 0.00045164707897013014\n",
      "epochs 9081\n",
      "training loss 0.0004533504347860428\n",
      "epochs 9082\n",
      "training loss 0.00048022916470442\n",
      "epochs 9083\n",
      "training loss 0.000498366470772088\n",
      "epochs 9084\n",
      "training loss 0.0005418989644775105\n",
      "epochs 9085\n",
      "training loss 0.0004445308404794178\n",
      "epochs 9086\n",
      "training loss 0.0005893310557450748\n",
      "epochs 9087\n",
      "training loss 0.0006895454615137984\n",
      "epochs 9088\n",
      "training loss 0.0005740272490722396\n",
      "epochs 9089\n",
      "training loss 0.0007232688371789865\n",
      "testing loss 0.002846244770079085\n",
      "epochs 9090\n",
      "training loss 0.0010038665164966917\n",
      "epochs 9091\n",
      "training loss 0.0009739135619710089\n",
      "epochs 9092\n",
      "training loss 0.0006374993698924814\n",
      "epochs 9093\n",
      "training loss 0.00047297285244117933\n",
      "epochs 9094\n",
      "training loss 0.0005016468780604969\n",
      "epochs 9095\n",
      "training loss 0.0004293008354148547\n",
      "epochs 9096\n",
      "training loss 0.0004319489551750564\n",
      "epochs 9097\n",
      "training loss 0.000492672771031439\n",
      "epochs 9098\n",
      "training loss 0.0004306904353076836\n",
      "epochs 9099\n",
      "training loss 0.000485058029040363\n",
      "testing loss 0.0025515776645253473\n",
      "epochs 9100\n",
      "training loss 0.0006109181866559305\n",
      "epochs 9101\n",
      "training loss 0.0005566311318471202\n",
      "epochs 9102\n",
      "training loss 0.00045305698245585443\n",
      "epochs 9103\n",
      "training loss 0.00043255401151410464\n",
      "epochs 9104\n",
      "training loss 0.00048735145179379315\n",
      "epochs 9105\n",
      "training loss 0.0004899607374903245\n",
      "epochs 9106\n",
      "training loss 0.0004688700509617122\n",
      "epochs 9107\n",
      "training loss 0.00044429792884926917\n",
      "epochs 9108\n",
      "training loss 0.0004584930707469843\n",
      "epochs 9109\n",
      "training loss 0.0004956400345502801\n",
      "testing loss 0.0026654633664499627\n",
      "epochs 9110\n",
      "training loss 0.0006609102066197237\n",
      "epochs 9111\n",
      "training loss 0.0005537450955267769\n",
      "epochs 9112\n",
      "training loss 0.0005466937030683977\n",
      "epochs 9113\n",
      "training loss 0.0011736664608422394\n",
      "epochs 9114\n",
      "training loss 0.0009047150731123531\n",
      "epochs 9115\n",
      "training loss 0.0006428409345153617\n",
      "epochs 9116\n",
      "training loss 0.0005291446359257715\n",
      "epochs 9117\n",
      "training loss 0.000491482498098411\n",
      "epochs 9118\n",
      "training loss 0.0004422302226664068\n",
      "epochs 9119\n",
      "training loss 0.0004439998962484742\n",
      "testing loss 0.0025611754770205747\n",
      "epochs 9120\n",
      "training loss 0.0004330520387820328\n",
      "epochs 9121\n",
      "training loss 0.0005134940351745945\n",
      "epochs 9122\n",
      "training loss 0.0004556033473959374\n",
      "epochs 9123\n",
      "training loss 0.00045614716321609256\n",
      "epochs 9124\n",
      "training loss 0.0004737011465176057\n",
      "epochs 9125\n",
      "training loss 0.0004291350722042589\n",
      "epochs 9126\n",
      "training loss 0.0004979088913265752\n",
      "epochs 9127\n",
      "training loss 0.0004325584685578546\n",
      "epochs 9128\n",
      "training loss 0.0004966027164579819\n",
      "epochs 9129\n",
      "training loss 0.0005142834807334236\n",
      "testing loss 0.0026102751503361667\n",
      "epochs 9130\n",
      "training loss 0.00046572234838249837\n",
      "epochs 9131\n",
      "training loss 0.00045320613702156195\n",
      "epochs 9132\n",
      "training loss 0.00048138969648618105\n",
      "epochs 9133\n",
      "training loss 0.0007505045078856174\n",
      "epochs 9134\n",
      "training loss 0.00048825416813383734\n",
      "epochs 9135\n",
      "training loss 0.0004271461775135051\n",
      "epochs 9136\n",
      "training loss 0.0004383090342639869\n",
      "epochs 9137\n",
      "training loss 0.0004717607217795558\n",
      "epochs 9138\n",
      "training loss 0.00048618137284987367\n",
      "epochs 9139\n",
      "training loss 0.0007269707508650566\n",
      "testing loss 0.002616377517247427\n",
      "epochs 9140\n",
      "training loss 0.0007189691083018858\n",
      "epochs 9141\n",
      "training loss 0.0005192629211669997\n",
      "epochs 9142\n",
      "training loss 0.0004500912322035048\n",
      "epochs 9143\n",
      "training loss 0.0004415826630137442\n",
      "epochs 9144\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss 0.0004504084819573966\n",
      "epochs 9145\n",
      "training loss 0.0005261896032695644\n",
      "epochs 9146\n",
      "training loss 0.00045214020277339526\n",
      "epochs 9147\n",
      "training loss 0.0005168388385359639\n",
      "epochs 9148\n",
      "training loss 0.0004646293870258318\n",
      "epochs 9149\n",
      "training loss 0.0004595118375052061\n",
      "testing loss 0.0025770789741353523\n",
      "epochs 9150\n",
      "training loss 0.0004341736788674623\n",
      "epochs 9151\n",
      "training loss 0.00045427774890512796\n",
      "epochs 9152\n",
      "training loss 0.0005002916083029984\n",
      "epochs 9153\n",
      "training loss 0.00046006414549578105\n",
      "epochs 9154\n",
      "training loss 0.0005001400679308854\n",
      "epochs 9155\n",
      "training loss 0.0004376252927558389\n",
      "epochs 9156\n",
      "training loss 0.0004968824507551845\n",
      "epochs 9157\n",
      "training loss 0.0004641922842923518\n",
      "epochs 9158\n",
      "training loss 0.0004680903073726505\n",
      "epochs 9159\n",
      "training loss 0.00047557373447301243\n",
      "testing loss 0.0025649395307314627\n",
      "epochs 9160\n",
      "training loss 0.00045660697419117106\n",
      "epochs 9161\n",
      "training loss 0.0004562887368974273\n",
      "epochs 9162\n",
      "training loss 0.0004425745295614746\n",
      "epochs 9163\n",
      "training loss 0.000463905988850611\n",
      "epochs 9164\n",
      "training loss 0.00044627691076652324\n",
      "epochs 9165\n",
      "training loss 0.0008691396064614724\n",
      "epochs 9166\n",
      "training loss 0.0007586609864979699\n",
      "epochs 9167\n",
      "training loss 0.0007613179509918627\n",
      "epochs 9168\n",
      "training loss 0.0008848786528687924\n",
      "epochs 9169\n",
      "training loss 0.0005045765090880966\n",
      "testing loss 0.002532996609229066\n",
      "epochs 9170\n",
      "training loss 0.000427215825943248\n",
      "epochs 9171\n",
      "training loss 0.00040872599490802156\n",
      "epochs 9172\n",
      "training loss 0.00047109005178358845\n",
      "epochs 9173\n",
      "training loss 0.00045036326468947673\n",
      "epochs 9174\n",
      "training loss 0.00043395040591288426\n",
      "epochs 9175\n",
      "training loss 0.0004187142399477979\n",
      "epochs 9176\n",
      "training loss 0.0004245820848906758\n",
      "epochs 9177\n",
      "training loss 0.000487434644341231\n",
      "epochs 9178\n",
      "training loss 0.0004934453238070713\n",
      "epochs 9179\n",
      "training loss 0.0004892445288458415\n",
      "testing loss 0.0025880561542122606\n",
      "epochs 9180\n",
      "training loss 0.0004728791097109701\n",
      "epochs 9181\n",
      "training loss 0.00044640171551074844\n",
      "epochs 9182\n",
      "training loss 0.00042087811199802405\n",
      "epochs 9183\n",
      "training loss 0.0004796894741531937\n",
      "epochs 9184\n",
      "training loss 0.0004464035637366747\n",
      "epochs 9185\n",
      "training loss 0.0004820261090621635\n",
      "epochs 9186\n",
      "training loss 0.0004924487409791923\n",
      "epochs 9187\n",
      "training loss 0.00047621821115426095\n",
      "epochs 9188\n",
      "training loss 0.0005142177351804218\n",
      "epochs 9189\n",
      "training loss 0.00043174695490900495\n",
      "testing loss 0.002649200579039224\n",
      "epochs 9190\n",
      "training loss 0.00046080220833040014\n",
      "epochs 9191\n",
      "training loss 0.00041442156755535275\n",
      "epochs 9192\n",
      "training loss 0.00046834379284554884\n",
      "epochs 9193\n",
      "training loss 0.0004257709883955961\n",
      "epochs 9194\n",
      "training loss 0.0005039524734689002\n",
      "epochs 9195\n",
      "training loss 0.0004198687263597426\n",
      "epochs 9196\n",
      "training loss 0.0004156630057300155\n",
      "epochs 9197\n",
      "training loss 0.0005423932790166718\n",
      "epochs 9198\n",
      "training loss 0.0005577449912579\n",
      "epochs 9199\n",
      "training loss 0.0005926903134486482\n",
      "testing loss 0.002600385083780617\n",
      "epochs 9200\n",
      "training loss 0.0006006150276436949\n",
      "epochs 9201\n",
      "training loss 0.0005991983918404478\n",
      "epochs 9202\n",
      "training loss 0.0011904238053388034\n",
      "epochs 9203\n",
      "training loss 0.0010394763555674953\n",
      "epochs 9204\n",
      "training loss 0.0005934512985574427\n",
      "epochs 9205\n",
      "training loss 0.000529232565409116\n",
      "epochs 9206\n",
      "training loss 0.0005300433170949151\n",
      "epochs 9207\n",
      "training loss 0.0005088860883291153\n",
      "epochs 9208\n",
      "training loss 0.00045168687332751325\n",
      "epochs 9209\n",
      "training loss 0.0004454861446987911\n",
      "testing loss 0.0025679609521146837\n",
      "epochs 9210\n",
      "training loss 0.0004989486797196128\n",
      "epochs 9211\n",
      "training loss 0.00041829462534334724\n",
      "epochs 9212\n",
      "training loss 0.0004270852553675172\n",
      "epochs 9213\n",
      "training loss 0.0004109564033127461\n",
      "epochs 9214\n",
      "training loss 0.0003975787925683273\n",
      "epochs 9215\n",
      "training loss 0.0004634726273304978\n",
      "epochs 9216\n",
      "training loss 0.0004326926159412716\n",
      "epochs 9217\n",
      "training loss 0.0004585177983874936\n",
      "epochs 9218\n",
      "training loss 0.000452521658629196\n",
      "epochs 9219\n",
      "training loss 0.000435231343337397\n",
      "testing loss 0.002562598296414717\n",
      "epochs 9220\n",
      "training loss 0.00042625121703466237\n",
      "epochs 9221\n",
      "training loss 0.00047589155741313354\n",
      "epochs 9222\n",
      "training loss 0.00045910163170914236\n",
      "epochs 9223\n",
      "training loss 0.0004415706559586817\n",
      "epochs 9224\n",
      "training loss 0.00048337340950088345\n",
      "epochs 9225\n",
      "training loss 0.0004663113279956022\n",
      "epochs 9226\n",
      "training loss 0.0004300490108132504\n",
      "epochs 9227\n",
      "training loss 0.0005955932061945153\n",
      "epochs 9228\n",
      "training loss 0.000458098989092224\n",
      "epochs 9229\n",
      "training loss 0.00043526068017542036\n",
      "testing loss 0.002607960016995087\n",
      "epochs 9230\n",
      "training loss 0.0004611954716279095\n",
      "epochs 9231\n",
      "training loss 0.00047092323676586764\n",
      "epochs 9232\n",
      "training loss 0.00048723248727718723\n",
      "epochs 9233\n",
      "training loss 0.0005263738444048096\n",
      "epochs 9234\n",
      "training loss 0.0008126697901107008\n",
      "epochs 9235\n",
      "training loss 0.0007391999778903931\n",
      "epochs 9236\n",
      "training loss 0.0007571944750004694\n",
      "epochs 9237\n",
      "training loss 0.0005007095083468353\n",
      "epochs 9238\n",
      "training loss 0.00043442757581898487\n",
      "epochs 9239\n",
      "training loss 0.0004237979402539878\n",
      "testing loss 0.002541166173330515\n",
      "epochs 9240\n",
      "training loss 0.00046340077019425385\n",
      "epochs 9241\n",
      "training loss 0.0004246863203479181\n",
      "epochs 9242\n",
      "training loss 0.00044727250866416425\n",
      "epochs 9243\n",
      "training loss 0.0004888380023843317\n",
      "epochs 9244\n",
      "training loss 0.000431341917342846\n",
      "epochs 9245\n",
      "training loss 0.00045007234319830797\n",
      "epochs 9246\n",
      "training loss 0.0004104361539433419\n",
      "epochs 9247\n",
      "training loss 0.00045584589690550323\n",
      "epochs 9248\n",
      "training loss 0.0004619365426397523\n",
      "epochs 9249\n",
      "training loss 0.00044123016144425003\n",
      "testing loss 0.0025227589219815184\n",
      "epochs 9250\n",
      "training loss 0.00044870143110501526\n",
      "epochs 9251\n",
      "training loss 0.00046440096238364767\n",
      "epochs 9252\n",
      "training loss 0.0004128768944923163\n",
      "epochs 9253\n",
      "training loss 0.0004506118626207804\n",
      "epochs 9254\n",
      "training loss 0.0004807411323090602\n",
      "epochs 9255\n",
      "training loss 0.00047269421342992446\n",
      "epochs 9256\n",
      "training loss 0.0004146107995994446\n",
      "epochs 9257\n",
      "training loss 0.0004117423174888643\n",
      "epochs 9258\n",
      "training loss 0.00044647776912742134\n",
      "epochs 9259\n",
      "training loss 0.000635783040535489\n",
      "testing loss 0.0026488027482537936\n",
      "epochs 9260\n",
      "training loss 0.0012608485640129951\n",
      "epochs 9261\n",
      "training loss 0.0006904902064388669\n",
      "epochs 9262\n",
      "training loss 0.0005308310322585235\n",
      "epochs 9263\n",
      "training loss 0.000451222103776263\n",
      "epochs 9264\n",
      "training loss 0.00048531071199061726\n",
      "epochs 9265\n",
      "training loss 0.0004497252043855368\n",
      "epochs 9266\n",
      "training loss 0.0004522295086290744\n",
      "epochs 9267\n",
      "training loss 0.00046703886408974504\n",
      "epochs 9268\n",
      "training loss 0.00041787360915503715\n",
      "epochs 9269\n",
      "training loss 0.0004553974692877467\n",
      "testing loss 0.0025769593833998533\n",
      "epochs 9270\n",
      "training loss 0.00046839568524063765\n",
      "epochs 9271\n",
      "training loss 0.0004402227024087756\n",
      "epochs 9272\n",
      "training loss 0.0004217135224128312\n",
      "epochs 9273\n",
      "training loss 0.0004682637978271556\n",
      "epochs 9274\n",
      "training loss 0.0004573231081741559\n",
      "epochs 9275\n",
      "training loss 0.00048604128810812047\n",
      "epochs 9276\n",
      "training loss 0.0004333558135066538\n",
      "epochs 9277\n",
      "training loss 0.00042955971562330496\n",
      "epochs 9278\n",
      "training loss 0.0004643493361691845\n",
      "epochs 9279\n",
      "training loss 0.00043569121066244505\n",
      "testing loss 0.0025005383686994777\n",
      "epochs 9280\n",
      "training loss 0.0004675911362091855\n",
      "epochs 9281\n",
      "training loss 0.00046682709280973283\n",
      "epochs 9282\n",
      "training loss 0.00047877338385113197\n",
      "epochs 9283\n",
      "training loss 0.0004576541791071317\n",
      "epochs 9284\n",
      "training loss 0.0004536409913293315\n",
      "epochs 9285\n",
      "training loss 0.00046031369120349663\n",
      "epochs 9286\n",
      "training loss 0.00044213429414122267\n",
      "epochs 9287\n",
      "training loss 0.0004990283689266325\n",
      "epochs 9288\n",
      "training loss 0.0006064408797399908\n",
      "epochs 9289\n",
      "training loss 0.0006101473276082307\n",
      "testing loss 0.0025621293885022376\n",
      "epochs 9290\n",
      "training loss 0.0008127065592620233\n",
      "epochs 9291\n",
      "training loss 0.0007309678982303543\n",
      "epochs 9292\n",
      "training loss 0.0005407930221932298\n",
      "epochs 9293\n",
      "training loss 0.00048794193817146893\n",
      "epochs 9294\n",
      "training loss 0.00047254982233857083\n",
      "epochs 9295\n",
      "training loss 0.0004345053644308758\n",
      "epochs 9296\n",
      "training loss 0.0004533795022588268\n",
      "epochs 9297\n",
      "training loss 0.00042857134445445854\n",
      "epochs 9298\n",
      "training loss 0.00047987538468946154\n",
      "epochs 9299\n",
      "training loss 0.00043898709778288964\n",
      "testing loss 0.0025113708432928945\n",
      "epochs 9300\n",
      "training loss 0.0004567760982749542\n",
      "epochs 9301\n",
      "training loss 0.000462977444320651\n",
      "epochs 9302\n",
      "training loss 0.00041710478821585354\n",
      "epochs 9303\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss 0.0004556331843509987\n",
      "epochs 9304\n",
      "training loss 0.0004290491249217683\n",
      "epochs 9305\n",
      "training loss 0.0004390382983206593\n",
      "epochs 9306\n",
      "training loss 0.0004347106098182539\n",
      "epochs 9307\n",
      "training loss 0.0004379271008488283\n",
      "epochs 9308\n",
      "training loss 0.0004282942544039067\n",
      "epochs 9309\n",
      "training loss 0.0004433885880262594\n",
      "testing loss 0.0024544911938785504\n",
      "epochs 9310\n",
      "training loss 0.0004603814067496666\n",
      "epochs 9311\n",
      "training loss 0.0004560276475843993\n",
      "epochs 9312\n",
      "training loss 0.00045529830117007903\n",
      "epochs 9313\n",
      "training loss 0.00044178096333371425\n",
      "epochs 9314\n",
      "training loss 0.0004967452201349689\n",
      "epochs 9315\n",
      "training loss 0.000572538305288761\n",
      "epochs 9316\n",
      "training loss 0.0004255765266850942\n",
      "epochs 9317\n",
      "training loss 0.0005940260689551334\n",
      "epochs 9318\n",
      "training loss 0.0019099613940725415\n",
      "epochs 9319\n",
      "training loss 0.0011324422607533803\n",
      "testing loss 0.002741585518249991\n",
      "epochs 9320\n",
      "training loss 0.000887413218151778\n",
      "epochs 9321\n",
      "training loss 0.0005770818530978199\n",
      "epochs 9322\n",
      "training loss 0.000438307077761196\n",
      "epochs 9323\n",
      "training loss 0.00044219079055882833\n",
      "epochs 9324\n",
      "training loss 0.00044371341751452457\n",
      "epochs 9325\n",
      "training loss 0.0004371659192670629\n",
      "epochs 9326\n",
      "training loss 0.0004178956365527721\n",
      "epochs 9327\n",
      "training loss 0.00040787570018393463\n",
      "epochs 9328\n",
      "training loss 0.00041433426977551365\n",
      "epochs 9329\n",
      "training loss 0.0004409948583461605\n",
      "testing loss 0.0025068383489682583\n",
      "epochs 9330\n",
      "training loss 0.0004402546998145948\n",
      "epochs 9331\n",
      "training loss 0.0004467391396595284\n",
      "epochs 9332\n",
      "training loss 0.0004860517030332724\n",
      "epochs 9333\n",
      "training loss 0.0005051062515254576\n",
      "epochs 9334\n",
      "training loss 0.0004074898948977874\n",
      "epochs 9335\n",
      "training loss 0.00042865333096216233\n",
      "epochs 9336\n",
      "training loss 0.00043559322912298357\n",
      "epochs 9337\n",
      "training loss 0.00046578335673420895\n",
      "epochs 9338\n",
      "training loss 0.00047598669650797425\n",
      "epochs 9339\n",
      "training loss 0.0004165587072065355\n",
      "testing loss 0.002527649515202758\n",
      "epochs 9340\n",
      "training loss 0.00040911475157911543\n",
      "epochs 9341\n",
      "training loss 0.00041011262523706743\n",
      "epochs 9342\n",
      "training loss 0.0004491518070428748\n",
      "epochs 9343\n",
      "training loss 0.0006489748111147558\n",
      "epochs 9344\n",
      "training loss 0.0005957975602881434\n",
      "epochs 9345\n",
      "training loss 0.000589843769433928\n",
      "epochs 9346\n",
      "training loss 0.0005175672549988628\n",
      "epochs 9347\n",
      "training loss 0.0004479466593544081\n",
      "epochs 9348\n",
      "training loss 0.00047790083579866266\n",
      "epochs 9349\n",
      "training loss 0.00045305425439194115\n",
      "testing loss 0.0025076899769986773\n",
      "epochs 9350\n",
      "training loss 0.0004122416337291741\n",
      "epochs 9351\n",
      "training loss 0.0004010000196250161\n",
      "epochs 9352\n",
      "training loss 0.0004898931817498375\n",
      "epochs 9353\n",
      "training loss 0.0004618988303562462\n",
      "epochs 9354\n",
      "training loss 0.0004485041119114391\n",
      "epochs 9355\n",
      "training loss 0.00048324945164273997\n",
      "epochs 9356\n",
      "training loss 0.00043020488522341053\n",
      "epochs 9357\n",
      "training loss 0.0004486008879419354\n",
      "epochs 9358\n",
      "training loss 0.0004306194245709831\n",
      "epochs 9359\n",
      "training loss 0.0004385942185851731\n",
      "testing loss 0.0025821106895599646\n",
      "epochs 9360\n",
      "training loss 0.0004495613156296992\n",
      "epochs 9361\n",
      "training loss 0.0004221823861830271\n",
      "epochs 9362\n",
      "training loss 0.00043693494671279154\n",
      "epochs 9363\n",
      "training loss 0.0004565293433945796\n",
      "epochs 9364\n",
      "training loss 0.0004573866925687079\n",
      "epochs 9365\n",
      "training loss 0.00046367657052050134\n",
      "epochs 9366\n",
      "training loss 0.0005146537399298786\n",
      "epochs 9367\n",
      "training loss 0.0009345013693740767\n",
      "epochs 9368\n",
      "training loss 0.0007376320250360663\n",
      "epochs 9369\n",
      "training loss 0.0005702096243505012\n",
      "testing loss 0.002554668000476527\n",
      "epochs 9370\n",
      "training loss 0.0005520533785007407\n",
      "epochs 9371\n",
      "training loss 0.0004566942232287288\n",
      "epochs 9372\n",
      "training loss 0.00045811953015999137\n",
      "epochs 9373\n",
      "training loss 0.00041675829145658227\n",
      "epochs 9374\n",
      "training loss 0.0004451758543430689\n",
      "epochs 9375\n",
      "training loss 0.0004000543391754522\n",
      "epochs 9376\n",
      "training loss 0.000490540955081231\n",
      "epochs 9377\n",
      "training loss 0.00043406788538221416\n",
      "epochs 9378\n",
      "training loss 0.0004394660113976651\n",
      "epochs 9379\n",
      "training loss 0.0004535855054957962\n",
      "testing loss 0.0025603058306229508\n",
      "epochs 9380\n",
      "training loss 0.00043099601225825567\n",
      "epochs 9381\n",
      "training loss 0.00043899898753801535\n",
      "epochs 9382\n",
      "training loss 0.00044133135351659533\n",
      "epochs 9383\n",
      "training loss 0.0004452081830371709\n",
      "epochs 9384\n",
      "training loss 0.0004558846474172955\n",
      "epochs 9385\n",
      "training loss 0.0004304851815606946\n",
      "epochs 9386\n",
      "training loss 0.00044132122507398115\n",
      "epochs 9387\n",
      "training loss 0.00044419830661453875\n",
      "epochs 9388\n",
      "training loss 0.0004360890511786395\n",
      "epochs 9389\n",
      "training loss 0.00043051594784794696\n",
      "testing loss 0.0025078242744570136\n",
      "epochs 9390\n",
      "training loss 0.00044939931778245715\n",
      "epochs 9391\n",
      "training loss 0.000452088969151028\n",
      "epochs 9392\n",
      "training loss 0.00047008374376480093\n",
      "epochs 9393\n",
      "training loss 0.00046606847134774044\n",
      "epochs 9394\n",
      "training loss 0.0004040442882080939\n",
      "epochs 9395\n",
      "training loss 0.00040064849767807055\n",
      "epochs 9396\n",
      "training loss 0.00043883261385467185\n",
      "epochs 9397\n",
      "training loss 0.0005118181916784585\n",
      "epochs 9398\n",
      "training loss 0.000895433777806669\n",
      "epochs 9399\n",
      "training loss 0.000521127451165214\n",
      "testing loss 0.002545611272774082\n",
      "epochs 9400\n",
      "training loss 0.0005056101884190446\n",
      "epochs 9401\n",
      "training loss 0.00041950195829602\n",
      "epochs 9402\n",
      "training loss 0.00042914699451321325\n",
      "epochs 9403\n",
      "training loss 0.0004216329404524468\n",
      "epochs 9404\n",
      "training loss 0.000437142131839508\n",
      "epochs 9405\n",
      "training loss 0.0004779241243476405\n",
      "epochs 9406\n",
      "training loss 0.0004503302978341805\n",
      "epochs 9407\n",
      "training loss 0.00042877184919054735\n",
      "epochs 9408\n",
      "training loss 0.00047196613904761044\n",
      "epochs 9409\n",
      "training loss 0.00044693283140121484\n",
      "testing loss 0.002469281384437378\n",
      "epochs 9410\n",
      "training loss 0.00042885763206735743\n",
      "epochs 9411\n",
      "training loss 0.000421508794171328\n",
      "epochs 9412\n",
      "training loss 0.0004372733841437173\n",
      "epochs 9413\n",
      "training loss 0.00042439580179883966\n",
      "epochs 9414\n",
      "training loss 0.0004541653435426767\n",
      "epochs 9415\n",
      "training loss 0.0004668516768772427\n",
      "epochs 9416\n",
      "training loss 0.000590475524777807\n",
      "epochs 9417\n",
      "training loss 0.0005242713651157021\n",
      "epochs 9418\n",
      "training loss 0.0005731482236040332\n",
      "epochs 9419\n",
      "training loss 0.0004611579077827849\n",
      "testing loss 0.0024327108766949664\n",
      "epochs 9420\n",
      "training loss 0.00043914128651511273\n",
      "epochs 9421\n",
      "training loss 0.000451613543705525\n",
      "epochs 9422\n",
      "training loss 0.00043852500113981317\n",
      "epochs 9423\n",
      "training loss 0.00045230852818260915\n",
      "epochs 9424\n",
      "training loss 0.00047480732384406734\n",
      "epochs 9425\n",
      "training loss 0.0004742607295811799\n",
      "epochs 9426\n",
      "training loss 0.00047492401118497834\n",
      "epochs 9427\n",
      "training loss 0.0005172791583042473\n",
      "epochs 9428\n",
      "training loss 0.0004979042705406058\n",
      "epochs 9429\n",
      "training loss 0.0006224247469056517\n",
      "testing loss 0.002565168824743691\n",
      "epochs 9430\n",
      "training loss 0.0005807445208877495\n",
      "epochs 9431\n",
      "training loss 0.0005255551665694394\n",
      "epochs 9432\n",
      "training loss 0.0005677979088127953\n",
      "epochs 9433\n",
      "training loss 0.0005704078914089508\n",
      "epochs 9434\n",
      "training loss 0.0005878038369745474\n",
      "epochs 9435\n",
      "training loss 0.000640691497301581\n",
      "epochs 9436\n",
      "training loss 0.0006425092315250345\n",
      "epochs 9437\n",
      "training loss 0.0004888725841926032\n",
      "epochs 9438\n",
      "training loss 0.00048765737347879467\n",
      "epochs 9439\n",
      "training loss 0.000440024146656251\n",
      "testing loss 0.0025478859835779888\n",
      "epochs 9440\n",
      "training loss 0.00043740415765010783\n",
      "epochs 9441\n",
      "training loss 0.0004667222158739904\n",
      "epochs 9442\n",
      "training loss 0.0004189319576092183\n",
      "epochs 9443\n",
      "training loss 0.0004676101807739138\n",
      "epochs 9444\n",
      "training loss 0.00045759497404291005\n",
      "epochs 9445\n",
      "training loss 0.0004564006153832396\n",
      "epochs 9446\n",
      "training loss 0.0004291931411133241\n",
      "epochs 9447\n",
      "training loss 0.0004130516349519164\n",
      "epochs 9448\n",
      "training loss 0.0004453049197907653\n",
      "epochs 9449\n",
      "training loss 0.00043281933406331095\n",
      "testing loss 0.0025112705073213693\n",
      "epochs 9450\n",
      "training loss 0.0004285481076996836\n",
      "epochs 9451\n",
      "training loss 0.0005566603570025114\n",
      "epochs 9452\n",
      "training loss 0.0005926928387588247\n",
      "epochs 9453\n",
      "training loss 0.0004532561735388056\n",
      "epochs 9454\n",
      "training loss 0.0005083000581990361\n",
      "epochs 9455\n",
      "training loss 0.0005915611581615028\n",
      "epochs 9456\n",
      "training loss 0.0005748881876155859\n",
      "epochs 9457\n",
      "training loss 0.0005809470463939022\n",
      "epochs 9458\n",
      "training loss 0.0005611500141156361\n",
      "epochs 9459\n",
      "training loss 0.0005803860560849331\n",
      "testing loss 0.0024871558358839957\n",
      "epochs 9460\n",
      "training loss 0.0005912269975340396\n",
      "epochs 9461\n",
      "training loss 0.0005942521464928141\n",
      "epochs 9462\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss 0.0005833316056693318\n",
      "epochs 9463\n",
      "training loss 0.0005746801173431929\n",
      "epochs 9464\n",
      "training loss 0.0005397937707917901\n",
      "epochs 9465\n",
      "training loss 0.0005535923479649303\n",
      "epochs 9466\n",
      "training loss 0.0006115001669305017\n",
      "epochs 9467\n",
      "training loss 0.0005854901189436021\n",
      "epochs 9468\n",
      "training loss 0.0005705372277699626\n",
      "epochs 9469\n",
      "training loss 0.0005464431047131729\n",
      "testing loss 0.0025276715994370005\n",
      "epochs 9470\n",
      "training loss 0.0005936764638360001\n",
      "epochs 9471\n",
      "training loss 0.0006139644485860101\n",
      "epochs 9472\n",
      "training loss 0.0006366774836030724\n",
      "epochs 9473\n",
      "training loss 0.0005315566031806494\n",
      "epochs 9474\n",
      "training loss 0.0005412473228578187\n",
      "epochs 9475\n",
      "training loss 0.000570030437285607\n",
      "epochs 9476\n",
      "training loss 0.0005320956666283677\n",
      "epochs 9477\n",
      "training loss 0.0004991424942016177\n",
      "epochs 9478\n",
      "training loss 0.0005567757827498721\n",
      "epochs 9479\n",
      "training loss 0.0005536783485012383\n",
      "testing loss 0.002534298540393538\n",
      "epochs 9480\n",
      "training loss 0.000534720857524013\n",
      "epochs 9481\n",
      "training loss 0.0005423858019418585\n",
      "epochs 9482\n",
      "training loss 0.0005750432076204376\n",
      "epochs 9483\n",
      "training loss 0.0005348846962106468\n",
      "epochs 9484\n",
      "training loss 0.0005476417771974397\n",
      "epochs 9485\n",
      "training loss 0.0005281288222332647\n",
      "epochs 9486\n",
      "training loss 0.000564014560928339\n",
      "epochs 9487\n",
      "training loss 0.0005448455364113577\n",
      "epochs 9488\n",
      "training loss 0.000855690714730499\n",
      "epochs 9489\n",
      "training loss 0.0006613552732758314\n",
      "testing loss 0.002481528764659975\n",
      "epochs 9490\n",
      "training loss 0.0005616754748841527\n",
      "epochs 9491\n",
      "training loss 0.0005923423936978367\n",
      "epochs 9492\n",
      "training loss 0.000551454136647018\n",
      "epochs 9493\n",
      "training loss 0.0005224571824884098\n",
      "epochs 9494\n",
      "training loss 0.0005590695989357823\n",
      "epochs 9495\n",
      "training loss 0.0005234593332152089\n",
      "epochs 9496\n",
      "training loss 0.0005362129982173058\n",
      "epochs 9497\n",
      "training loss 0.000507946956639481\n",
      "epochs 9498\n",
      "training loss 0.0005732793734698361\n",
      "epochs 9499\n",
      "training loss 0.0005759655057960742\n",
      "testing loss 0.0023979882896276758\n",
      "epochs 9500\n",
      "training loss 0.0005156025435566041\n",
      "epochs 9501\n",
      "training loss 0.0005919605750172317\n",
      "epochs 9502\n",
      "training loss 0.0005348381601145921\n",
      "epochs 9503\n",
      "training loss 0.0005574946441775397\n",
      "epochs 9504\n",
      "training loss 0.0005240381439587974\n",
      "epochs 9505\n",
      "training loss 0.0005380992551538017\n",
      "epochs 9506\n",
      "training loss 0.0005327867566325523\n",
      "epochs 9507\n",
      "training loss 0.000532201818957653\n",
      "epochs 9508\n",
      "training loss 0.0005382182785415297\n",
      "epochs 9509\n",
      "training loss 0.0005342213022607551\n",
      "testing loss 0.002533607619999518\n",
      "epochs 9510\n",
      "training loss 0.0005779167619359744\n",
      "epochs 9511\n",
      "training loss 0.0005306854405678175\n",
      "epochs 9512\n",
      "training loss 0.0005218664916319982\n",
      "epochs 9513\n",
      "training loss 0.0005616166551581847\n",
      "epochs 9514\n",
      "training loss 0.0005694352527181576\n",
      "epochs 9515\n",
      "training loss 0.0006444364256971434\n",
      "epochs 9516\n",
      "training loss 0.0005453376283113332\n",
      "epochs 9517\n",
      "training loss 0.0005715408756632618\n",
      "epochs 9518\n",
      "training loss 0.0005709957813976423\n",
      "epochs 9519\n",
      "training loss 0.000541913840161795\n",
      "testing loss 0.0025759879491417436\n",
      "epochs 9520\n",
      "training loss 0.0005474690269886893\n",
      "epochs 9521\n",
      "training loss 0.0005629416345954819\n",
      "epochs 9522\n",
      "training loss 0.0004987775968772708\n",
      "epochs 9523\n",
      "training loss 0.0005364259141890083\n",
      "epochs 9524\n",
      "training loss 0.000533344344756818\n",
      "epochs 9525\n",
      "training loss 0.000523022795883347\n",
      "epochs 9526\n",
      "training loss 0.0005649645793524863\n",
      "epochs 9527\n",
      "training loss 0.0005735730610191284\n",
      "epochs 9528\n",
      "training loss 0.000568072334535938\n",
      "epochs 9529\n",
      "training loss 0.0005577579825355086\n",
      "testing loss 0.0025410925187599838\n",
      "epochs 9530\n",
      "training loss 0.0005527309931660394\n",
      "epochs 9531\n",
      "training loss 0.0005510420578115798\n",
      "epochs 9532\n",
      "training loss 0.0005369564074875028\n",
      "epochs 9533\n",
      "training loss 0.0005450046428947746\n",
      "epochs 9534\n",
      "training loss 0.0005380454449135935\n",
      "epochs 9535\n",
      "training loss 0.0005342518692442689\n",
      "epochs 9536\n",
      "training loss 0.000577380520055965\n",
      "epochs 9537\n",
      "training loss 0.0005465617824818565\n",
      "epochs 9538\n",
      "training loss 0.000536793874227088\n",
      "epochs 9539\n",
      "training loss 0.0005369886396258877\n",
      "testing loss 0.0025614134266358267\n",
      "epochs 9540\n",
      "training loss 0.0005519490850569912\n",
      "epochs 9541\n",
      "training loss 0.0005398025156082274\n",
      "epochs 9542\n",
      "training loss 0.0005123845056884025\n",
      "epochs 9543\n",
      "training loss 0.0005837100773652036\n",
      "epochs 9544\n",
      "training loss 0.0005470266105946137\n",
      "epochs 9545\n",
      "training loss 0.0005396371510935704\n",
      "epochs 9546\n",
      "training loss 0.0005643257055566774\n",
      "epochs 9547\n",
      "training loss 0.000504695192120239\n",
      "epochs 9548\n",
      "training loss 0.0005623742264053589\n",
      "epochs 9549\n",
      "training loss 0.0005086231820170674\n",
      "testing loss 0.0025654134360399653\n",
      "epochs 9550\n",
      "training loss 0.0005584483523746969\n",
      "epochs 9551\n",
      "training loss 0.0005262098772278605\n",
      "epochs 9552\n",
      "training loss 0.0005746553572373164\n",
      "epochs 9553\n",
      "training loss 0.0005074366325166467\n",
      "epochs 9554\n",
      "training loss 0.0005377817559385061\n",
      "epochs 9555\n",
      "training loss 0.0005340860382721712\n",
      "epochs 9556\n",
      "training loss 0.0005378136946501261\n",
      "epochs 9557\n",
      "training loss 0.000548656888859556\n",
      "epochs 9558\n",
      "training loss 0.0005046743930987646\n",
      "epochs 9559\n",
      "training loss 0.0005355921041752611\n",
      "testing loss 0.002609303617826828\n",
      "epochs 9560\n",
      "training loss 0.000553559130630923\n",
      "epochs 9561\n",
      "training loss 0.0005529663221833458\n",
      "epochs 9562\n",
      "training loss 0.0005543994727296086\n",
      "epochs 9563\n",
      "training loss 0.0005315337848487257\n",
      "epochs 9564\n",
      "training loss 0.000539904349822534\n",
      "epochs 9565\n",
      "training loss 0.0005125394039702429\n",
      "epochs 9566\n",
      "training loss 0.0005775052043598706\n",
      "epochs 9567\n",
      "training loss 0.00053034957068743\n",
      "epochs 9568\n",
      "training loss 0.0005361662977155705\n",
      "epochs 9569\n",
      "training loss 0.0005313151743012483\n",
      "testing loss 0.002555281276804732\n",
      "epochs 9570\n",
      "training loss 0.0005407437842178632\n",
      "epochs 9571\n",
      "training loss 0.0005164604675977301\n",
      "epochs 9572\n",
      "training loss 0.0006158882544176387\n",
      "epochs 9573\n",
      "training loss 0.0005827099319277077\n",
      "epochs 9574\n",
      "training loss 0.00051170144692604\n",
      "epochs 9575\n",
      "training loss 0.0005303663384303094\n",
      "epochs 9576\n",
      "training loss 0.0005201136770850687\n",
      "epochs 9577\n",
      "training loss 0.0005387785989316294\n",
      "epochs 9578\n",
      "training loss 0.0005067133488548257\n",
      "epochs 9579\n",
      "training loss 0.0005232294585122685\n",
      "testing loss 0.0026017207716730363\n",
      "epochs 9580\n",
      "training loss 0.0006577324894990058\n",
      "epochs 9581\n",
      "training loss 0.0010515362788437608\n",
      "epochs 9582\n",
      "training loss 0.0008351906336487291\n",
      "epochs 9583\n",
      "training loss 0.0007021632038430512\n",
      "epochs 9584\n",
      "training loss 0.0006142636958515345\n",
      "epochs 9585\n",
      "training loss 0.0008197929562419076\n",
      "epochs 9586\n",
      "training loss 0.0006856481086619843\n",
      "epochs 9587\n",
      "training loss 0.0006193248186179785\n",
      "epochs 9588\n",
      "training loss 0.0006374418846081014\n",
      "epochs 9589\n",
      "training loss 0.0006217219241212566\n",
      "testing loss 0.002602131981964071\n",
      "epochs 9590\n",
      "training loss 0.0006324117909037681\n",
      "epochs 9591\n",
      "training loss 0.0006014537171048104\n",
      "epochs 9592\n",
      "training loss 0.0006247399591396373\n",
      "epochs 9593\n",
      "training loss 0.000600738001500446\n",
      "epochs 9594\n",
      "training loss 0.0006601400254081968\n",
      "epochs 9595\n",
      "training loss 0.0005995482974190344\n",
      "epochs 9596\n",
      "training loss 0.0005838258140104736\n",
      "epochs 9597\n",
      "training loss 0.0006200119723069785\n",
      "epochs 9598\n",
      "training loss 0.0006202272122505045\n",
      "epochs 9599\n",
      "training loss 0.0006317544953563565\n",
      "testing loss 0.002520561609615354\n",
      "epochs 9600\n",
      "training loss 0.0006034301118330753\n",
      "epochs 9601\n",
      "training loss 0.0006067626970260345\n",
      "epochs 9602\n",
      "training loss 0.0006413996002638973\n",
      "epochs 9603\n",
      "training loss 0.0006421885229710852\n",
      "epochs 9604\n",
      "training loss 0.0005723438998839979\n",
      "epochs 9605\n",
      "training loss 0.0006088542452171915\n",
      "epochs 9606\n",
      "training loss 0.000636705332386129\n",
      "epochs 9607\n",
      "training loss 0.0006288951079716402\n",
      "epochs 9608\n",
      "training loss 0.0006158150681474962\n",
      "epochs 9609\n",
      "training loss 0.000578885960447854\n",
      "testing loss 0.0025453334897162115\n",
      "epochs 9610\n",
      "training loss 0.0006204686603260489\n",
      "epochs 9611\n",
      "training loss 0.0006055091783732719\n",
      "epochs 9612\n",
      "training loss 0.0012694812187108305\n",
      "epochs 9613\n",
      "training loss 0.000978639702037356\n",
      "epochs 9614\n",
      "training loss 0.0007564579826669263\n",
      "epochs 9615\n",
      "training loss 0.000683231988449731\n",
      "epochs 9616\n",
      "training loss 0.0006103835902481105\n",
      "epochs 9617\n",
      "training loss 0.0005975523849455272\n",
      "epochs 9618\n",
      "training loss 0.0005721249858251458\n",
      "epochs 9619\n",
      "training loss 0.0005581250089510149\n",
      "testing loss 0.002473176238605924\n",
      "epochs 9620\n",
      "training loss 0.0005434046482711911\n",
      "epochs 9621\n",
      "training loss 0.0005505239379314117\n",
      "epochs 9622\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss 0.0005091784478945086\n",
      "epochs 9623\n",
      "training loss 0.0008011523949206696\n",
      "epochs 9624\n",
      "training loss 0.0017989655459649282\n",
      "epochs 9625\n",
      "training loss 0.0013433968787906708\n",
      "epochs 9626\n",
      "training loss 0.0010403926361502237\n",
      "epochs 9627\n",
      "training loss 0.0010005151361119466\n",
      "epochs 9628\n",
      "training loss 0.0007664733937882046\n",
      "epochs 9629\n",
      "training loss 0.0007608867812821059\n",
      "testing loss 0.0025345747991124866\n",
      "epochs 9630\n",
      "training loss 0.0006724049219200642\n",
      "epochs 9631\n",
      "training loss 0.0005466545580625874\n",
      "epochs 9632\n",
      "training loss 0.0005069938030958708\n",
      "epochs 9633\n",
      "training loss 0.000527975193462278\n",
      "epochs 9634\n",
      "training loss 0.0008124171838123284\n",
      "epochs 9635\n",
      "training loss 0.0006693732813474833\n",
      "epochs 9636\n",
      "training loss 0.0005423593469138192\n",
      "epochs 9637\n",
      "training loss 0.0004941570632885802\n",
      "epochs 9638\n",
      "training loss 0.0004959216696637652\n",
      "epochs 9639\n",
      "training loss 0.0006638545508278494\n",
      "testing loss 0.0025043261566873084\n",
      "epochs 9640\n",
      "training loss 0.0007170256232827941\n",
      "epochs 9641\n",
      "training loss 0.0006134564322907772\n",
      "epochs 9642\n",
      "training loss 0.0006791607073032634\n",
      "epochs 9643\n",
      "training loss 0.000611448389181505\n",
      "epochs 9644\n",
      "training loss 0.0006418090894334244\n",
      "epochs 9645\n",
      "training loss 0.0006287773510870753\n",
      "epochs 9646\n",
      "training loss 0.0006354576541379088\n",
      "epochs 9647\n",
      "training loss 0.0006396304772661483\n",
      "epochs 9648\n",
      "training loss 0.0006280291086791004\n",
      "epochs 9649\n",
      "training loss 0.0006154969594325293\n",
      "testing loss 0.002460178238808686\n",
      "epochs 9650\n",
      "training loss 0.0006055140997956175\n",
      "epochs 9651\n",
      "training loss 0.0006646479762691472\n",
      "epochs 9652\n",
      "training loss 0.0006028352858000477\n",
      "epochs 9653\n",
      "training loss 0.0006778556520917586\n",
      "epochs 9654\n",
      "training loss 0.0006647254040466175\n",
      "epochs 9655\n",
      "training loss 0.0006112526726447567\n",
      "epochs 9656\n",
      "training loss 0.0006573519181254203\n",
      "epochs 9657\n",
      "training loss 0.0006342978141250055\n",
      "epochs 9658\n",
      "training loss 0.0009150869964259623\n",
      "epochs 9659\n",
      "training loss 0.0013760357376330994\n",
      "testing loss 0.0026872434466747\n",
      "epochs 9660\n",
      "training loss 0.001008739620733774\n",
      "epochs 9661\n",
      "training loss 0.0008985311038668995\n",
      "epochs 9662\n",
      "training loss 0.00073900293956205\n",
      "epochs 9663\n",
      "training loss 0.0006262248022464815\n",
      "epochs 9664\n",
      "training loss 0.0007066764561126807\n",
      "epochs 9665\n",
      "training loss 0.0005819565623359596\n",
      "epochs 9666\n",
      "training loss 0.0008945865918405207\n",
      "epochs 9667\n",
      "training loss 0.0005048763550609905\n",
      "epochs 9668\n",
      "training loss 0.0005315935639395608\n",
      "epochs 9669\n",
      "training loss 0.0005157985428162769\n",
      "testing loss 0.0025788629493603468\n",
      "epochs 9670\n",
      "training loss 0.00048798910353833804\n",
      "epochs 9671\n",
      "training loss 0.00044990380287190224\n",
      "epochs 9672\n",
      "training loss 0.0005001407736324278\n",
      "epochs 9673\n",
      "training loss 0.0005099128920791563\n",
      "epochs 9674\n",
      "training loss 0.0005152575388772974\n",
      "epochs 9675\n",
      "training loss 0.0005011531522767873\n",
      "epochs 9676\n",
      "training loss 0.00046301920968850956\n",
      "epochs 9677\n",
      "training loss 0.0005268984658064711\n",
      "epochs 9678\n",
      "training loss 0.0004786868078728266\n",
      "epochs 9679\n",
      "training loss 0.0009956770481175168\n",
      "testing loss 0.0024853368419394265\n",
      "epochs 9680\n",
      "training loss 0.0005900234816946927\n",
      "epochs 9681\n",
      "training loss 0.000593171713494775\n",
      "epochs 9682\n",
      "training loss 0.0005257038712200049\n",
      "epochs 9683\n",
      "training loss 0.0005345990955454543\n",
      "epochs 9684\n",
      "training loss 0.0004833557753219329\n",
      "epochs 9685\n",
      "training loss 0.0005045361276560302\n",
      "epochs 9686\n",
      "training loss 0.0004857276587734299\n",
      "epochs 9687\n",
      "training loss 0.00047786499721799215\n",
      "epochs 9688\n",
      "training loss 0.0005777650948870066\n",
      "epochs 9689\n",
      "training loss 0.000534767212539396\n",
      "testing loss 0.002591870876659923\n",
      "epochs 9690\n",
      "training loss 0.0005045164632858669\n",
      "epochs 9691\n",
      "training loss 0.0004968969087243097\n",
      "epochs 9692\n",
      "training loss 0.0004577325904436868\n",
      "epochs 9693\n",
      "training loss 0.000559578933705304\n",
      "epochs 9694\n",
      "training loss 0.000473339153914769\n",
      "epochs 9695\n",
      "training loss 0.00048594597784029517\n",
      "epochs 9696\n",
      "training loss 0.0005138969294957557\n",
      "epochs 9697\n",
      "training loss 0.00046740522279791917\n",
      "epochs 9698\n",
      "training loss 0.0005075430614207829\n",
      "epochs 9699\n",
      "training loss 0.00048539612757531774\n",
      "testing loss 0.0025543836705016754\n",
      "epochs 9700\n",
      "training loss 0.0005128044116850036\n",
      "epochs 9701\n",
      "training loss 0.0004813636746982928\n",
      "epochs 9702\n",
      "training loss 0.0004942517634375038\n",
      "epochs 9703\n",
      "training loss 0.0004785880341164847\n",
      "epochs 9704\n",
      "training loss 0.0005124054008232865\n",
      "epochs 9705\n",
      "training loss 0.0005268847541869434\n",
      "epochs 9706\n",
      "training loss 0.0004658776470410459\n",
      "epochs 9707\n",
      "training loss 0.0005445932430897395\n",
      "epochs 9708\n",
      "training loss 0.0004991441186199723\n",
      "epochs 9709\n",
      "training loss 0.0004963227656512808\n",
      "testing loss 0.0025833843631755745\n",
      "epochs 9710\n",
      "training loss 0.0004927518312330287\n",
      "epochs 9711\n",
      "training loss 0.0004960241967969288\n",
      "epochs 9712\n",
      "training loss 0.0005256502919969797\n",
      "epochs 9713\n",
      "training loss 0.000991649360218691\n",
      "epochs 9714\n",
      "training loss 0.0006360166646344842\n",
      "epochs 9715\n",
      "training loss 0.0006545227240186502\n",
      "epochs 9716\n",
      "training loss 0.0005786786896019529\n",
      "epochs 9717\n",
      "training loss 0.0007107886876755233\n",
      "epochs 9718\n",
      "training loss 0.0005697730717590322\n",
      "epochs 9719\n",
      "training loss 0.0005383399849220414\n",
      "testing loss 0.0025947144839595605\n",
      "epochs 9720\n",
      "training loss 0.0005016393962529938\n",
      "epochs 9721\n",
      "training loss 0.00048100885079351274\n",
      "epochs 9722\n",
      "training loss 0.0004805945997419385\n",
      "epochs 9723\n",
      "training loss 0.0004956678655968079\n",
      "epochs 9724\n",
      "training loss 0.00047531582145827133\n",
      "epochs 9725\n",
      "training loss 0.0005252576702222013\n",
      "epochs 9726\n",
      "training loss 0.0005139238508043125\n",
      "epochs 9727\n",
      "training loss 0.0005240093330243365\n",
      "epochs 9728\n",
      "training loss 0.0004651429337565433\n",
      "epochs 9729\n",
      "training loss 0.0005383735018751179\n",
      "testing loss 0.0025032526641714237\n",
      "epochs 9730\n",
      "training loss 0.0005128491508627968\n",
      "epochs 9731\n",
      "training loss 0.0004575837255009\n",
      "epochs 9732\n",
      "training loss 0.0006143363857200216\n",
      "epochs 9733\n",
      "training loss 0.0005278601784416188\n",
      "epochs 9734\n",
      "training loss 0.0005096428688190238\n",
      "epochs 9735\n",
      "training loss 0.0005054555257543848\n",
      "epochs 9736\n",
      "training loss 0.000464210925870759\n",
      "epochs 9737\n",
      "training loss 0.0004834174204194539\n",
      "epochs 9738\n",
      "training loss 0.0004857042625225871\n",
      "epochs 9739\n",
      "training loss 0.0006604016901189914\n",
      "testing loss 0.002744799629283131\n",
      "epochs 9740\n",
      "training loss 0.0006339989299496698\n",
      "epochs 9741\n",
      "training loss 0.0004943896305823761\n",
      "epochs 9742\n",
      "training loss 0.0005044658854727614\n",
      "epochs 9743\n",
      "training loss 0.0004701941820975438\n",
      "epochs 9744\n",
      "training loss 0.0005465272659581653\n",
      "epochs 9745\n",
      "training loss 0.0006602217350756653\n",
      "epochs 9746\n",
      "training loss 0.0007864452655587097\n",
      "epochs 9747\n",
      "training loss 0.0006765199219737213\n",
      "epochs 9748\n",
      "training loss 0.0005073495215232453\n",
      "epochs 9749\n",
      "training loss 0.0006018970188214854\n",
      "testing loss 0.0026467782948892695\n",
      "epochs 9750\n",
      "training loss 0.0004722659913012701\n",
      "epochs 9751\n",
      "training loss 0.0006563408027996103\n",
      "epochs 9752\n",
      "training loss 0.0006697142187443684\n",
      "epochs 9753\n",
      "training loss 0.0005775305109366061\n",
      "epochs 9754\n",
      "training loss 0.0004955318813547662\n",
      "epochs 9755\n",
      "training loss 0.0005647135215282786\n",
      "epochs 9756\n",
      "training loss 0.0004857192366202801\n",
      "epochs 9757\n",
      "training loss 0.000544675080760985\n",
      "epochs 9758\n",
      "training loss 0.0005273530248228438\n",
      "epochs 9759\n",
      "training loss 0.0005522906469920011\n",
      "testing loss 0.002436190551305388\n",
      "epochs 9760\n",
      "training loss 0.0005054019858967229\n",
      "epochs 9761\n",
      "training loss 0.0004756654501966226\n",
      "epochs 9762\n",
      "training loss 0.0005815679647628569\n",
      "epochs 9763\n",
      "training loss 0.0005496115829600276\n",
      "epochs 9764\n",
      "training loss 0.0005209343142097668\n",
      "epochs 9765\n",
      "training loss 0.0005639245599864962\n",
      "epochs 9766\n",
      "training loss 0.0004938895223021089\n",
      "epochs 9767\n",
      "training loss 0.0005122420795036814\n",
      "epochs 9768\n",
      "training loss 0.0005677474001323447\n",
      "epochs 9769\n",
      "training loss 0.0006823526668124535\n",
      "testing loss 0.0025612880824239436\n",
      "epochs 9770\n",
      "training loss 0.000823297084940422\n",
      "epochs 9771\n",
      "training loss 0.0006210638235300484\n",
      "epochs 9772\n",
      "training loss 0.0004892371507152054\n",
      "epochs 9773\n",
      "training loss 0.0005099763761583778\n",
      "epochs 9774\n",
      "training loss 0.0004600561054520405\n",
      "epochs 9775\n",
      "training loss 0.00046748307855208165\n",
      "epochs 9776\n",
      "training loss 0.00046474685835670455\n",
      "epochs 9777\n",
      "training loss 0.0004909560242246717\n",
      "epochs 9778\n",
      "training loss 0.000457455657589204\n",
      "epochs 9779\n",
      "training loss 0.0004941284632020825\n",
      "testing loss 0.0026165016370343296\n",
      "epochs 9780\n",
      "training loss 0.0005352992174678446\n",
      "epochs 9781\n",
      "training loss 0.00041564055172674144\n",
      "epochs 9782\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss 0.0004608264077673482\n",
      "epochs 9783\n",
      "training loss 0.0004944880904331181\n",
      "epochs 9784\n",
      "training loss 0.00050618294627359\n",
      "epochs 9785\n",
      "training loss 0.0005669162715633051\n",
      "epochs 9786\n",
      "training loss 0.0007830458939306178\n",
      "epochs 9787\n",
      "training loss 0.0004894049243458708\n",
      "epochs 9788\n",
      "training loss 0.0006143779440879919\n",
      "epochs 9789\n",
      "training loss 0.0005031691905355936\n",
      "testing loss 0.002738546653145409\n",
      "epochs 9790\n",
      "training loss 0.0004690319633551542\n",
      "epochs 9791\n",
      "training loss 0.00048783281260724874\n",
      "epochs 9792\n",
      "training loss 0.00047332414575940206\n",
      "epochs 9793\n",
      "training loss 0.0004501903553827352\n",
      "epochs 9794\n",
      "training loss 0.00048210624955547833\n",
      "epochs 9795\n",
      "training loss 0.00048022731400157204\n",
      "epochs 9796\n",
      "training loss 0.0004888394473143217\n",
      "epochs 9797\n",
      "training loss 0.000491429577382723\n",
      "epochs 9798\n",
      "training loss 0.0004918981021684863\n",
      "epochs 9799\n",
      "training loss 0.0004645999601340108\n",
      "testing loss 0.0025440227803410894\n",
      "epochs 9800\n",
      "training loss 0.0004993435209489634\n",
      "epochs 9801\n",
      "training loss 0.0005191415586363026\n",
      "epochs 9802\n",
      "training loss 0.0004994618364236117\n",
      "epochs 9803\n",
      "training loss 0.0005112540578019542\n",
      "epochs 9804\n",
      "training loss 0.0004540967944681101\n",
      "epochs 9805\n",
      "training loss 0.0004823245038243016\n",
      "epochs 9806\n",
      "training loss 0.00048235968111109804\n",
      "epochs 9807\n",
      "training loss 0.0004558943204601553\n",
      "epochs 9808\n",
      "training loss 0.0004673404978251362\n",
      "epochs 9809\n",
      "training loss 0.0005468861802338162\n",
      "testing loss 0.002577039735979592\n",
      "epochs 9810\n",
      "training loss 0.00044421584618392493\n",
      "epochs 9811\n",
      "training loss 0.0004980781728275811\n",
      "epochs 9812\n",
      "training loss 0.00047839468365922953\n",
      "epochs 9813\n",
      "training loss 0.0004831082147785312\n",
      "epochs 9814\n",
      "training loss 0.0004867750381354503\n",
      "epochs 9815\n",
      "training loss 0.0004995153593851287\n",
      "epochs 9816\n",
      "training loss 0.0004587929621890844\n",
      "epochs 9817\n",
      "training loss 0.0005009806424179072\n",
      "epochs 9818\n",
      "training loss 0.0004886861300604747\n",
      "epochs 9819\n",
      "training loss 0.0005229860140820315\n",
      "testing loss 0.002685723751981525\n",
      "epochs 9820\n",
      "training loss 0.0004704827213649975\n",
      "epochs 9821\n",
      "training loss 0.0004958466016407914\n",
      "epochs 9822\n",
      "training loss 0.00047450005205979396\n",
      "epochs 9823\n",
      "training loss 0.00046328038281880004\n",
      "epochs 9824\n",
      "training loss 0.00048279770402100483\n",
      "epochs 9825\n",
      "training loss 0.00044562504533925986\n",
      "epochs 9826\n",
      "training loss 0.0005109684772175202\n",
      "epochs 9827\n",
      "training loss 0.0004983082853150086\n",
      "epochs 9828\n",
      "training loss 0.0004907146614702351\n",
      "epochs 9829\n",
      "training loss 0.0004802288848122633\n",
      "testing loss 0.002607738867514364\n",
      "epochs 9830\n",
      "training loss 0.0004916197834762895\n",
      "epochs 9831\n",
      "training loss 0.0004883551057909353\n",
      "epochs 9832\n",
      "training loss 0.0005052863926032988\n",
      "epochs 9833\n",
      "training loss 0.0005398295959705447\n",
      "epochs 9834\n",
      "training loss 0.0004591074719367617\n",
      "epochs 9835\n",
      "training loss 0.0005246899850591507\n",
      "epochs 9836\n",
      "training loss 0.0005073376316796581\n",
      "epochs 9837\n",
      "training loss 0.0004665965832186733\n",
      "epochs 9838\n",
      "training loss 0.0004580069157188068\n",
      "epochs 9839\n",
      "training loss 0.0004706683514783397\n",
      "testing loss 0.0026209820904075465\n",
      "epochs 9840\n",
      "training loss 0.0004816588737448468\n",
      "epochs 9841\n",
      "training loss 0.0004600613947857262\n",
      "epochs 9842\n",
      "training loss 0.0004780439839618405\n",
      "epochs 9843\n",
      "training loss 0.000490455210950554\n",
      "epochs 9844\n",
      "training loss 0.0004868805234208646\n",
      "epochs 9845\n",
      "training loss 0.0004891040638523703\n",
      "epochs 9846\n",
      "training loss 0.0004315335207298896\n",
      "epochs 9847\n",
      "training loss 0.0005504896173056917\n",
      "epochs 9848\n",
      "training loss 0.0005074008518782526\n",
      "epochs 9849\n",
      "training loss 0.0004779631745669634\n",
      "testing loss 0.0026208601307028123\n",
      "epochs 9850\n",
      "training loss 0.0005194614713022196\n",
      "epochs 9851\n",
      "training loss 0.0004882994679805588\n",
      "epochs 9852\n",
      "training loss 0.000510282354016426\n",
      "epochs 9853\n",
      "training loss 0.000509182759463337\n",
      "epochs 9854\n",
      "training loss 0.0005104884642033377\n",
      "epochs 9855\n",
      "training loss 0.0005030334652203353\n",
      "epochs 9856\n",
      "training loss 0.0004514382965385059\n",
      "epochs 9857\n",
      "training loss 0.0008422785792354704\n",
      "epochs 9858\n",
      "training loss 0.0006208881662113275\n",
      "epochs 9859\n",
      "training loss 0.0005401679227361456\n",
      "testing loss 0.0025683453575714578\n",
      "epochs 9860\n",
      "training loss 0.0005166275377383902\n",
      "epochs 9861\n",
      "training loss 0.0005061584448733432\n",
      "epochs 9862\n",
      "training loss 0.00048610011177062476\n",
      "epochs 9863\n",
      "training loss 0.00046273041184811844\n",
      "epochs 9864\n",
      "training loss 0.00047511175318371994\n",
      "epochs 9865\n",
      "training loss 0.00044406869734982794\n",
      "epochs 9866\n",
      "training loss 0.0005467026723558677\n",
      "epochs 9867\n",
      "training loss 0.0004748331303166871\n",
      "epochs 9868\n",
      "training loss 0.0004749539561072891\n",
      "epochs 9869\n",
      "training loss 0.0005019939180175522\n",
      "testing loss 0.0025940410060484413\n",
      "epochs 9870\n",
      "training loss 0.0004344409351848564\n",
      "epochs 9871\n",
      "training loss 0.0004711541341721026\n",
      "epochs 9872\n",
      "training loss 0.0004663797830798349\n",
      "epochs 9873\n",
      "training loss 0.00048657906744883916\n",
      "epochs 9874\n",
      "training loss 0.0004856360216036235\n",
      "epochs 9875\n",
      "training loss 0.000481893623118235\n",
      "epochs 9876\n",
      "training loss 0.0005264740095277088\n",
      "epochs 9877\n",
      "training loss 0.00042329064275259805\n",
      "epochs 9878\n",
      "training loss 0.00046471310888259956\n",
      "epochs 9879\n",
      "training loss 0.0004750743353442858\n",
      "testing loss 0.002592885056394978\n",
      "epochs 9880\n",
      "training loss 0.0005014317528957552\n",
      "epochs 9881\n",
      "training loss 0.0005242112635385024\n",
      "epochs 9882\n",
      "training loss 0.00048224221110714763\n",
      "epochs 9883\n",
      "training loss 0.0004852557765644774\n",
      "epochs 9884\n",
      "training loss 0.00048273155508360524\n",
      "epochs 9885\n",
      "training loss 0.0004621256230166182\n",
      "epochs 9886\n",
      "training loss 0.000473344167337065\n",
      "epochs 9887\n",
      "training loss 0.0005019913889477624\n",
      "epochs 9888\n",
      "training loss 0.0004818467714358121\n",
      "epochs 9889\n",
      "training loss 0.0004595322786999504\n",
      "testing loss 0.0026409770283643288\n",
      "epochs 9890\n",
      "training loss 0.00048469493376504416\n",
      "epochs 9891\n",
      "training loss 0.0004853241388526063\n",
      "epochs 9892\n",
      "training loss 0.0005033263476373695\n",
      "epochs 9893\n",
      "training loss 0.0005136106465713158\n",
      "epochs 9894\n",
      "training loss 0.0006307696276606205\n",
      "epochs 9895\n",
      "training loss 0.0005953330380309905\n",
      "epochs 9896\n",
      "training loss 0.0005379097484367812\n",
      "epochs 9897\n",
      "training loss 0.0004937605040043869\n",
      "epochs 9898\n",
      "training loss 0.0005622083933986469\n",
      "epochs 9899\n",
      "training loss 0.00047960469615468784\n",
      "testing loss 0.0026771967094523686\n",
      "epochs 9900\n",
      "training loss 0.0005729470629702211\n",
      "epochs 9901\n",
      "training loss 0.000548715785193175\n",
      "epochs 9902\n",
      "training loss 0.0004935727122018261\n",
      "epochs 9903\n",
      "training loss 0.0005271242192654806\n",
      "epochs 9904\n",
      "training loss 0.0005102819483762601\n",
      "epochs 9905\n",
      "training loss 0.0005615039195247577\n",
      "epochs 9906\n",
      "training loss 0.0005041256624024141\n",
      "epochs 9907\n",
      "training loss 0.0005443193293817052\n",
      "epochs 9908\n",
      "training loss 0.0005437614448229841\n",
      "epochs 9909\n",
      "training loss 0.0005404955873709585\n",
      "testing loss 0.002622724113596194\n",
      "epochs 9910\n",
      "training loss 0.0005250320313208224\n",
      "epochs 9911\n",
      "training loss 0.0005256212268684252\n",
      "epochs 9912\n",
      "training loss 0.0005484141438943264\n",
      "epochs 9913\n",
      "training loss 0.000525666004482736\n",
      "epochs 9914\n",
      "training loss 0.00296969286245393\n",
      "epochs 9915\n",
      "training loss 0.0007639402491082989\n",
      "epochs 9916\n",
      "training loss 0.0006034108805261399\n",
      "epochs 9917\n",
      "training loss 0.0005865845768033077\n",
      "epochs 9918\n",
      "training loss 0.0006380920962035645\n",
      "epochs 9919\n",
      "training loss 0.0005283104954198948\n",
      "testing loss 0.002709332083645838\n",
      "epochs 9920\n",
      "training loss 0.0005094832443493477\n",
      "epochs 9921\n",
      "training loss 0.00046966281882451853\n",
      "epochs 9922\n",
      "training loss 0.0005248373712796582\n",
      "epochs 9923\n",
      "training loss 0.0005617843180792944\n",
      "epochs 9924\n",
      "training loss 0.0005980404857284245\n",
      "epochs 9925\n",
      "training loss 0.0007235770196743072\n",
      "epochs 9926\n",
      "training loss 0.0006283851717966736\n",
      "epochs 9927\n",
      "training loss 0.0006643828783236659\n",
      "epochs 9928\n",
      "training loss 0.000585294207128113\n",
      "epochs 9929\n",
      "training loss 0.0005514871706888164\n",
      "testing loss 0.0025751521911617395\n",
      "epochs 9930\n",
      "training loss 0.0006324086485304629\n",
      "epochs 9931\n",
      "training loss 0.0004958350917835377\n",
      "epochs 9932\n",
      "training loss 0.000537650728901483\n",
      "epochs 9933\n",
      "training loss 0.00047402484374302003\n",
      "epochs 9934\n",
      "training loss 0.0005260531268720189\n",
      "epochs 9935\n",
      "training loss 0.0005612663112086807\n",
      "epochs 9936\n",
      "training loss 0.0005342051329156299\n",
      "epochs 9937\n",
      "training loss 0.000458420767587904\n",
      "epochs 9938\n",
      "training loss 0.000576887601748743\n",
      "epochs 9939\n",
      "training loss 0.0005334756914936686\n",
      "testing loss 0.0025663481233063556\n",
      "epochs 9940\n",
      "training loss 0.0005132431531675997\n",
      "epochs 9941\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss 0.000501849946720203\n",
      "epochs 9942\n",
      "training loss 0.0005140803356872203\n",
      "epochs 9943\n",
      "training loss 0.0004909597197476786\n",
      "epochs 9944\n",
      "training loss 0.0005103889626743113\n",
      "epochs 9945\n",
      "training loss 0.0005579652291871919\n",
      "epochs 9946\n",
      "training loss 0.00048313394937618976\n",
      "epochs 9947\n",
      "training loss 0.0005009540389957172\n",
      "epochs 9948\n",
      "training loss 0.0005157894472057979\n",
      "epochs 9949\n",
      "training loss 0.0004913764404671515\n",
      "testing loss 0.002558692625528928\n",
      "epochs 9950\n",
      "training loss 0.0005374148676556175\n",
      "epochs 9951\n",
      "training loss 0.0005288351526042293\n",
      "epochs 9952\n",
      "training loss 0.000534932243908079\n",
      "epochs 9953\n",
      "training loss 0.0005169448302634128\n",
      "epochs 9954\n",
      "training loss 0.0005474887938857203\n",
      "epochs 9955\n",
      "training loss 0.0005769838954871917\n",
      "epochs 9956\n",
      "training loss 0.0005243891453098698\n",
      "epochs 9957\n",
      "training loss 0.0005728045891932181\n",
      "epochs 9958\n",
      "training loss 0.0004889031314492044\n",
      "epochs 9959\n",
      "training loss 0.0004589569743487016\n",
      "testing loss 0.0026178985494783426\n",
      "epochs 9960\n",
      "training loss 0.0005339583385371996\n",
      "epochs 9961\n",
      "training loss 0.0004668067600687762\n",
      "epochs 9962\n",
      "training loss 0.0005418954173044237\n",
      "epochs 9963\n",
      "training loss 0.0005193321884604098\n",
      "epochs 9964\n",
      "training loss 0.0005062817657202918\n",
      "epochs 9965\n",
      "training loss 0.0005142557897656663\n",
      "epochs 9966\n",
      "training loss 0.00048332708168740877\n",
      "epochs 9967\n",
      "training loss 0.0005254892253396201\n",
      "epochs 9968\n",
      "training loss 0.0004619406413702339\n",
      "epochs 9969\n",
      "training loss 0.0005438005946941764\n",
      "testing loss 0.0025595203421825002\n",
      "epochs 9970\n",
      "training loss 0.0005071438590841691\n",
      "epochs 9971\n",
      "training loss 0.0005300031582319594\n",
      "epochs 9972\n",
      "training loss 0.0005239230024382065\n",
      "epochs 9973\n",
      "training loss 0.00048314298337324036\n",
      "epochs 9974\n",
      "training loss 0.0004921444069125653\n",
      "epochs 9975\n",
      "training loss 0.0005098615802126005\n",
      "epochs 9976\n",
      "training loss 0.0005514964564472697\n",
      "epochs 9977\n",
      "training loss 0.0005072801619645004\n",
      "epochs 9978\n",
      "training loss 0.0005237025451686482\n",
      "epochs 9979\n",
      "training loss 0.0005171311226879363\n",
      "testing loss 0.002644266939807868\n",
      "epochs 9980\n",
      "training loss 0.0005098792655222927\n",
      "epochs 9981\n",
      "training loss 0.000565795637373487\n",
      "epochs 9982\n",
      "training loss 0.0005530769990967292\n",
      "epochs 9983\n",
      "training loss 0.0008654204576904673\n",
      "epochs 9984\n",
      "training loss 0.0010905127794910675\n",
      "epochs 9985\n",
      "training loss 0.0006198509186534579\n",
      "epochs 9986\n",
      "training loss 0.0005498383750896307\n",
      "epochs 9987\n",
      "training loss 0.0004753429780743937\n",
      "epochs 9988\n",
      "training loss 0.0005278963799355552\n",
      "epochs 9989\n",
      "training loss 0.00047881352139486844\n",
      "testing loss 0.002559054970282216\n",
      "epochs 9990\n",
      "training loss 0.0006245046062819592\n",
      "epochs 9991\n",
      "training loss 0.0005349703679798244\n",
      "epochs 9992\n",
      "training loss 0.0004547147999770973\n",
      "epochs 9993\n",
      "training loss 0.0004919604996309862\n",
      "epochs 9994\n",
      "training loss 0.000489657514367329\n",
      "epochs 9995\n",
      "training loss 0.0005237097708359049\n",
      "epochs 9996\n",
      "training loss 0.0005513242445709212\n",
      "epochs 9997\n",
      "training loss 0.0010881421026543044\n",
      "epochs 9998\n",
      "training loss 0.0017598709813389916\n",
      "epochs 9999\n",
      "training loss 0.0016159166201190475\n",
      "testing loss 0.0026609988912860765\n"
     ]
    }
   ],
   "source": [
    "train_losses = []\n",
    "eval_losses = []\n",
    "accs = []\n",
    "for t in range(10000):\n",
    "    print('epochs', t)\n",
    "    train_loss = train_func(model, train_loader)\n",
    "    if (t+1) % 10 == 0:\n",
    "        eval_loss = eval_func(model, eval_loader)\n",
    "        #acc = accuracy(model)\n",
    "        \n",
    "        eval_losses.append(eval_loss)\n",
    "        train_losses.append(train_loss)\n",
    "        \n",
    "        #accs.append(acc)\n",
    "        #print('accuracy: ',acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fca59f8e748>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_losses, label='Training loss')\n",
    "plt.plot(eval_losses, label='Validation loss')\n",
    "plt.legend(frameon=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.eval()\n",
    "label = y_train.cpu()\n",
    "label = y_scaler.inverse_transform(label)\n",
    "with torch.no_grad():\n",
    "    pred = model(X_train)\n",
    "    pred = pred.cpu().numpy()\n",
    "    pred = y_scaler.inverse_transform(pred)\n",
    "    plot(label, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = test_func(model, X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>building_id</th>\n",
       "      <th>total_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>X5gsdTWGS3W7JJQB</td>\n",
       "      <td>1.398167e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BTshNOJyKHnT2YIT</td>\n",
       "      <td>5.928512e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dhdymr0lV8N5kZOT</td>\n",
       "      <td>1.154590e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>VEwyGGMcD56w5BOc</td>\n",
       "      <td>1.611052e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>wmUeMoJZfsqaSX9b</td>\n",
       "      <td>5.928512e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>EtBjGAHmHCe9t7TZ</td>\n",
       "      <td>5.928512e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>hPNH34vmaZtvBtqc</td>\n",
       "      <td>1.299164e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>wXjeI38bYDMJJwZC</td>\n",
       "      <td>4.951337e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>fxZSGX6aPAFKU8W4</td>\n",
       "      <td>5.928512e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ewr0Fx6ign87OwaV</td>\n",
       "      <td>1.045293e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>gHKurnEP4AowzsLg</td>\n",
       "      <td>5.928512e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>PmLfTgY2FElLrTl0</td>\n",
       "      <td>1.090820e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>eM2NppIOwzW0o8iy</td>\n",
       "      <td>9.478340e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>dxxwNun97NH4WTrZ</td>\n",
       "      <td>7.260562e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>jykBfhh3vdeFUi3H</td>\n",
       "      <td>5.928512e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>NlXbvdFfmJZf3L18</td>\n",
       "      <td>2.666865e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>D7jaFWHCzSqLBwdt</td>\n",
       "      <td>5.928512e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>L10dBBdqGmemweSl</td>\n",
       "      <td>6.564394e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>OgB0AdiPKlElakKN</td>\n",
       "      <td>5.928512e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>StiWNN1GQrpPBOYt</td>\n",
       "      <td>2.732328e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>a016eMAVQKnfwMnt</td>\n",
       "      <td>2.577678e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>gsCFcQHnOH3AKMcZ</td>\n",
       "      <td>3.748389e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>IbNsDXfsPwSuFpow</td>\n",
       "      <td>9.269337e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>EgAVWOVxD1Jy5YkE</td>\n",
       "      <td>5.928512e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>BrKghvR76XdbQPnx</td>\n",
       "      <td>1.952257e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>a7fxkXTnUGWHUmKG</td>\n",
       "      <td>1.556509e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>WgzXa170DfpzpURE</td>\n",
       "      <td>6.676816e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>JPWqZbLq0VNC0yKI</td>\n",
       "      <td>1.104522e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>JQgTtbVstqFZwEK1</td>\n",
       "      <td>5.928512e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>bCSDbEthlS3nSIor</td>\n",
       "      <td>5.928512e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9970</th>\n",
       "      <td>QL412tWF5RDIX7IO</td>\n",
       "      <td>5.928512e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9971</th>\n",
       "      <td>d3c2ceGtckONZzsr</td>\n",
       "      <td>7.737816e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9972</th>\n",
       "      <td>P1j8YRbxDAovumaI</td>\n",
       "      <td>7.091271e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9973</th>\n",
       "      <td>IxcBhEoFLcrI9TPr</td>\n",
       "      <td>5.928512e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9974</th>\n",
       "      <td>rKiV0KDbAl2myBQI</td>\n",
       "      <td>5.928512e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9975</th>\n",
       "      <td>GSdIXmKr0g5jQQcF</td>\n",
       "      <td>5.928512e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9976</th>\n",
       "      <td>Am6Wcg3TO64qvzd8</td>\n",
       "      <td>2.757750e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9977</th>\n",
       "      <td>RZqACAhkL4Tgw4Jr</td>\n",
       "      <td>9.791903e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9978</th>\n",
       "      <td>u7NKZfWoMUlZy9rJ</td>\n",
       "      <td>4.084878e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9979</th>\n",
       "      <td>C1BqV4MWH15rjAgz</td>\n",
       "      <td>8.119566e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9980</th>\n",
       "      <td>wz8A2UbwsgR0lXGJ</td>\n",
       "      <td>5.928512e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9981</th>\n",
       "      <td>MGJ8ABBTmC2yIaSm</td>\n",
       "      <td>9.435316e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9982</th>\n",
       "      <td>MjHL2HP1PGIp8aBt</td>\n",
       "      <td>5.928512e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9983</th>\n",
       "      <td>FMz7nnURFn85LaGt</td>\n",
       "      <td>6.488028e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9984</th>\n",
       "      <td>kydULx0r0G7OklRD</td>\n",
       "      <td>5.062612e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9985</th>\n",
       "      <td>nVNYRuk2fRbtlV00</td>\n",
       "      <td>3.259674e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9986</th>\n",
       "      <td>F8SGEOGPxrPfiRv2</td>\n",
       "      <td>5.928512e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9987</th>\n",
       "      <td>w7VMfiMvRb765ejK</td>\n",
       "      <td>3.408445e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9988</th>\n",
       "      <td>lgZWdUKliWt2y5sM</td>\n",
       "      <td>1.303264e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9989</th>\n",
       "      <td>TER8YrP9mw7UwWwr</td>\n",
       "      <td>3.070062e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9990</th>\n",
       "      <td>TXHk3oUpVsm5Cmag</td>\n",
       "      <td>2.633998e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9991</th>\n",
       "      <td>JtgDm9aQcGE9zELB</td>\n",
       "      <td>5.928512e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9992</th>\n",
       "      <td>wTQmcqbN0OCuSF1t</td>\n",
       "      <td>1.502585e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9993</th>\n",
       "      <td>WgsI1cBtzSfiWA1j</td>\n",
       "      <td>4.220515e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9994</th>\n",
       "      <td>qNgt1ajb5uVMKbqm</td>\n",
       "      <td>2.238283e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>UEeCDaAJzPwdKKKA</td>\n",
       "      <td>1.470932e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>i0fgbPaQsDWs7Q87</td>\n",
       "      <td>2.379723e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>YunNwAhcqkf6YclI</td>\n",
       "      <td>5.928512e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>A2NotxtRY9MYoWMl</td>\n",
       "      <td>2.930944e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>kKvgBXiA50gRmQhP</td>\n",
       "      <td>2.560456e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           building_id   total_price\n",
       "0     X5gsdTWGS3W7JJQB  1.398167e+07\n",
       "1     BTshNOJyKHnT2YIT  5.928512e+05\n",
       "2     dhdymr0lV8N5kZOT  1.154590e+07\n",
       "3     VEwyGGMcD56w5BOc  1.611052e+06\n",
       "4     wmUeMoJZfsqaSX9b  5.928512e+05\n",
       "5     EtBjGAHmHCe9t7TZ  5.928512e+05\n",
       "6     hPNH34vmaZtvBtqc  1.299164e+07\n",
       "7     wXjeI38bYDMJJwZC  4.951337e+06\n",
       "8     fxZSGX6aPAFKU8W4  5.928512e+05\n",
       "9     ewr0Fx6ign87OwaV  1.045293e+06\n",
       "10    gHKurnEP4AowzsLg  5.928512e+05\n",
       "11    PmLfTgY2FElLrTl0  1.090820e+07\n",
       "12    eM2NppIOwzW0o8iy  9.478340e+06\n",
       "13    dxxwNun97NH4WTrZ  7.260562e+05\n",
       "14    jykBfhh3vdeFUi3H  5.928512e+05\n",
       "15    NlXbvdFfmJZf3L18  2.666865e+07\n",
       "16    D7jaFWHCzSqLBwdt  5.928512e+05\n",
       "17    L10dBBdqGmemweSl  6.564394e+06\n",
       "18    OgB0AdiPKlElakKN  5.928512e+05\n",
       "19    StiWNN1GQrpPBOYt  2.732328e+06\n",
       "20    a016eMAVQKnfwMnt  2.577678e+07\n",
       "21    gsCFcQHnOH3AKMcZ  3.748389e+06\n",
       "22    IbNsDXfsPwSuFpow  9.269337e+06\n",
       "23    EgAVWOVxD1Jy5YkE  5.928512e+05\n",
       "24    BrKghvR76XdbQPnx  1.952257e+06\n",
       "25    a7fxkXTnUGWHUmKG  1.556509e+07\n",
       "26    WgzXa170DfpzpURE  6.676816e+06\n",
       "27    JPWqZbLq0VNC0yKI  1.104522e+07\n",
       "28    JQgTtbVstqFZwEK1  5.928512e+05\n",
       "29    bCSDbEthlS3nSIor  5.928512e+05\n",
       "...                ...           ...\n",
       "9970  QL412tWF5RDIX7IO  5.928512e+05\n",
       "9971  d3c2ceGtckONZzsr  7.737816e+06\n",
       "9972  P1j8YRbxDAovumaI  7.091271e+06\n",
       "9973  IxcBhEoFLcrI9TPr  5.928512e+05\n",
       "9974  rKiV0KDbAl2myBQI  5.928512e+05\n",
       "9975  GSdIXmKr0g5jQQcF  5.928512e+05\n",
       "9976  Am6Wcg3TO64qvzd8  2.757750e+07\n",
       "9977  RZqACAhkL4Tgw4Jr  9.791903e+07\n",
       "9978  u7NKZfWoMUlZy9rJ  4.084878e+06\n",
       "9979  C1BqV4MWH15rjAgz  8.119566e+06\n",
       "9980  wz8A2UbwsgR0lXGJ  5.928512e+05\n",
       "9981  MGJ8ABBTmC2yIaSm  9.435316e+06\n",
       "9982  MjHL2HP1PGIp8aBt  5.928512e+05\n",
       "9983  FMz7nnURFn85LaGt  6.488028e+07\n",
       "9984  kydULx0r0G7OklRD  5.062612e+06\n",
       "9985  nVNYRuk2fRbtlV00  3.259674e+07\n",
       "9986  F8SGEOGPxrPfiRv2  5.928512e+05\n",
       "9987  w7VMfiMvRb765ejK  3.408445e+07\n",
       "9988  lgZWdUKliWt2y5sM  1.303264e+07\n",
       "9989  TER8YrP9mw7UwWwr  3.070062e+06\n",
       "9990  TXHk3oUpVsm5Cmag  2.633998e+06\n",
       "9991  JtgDm9aQcGE9zELB  5.928512e+05\n",
       "9992  wTQmcqbN0OCuSF1t  1.502585e+07\n",
       "9993  WgsI1cBtzSfiWA1j  4.220515e+07\n",
       "9994  qNgt1ajb5uVMKbqm  2.238283e+06\n",
       "9995  UEeCDaAJzPwdKKKA  1.470932e+06\n",
       "9996  i0fgbPaQsDWs7Q87  2.379723e+07\n",
       "9997  YunNwAhcqkf6YclI  5.928512e+05\n",
       "9998  A2NotxtRY9MYoWMl  2.930944e+06\n",
       "9999  kKvgBXiA50gRmQhP  2.560456e+06\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.read_csv('./dataset-0510/submit_test.csv')\n",
    "submission['total_price'] = pred\n",
    "submission.to_csv('submission/DNN2_result.csv', index=False)\n",
    "submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f8222768b70>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_losses, label='Training loss')\n",
    "plt.legend(frameon=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f8222aec048>]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(eval_losses, label='Validation loss')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## overfitting2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f3d934b4b38>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_losses, label='Training loss')\n",
    "plt.legend(frameon=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f3d8cfab080>]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(eval_losses, label='Validation loss')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f3b1933e668>]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(pred, label='pred')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Batch size use 128 or 32 , learning rate use 0.003 which find loss will stock in 0.6\n",
    "\n",
    "Result 1 DNN 233->256->128->1, lr=0.001, batch_size=128, predict score : 13\n",
    "change: \n",
    "- replacing Standard to MinMax \n",
    "- adding DropOut 0.3 layer\n",
    "- batch size change to 512\n",
    "\n",
    "Result 2 lr=0.001, batch_size=64, DNN 233->256->128->64->1\n",
    "after 1k loss : 0.00011785521522113447, can't decrease...\n",
    "- x_scale false\n",
    "- y_scale true\n",
    "\n",
    "Result 3 lr=0.001 batch_size=128 DNN 211->256->512->512->256->128->1\n",
    "after 1w loss : 0.0003, test loss : 0.0007 score: 16000\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "why output is negative?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
